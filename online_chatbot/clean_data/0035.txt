arXiv:1603.08314v1 [cs.CR] 28 Mar 2016 Active Cyber Defense Dynamics Exhibiting Rich Phenomena Ren Zheng Fudan University zhrkevin@gmail.com Wenlian Lu Fudan University wenlian@fudan.edu.cn Shouhuai Xu UT San Antonio shxu@cs.utsa.edu ABSTRACT The Internet is a man-made complex system under constant attacks (e.g., Advanced Persistent Threats and malwares). It is therefore important to understand the phenomena that can be induced by the interaction between cyber attacks and cyber defenses. In this paper, we explore the rich phenomena that can be exhibited when the de- fender employs active defense to combat cyber attacks. To the best of our knowledge, this is the ï¬rst study that shows that active cyber defense dynamics (or more generally, cybersecurity dynamics) can exhibit the bifurcation and chaos phenomena. This has profound implications for cyber security measurement and prediction: (i) it is infeasible (or even impossible) to accurately measure and predict cyber security under certain circumstances; (ii) the defender must manipulate the dynamics to avoid such unmanageable situations in real-life defense operations. Categories and Subject Descriptors D.4.6 [Security and Protection] General Terms Security, Theory Keywords Active cyber defense, active cyber defense dynamics, cyber attack- defense dynamics, cybersecurity dynamics, cyber security models 1. INTRODUCTION Malicious attacks in cyberspace will remain to be a big problem for the many years to come. This is fundamentally caused by the complexity of the Internet and computer systems (e.g., we cannot assure that a large software system has no security vulnerabilities). It is therefore important to understand and characterize the phe- nomena that can be exhibited at the global level of a cyber system, ranging from an enterprise network to the entire cyberspace. The emerging framework of Cybersecurity Dynamics [34, 35, 7, 4] of- fers a systematic approach for understanding, characterizing, and quantifying the phenomena as well as cyber security in general. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for proï¬t or commercial advantage and that copies bear this notice and the full citation on the ï¬rst page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior speciï¬c permission and/or a fee. Request permissions from Permissions@acm.org. HotSoS â€™15, April 21 - 22, 2015, Urbana, IL, USA Copyright 2015 ACM 978-1-4503-3376-4/15/04...$15.00 http://dx.doi.org/10.1145/2746194.2746196. The current generation of cyber defenses is often based on re- active tools that are known to have limited success. For example, infected/compromised computers cannot be cleaned up even by us- ing multiple anti-malware tools together [21]. Moreover, reactive defense has a fundamental limitation, namely that the effect of at- tacks is automatically ampliï¬ed by network connectivity, but the effect of reactive defenses is not. This attack-defense asymmetry had been implied by studies such as [29, 6, 3, 28, 39], but was not explicitly pointed out until [36]. One approach to overcoming the aforementioned attack-defense asymmetry is to adopt active cyber defense, which is to use the same mechanism that is exploited by attackers. More speciï¬cally, active defense aims to spread some â€œwhiteâ€ worms (called defense- ware in this paper) to automatically identify and â€œkillâ€ the mali- cious malwares in compromised/infected computers [2, 1, 30, 26, 16, 18, 14, 31]. In some sense, active cyber defense already takes place in cyberspace because (for example) the malware called Welchia attempts to â€œkill" the malware called Blaster in compromised computers [26, 22], but it may take some years for full-scale ac- tive cyber defenses to arise [18, 27, 32]. The ï¬rst mathematical model for studying the global effectiveness of active cyber defense has been proposed recently [36]. In this paper, we further the study of active cyber defense dynamics from a new perspective. Our contributions. We substantially extend some aspects of the ï¬rst mathematical model of active cyber defense dynamics [36] (to be fair, we should note that [36] offers some perspectives that are not considered in our model as well). The extensions can be char- acterized as follows. First, we accommodate more general attack- power and defense-power functions, meaning that our results are applicable to a broader setting than what is investigated in [36]. Second, we allow the attack network structure to be different from the defense network structure, which are assumed to be identical in [36]. This is important and realistic because the attack-defense interaction structures are often â€œoverlayâ€ networks on top of some physical networks, and as such, the defender and the attacker can use different structures based on their own defense/attack strate- gies. The extended model allows us to explore the rich phenomena that can be exhibited by active cyber defense dynamics. Speciï¬- cally, we show that active cyber defense dynamics can exhibit the bifurcation and chaos phenomena (we call them unmanageable sit- uations in cyber security). To the best of our knowledge, this is the ï¬rst study that shows that bifurcation and chaos are relevant in the cyber security domain. These phenomena indicate limitations on the measurement and prediction of cyber security, and highlight that cyber defenders must manipulate the (active) cyber defense dynamics to avoid such unmanageable situations in real-life cyber defense operations. Disclaimer. The active cyber defense strategy explored in the present paper does not advocate that defenders should retaliate from at- tackers, because it is well known that the attackers, or more pre- cisely the IP addresses that are launching attacks against the vic- tims, could well be victims that are abused by the real attackers as stepping stones. Moreover, defensewares (i.e., â€œwhiteâ€ worms) are meant to clean up the compromised computers, not to compromise the secure computers. Most important of all, the active defense operations should be contained within the networks under the de- fenderâ€™s jurisdiction (e.g., an enterprise network defender may use active defense to clean up the enterprise network but not going be- yond the enterpriseâ€™s perimeter). This can be assured, for example, by making the enterpriseâ€™s computers and ï¬rewalls recognize de- fensewares via digital signatures. This means that the enterprise computers will only run defensewares that are accompanied with digital signatures that can be veriï¬ed by the computersâ€™ hardware via an embedded signature veriï¬cation key, and that the ï¬rewall recognizes and blocks out-bound defensewares. The rest of the paper is organized as follows. In Section 2, we present our active cyber defense dynamics model. In Section 3, we analyze equilibria (or attractors) of active cyber defense dynamics. In Section 4, we explore the transition between attractors. In Sec- tion 5, we investigate the emergence of bifurcation. In Section 6, we explore the chaos phenomenon. We discuss related prior work in Section 7 and conclude the paper in Section 8. The main notations we use are summarized as follows. R, R+, C the sets of real numbers, positive real numbers and complex numbers, respectively â„œ(Ï‰), â„‘(Ï‰) the real and imaginary parts of complex num- ber Ï‰ âˆˆC, respectively In the n Ã— n identity matrix GB, AB GB = (V, EB) is the defense network struc- ture, AB is the adjacency matrix of GB GR, AR GR = (V, ER) is the attack network struc- ture, AR is the adjacency matrix of GR Nv,Gâ€² Nv,Gâ€² = {u âˆˆV â€² : (u, v) âˆˆEâ€²} is the neighbors of v in graph/network Gâ€² = (V â€², Eâ€²) deg(v, Gâ€²) deg(v) = |Nv| is node vâ€™s in-degree in graph/network Gâ€² = (V â€², Eâ€²) DAâ€² DAâ€² = [dvv]nÃ—n is a diagonal matrix corre- sponding to adjacency matrix Aâ€² = [aâ€² vu]nÃ—n, where dvv = Pn u=1 avu is the in-degree of node v in graph Gâ€² corresponding to Aâ€² Î»(M) the set of eigenvalues of matrix M Î»1(M) the eigenvalue of M with the largest real part (or Î»1 when M is clear from the context) Bv(t), Rv(t) the probability that node v âˆˆV is in sate blue (i.e., secure) and state red (i.e., compromised) at time t, respectively âŸ¨Bv(t)âŸ© the average portion of blue nodes at time t â‰¥ 0, namely âŸ¨Bv(t)âŸ©= 1 |V | P vâˆˆV Bv(t) B(t), R(t) B(t) = [B1(t), . . . , Bn(t)], R(t) = [R1(t), . . . , Rn(t)], where n = |V | Bâˆ— the homogeneous equilibrium of B(t) as t â†’ âˆ, namely Bv(t) = Ïƒ âˆ€v âˆˆV as t â†’âˆ f(Â·), g(Â·) f(Â·) : [0, 1] â†’{0}âˆªR+ is the defense-power function, g(Â·) : [0, 1] â†’{0} âˆªR+ is the attack-power function Î¸v,BR(t) the probability that the state of node v changes from blue to red at time t Î¸v,RB(t) the probability that the state of node v changes from red to blue at time t 2. EXTENDED ACTIVE CYBER DEFENSE DYNAMICS MODEL Review of the model in [36]. Suppose attacker and defender in- teract in a cyber system that consists of a ï¬nite node population V = {1, 2, Â· Â· Â· , n}, where each node can abstract/represent a com- puter. At any time t â‰¥0, a node v âˆˆV is in one of two states: blue, meaning that the node is secure but vulnerable to attacks; red, meaning that the node is compromised. For a given cyber system, the attacker spreads computer malwares (e.g., Advanced Persistent Threats) to compromise computers, while the defender spreads defensewares (e.g., â€œwhiteâ€ worms) to detect and clean up (or â€œcure") the compromised computers. Suppose both the mal- wares and the defensewares spread over the same attack-defense network structure, namely a ï¬nite simple graph G = (V, E), where V = {1, 2, Â· Â· Â· , n} is the vertex set mentioned above, and E is the edge set such that (u, v) âˆˆE means (i) a compromised node u can attack a secure node v and (ii) a secure node u can use active defense to detect and clean up a compromised node v. Our extension to the model in [36]. Rather than assuming the at- tacker and defender use the same attack-defense network structure, we consider two network structures: the defense network structure GB = (V, EB) over which defensewares spread, and the attack network structure GR = (V, ER) over which malwares spread. Both network structures are directed or undirected graphs. Specif- ically, (u, v) âˆˆEB means a secure node u can use active defense to â€œcureâ€ a compromised node v, and (u, v) âˆˆER means a com- promised node u can attack a secure node v. We do not make any restrictions on the attack/defense network structures, except that we assume GB and GR are simple graphs with no self-edges.1 (For the purpose of illustrating results, we will use random graphs as con- crete examples though.) Denote by AB = [aB vu]nÃ—n the adjacency matrix of GB where aB vu = 1 if and only if (u, v) âˆˆEB. Denote by AR = [aR vu]nÃ—n the adjacency matrix of GR where aR vu = 1 if and only if (u, v) âˆˆ ER. Note that the representation accommodates both directed and undirected graphs. Denote by Bv(t) and Rv(t) the probability that node v âˆˆV is in state blue (i.e., secure) and state red (i.e., com- promised) at time t, respectively. B (Blue) R (Red) Tv, BR(t) Tv, RB(t) Figure 1: The state transition diagram for a node v âˆˆV . Figure 1 depicts the state transition diagram for individual node v âˆˆV , where Î¸v,RB(t) is the probability that node vâ€™s state changes from red to blue at time t, and Î¸v,BR(t) is the probability that node vâ€™s state changes from blue to red at time t. This leads to the fol- lowing master equation of active cyber defense dynamics: ï£± ï£´ ï£² ï£´ ï£³ dBv(t) dt = Î¸v,RB(t) Â· Rv(t) âˆ’Î¸v,BR(t) Â· Bv(t) dRv(t) dt = Î¸v,BR(t) Â· Bv(t) âˆ’Î¸v,RB(t) Â· Rv(t) (1) In order to specify Î¸v,RB(t), we use the concept of defense- power function f(Â·) : [0, 1] â†’{0} âˆªR+, which abstracts the 1It is possible to accommodate privilege escalation in the present model, by treating a computer as a set of nodes that correspond to different privileges. We leave the details to future investigation. power of the defenseware in detecting and cleaning up compro- mised (red) nodes. In order to specify Î¸v,BR(t), we use the concept of attack-power function g(Â·) : [0, 1] â†’{0}âˆªR+, which abstracts the power of the malware in compromising secure (blue) nodes. It is intuitive that both defense-power and attack-power functions should be dependent on the defense and attack network structures, respectively. Therefore, we have the following general form: Î¸v,RB(t) = f ï£« ï£­ 1 deg(v, GB) X uâˆˆNv,GB Bu(t) ï£¶ ï£¸, Î¸v,BR(t) = g ï£« ï£­ 1 deg(v, GR) X uâˆˆNv,GR Bu(t) ï£¶ ï£¸ where Nv,GB = {u : (u, v) âˆˆEB} is the set of node vâ€™s neigh- bors in graph GB and Nv,GR = {u : (u, v) âˆˆER} is the set of node vâ€™s neighbors in graph GR. For the present characterization study, it is sufï¬cient to require that the defense-power and attack-power functions possess some basic properties. First, we have f(0) = 0 because active defense must be launched from some blue node, and g(1) = 0 because attack must be launched from some red node. Second, we have f(x) > 0 for x âˆˆ(0, 1] because any active defense may succeed, and g(x) > 0 for x âˆˆ[0, 1) because any attack may succeed. Third, the two functions do not have to abide by any speciï¬c re- lation, except that they are differentiable (for the sake of analytic treatment). As a result, the master equation of active cyber defense dynam- ics, namely Eq. (1), becomes: dBv(t) dt = f ï£« ï£­ 1 deg(v, GB) X uâˆˆNv,GB Bu(t) ï£¶ ï£¸Rv(t) âˆ’ g ï£« ï£­ 1 deg(v, GR) X uâˆˆNv,GR Bu(t) ï£¶ ï£¸Bv(t) dRv(t) dt = g ï£« ï£­ 1 deg(v, GR) X uâˆˆNv,GR Bu(t) ï£¶ ï£¸Bv(t) âˆ’ f ï£« ï£­ 1 deg(v, GB) X uâˆˆNv,GB Bu(t) ï£¶ ï£¸Rv(t) Since dBv(t) dt + dRv(t) dt = 0 holds for all t â‰¥0 and all v âˆˆV , Bv(t) + Rv(t) = 1 for all t and all v âˆˆV . Therefore, we only need to consider the following master equation for v âˆˆV : dBv(t) dt = f ï£« ï£­ 1 deg(v, GB) X uâˆˆNv,GB Bu(t) ï£¶ ï£¸ h 1 âˆ’Bv(t) i âˆ’ g ï£« ï£­ 1 deg(v, GR) X uâˆˆNv,GR Bu(t) ï£¶ ï£¸Bv(t). (2) The main research task is to analyze system (2) for all v âˆˆV . Remark. When we investigate speciï¬c attacks and defenses, we need to obtain their concrete attack-power and defense-power func- tions. Similarly, when we investigate speciï¬c cyber systems, we need to obtain the concrete attack and defense network structures. These are important research problems that are orthogonal to the focus of the present paper because our characterization study deals with all possible attack-power and defense-power functions as well as all possible attack and defense network structures. In principle, these functions and structures do exist, although how to obtain them is an excellent problem for future investigation. 3. EQUILIBRIA AND THEIR STABILITY Equilibrium is an important concept for quantifying cyber secu- rity. Suppose Ïƒ is the equilibrium under certain active defense. We can quantify the effectiveness of active defense via the notion of Ïƒ-effectiveness because the dynamics converge to Ïƒ. Moreover, the stability of an equilibrium reï¬‚ects the consequence/effect of per- turbations, which can be caused (for example) by manipulations to the initial global state (e.g., the defender manually cleans up some compromised computers before launching active defense for more effectiveness â€” this may sound counterintuitive, but it actu- ally shows the value of rigorous characterization study because the defender would not know this tactics otherwise). We consider a class of equilibria of Eq. (2), namely homoge- neous equilibria [Bâˆ— 1, Â· Â· Â· , Bâˆ— n] with Bâˆ— 1 = . . . = Bâˆ— n = Ïƒ âˆˆ[0, 1]. This class contains the following: â€¢ All-blue equilibrium, denoted by Bâˆ—= 1; Bâˆ— v = 1 for all v âˆˆV (i.e., active defense is 1-effective). â€¢ All-red equilibrium, denoted by Bâˆ—= 0; Bâˆ— v = 0 for all v âˆˆV (i.e., active defense is 0-effective). â€¢ Ïƒ-equilibrium, denoted by Bâˆ—= Ïƒ âˆˆ(0, 1); Bâˆ— v = Ïƒ for all v âˆˆV (i.e., active cyber defense is Ïƒ-effective). The Jacobian matrix of (2) near an equilibrium is denoted by M = h (1 âˆ’Ïƒ)f â€²(Ïƒ)Dâˆ’1 ABAB âˆ’Ïƒgâ€²(Ïƒ)Dâˆ’1 ARAR i âˆ’ h f(Ïƒ) + g(Ïƒ) i In. (3) 3.1 Existence and Stability of Equilibria We show that homogeneous equilibria exist under the following hypothesis (or condition): H0: there exists some Ïƒ âˆˆ[0, 1] such that (1 âˆ’Ïƒ) Â· f(Ïƒ) = Ïƒ Â· g(Ïƒ) holds. PROPOSITION 1. Under hypothesis H0, Bâˆ—= Ïƒ âˆˆ[0, 1] is an equilibrium of (2). Moreover, Bâˆ—is stable if â„œ(Âµ) < 0 for all Âµ âˆˆÎ»(M), and unstable if â„œ(Âµ) > 0 for some Âµ âˆˆÎ»(M). PROOF. Under hypothesis H0, namely (1âˆ’Ïƒ)Â·f(Ïƒ) = ÏƒÂ·g(Ïƒ), we see that Bâˆ— v = Ïƒ satisï¬es dBv(t) dt = (1 âˆ’Ïƒ) Â· f(Ïƒ) âˆ’Ïƒ Â· g(Ïƒ) = 0, âˆ€v âˆˆV. Thus Bâˆ—= Ïƒ is an equilibrium. To see the stability of equilibrium Bâˆ—= Ïƒ âˆˆ[0, 1], we consider a small perturbation to Bâˆ—, namely Î´B = [B1 âˆ’Bâˆ— 1, Â· Â· Â· , Bn âˆ’ Bâˆ— n]. The linearization system of Eq. (2) near Bâˆ—leads to dÎ´B dt = h (1 âˆ’Ïƒ)f â€²(Ïƒ)Dâˆ’1 ABAB âˆ’Ïƒgâ€²(Ïƒ)Dâˆ’1 ARAR i âˆ’ h f(Ïƒ) + g(Ïƒ) i In  Î´B, (4) where In is the identity matrix of size n. Note that M as deï¬ned in Eq. (3) is the coefï¬cient matrix of linear system (4). The stability of equilibrium Bâˆ—= Ïƒ is determined by the eigenvalues of matrix M. For the general case GB = (V, EB) Ì¸= GR = (V, ER), it can be shown that Î»(M) = Î»  (1 âˆ’Ïƒ)f â€²(Ïƒ)Dâˆ’1 ABAB âˆ’ Ïƒgâ€²(Ïƒ)Dâˆ’1 ARAR  âˆ’ h f(Ïƒ) + g(Ïƒ) i . (5) If â„œ(Âµ) < 0 for all Âµ âˆˆÎ»(MÏƒ), Bâˆ—= Ïƒ is locally stable; if â„œ(Âµ) > 0 for some Âµ âˆˆÎ»(M), Bâˆ—= Ïƒ is locally unstable. Proposition 1 can be simpliï¬ed when Ïƒ = 0 and Ïƒ = 1. COROLLARY 1. If g(1) = 0, then Bâˆ—= 1 is an equilibrium. It is locally stable if âˆ’gâ€²(1) < f(1) and locally unstable if âˆ’gâ€²(1) > f(1). If f(0) = 0, then Bâˆ—= 0 is an equilibrium. It is locally stable if f â€²(0) < g(0) and locally unstable if f â€²(0) > g(0). PROOF. To prove the ï¬rst part, we observe that g(1) = 0 im- plies H0 holds for Ïƒ = 1, namely that Bâˆ—= 1 is an equilibrium of system (2). For Ïƒ = 1, it can be shown that Eq. (4) becomes dÎ´B dt = = h âˆ’gâ€²(1)Dâˆ’1 ARAR âˆ’f(1)In i Î´B. Proposition 1 says that a sufï¬cient condition under which equilib- rium Bâˆ—= 1 is locally stable is âˆ’gâ€²(1)â„œ(Âµ) < f(1), âˆ€Âµ âˆˆÎ»  Dâˆ’1 ARAR  . (6) Since g(1) = 0 and g(x) â‰¥0 for x âˆˆ[0, 1], g(x) is locally non-increasing at x = 1 and thus âˆ’gâ€²(1) â‰¥0. Since the sum for every row in matrix Dâˆ’1 ARAR equals 1, the Perron-Frobenius theorem [10] says that its largest eigenvalue is 1. From Eq. (6), we have âˆ’gâ€²(1)â„œ(Âµ) < âˆ’gâ€²(1) < f(1), âˆ€Âµ âˆˆÎ»  Dâˆ’1 ARAR  . That is, if âˆ’gâ€²(1) < f(1), then Bâˆ—= 1 is locally stable; if âˆ’gâ€²(1) > f(1), there exists at least one eigenvalue Âµ0 âˆˆÎ»  Dâˆ’1 ARAR  , say Âµ0 = 1, such that âˆ’gâ€²(1)â„œ(Âµ0) âˆ’f(1) > 0, meaning that Bâˆ—= 1 is locally unstable. To prove the second part, we observe that f(0) = 0 implies H0 with Ïƒ = 0, namely that Bâˆ—= 0 is an equilibrium of (2). For Ïƒ = 0, Eq. (4) becomes dÎ´B dt = h (1 âˆ’0) Â· f â€²(0)Dâˆ’1 ABAB âˆ’0 Â· gâ€²(0)Dâˆ’1 ARAR i âˆ’ h f(0) + g(0) i In  Î´B = h f â€²(0)Dâˆ’1 ABAB âˆ’g(0)In i Î´B. Proposition 1 says that the sufï¬cient condition for equilibrium Bâˆ—= 0 to be locally stable is f â€²(0)â„œ(Âµ) < g(0), âˆ€Âµ âˆˆÎ»  Dâˆ’1 ABAB  . (7) Since f(0) = 0 and f(x) â‰¥0 for x âˆˆ[0, 1], f(x) is locally non-decreasing at x = 0 and thus f â€²(0) â‰¥0. Since the largest eigenvalue of Dâˆ’1 ABAB is 1, from Eq. (7) we have f â€²(0)â„œ(Âµ) < f â€²(0) < g(0), âˆ€Âµ âˆˆÎ»  Dâˆ’1 ABAB  . That is, if f â€²(0) < g(0), then Bâˆ—= 0 is locally stable; if f â€²(0) > g(0), there exists at least one eigenvalue Âµ0 âˆˆÎ»  Dâˆ’1 ABAB  , say Âµ0 = 1, such that f â€²(0)â„œ(Âµ0) âˆ’g(0) > 0, meaning that Bâˆ—= 0 is locally unstable. In the special case GB = GR, namely AB = AR, we immedi- ately obtain the following corollary of Proposition 1: COROLLARY 2. Suppose hypothesis H0 holds and GB = GR = G (i.e., AB = AR = A). Let Âµ1 be the eigenvalue of Dâˆ’1 A A that has the smallest real part. If the attack-power and defense-power functions satisfy one of the following two conditions: (i). (1âˆ’Ïƒ)f â€²(Ïƒ)âˆ’Ïƒgâ€²(Ïƒ) > 0 and f(Ïƒ) + g(Ïƒ) (1 âˆ’Ïƒ)f â€²(Ïƒ) âˆ’Ïƒgâ€²(Ïƒ) > 1, (ii). (1 âˆ’Ïƒ)f â€²(Ïƒ) âˆ’Ïƒgâ€²(Ïƒ) < 0 and f(Ïƒ) + g(Ïƒ) (1 âˆ’Ïƒ)f â€²(Ïƒ) âˆ’Ïƒgâ€²(Ïƒ) < â„œ(Âµ1), then equilibrium Bâˆ—= Ïƒ âˆˆ[0, 1] is locally stable. If the attack-power and defense-power functions satisfy one of the two following conditions: (i). (1âˆ’Ïƒ)f â€²(Ïƒ)âˆ’Ïƒgâ€²(Ïƒ) > 0 and f(Ïƒ) + g(Ïƒ) (1 âˆ’Ïƒ)f â€²(Ïƒ) âˆ’Ïƒgâ€²(Ïƒ) < 1, (ii). (1 âˆ’Ïƒ)f â€²(Ïƒ) âˆ’Ïƒgâ€²(Ïƒ) < 0 and f(Ïƒ) + g(Ïƒ) (1 âˆ’Ïƒ)f â€²(Ïƒ) âˆ’Ïƒgâ€²(Ïƒ) > â„œ(Âµ1), then equilibrium Bâˆ—= Ïƒ âˆˆ[0, 1] is locally unstable. 3.2 Examples Example 1: Stability effect of different defense-power functions vs. a ï¬xed attack-power function. Suppose GB = GR is an ErdÃ¶s-RÃ©nyi (ER) random graph instance G = (V, E) with |V | = 2, 000 and edge probability p = 0.005 (i.e., every pair of nodes is connected with probability 0.005, independent of each other). We consider attack-power function g(x) = 1âˆ’x against the following four scenarios of defense-power function f(x): â€¢ Scenario I: f(x) = x2, meaning that Bâˆ—= 0 is stable and Bâˆ—= 1 is unstable. â€¢ Scenario II: f(x) = x2+x, meaning that Bâˆ—= 0 is unstable and Bâˆ—= 1 is stable. â€¢ Scenario III: f(x) = x2 + 1 2x, meaning that Bâˆ—= 0 and Bâˆ—= 1 are stable, but Bâˆ—= 1 2 is unstable. â€¢ Scenario IV: f(x) = âˆ’2x2 + 2x, meaning that Bâˆ—= 1 2 is stable, but Bâˆ—= 0 and Bâˆ—= 1 are unstable. Figure 2 plots the phase portraits of âŸ¨Bv(t)âŸ©= 1 |V | P vâˆˆV Bv(t), the portion of secure nodes. We observe that the simulation results conï¬rm the analytic results. Speciï¬cally, Figure 2(a) shows that âŸ¨Bv(t)âŸ©converges to Bâˆ—= 0 when Bv(0) < 1 for all v âˆˆV ; Fig- ure 2(b) shows that âŸ¨Bv(t)âŸ©converges to Bâˆ—= 1 when Bv(0) > 0 for all v âˆˆV ; Figure 2(c) shows that âŸ¨Bv(t)âŸ©converges to Bâˆ—= 1 when Bv(0) > 0.5 for all v âˆˆV and converges to Bâˆ—= 0 when Bv(0) < 0.5 for all v âˆˆV ; Figure 2(d) shows that âŸ¨Bv(t)âŸ©con- verges to Bâˆ—= 0.5 when 0 < Bv(0) < 1 for all v âˆˆV . time t f(x) g(x) Bâˆ— [0, 150] f(x) = x2 + x g(x) = 1 âˆ’x Bâˆ—= 1 [150, 300] f(x) = x2 g(x) = 1 âˆ’x Bâˆ—= 0 [300, 400] f(x) = âˆ’2x2 + 2x g(x) = 1 âˆ’x Bâˆ—= 0.5 [400, 500] f(x) = x2 + 1 2x g(x) = 1 âˆ’x Bâˆ—= 1 Table 1: The dynamics go to the respective equilibrium Bâˆ— under some combinations of defense-power function f(x) and attack-power function g(x). 0 2 4 6 8 10 12 14 16 18 20 0 0.2 0.4 0.6 0.8 1 âŒ©Bv(t)âŒª t (a) Scenario I: Bâˆ—= 0 is stable, Bâˆ—= 1 is unstable. 0 2 4 6 8 10 12 14 16 18 20 0 0.2 0.4 0.6 0.8 1 âŒ©Bv(t)âŒª t (b) Scenario II: Bâˆ—= 0 is unsta- ble, Bâˆ—= 1 is stable. 0 2 4 6 8 10 12 14 16 18 20 0 0.2 0.4 0.6 0.8 1 âŒ©Bv(t)âŒª t (c) Scenario III: Bâˆ—= 0 and Bâˆ—= 1 are stable, Bâˆ—= 1 2 is unstable. 0 2 4 6 8 10 12 14 16 18 20 0 0.2 0.4 0.6 0.8 1 âŒ©Bv(t)âŒª t (d) Scenario IV: Bâˆ—= 0 and Bâˆ—= 1 are unstable, Bâˆ—= 1 2 is stable. Figure 2: Phase portraits of the four scenarios conï¬rming the stabilities of the equilibria, where x-axis represents time, and y-axis represents the portion of secure nodes âŸ¨Bv(t)âŸ©. Now we study the stability of the equilibria. For the GB = GR mentioned above, we consider the above four scenarios as high- lighted in Table 1. More speciï¬cally, for time t âˆˆ[0, 150], the defense-power function is f(x) = x2 + x and the attack-power function is g(x) = 1 âˆ’x (i.e, the above Scenario I); for time t âˆˆ[150, 300], the defense-power function is f(x) = x2 and the attack-power function is g(x) = 1 âˆ’x (i.e., the above Sce- nario II); for time t âˆˆ[300, 400], the defense-power function is f(x) = âˆ’2x2 + 2x and the attack-power function is g(x) = 1 âˆ’x (i.e., the above Scenario IV); for time t âˆˆ[400, 500], the defense- power function is f(x) = x2 + 1 2x and the attack-power function is g(x) = 1 âˆ’x (i.e., the above Scenario III). 0 50 100 150 200 250 300 350 400 450 500 0 0.2 0.4 0.6 0.8 1 âŒ©Bv(t)âŒª t Figure 3: Active cyber defense dynamics lack persistent equi- librium due to frequent perturbations. Figure 3 plots a very probable scenario that can happen to the portion of secure nodes, where three small perturbations are im- posed at t = 150, 300, 400. This scenario is very probable because it can explain why the cyber security state may rarely enter some persistent equilibrium. Speciï¬cally, the initial value Bv(0), v âˆˆV , is randomly chosen from interval (0, 0.01] by the uniform distribu- tion. At t = 150, we ï¬nd that âŸ¨Bv(150)âŸ©= 1. We then impose a small perturbation on each Bv(150), by replacing Bv(150) with Bv(150) âˆ’Îµv where Îµv is an independent random variable of a uniform distribution in the interval [0, 0.01] for all v âˆˆV . Simi- larly, we replace Bv(300) with Bv(300) + Îµv and Bv(400) with Bv(400) âˆ’Îµv for all v âˆˆV . Figure 3 illustrates that under small perturbations, the overall cyber security dynamics never enter any persistent equilibrium. This offers one possible explanation why real-life cyber security is perhaps never in any equilibrium. 0 2 4 6 8 10 12 14 16 18 20 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 âŒ©Bv(t)âŒª t (a) Î½ = 0.5 0 10 20 30 40 50 60 70 80 90 100 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 âŒ©Bv(t)âŒª t (b) Î½ = 0.8 0 5 10 15 20 25 30 35 40 45 50 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 âŒ©Bv(t)âŒª t (c) Î½ = 0.85 0 5 10 15 20 25 30 35 40 45 50 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 âŒ©Bv(t)âŒª t (d) Î½ = 1 0 2 4 6 8 10 12 14 16 18 20 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 âŒ©Bv(t)âŒª t (e) Î½ = 1.5 0 2 4 6 8 10 12 14 16 18 20 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 âŒ©Bv(t)âŒª t (f) Î½ = 2 Figure 4: Phase portraits of the portion of secure nodes âŸ¨Bv(t)âŸ©: f(x, Î½) = Î½x âˆ’2x2 and g(x) = (1 âˆ’2x)2. Example 2: Stability effect of parameterized defense-power func- tions vs. a ï¬xed attack-power function. Suppose GB = GR is an ER graph G = (V, E) with |V | = 2, 000, but with edge probability p = 0.5. We consider the following parameterized defense-power function f(x, Î½) with parameter Î½ âˆˆ(0, +âˆ) and ï¬xed attack- power function g(x): f(x, Î½) = Î½x âˆ’2x2, g(x) = (1 âˆ’2x)2. Figure 4 plots the phase portraits of âŸ¨Bv(t)âŸ©with Î½ = 0.5, 0.8, 0.85, 1, 1.5, 2, respectively. The portraits can be classiï¬ed into three classes. Figures 4(a)-4(b) show that there is one stable equi- librium Bâˆ—= 0. Figure 4(c) shows that there are three equilibria Bâˆ—= 0, 0.38, 0.2, where the ï¬rst two are stable but the last one is unstable. Figures 4(d)-4(f) show that there exist two equilibria Bâˆ—= 0, Ïƒ with Ïƒ > 0, where Bâˆ—= 0 is unstable and Bâˆ—= Ïƒ is stable. We observe that active cyber defense dynamics exhibit different phenomena with respect to different parameters. More- over, we observe a sort of phase transition in parameter Î½: when Î½ â‰¤0.8, the global cyber security state converges to Bâˆ—= 0 al- most regardless of the initial value; when Î½ â‰¥1, the global cyber security state converges to some Bâˆ—= Ïƒ > 0 almost regardless of the initial value; when 0.8 < Î½ = 0.85 < 1, the global cyber security state converges to some equilibrium dependent upon the initial value. We summarize the discussion in this section into: INSIGHT 1. Active cyber defense dynamics may rarely enter into any equilibrium because of perturbations to the global secu- rity state as caused by the manual cleaning of some compromised computers (Figure 2), and/or because of perturbations to the at- tack/defense power function as caused by the introduction of a new attack/defense method (Figures 3-4 ) 4. TRANSITION BETWEEN MULTIPLE ATTRACTORS We are now ready to precisely characterize the transition be- tween the equilibria, which reï¬‚ects the consequence/effect of the defender manipulating the initial global security state (e.g., man- ually cleaning up some compromised computers before launch- ing active defense) and/or manipulating the attack/defense network structure (e.g., by changing the network access control policy to block/allow certain computers to communicate with certain other computers). 4.1 Transition Between the All-blue and All-red Equilibria Under the conditions mentioned in Corollary 1, namely, f(0) = g(1) = 0, system (2) has two locally stable equilibria Bâˆ—= 1 and Bâˆ—= 0. Let B =  B1, B2, Â· Â· Â· , Bn  âˆˆ[0, 1]n and R = 1âˆ’B =  1 âˆ’B1, 1 âˆ’B2, Â· Â· Â· , 1 âˆ’Bn  âˆˆ[0, 1]n, where n = |V |. For Ï„ âˆ— 1 , Ï„ âˆ— 2 âˆˆ(0, 1), we deï¬ne two sets ÎGB,Ï„âˆ— 1 and ÎGR,Ï„âˆ— 2 as follows: ÎGB,Ï„âˆ— 1 = ( B âˆˆ[0, 1]n 1 deg(v, GB) X uâˆˆNv,GB Bu â‰¥Ï„ âˆ— 1 , âˆ€v âˆˆV ) , (8) ÎGR,Ï„âˆ— 2 = ( R âˆˆ[0, 1]n 1 deg(v, GR) X uâˆˆNv,GR Ru â‰¥Ï„ âˆ— 2 , âˆ€v âˆˆV ) . (9) The following Theorem 1, whose proof is deferred to the Ap- pendix, gives the transition between the all-blue and all-red equi- libria by manipulating the initial state B(0). THEOREM 1. Let GB = (V, EB) and GR = (V, ER) be two arbitrary graphs. Suppose that f(Â·) and g(Â·) are continuous with f(0) = g(1) = 0. Case 1: Suppose the attack-power and defense-power functions sat- isfy, âˆ€z âˆˆ[Ï„ âˆ— 1 , 1) and âˆ€B âˆˆÎGB,Ï„âˆ— 1 and some Î± > 0, f (z) > Î± Â· z, (10) f 1 deg(v, GB) X uâˆˆNv,GB Bu ! + g 1 deg(v, GR) X uâˆˆNv,GR Bu ! â‰¤ Î± (11) If initial value B(0) âˆˆÎGB,Ï„âˆ— 1 , then lim tâ†’âˆBv(t) = 1 âˆ€v âˆˆV . Case 2: Suppose the attack-power and defense-power functions sat- isfy, âˆ€z âˆˆ[Ï„ âˆ— 2 , 1) and âˆ€R âˆˆÎGR,Ï„âˆ— 2 and some Î² > 0, g (1 âˆ’z) > Î² Â· z and f 1 âˆ’ 1 deg(v, GB) X uâˆˆNv,GB Ru ! + g 1 âˆ’ 1 deg(v, GR) X uâˆˆNv,GR Ru ! â‰¤ Î² (12) If initial value R(0) âˆˆÎGR,Ï„âˆ— 2 , then lim tâ†’âˆRv(t) = 1 âˆ€v âˆˆV . The cyber security meaning of Theorem 1 is: Under a certain condition (case 1), the defender needs to manipulate the initial global security state B(0) to belong to ÎGB,Ï„âˆ— 1 to make active defense 1-effective; this says what the defender should strive to do. Under certain other circumstances (case 2), the defender should make sure that the initial global security state B(0) does not cause R(0) = 1 âˆ’B(0) âˆˆÎGR,Ï„âˆ— 2 , because in this regime active defense is 0- effective; this says what the defender should strive to avoid. For the following two corollaries, we deï¬ne ÎGB,Ï„âˆ—= ï£± ï£² ï£³B âˆˆ[0, 1]n 1 deg(v, GB) X uâˆˆNv,GB Bu > Ï„ âˆ—, âˆ€v âˆˆV ï£¼ ï£½ ï£¾, Î˜GR,Ï„âˆ—= ï£± ï£² ï£³B âˆˆ[0, 1]n 1 deg(v, GR) X uâˆˆNv,GR Bu < Ï„ âˆ—, âˆ€v âˆˆV ï£¼ ï£½ ï£¾. On one hand, the following Corollary 3 says that when Ï„ âˆ— 1 = Ï„ âˆ— 2 = Ï„ âˆ—, we obtain the same threshold for the transitions. COROLLARY 3. Suppose f(Â·) and g(Â·) are continuous with f(0) = g(1) = 0. There exist constants Ï„ âˆˆ(0, 1) and Î± > 0 such that the following two conditions hold: (i) The attack-power and the defense-power functions satisfy f (z) > Î± Â· z for any z âˆˆ(Ï„ âˆ—, 1), and for any B âˆˆÎGB,Ï„âˆ— f ï£« ï£­ 1 deg(v, GB) X uâˆˆNv,GB Bu ï£¶ ï£¸+ g ï£« ï£­ 1 deg(v, GR) X uâˆˆNv,GR Bu ï£¶ ï£¸ â‰¤Î±. (ii) The attack-power and the defense-power functions satisfy g (z) > Î±(1 âˆ’z) for any z âˆˆ(0, Ï„ âˆ—), and for any B âˆˆÎ˜GR,Ï„âˆ— f ï£« ï£­ 1 deg(v, GB) X uâˆˆNv,GB Bu ï£¶ ï£¸+ g ï£« ï£­ 1 deg(v, GR) X uâˆˆNv,GR Bu ï£¶ ï£¸ â‰¤Î±. If initial value B(0) âˆˆÎGB,Ï„âˆ—, then lim tâ†’âˆBv(t) = 1 âˆ€v âˆˆV ; if initial value B(0) âˆˆÎ˜GR,Ï„âˆ—, then lim tâ†’âˆBv(t) = 0 âˆ€v âˆˆV . On the other hand, the following Corollary 4 makes a connection to [36], by accommodating Theorems 1, 5, 8 and 9 in [36] as a special case with GB = GR and Î± = 1. COROLLARY 4. Suppose GB = GR = G = (V, E) and f(Â·), and g(Â·) are continuous with f(0) = g(1) = 1. There exist Ï„ âˆ—âˆˆ (0, 1) and Î± > 0 such that the attack-power and defense-power functions satisfy f (z) + g (z) â‰¤Î± âˆ€z âˆˆ[0, 1] and the defense-power function satisfy f (z) > Î± Â· z âˆ€z âˆˆ(Ï„ âˆ—, 1) and f (z) < Î± Â· z âˆ€z âˆˆ(0, Ï„ âˆ—). If initial value B(0) âˆˆÎG,Ï„âˆ—, then lim tâ†’âˆBv(t) = 1 for all v âˆˆV ; if initial value B(0) âˆˆÎ˜G,Ï„âˆ—, then lim tâ†’âˆBv(t) = 0 for all v âˆˆV . 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.2 0.4 0.6 0.8 1 1.2 1.4 1.6 1.8 2 Ï„*= 0.5 initial value x f (x) and g (x) g(x)=2(1âˆ’x)2 f(x)=(eâˆ’10x+5+1)âˆ’1 (a) f(x), g(x) and threshold Ï„ âˆ—= 0.5 satisfy the condition of transition between Bâˆ—= 0 and Bâˆ—= 1 0 5 10 15 20 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Transition induced by initial values âŒ©Bv(t)âŒª t (b) Transition induced by varying initial value âŸ¨Bv(0)âŸ© Figure 5: Transition between equilibria Bâˆ—= 0 and Bâˆ—= 1 as induced by varying the initial value. 4.2 Example We consider the transition between equilibria Bâˆ—= 0 and Bâˆ—= 1 as caused by varying the initial value B(0). We use two concrete defense-power and attack-power functions: f(x) = 1 eâˆ’10x+5 + 1, g(x) = 2(1 âˆ’x)2, which are plotted in Figure 5(a). The graphs GB and GR are two ER graph instances with |V | = 2, 000 and p = 0.5. We consider the transition induced by varying the initial value âŸ¨Bv(0)âŸ©between 0 and 1. Figure 5(b) shows that when âŸ¨Bv(0)âŸ©> 0.5, the dynamics converge to Bâˆ—= 1; when âŸ¨Bv(0)âŸ©< 0.5, the dynamics converge to Bâˆ—= 0. The exploration in this section can be summarized as: INSIGHT 2. A small change in the initial global security state, in the model parameters, in the attack network structure, or in the defense network structure can lead to substantial change in active cyber defense dynamics. A rigorous characterization, such as The- orem 1, can offer precise guidance on â€œwhat the defender should strive to doâ€ and â€œwhat the defender should strive to avoidâ€ (e.g., how to manipulate the dynamics to beneï¬t the defender rather than the attacker). 5. HOPF BIFURCATION We consider Hopf bifurcation near equilibrium Bâˆ—= Ïƒ âˆˆ(0, 1) under condition (1 âˆ’Ïƒ) Â· f(Ïƒ) = Ïƒ Â· g(Ïƒ). Recall that the stability of Bâˆ—= Ïƒ âˆˆ(0, 1) depends on Î»1(M), where M, as deï¬ned in Eq. (3), is the Jacobian matrix of system (2). In the rest of the paper, we may simplify the notation Î»1(M) as Î»1 unless there is potential ambiguity. Consider differentiable defense-power and attack-power func- tions f(x, Î½) and g(x, Î½) with parameter Î½. Suppose âˆ‚f âˆ‚Î½ , âˆ‚g âˆ‚Î½ and âˆ‚M âˆ‚Î½ all depend on Î½. Consider the following critical condition for Hopf bifurcation: â„œ(Î»1) = 0 and â„‘(Î»1) Ì¸= 0. (13) It is known that if (13) holds for some Î½ = Î½âˆ—, Î»1(Î½) is differen- tiable in Î½, and dÎ»1 dÎ½ Ì¸= 0 at Î½ = Î½âˆ—, then system (2) exhibits Hopf bifurcation [24]. Therefore, we need to ï¬nd the critical value Î½âˆ—. For this purpose, we adopt the approach described in [20] to inves- tigate how Î»1 depends on the permutation to M, namely to conduct a perturbation spectral analysis to compute the perturbation to Î»1, denoted by Î´Î»1, as caused by perturbation to M, denoted by Î´M. 5.1 How to Estimate Î´Î»1 Let x1 be the eigenvector of M associated to eigenvalue Î»1, namely, Mx1 = Î»1x1. For perturbation Î´M to M, M + Î´M can be described as M(Î½) + M â€²(Î½)Î´Î½. The perturbation to M causes perturbation Î´Î»1 to Î»1 and perturbation Î´x1 to x1. That is,  M + Î´M  x1 + Î´x1  =  Î»1 + Î´Î»1  x1 + Î´x1  . By ignoring the second-order term, we obtain MÎ´x1 + Î´Mx1 = Î»1Î´x1 + Î´Î»1x1. (14) By multiplying both sides of Eq. (14) with the left eigenvector y1 corresponding to Î»1, we obtain yâŠ¤ 1 MÎ´x1 + yâŠ¤ 1 Î´Mx1 = yâŠ¤ 1 Î»1Î´x1 + yâŠ¤ 1 Î´Î»1x1, yâŠ¤ 1 Î»1Î´x1 + yâŠ¤ 1 Î´Mx1 = yâŠ¤ 1 Î»1Î´x1 + yâŠ¤ 1 Î´Î»1x1, yâŠ¤ 1 Î´Mx1 = yâŠ¤ 1 Î´Î»1x1. As a result, we can estimate Î´Î»1 as Î´Î»1 = yâŠ¤ 1 Î´Mx1 yâŠ¤ 1 x1 , (15) where Î´M can be estimated depending on whether the perturba- tion is to the attack and/or defense power (Case A below) or to the attack/defense network structure (Case B below). Case A: Î´M is caused by perturbation to attack- and/or defense power. Suppose the perturbation is imposed on parameter Î½ in the attack-power and defense-power functions f(x, Î½) and g(x,Î½), where âˆ‚f âˆ‚Î½ and âˆ‚g âˆ‚Î½ depend on Î½ as mentioned above. The cyber security meanings of such perturbations is (for example) that new attack and/or defense techniques are introduced. Note that Î´M(Î½) = ( (1 âˆ’Ïƒ)âˆ‚f â€²(Ïƒ, Î½) âˆ‚Î½ Dâˆ’1 ABAB âˆ’Ïƒ âˆ‚gâ€²(Ïƒ, Î½) âˆ‚Î½ Dâˆ’1 ARAR  âˆ’ âˆ‚f(Ïƒ, Î½) âˆ‚Î½ + âˆ‚g(Ïƒ, Î½) âˆ‚Î½  In ) Î´Î½. In the special case GB = GR = G (i.e., the adjacency matrix AB = AR = A), we have M =  (1 âˆ’Ïƒ)f â€²(Ïƒ) âˆ’Ïƒgâ€²(Ïƒ)  Dâˆ’1 A A âˆ’  f(Ïƒ) + g(Ïƒ)  In, the eigenvalues of M are  (1 âˆ’Ïƒ)f â€²(Ïƒ) âˆ’Ïƒgâ€²(Ïƒ)  Âµ âˆ’  f(Ïƒ) + g(Ïƒ)  In for all Âµ âˆˆÎ»(Dâˆ’1 A A), and the perturbation can be rewrit- ten as Î´M(Î½) = ( (1 âˆ’Ïƒ)âˆ‚f â€²(Ïƒ, Î½) âˆ‚Î½ âˆ’Ïƒ âˆ‚gâ€²(Ïƒ, Î½) âˆ‚Î½  Dâˆ’1 A A âˆ’ âˆ‚f(Ïƒ, Î½) âˆ‚Î½ + âˆ‚g(Ïƒ, Î½) âˆ‚Î½  In ) Î´Î½. Hence, (15) becomes Î´Î»1 = yâŠ¤ 1 h (1 âˆ’Ïƒ)âˆ‚f â€²(Ïƒ, Î½) âˆ‚Î½ âˆ’Ïƒ âˆ‚gâ€²(Ïƒ, Î½) âˆ‚Î½ i Dâˆ’1 A A âˆ’ hâˆ‚f(Ïƒ, Î½) âˆ‚Î½ + âˆ‚g(Ïƒ, Î½) âˆ‚Î½ i In  Î´Î½ Â· x1 , yâŠ¤ 1 x1. (16) Case B: Î´M is caused by perturbation to attack and/or de- fense network structure. Suppose the perturbation is imposed on GB = (V, EB) and/or GR = (V, ER) by adding/deleting edges. The cyber security meaning of such perturbations is that the net- work is disrupted (e.g., edges are deleted by the attacker, or security policies have changed) and then edges are added by the defender. We assume that the number of added/deleted edges is small (com- pared with |EB| and |ER|, respectively) so that we can approxi- mately treat Î´M as a small perturbation. Let CB = Dâˆ’1 ABAB and CR = Dâˆ’1 ARAR. Perturbations to AB and AR lead to AB + Î´AB and AR + Î´AR, respectively. Correspondingly, we obtain the per- turbations to CB and CR: Î´CB = Dâˆ’1 AB+Î´AB(AB + Î´AB) âˆ’Dâˆ’1 ABAB, Î´CR = Dâˆ’1 AR+Î´AR(AR + Î´AR) âˆ’Dâˆ’1 ARAR. Then, the perturbation to Jacobian matrix M is Î´M = (1 âˆ’Ïƒ)f â€²(Ïƒ)Î´CB âˆ’Ïƒgâ€²(Ïƒ)Î´CR. From (15), we have Î´Î»1 = yâŠ¤ 1 h (1 âˆ’Ïƒ)f â€²(Ïƒ)Î´CB âˆ’Ïƒgâ€²(Ïƒ)Î´CR i x1 yâŠ¤ 1 x1 . Note that in the special case GB = GR = G (i.e., AB = AR = A) with perturbations Î´CB = Î´CR, we have Î´M = h (1 âˆ’Ïƒ)f â€²(Ïƒ) âˆ’Ïƒgâ€²(Ïƒ) i Î´C, Î´Î»1 = yâŠ¤ 1 h (1 âˆ’Ïƒ)f â€²(Ïƒ) âˆ’Ïƒgâ€²(Ïƒ) i Î´Cx1 yâŠ¤ 1 x1 . 5.2 Example: Hopf Bifurcation Induced by Perturbation to Parameter In order to show that Hopf bifurcation can happen, we consider an ER graph GB = GR = G = (V, E) with |V | = 2, 000 and edge probability p = 0.005. Let Âµ1 denote the eigenvalue of Dâˆ’1 A A with the smallest real part, where A is the adjacency matrix of G. For the ER graph, we have â„œ(Âµ1) = âˆ’0.3448. We consider the following defense-power and attack-power functions: f(x) = âˆ’4x2 + 4x, g(x, Î½) =  Î½x âˆ’Î½ 2 2 , where f(x) does not depend on Î½. Recall that under condition (1 âˆ’Ïƒ)f(Ïƒ) = Ïƒg(Ïƒ), there exists equilibrium Bâˆ—= Ïƒ âˆˆ(0, 1). When Î½ = 3, we have homogeneous equilibrium Bâˆ—= 0.7, which is locally stable according to the second condition in the ï¬rst part of Corollary 2: (1 âˆ’Ïƒ)f â€²(Ïƒ) âˆ’Ïƒgâ€²(Ïƒ, 3) = âˆ’3 < 0, f(Ïƒ) + g(Ïƒ, 3) (1 âˆ’Ïƒ)f â€²(Ïƒ) âˆ’Ïƒgâ€²(Ïƒ, 3) = âˆ’0.4 < â„œ(Âµ1) = âˆ’0.3448. When Î½ = 4, we have homogeneous equilibrium Bâˆ—= 0.6667, which is locally unstable according to the second condition in the second part of Corollary 2: (1 âˆ’Ïƒ)f â€²(Ïƒ) âˆ’Ïƒgâ€²(Ïƒ, 4) = âˆ’4 < 0 f(Ïƒ) + g(Ïƒ, 4) (1 âˆ’Ïƒ)f â€²(Ïƒ) âˆ’Ïƒgâ€²(Ïƒ, 4) = âˆ’0.3333 > â„œ(Âµ1) = âˆ’0.3448. Therefore, there is a critical value between Î½ = 3 and Î½ = 4, at which â„œ(Î»1(M)) = 0. By conducting 100 independent simulation runs of Î½ âˆˆ[3, 4) with step-length 0.01, we ï¬nd the critical value Î½ = 3.8 and the corresponding equilibrium Bâˆ—= 0.6724, where (1 âˆ’Ïƒ)f â€²(Ïƒ) âˆ’Ïƒgâ€²(Ïƒ, 3.8) = 7 âˆ’3.81 < 0, f(Ïƒ) + g(Ïƒ, 3.8) (1 âˆ’Ïƒ)f â€²(Ïƒ) âˆ’Ïƒgâ€²(Ïƒ, 3.8) = âˆ’0.3448 = â„œ(Âµ1). Figure 6(a) plots the periodic trajectory of âŸ¨Bv(t)âŸ©when Î½ = 4 > 3.8, which surrounds equilibrium Bâˆ—= 0.6724. Figure 6(b) plots the periodic trajectory of âŸ¨Bv(t)âŸ©when Î½ = 5.05 > 3.8. Figure 6(c) plots the bifurcation diagram with respect to Î½ âˆˆ (3, 6). Figure 6(d) plots the bifurcation diagram with respect to Î½ âˆˆ(4.75, 5.5). We observe that when Î½ âˆˆ(5, 5.5), there are not only two-periodic trajectories, but also k-periodic trajectories (k > 2). In summary, the periodic trajectories exhibit the period- doubling cascade phenomenon. 5.3 Example: Hopf Bifurcation Induced by Perturbation to Attack/Defense Network Structures For the purpose of demonstrating the bifurcation phenomenon caused by perturbation to network structures, we use two randomly generated ER graph examples GB = (V, EB) and GR = (V, ER), both with |V | = 2, 000 and p = 0.005. The average degree is 10.0565 for GB and 11.1865 for GR. We use the following defense-power and attack-power functions: f(x) = âˆ’4x2 + 4x, g(x, Î½) =  Î½x âˆ’Î½ 2 2 with Î½ = 6 We perform 100 iterations of operations to GR as follows: during each of the ï¬rst 50 iterations, we delete 226 edges (or 1% of the edges in the original ER) chosen independently and uniformly at random; during each of the following 50 iterations, we add 226 edges chosen independently and uniformly random among all the unconnected edges. That is, we delete and then add 50% edges of the original |ER|. Figure 7 demonstrates that the period-doubling cascade phe- nomenon appears and ï¬nally leads to chaos after deleting more than 36% edges and before adding 14% edges. We observe that eventually the diagram becomes stable after adding the same num- ber of edges as those deleted. (Note that Figure 7 is not symmetric because the added edges are random and in general are different from the edges that are deleted.) The following insight summarizes the exploration of this section. INSIGHT 3. Active cyber defense dynamics can exhibit Hopf bi- furcation, when the attack/defense power varies in certain parame- ter regimes and/or when the attack/defense network structure varies 0 50 100 150 200 250 300 350 400 450 500 0.664 0.665 0.666 0.667 0.668 0.669 0.67 âŒ©Bv(t)âŒª t Limit cycle (a) Periodic trajectory of âŸ¨Bv(t)âŸ©with Î½ = 4 0 50 100 150 200 250 300 350 400 450 500 0.633 0.635 0.637 0.639 0.641 0.643 0.645 0.647 0.633 t âŒ©Bv(t)âŒª Multi period (b) Periodic trajectory of âŸ¨Bv(t)âŸ©w/ Î½ = 5.05 3.5 4 4.5 5 5.5 6 0.615 0.625 0.635 0.645 0.655 0.665 0.675 0.685 âŒ©Bv âŒª Î½ Hopf bifurcation Diagram (c) Bifurcation diagram w/ Î½ âˆˆ(3, 6) 4.75 4.875 5 5.125 5.25 5.375 5.5 0.63 0.635 0.64 0.645 0.65 Î½ âŒ©Bv âŒª Hopf bifurcation Diagram (d) Bifurcation diagram w/ Î½ âˆˆ(4.75, 5.5) Figure 6: Limit cycle and Hopf bifurcation diagram, where âŸ¨BvâŸ©are the extremum points of âŸ¨Bv(t)âŸ©in time period t âˆˆ(1000, 2000). 0 âˆ’10 âˆ’20 âˆ’30 âˆ’40 âˆ’50 +10 +20 +30 +40 +50 0.618 0.62 0.622 0.624 0.626 0.628 0.63 0.632 chaos region Percentage of deleting (âˆ’) or adding (+) edges (%) âŒ©Bv âŒª Diagram Figure 7: Hops bifurcation induced by perturbation to the net- work structure. in certain patterns. These situations are â€œunmanageableâ€ because it would be infeasible, if not impossible, to estimate the global secu- rity state in real-time. Therefore, the defender must strive to avoid such unmanageable situations by manipulating the dynamics care- fully (e.g., by disrupting the bifurcation condition or containing the attack-power of the adversary). 6. CHAOS Figure 6(c) shows that the number of periodic points increase with parameter Î½, which hints that system (2) can exhibit the chaos phenomenon. To see this, we consider the case GB = GR. In this case, system (2) becomes dBv(t) dt = f ï£« ï£­ 1 deg(v, G) X uâˆˆNv,G Bu(t) ï£¶ ï£¸ h 1 âˆ’Bv(t) i âˆ’ g ï£« ï£­ 1 deg(v, G) X uâˆˆNv,G Bu(t) ï£¶ ï£¸Bv(t). Let F  Bv(0), t  denote the right-hand part. Consider Bv(0) and Bv(0) + Îµv(0) for all v âˆˆV , where Îµv(0) âˆˆRn is a small pertur- bation to the initial point Bv(0). Then, we have âˆ€v âˆˆV , Îµv(t) = F  Bv(0) + Îµv(0), t  âˆ’F  Bv(0), t  = DF  Bv(0), t  Â· Îµv(0), where DF  Bv(0), t  is the Jacobian matrix of the map F at time t. By the QR decomposition of matrix Îµ(t) = [Îµ1(t), Îµ2(t), Â· Â· Â· , Îµn(t)] where n = |V |, we obtain matrix Îµ(t) = q(t) Â· r(t), where q(t) is an orthogonal matrix and r(t) is an upper triangular matrix. Note that Îµ(t) = q(t) and the diagonal element Î»ii(t) of rt at time t is the exponential magniï¬cation, where i âˆˆ{1, 2, Â· Â· Â· , n}. Thus, the average rate of divergence or convergence of the two tra- jectories  F  Bv(0), t  t â‰¥0 and {F  Bv(0)+Îµv(0), t  t â‰¥0 for all v âˆˆV is deï¬ned by Li = lim tâ†’âˆ 1 t ln Î»ii(t), where Li for i = 1, 2, Â· Â· Â· , n are the Lyapunov characteristic ex- ponents. It is known [24] that under some mild conditions, the above limit exists and is ï¬nite for almost all initial values B(0) = [B1(0), B2(0), Â· Â· Â· , Bn(0)] and for almost all matrices Îµ(0). Note that MLE = max1â‰¤iâ‰¤n Li indicates whether the dynamical sys- tem is chaotic or not. More speciï¬cally, when MLE > 0, a small perturbation to the initial value will lead to an exponential separa- tion and therefore leads to the chaos phenomenon. Example. Consider an ER graph instance GB = GR with |V | = 2, 000 and p = 0.005, and the following defense-power and attack- power functions: f(x) = âˆ’4x2 + 4x, gÎ½(x) =  Î½x âˆ’Î½ 2 2 . 1 2 3 4 5 6 7 8 9 10 âˆ’0.04 âˆ’0.02 0 0.02 0.04 0.06 Î½ Maximal Lyapunov exponent (MLE) (a) MLE with Î½: MLE > 0 indicates chaos. 0 100 200 300 400 500 0.588 0.59 0.592 0.594 0.596 0.598 0.6 0.602 0.604 âŒ©Bv(t)âŒª t (b) âŸ¨Bv(t)âŸ©for Î½ = 8 exhibits chaos. Figure 8: Active cyber defense dynamics exhibit the chaos phe- nomenon: GB = GR with |V | = 2, 000 and p = 0.005. Figure 8(a) plots the MLE with respect to Î½. We observe that MLE > 0 when Î½ > 5, meaning that system (17) exhibit chaos for Î½ > 5. Figure 8(b) plots the phase portrait of âŸ¨Bv(t)âŸ©(i.e., the average of the Bv(t)â€™s for all v âˆˆV ) when Î½ = 8, which hints the emergence of chaos. This means that the defender should strive to avoid the parameter regime Î½ > 5. This leads to the following: INSIGHT 4. Active cyber defense dynamics can be chaotic, mean- ing that it is impossible to predict the global cyber security state because it is too sensitive to the accuracy of the estimated initial global security state. Therefore, the defender must strive to avoid such unmanageable situations (e.g., by disrupting the attacks to as- sure Î½ â‰¤5 in the above example). 7. RELATED WORK Cybersecurity Dynamics is a framework for modeling and quan- tifying cyber security from a holistic perspective (rather than mod- eling and analyzing security of components or building-blocks) [34, 35, 36, 17]. This framework builds on a large body of literature across Computer Science, Mathematics and Statistical Physics (cf. [7, 4, 33, 37, 38, 17, 39, 29, 6, 3, 28, 23, 11, 12] and the references therein), which can be further traced back to the century-old studies on biological epidemic models [19, 13, 8]. As a speciï¬c kind of cybersecurity dynamics, active cyber de- fense dynamics were ï¬rst rigorously modeled and studied in [36], despite that the idea of active defense has been discussed and de- bated for many years [14, 31, 18, 16, 26, 30, 1, 2]. We move a signiï¬cant step beyond [36], by separating the attack network structure from the defense network structure, and by considering more general attack and defense power functions. To the best of our knowledge, we are the ï¬rst to show that bifurcation and chaos are relevant in the cyber security domain, and to discuss the cyber security implications of these phenomena. Following [36], Lu et al. [17] investigate optimal active defense strategies in the Control- Theoretic and Game-Theoretic frameworks. Our study is comple- mentary to [17] as we leave it to future work to investigate optimal strategies in our setting. It is worth mentioning that models of Lotka-Volterra type [9] capture the predator-prey dynamics, which are however different from the active cyber defense dynamics. Active cyber defense dy- namics may be seen as the non-linear generalization of the so- called Voter model in complex networks [25, 15]. Somewhat re- lated to our work is [5], which considers chaotic dynamics in discrete- time limited imitation contagion model on random networks. 8. CONCLUSION We have explored the rich phenomena that can be exhibited by active cyber defense dynamics. To the best of our knowledge, our study is the ï¬rst to show that bifurcation and chaos are relevant in the cyber security domain. The implication is of high practical value: In order to make cyber security measurement and prediction feasible, the defender must manipulate the cyber security dynamics to avoid these unmanageable situations. Interesting problems for future research include: First, we need to characterize non-homogeneous equilibria as we only focused on homogeneous equilibria. Second, we need to characterize which graph structure is more advantageous to the other (e.g., GB is ER graph but GR is power-law graph). Third, we need to explore the chaos phenomenon further (e.g., multi-direction chaos). Fourth, we need to systematically validate the models. Acknowledgement. We thank the reviewers for their useful com- ments and Marcus Pendleton for proofreading the paper. Wen- lian Lu was supported in part by the National Natural Sciences Foundation of China under Grant No. 61273309, the Program for New Century Excellent Talents in University (NCET-13-0139), the Programme of Introducing Talents of Discipline to Universi- ties (B08018), and the Laboratory of Mathematics for Nonlinear Science, Fudan University. Shouhuai Xu was supported in part by ARO Grant #W911NF-12-1-0286 and NSF Grant #1111925. Any opinions, ï¬ndings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reï¬‚ect the views of any of the funding agencies. 9. REFERENCES [1] D. Aitel. Nematodes â€“ beneï¬cial worms. http://www. immunityinc.com/downloads/nematodes.pdf, Sept. 2005. [2] F. Castaneda, E. Sezer, and J. Xu. Worm vs. worm: preliminary study of an active counter-attack mechanism. In Proceedings of ACM WORMâ€™04, pages 83â€“93, 2004. [3] D. Chakrabarti, Y. Wang, C. Wang, J. Leskovec, and C. Faloutsos. Epidemic thresholds in real networks. ACM Trans. Inf. Syst. Secur., 10(4):1â€“26, 2008. [4] G. Da, M. Xu, and S. Xu. A new approach to modeling and analyzing security of networked systems. In Proceedings of HotSoSâ€™14, pages 6:1â€“6:12. [5] P. S. Dodds, K. D. Harris, and C. M. Danforth. Limited imitation contagion on random networks: Chaos, universality, and unpredictability. Phys. Rev. Lett., 110:158701, Apr 2013. [6] A. Ganesh, L. Massoulie, and D. Towsley. The effect of network topology on the spread of epidemics. In Proceedings of IEEE Infocom 2005, 2005. [7] Y. Han, W. Lu, and S. Xu. Characterizing the power of moving target defense via cyber epidemic dynamics. In Proceedings of HotSoSâ€™14, pages 10:1â€“10:12. [8] H. Hethcote. The mathematics of infectious diseases. SIAM Rev., 42(4):599â€“653, 2000. [9] J. Hofbauer and K. Sigmund. The theory of evolution and dynamical systems. Cambridge University Press, 1998. [10] R. Horn and C. Johnson. Matrix Analysis. Cambridge University Press, 1985. [11] J. Kephart and S. White. Directed-graph epidemiological models of computer viruses. In IEEE Symposium on Security and Privacy, pages 343â€“361, 1991. [12] J. Kephart and S. White. Measuring and modeling computer virus prevalence. In IEEE Symposium on Security and Privacy, pages 2â€“15, 1993. [13] W. Kermack and A. McKendrick. A contribution to the mathematical theory of epidemics. Proc. of Roy. Soc. Lond. A, 115:700â€“721, 1927. [14] J. Kesan and C. Hayes. Mitigative counterstriking: Self-defense and deterrence in cyberspace. Harvard Journal of Law and Technology (forthcoming, available at SSRN: http://ssrn.com/abstract=1805163). [15] P. L. Krapivsky. Kinetics of monomer-monomer surface catalytic reactions. Phys. Rev. A, 45:1067â€“1072, Jan 1992. [16] H. Lin. Lifting the veil on cyber offense. IEEE Security & Privacy, 7(4):15â€“21, 2009. [17] W. Lu, S. Xu, and X. Yi. Optimizing active cyber defense dynamics. In Proceedings of GameSecâ€™13, pages 206â€“225. [18] W. Matthews. U.s. said to need stronger, active cyber defenses. http://www.defensenews.com/story. php?i=4824730, 1 Oct 2010. [19] A. McKendrick. Applications of mathematics to medical problems. Proc. of Edin. Math. Soceity, 14:98â€“130, 1926. [20] A. Milanese, J. Sun, and T. Nishikawa. Approximating spectral impact of structural perturbations in large networks. Phys. Rev. E, 81:046112, Apr 2010. [21] J. Morales, S. Xu, and R. Sandhu. Analyzing malware detection efï¬ciency with multiple anti-malware programs. In Proceedings of 2012 ASE CyberSecurityâ€™12. [22] R. Naraine. â€™friendlyâ€™ welchia worm wreaking havoc. http://www.internetnews.com/ent-news/ article.php/3065761/Friendly-Welchia -Worm-Wreaking-Havoc.htm, August 19, 2003. [23] R. Pastor-Satorras and A. Vespignani. Epidemic spreading in scale-free networks. PRL, 86(14):3200â€“3203, 2001. [24] R. Robinson. Dynamical Systems: Stability, Symbolic Dynamics, and Chaos (2dn Edition). CRC Press, 1999. [25] C. Schneider-Mizell and L. Sander. A generalized voter model on complex networks. Journal of Statistical Physics, 136(1):11, 2008. [26] B. Schneier. Benevolent worms. http://www. schneier.com/blog/archives/2008/02/ benevolent_worm_1.html, February 19, 2008. [27] L. Shaughnessy. The internet: Frontline of the next war? http://www.cnn.com/2011/11/07/us/darpa/, November 7, 2011. [28] P. Van Mieghem, J. Omic, and R. Kooij. Virus spread in networks. IEEE/ACM Trans. Netw., 17(1):1â€“14, Feb. 2009. [29] Y. Wang, D. Chakrabarti, C. Wang, and C. Faloutsos. Epidemic spreading in real networks: An eigenvalue viewpoint. In Proceedings of SRDSâ€™03, pages 25â€“34. [30] N. Weaver and D. Ellis. White worms donâ€™t work. ;login: The USENIX Magazine, 31(6):33â€“38, 2006. [31] H. S. N. Wire. Active cyber-defense strategy best deterrent against cyber-attacks. http://www. homelandsecuritynewswire.com/active -cyber-defense-strategy-best-deterrent -against-cyber-attacks, 28 June 2011. [32] J. Wolf. Update 2-u.s. says will boost its cyber arsenal. http://www.reuters.com/article/2011/11/ 07/cyber-usa-offensive- idUSN1E7A61YQ20111107, November 7, 2011. [33] M. Xu and S. Xu. An extended stochastic model for quantitative security analysis of networked systems. Internet Mathematics, 8(3):288â€“320, 2012. [34] S. Xu. Cybersecurity dynamics. In Proceedings of HotSoSâ€™14, pages 14:1â€“14:2. [35] S. Xu. Emergent behavior in cybersecurity. In Proceedings of HotSoSâ€™14, pages 13:1â€“13:2. [36] S. Xu, W. Lu, and H. Li. A stochastic model of active cyber defense dynamics. Internet Mathematics, 11(1):23â€“61, 2015. [37] S. Xu, W. Lu, and L. Xu. Push- and pull-based epidemic spreading in arbitrary networks: Thresholds and deeper insights. ACM TAAS, 7(3):32:1â€“32:26, 2012. [38] S. Xu, W. Lu, L. Xu, and Z. Zhan. Adaptive epidemic dynamics in networks: Thresholds and control. ACM TAAS, 8(4):19, 2014. [39] S. Xu, W. Lu, and Z. Zhan. A stochastic model of multivirus dynamics. IEEE TDSC, 9(1):30â€“45, 2012. APPENDIX Now we prove Theorem 1. PROOF. We prove the theorem in the ï¬rst statement with B(0) âˆˆ ÎGB,Ï„âˆ— 1 , and the second statement with R(0) âˆˆÎGR,Ï„âˆ— 2 can be proved similarly. First, we see that g(1) = 0 implies that Bâˆ—= 1 is an equilibrium of (2) according to Proposition 1. Deï¬ne Vt = argmin vâˆˆV Bv(t) = n u Bu(t) = min vâˆˆV Bv(t) o for t â‰¥0. Since the case minv Bv(0) = 1, namely Bv(t) = 1 for all v âˆˆV and t â‰¥0, is trivial, we assume minv Bv(0) < 1 without loss of any generality. For any v(0) âˆˆV0, the given condition (10) implies 1 deg(v(0),GB) P uâˆˆNv(0),GB Bu(0) â‰¥Ï„ âˆ— 1 , and thus we have f ï£« ï£­ 1 deg(v(0), GB) X uâˆˆNv(0),GB Bu(0) ï£¶ ï£¸ â‰¥ Î± Â· 1 deg(v(0), GB) X uâˆˆNv(0),GB Bu(0), where â€œ=â€ holds only when 1 deg(v(0),GB) P uâˆˆNv(0),GB Bu(0) = 1. Let t = 0 and v = v(0). Using Eq. (2) and condition (11), we have dBv(0)(t) dt t=0 = f ï£« ï£­ 1 deg(v(0), GB) X uâˆˆNv(0),GB Bu(0) ï£¶ ï£¸ h 1 âˆ’Bv(0)(0) i âˆ’ g ï£« ï£­ 1 deg(v(0), GB) X uâˆˆNv(0),GB Bu(0) ï£¶ ï£¸Bv(0)(0) â‰¥ f ï£« ï£­ 1 deg(v(0), GB) X uâˆˆNv(0),GB Bu(0) ï£¶ ï£¸âˆ’Î±Bv(0)(0) â‰¥ Î±  Bv(0)(0) âˆ’Bv(0)(0)  (17) = 0. Since the equality signs hold in the two inequalities in Eq. (17) only when minv Bv(0) = 1, which corresponds to the trivial case men- tioned above, we conclude that minvâˆˆV Bv(t) strictly increases in a small time interval starting at t = 0 except for the trivial case. Let Ï„ âˆ—âˆ— 1 > Ï„ âˆ— 1 such that 1 deg(v(0),GB) P uâˆˆNv(0),GB Bu(0) > Ï„ âˆ—âˆ— 1 for all v âˆˆV . We now show that 1 deg(v,GB) P uâˆˆNv,GB Bu(t) > Ï„ âˆ—âˆ— 1 for all t > 0 and for all v âˆˆV . Let t0 be the ï¬rst time that 1 deg(v,GB) P uâˆˆNv,GB Bu(t) = Ï„ âˆ—âˆ— 1 for some v âˆˆV , i.e. t0 = inf ï£± ï£² ï£³Ï„ 1 deg(v, GB) X uâˆˆNv,GB Bu(t) > Ï„ âˆ—âˆ— 1 âˆ€t âˆˆ[0, Ï„), âˆ€v âˆˆV ï£¼ ï£½ ï£¾. We show t0 = +âˆ. Suppose t0 < +âˆ. Let V âˆ—be the node set such that for each v âˆˆV âˆ—, 1 deg(v,GB) P uâˆˆNv,GB Bu(t) reaches Ï„ âˆ—âˆ— 1 for the ï¬rst time. Then, for some vâˆ—âˆˆV âˆ—, we know that 1 deg(vâˆ—,GB) P uâˆˆNvâˆ—,GB Bu(t) is not increasing at t = t0. How- ever, it can be shown that d dt ï£« ï£­ 1 deg(vâˆ—, GB) X uâˆˆNvâˆ—,GB Bu(t) ï£¶ ï£¸ t=t0 = 1 deg(vâˆ—, GB) X uâˆˆNvâˆ—,GB dBu(t) dt t=t0 â‰¥ Î± deg(vâˆ—, GB) Â· X uâˆˆNvâˆ—,GB ï£« ï£­ 1 deg(u, GB) X wâˆˆNu,GB Bw(t) âˆ’Bu(t0) ï£¶ ï£¸ â‰¥ 0, where the equality signs hold only for the trivial case as in the case of Eq. (17) mentioned above (i.e., in all other cases the inequalities are strict). So we reach a contradiction, which means t0 = +âˆ. Owing to Ï„ âˆ—âˆ— 1 > Ï„ âˆ— 1 , we have 1 deg(v,GB) P uâˆˆNv,GB Bu(t) > Ï„ âˆ— 1 for all t > 0. That is, B(t) âˆˆÎGB,Ï„âˆ— 1 for all t. Let t1 be the maximum time that minvâˆˆV Bv(t) is strictly in- creasing, i.e t1 = sup  t min v Bv(t) is strictly increasing in [0, t)  . We show that t1 = +âˆ. Suppose that t1 is ï¬nite, meaning that minvâˆˆV Bv(t) is not increasing at time t = t1. Since it holds that minvâˆˆV Bv(t1) > minvâˆˆV Bv(0) > Ï„ âˆ— 1 , by replacing B(0) with B(t1), we have f ï£« ï£­ 1 deg(v(t1), GB) X uâˆˆNv(t1),GB Bu(t1) ï£¶ ï£¸ > Î± deg(v(t1), GB) X uâˆˆNv(t1),GB Bu(t1) and therefore we can show dBv(t1)(t) dt t=t1 â‰¥ f ï£« ï£­ 1 deg(v(t1), GB) X uâˆˆNv(t1),GB Bu(t1) ï£¶ ï£¸âˆ’Î±Bv(t1)(t1) â‰¥ Î± ï£« ï£­ 1 deg(v(t1), GB) X uâˆˆNv(t1),GB Bu(t1) âˆ’Bv(t1)(t1) ï£¶ ï£¸ â‰¥ 0, where are inequalities are strict except for the trivial case â€” as discussed in the case of Eq. (17). That is, minvâˆˆV Bv(t) strictly increases at t = t1, which contradicts with the deï¬nition of t1. Therefore, we have t1 = +âˆand minvâˆˆV Bv(t) is strictly in- creasing in t âˆˆ[0, +âˆ). In order to show limtâ†’âˆBv(t) = 1 for all v âˆˆV , we will prove that limtâ†’âˆminvâˆˆV Bv(t) = 1 for limtâ†’âˆminvâˆˆV Bv(t) â‰¤ limtâ†’âˆBv(t). Since Bv(t) is the probability that node v âˆˆV is blue at time t, we have 0 â‰¤Bv(t) â‰¤1 for all v âˆˆV . Hence limtâ†’âˆminvâˆˆV Bv(t) exists. Suppose for the sake of contradic- tion that limtâ†’âˆminvâˆˆV Bv(t) < 1, meaning minvâˆˆV Bv(t) < 1 for all t due to its strict increasing monotonicity. For any v(t) âˆˆ Vt, under the condition that Eq. (10) holds, there exists Îµ > 0 such that f(Bv(t)(t)) âˆ’Î±Bv(t)(t) > Îµ for all t. Since minvâˆˆV Bv(t) is strictly increasing for t âˆˆ[0, +âˆ), there exists T > 0 such that dBv(t)(t) dt = f ï£« ï£­ 1 deg(v(t), GB) X uâˆˆNv(t),GB Bu(t) ï£¶ ï£¸ h 1 âˆ’Bv(t)(t) i âˆ’ g ï£« ï£­ 1 deg(v(t), GB) X uâˆˆNv(t),GB Bu(t) ï£¶ ï£¸Bv(t)(t) â‰¥ f  Bv(t)(t)  âˆ’Î±Bv(t)(t) > Îµ, for all t > T . This leads to Bv(t)(t) > Bv(T )(T ) + Îµ(t âˆ’T ). Since minvâˆˆV Bv(t) = Bv(t)(t) â†’âˆas t â†’âˆ, it contradicts with Bv(t) â‰¤1. Therefore, we conclude lim tâ†’âˆmin vâˆˆV Bv(t) = 1 and lim tâ†’âˆBv(t) = 1.