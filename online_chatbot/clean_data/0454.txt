The Cyber Alliance Game: How Alliances Influence Cyber-Warfare Gergely Benk˝o1 and Gergely Bicz´ok1,2,3 1 CrySyS Lab, Dept. of Networked Systems and Services, Budapest University of Technology and Economics benkogergely@edu.bme.hu, biczok@crysys.hu 2 BME-HUN-REN Information Systems Research Group, Hungary 3 University of Michigan, Ann Arbor, MI 48109, USA Abstract. Cyber-warfare has become the norm in current ongoing mil- itary conflicts. Over the past decade, numerous examples have shown the extent to which nation-states become vulnerable if they do not focus on building their cyber capacities. Adding to the inherent complexity of cyberwar scenarios, a state is usually a member of one or more alliances. Alliance policies and internal struggles could shape the individual actions of member states; intuitively, this also holds for the cyber domain. In this paper, we define and study a simple Cyber Alliance Game with the objective of understanding the fundamental influence of alliances on cy- ber conflicts between nation-states. Specifically, we focus on the decision of whether to exploit a newly found vulnerability individually or share it with the alliance. First, we characterize the impact of vulnerability- sharing rewards on the resulting equilibrium. Second, we study the impli- cations of the internal power structure of alliances on cyberwar outcomes and infer the expected behavior of Dictator, Veto, and Dummy players. Finally, we investigate how alliances can nudge their members via re- wards and punishments to adhere to their defensive or offensive cyber policy. We believe that our results contribute to the fundamental un- derstanding of real-world cyber-conflicts by characterizing the impact of alliances. Keywords: Cyber-Warfare · Weighted Voting · Game Theory · Al- liances 1 Introduction The ongoing Russo-Ukrainian war highlights the importance of military cyber operations and the significant difference between cyber- and traditional warfare in its dynamics, points of conflict, and applied weaponry [21]. Cyberattacks can be broadly categorized into two types: they could target either military or civilian objects, e.g., weapon guidance systems1 or telecommunication companies such as Kyivstar [22] (see Appendix A for examples from both sides). 1 https://www.wired.com/story/dire-possibility-cyberattacks-weapons- systems/ arXiv:2410.05953v1 [cs.GT] 8 Oct 2024 2 G. Benk˝o, G. Bicz´ok While the decision situations in an ongoing cyber conflict can be complex in themselves, most countries are also part of military and/or economic alliances, which have strict admission criteria, internal rules, and a common purpose. Once a nation-state becomes a member of an alliance, it represents both its own in- terests and those of the alliance through its actions and behavior. During the collaboration, members align their military and economic objectives; nowadays, a common cyber defense strategy has also been implemented in most alliances, blurring the lines between military and other alliances. The European Union has been advocating for harsh sanctions against cybercrime and supporting joint re- search and knowledge sharing [9]. BRICS+ countries research three main topics within the framework of the CyberBRICS project [5]: protection of personal data, secure digital transition, and regulation of artificial intelligence [10]. While NATO has prioritized the defense of information systems [13] and employs a policy of deterrence through cyber exercises and capability enhancement, the operations, regulations, and guidelines of the Collective Security Treaty Organi- zation (CSTO), which includes post-Soviet successor states, receives less public attention regarding cyberspace [11]. (See Appendix B for more details.) Military operations have been a fertile application domain for studying strate- gic decision-making via game theory since its inception [4]. Recently, cyber- warfare has also been studied with a similar toolset, but existing studies have not considered alliance systems and their impact on the actors. For instance, in their seminal work [17], the authors modeled and studied the discovery process, stockpiling, and weaponization of (software) vulnerabilities in the cyber-conflict of two nation-states. Their main finding was that at least one state has the in- centive to act as an aggressor as opposed to focusing on defensive efforts in a wide range of scenarios. In this paper, we ask the question: how do the presence of alliances influ- ence the outcomes of cyber-warfare?. Inspired by the Cyber Hawk game [17], we construct and analyze the equilibria of the Cyber Alliance Game (CAG). Specif- ically, through games of increasing complexity and with the help of weighted voting theory [18], we show how i) alliances can encourage peaceful, defensive outcomes via rewards for sharing newly discovered vulnerabilities, ii) the inter- nal power structure within an alliance affects the equilibria, and iii) how the fundamental posture of alliances (defensive or offensive) perturb the resulting strategy profiles. Although our model is quite generic and high-level, we be- lieve that our results can help better understand and perhaps predict real-world cyber-warfare-related decisions of various member states of different alliances. The rest of the paper is structured as follows. Section 2 lays out the terminol- ogy, the basics of weighted voting, and related modeling efforts. Section 3 defines our baseline game CAG and analyzes its possible outcomes. Section 4 extends CAG with intra-alliance power structures. Section 5 further extends the model with the fundamental defensive/offensive posture of alliances. Finally, Section 6 provides a discussion on the implications of our results and concludes the paper. The Cyber Alliance Game: How Alliances Influence Cyber-Warfare 3 2 Background 2.1 Terminology Here, we define the basic cybersecurity concepts used throughout the paper. A vulnerability constitutes an opportunity for attack. If previously undiscovered or undisclosed, it can be referred to as a zero-day. Software vulnerabilities are the most common, but there also exist hardware, organizational, and human vulnerabilities. An exploit is a weaponized vulnerability; the attacker develops a piece of code with which he can corrupt the system through the identified vulnerability. A discoverer of a specific vulnerability can never be certain whether they are the sole possessor of that piece of knowledge (unless it was made public or they were attacked through that exact vulnerability), it is possible that they just made a rediscovery [19]. Nevertheless, a strategic discoverer can choose between several actions [17]. First, they can stockpile, storing a discovered vulnerability for later offensive usage. Note that alleged zero-days can also be acquired from the black market, resulting in a similar situation [2]. Second, they can patch their own system via fixing the vulnerability, but at the cost of eliminating the possibility of an attack (patching makes the vulnerability public, hence other actors can also patch their system, resulting in an overall increased level of cybersecurity). The actual patch development is usually done by software vendors [20], but a nation-state might also be able to fix critical vulnerabilities. A glimpse into the economics of a real- world vulnerability disclosure process and related actions of the United States was given in [7] based on a redacted version of the document and a blog post by the former White House Cybersecurity Coordinator. Finally, in relation to alliances, an actor can choose to share the vulnerability results with its alliance. With this step, the discoverer forfeits the opportunity for individual exploitation and places the decision in the hands of the alliance and its internal processes. 2.2 Game theoretical models of cyber-warfare Although there has been much research in modeling different aspects of attacker- defender dynamics in the cyber domain [16,14], the cyber struggle specific to nation-states has received considerably less attention in the game theory litera- ture. In the seminal paper already mentioned above [17], Moore et al. study two simple cyberwar games (one on stockpiling and one on weaponizing/exploiting the discovered vulnerability) between two nation-states. The factors they take into account are the technical sophistication of the states and their willingness to attack. Although the equilibrium outcomes are influenced by these factors, the key takeaway is that there is no all-defensive equilibrium: at least one of the players (whether based on perceived technical superiority or a more aggressive posture) will choose stockpile/attack. Next, Bao et al. present a comprehensive game-theoretical framework to be used as an automated tool in cyber-strategy development [3]. This paper relaxes 4 G. Benk˝o, G. Bicz´ok the many simplifying assumptions of previous works and develops a computation- ally feasible algorithm for deriving equilibria in the complex model. Focusing on algorithmic details, this paper does not offer high-level insights on cyber-warfare. Chen et al.[8] introduced a practical framework for governments that, utiliz- ing various parameters, rapidly determines whether the attacker’s exploitation of a vulnerability or patching it would yield greater benefits. If a country’s sys- tems are affected or if the manufacturer is located within the territory of that country, patching becomes significantly more cost-effective. Another important finding (in line with [17]) is that technically inferior countries are more likely to opt for publicly disclosing the vulnerability. Finally, Wang et al. focused on a two-player two-stage conflict [27], where one player can both invest into attack- ing and stockpiling in the first stage, while it can also use the stockpile created in the second stage; the other player defends in both stages. The paper studied how players managed the trade-off in exerting their efforts across the two peri- ods depending on asset valuations, asset growth, time discounting, and contest intensities. As opposed to the related literature, we analyze simple two-player cyber- warfare games inspired by [17] and focus exclusively on the impact of alliances. This approach enables us to i) compare to a baseline without alliances and ii) isolate the effect of alliances, adding a new dimension to the strategic under- standing of cyber-warfare situations. 2.3 Weighted voting Weighted voting is a crucial mechanism for making collective decisions [18], especially in environments where various stakeholders have differing levels of ex- pertise, resources, and risk exposure. Weighted voting assigns different weights to the votes of different participants, reflecting their relative importance, ex- pertise, or investment in the outcome [25]. In the context of (cyber) alliances, such mechanisms are widely used to establish the joint decisions of the member states. Terminology. Each entity casting a vote is called a Player in the election. They’re often denoted as P1,P2,P3,...,PN where N is the total number of voters. A player is given a Weight, which represents how many votes they get. The Quota is the minimum aggregated weight needed for the votes to be approved; the quota must be larger than 50% and not larger than 100% of the total number of votes. The Coalition is a group of players who voted in the same way. A coalition is a Winning coalition if it has enough weight to reach the quota. A Player is Critical if the coalition loses the vote without them. A weighted voting system is often represented in a shorthand form: [q:w1,w2,w3,...,wN]. In this form, q is the quota, while wi is the weight of Player i. Power relations. Players of different powers may fall into distinct categories of importance. A player is a Dictator if their weight is equal to or greater than the quota. A player has Veto power if their support is essential to reach the quota. Finally, a player is a Dummy if they are never essential to reach the quota. In general, the power of a player can be characterized by the Banzhaf Power Index The Cyber Alliance Game: How Alliances Influence Cyber-Warfare 5 that determines the proportion of all winning coalitions where the given player is critical, analogously to the Shapley-Shubik index in cooperative games [24]. 3 The Cyber Alliance Game Cyber conflicts entail the risk of escalation, but they also present a completely new opportunity for the aggressor. If there is reason to believe that escalation is unlikely, cyber conflicts offer an opportunity to increase the influence of nation- states. During the strategic decision-making process, the cyber commander must leverage their belief in the likelihood of the adversary exploiting a specific vul- nerability. The statutes of most alliances condemn private actions and may even introduce sanctions against members, tarnishing the reputation of the alliance. Nevertheless, the members of these alliances are diverse, autonomous entities driven by entirely different objectives and motivations. Below, we define the Cyber Alliance Game (CAG); our investigation revolves around how the alliance environment influences the decisions of two opposing nation-states belonging to different alliances. The model deals with the costs and benefits of exploiting or sharing vulnerabilities without considering the outcomes of an actual conflict; as such, CAG is inspired by the Cyber Hawk game and adopts its base parameters (p and q, see later) and mechanics regarding how the game is played [17]. The game is played by two players who are members of two different alliances. 3.1 Strategies and game mechanics Each player can choose from two strategies. Attack. The player discovers a vulnerability and develops an exploit from it but keeps it secret from the alliance (and the world). An attack is considered successful when a player discovers a vulnerability and uses it before any other player does. The reward for being the first to launch a successful attack is 1, while being subjected to an attack results in a cost of -1, making this a zero-sum strategy. Share. The player discovers a vulnerability and shares it with their allies. The alliance then decides whether to develop an exploit and collectively utilize it or to forward it to the vendor [8]. To preserve clarity, decision-making after sharing the vulnerability is omitted from CAG. The first player who shares a specific vulnerability with their alliance receives a payout; the alliance’s reward to the Player. In this situation, the other player receives a payout of 0, making sharing a non-zero-sum strategy. Using Fig. 1, we illustrate the mechanics of the game. Decision nodes are represented by circles, and leaf nodes by rectangles. Nodes can be labeled with either the letter “C” for chance or the number of the player. A numbered node and its children have two edges labeled “A” for Attack and “S” for Share, denot- ing the two possible moves. The edges between chance nodes and their children are labeled with probabilities. At the leaves of the tree, the first number in the 6 G. Benk˝o, G. Bicz´ok rectangle represents the payoff for Player 1, while the second number represents the payoff for Player 2. The game starts at the root of the tree, indicated by a double circle. 3.2 Game parameters Three parameters influence the payoffs and, thus, the equilibrium of CAG. These are the following: p. The parameter p takes a value between 0 and 1 and measures the player’s technical savvy in discovering vulnerabilities. The value of 1 −p represents the technical sophistication of the other player. Smaller values of p indicate that Player 1 is less sophisticated than Player 2, while larger values indicate the opposite. If the two players are evenly matched, then p = 0.5. CAG interprets p as the probability of discovering a new vulnerability. q. The parameter q measures the willingness of each player to launch an attack after discovering a vulnerability. Its value ranges from 0 to 1 and indicates how aggressive a player is. The value of 1 −q represents the attack willingness of the other player. Smaller values of q indicate that Player 1 is more restrained in launching attacks, while larger values indicate that Player 1 is “trigger-happy”. If the two players are evenly matched, then q = 0.5. Ri. The Ri value represents the alliance’s reward to a member who shared a valuable vulnerability. The value of Ri also falls between 0 and 1. In real-world scenarios, various factors can affect the magnitude of alliance rewards, such as the exploitability of the vulnerability or the number of affected systems. By introducing this reward, CAG becomes a non-zero-sum game (unlike the Cyber Hawk game) and enables modeling the influence of the alliance environment on the player’s decision regarding the discovered vulnerability. Fig. 1: Cyber Alliance Game in extensive form The Cyber Alliance Game: How Alliances Influence Cyber-Warfare 7 3.3 Payoffs To find a Nash equilibrium, we need to determine the payoff for each player for every possible strategy profile. A strategy profile is referred to as the pair (S1, S2), where S1 represents the first player’s strategy, and S2 represents the second player’s strategy. The corresponding expected payoffs are denoted as ui(S1, S2). The expected payoffs are determined following the game mechanics. At nodes labeled with “C”, the probability of reaching a specific child is associated with the value on the corresponding edge. At numbered nodes, the respective player must choose between the actions Attack (A) and Share (S). After making the choice, the game proceeds along the edge labeled with the chosen action. Leaf nodes signify the end of the game: the players receive the payoff specified in the leaf. Let’s determine the payoff for Player 1 when it chooses Attack (A), and their opponent chooses Share (S): u1(A, S). The game starts at the root, which is the node v1. Initially, the game proceeds along the left branch with a probability of p. Upon reaching the node v2, Player 1 is faced with a decision and chooses to Attack (A). After this choice, we arrive at the chance node v3, where the game ends with a probability of p. In this case, the first Player receives a payoff of 1. Otherwise, With a probability of 1 −p, Player 2 rediscovers the vulnerabil- ity, leading to node v4. At node v4, the Player 2 chooses the Share (S) action, resulting in a payoff 0 for the first Player. Thus we get: u1(A, S) = p · (p ∗1 + (1 −p) · 0) + (1 −p) · 0 = p · (p · 1) = p2 Note that at the root node, Player 2 discovers the vulnerability first with probability 1−p; in this case, the game progresses along the right branch instead. It is important to emphasize that player nodes belong to two distinct infor- mation sets (v2 and v8 versus v4 and v6, see the dashed lines in Fig. 1). Owing to imperfect information, a player does not know which exact node they are at inside their own information set; they do not know whether they are the first to discover a specific vulnerability. Following the method above, we determine the expected payoff for each strat- egy profile: u1(A, S) = p2 u1(S, A) = −p2 + 2 · p · R1 + 2p −p2R1 −1 u1(S, S) = p · R1 u1(A, A) = 2p2 + 4pq −4p2q −1 u2(A, S) = −p2 −p2R2 + R2 u2(S, A) = (1 −p)2 u2(S, S) = (1 −p) ∗R2 u2(A, A) = −2p2 −4pq + 4p2q + 1. 8 G. Benk˝o, G. Bicz´ok P1/P2 S A S 0.42,0.18 0.428,0.16 A 0.36,-0.072 0.008,-0.008 Table 1: CAG payoffs, p = 0.6, q = 0.3, R1 = 0.7, R2 = 0.45. Fig. 2: Left: R1=0.1, R2=0.1; Mid: R1=0.75, R2=0.75; Right: R1=0.25, R2=0.75 Note that in the case of the (A, A) strategy profile, the expected payoff de- pends on who attacks first (Player 1 with a probability of q and Player 2 with a probability of 1 −q). Afterward, we can represent the game in a 2-by-2 matrix format (see Table 1). In the example, we use the following parameter values: p = 0.6, q = 0.3, R1 = 0.7, R2 = 0.45. 3.4 Equilibrium analysis Similarly to [17], we utilize simple (pure strategy) Nash Equilibrium (NE) as our solution concept (as opposed to more involved sequential equilibrium con- cepts [15]). We can do this because a strategy in an extensive-form game with imperfect information is a function that maps information sets to actions; in fact, all the nodes in an information set have identical available actions. In CAG, this means that a player’s strategy is either A or S, and the same action is played in either node of a given player. In CAG, there are three parameters, each of which can take a value between 0 and 1. For solving and visualizing CAG instances, we wrote a Python script2. Specifically, we generate NE diagrams where the x-axis represents p, the y-axis represents q, and the Ri values are fixed according to various criteria. If both players receive equally low rewards from their alliance for sharing the discovered vulnerability, they tend to choose attack for a wide range of (p,q) val- ues (left plot in Fig. 2). As rewards go towards zero, CAG essentially transforms into the Cyber Hawk game [17]. Moreover, if the players’ technical proficiency (p) and aggressiveness (q) are similar, they both opt for attack (orange), result- ing in a risk of conflict escalation. Since most real-world alliances are defensive, it is in their best interest to offer high(er) rewards for vulnerability sharing to maintain peace. 2 Available at https://anonymous.4open.science/r/cyberwar-8F21/ The Cyber Alliance Game: How Alliances Influence Cyber-Warfare 9 As we begin to concurrently increase the rewards above a value of 0.5, the (S,S) equilibrium emerges (blue), promoting sharing in case of similar technical proficiency p (middle plot in Fig. 2). As we approach maximum symmetric re- wards, states will share vulnerabilities for any (p,q), trusting the alliance with the ultimate decision concerning a cyberattack. If alliance rewards are highly asymmetric, the player with the higher reward is more likely to play S, while the under-rewarded player will attack (red (A,S) NE, the right plot in Fig. 2). Note that the behavior of an alliance member can be predicted from the alliance’s rewards. This enables the other player (if familiar with this information) to optimize its own payoff; treating rewards as top-secret is advised. 4 The Cyber Alliance Game with Power Structure Our base game did not include the power distribution among the members of a given alliance. To illustrate the influence of allies, we will use the previously presented weighted voting system and the Banzhaf Power Index. Alliances are considered static, i.e., players in our model cannot change their weight value. In the present model, we differentiate between two types of alliances for visu- alization purposes: Dictatorial and Democratic. This allows us to examine the behavior of players with similar and significantly different alliance backgrounds. The dictatorial alliance is composed of a single Dictator and multiple Dum- mies such as [10 : 11, 2, 2, 2]. The number and weight of Dummy members in the dictatorial alliance do not significantly change the voting mechanism, as the Dummy players always make decisions in line with the Dictator’s interests. In the Democratic alliance, chosen to be [20 : 5, 5, 5, 5], each player has Veto power. Naturally, an alliance might have many members and unequal weights; never- theless, even with such changes, the behavioral characteristics typical of Veto players remain consistent with the presented findings of this study. 4.1 Parameters The meaning of parameters p, q, and Ri remain consistent with their definitions in the base game. We introduce a new parameter Bi to measure Player i’s influ- ence within the alliance. The value of Bi ranges from 0.1 to 1.5, and it appears as a multiplier alongside the Ri parameter in the payoff function. This captures the impact of how much the Player is capable of influencing the decision regarding the use of the vulnerability after sharing it with the alliance. Bi is calculated using the following formula: Bi = 1.4 · Pi + 0.1, where Pi is the Banzhaf Power Index. The addition of the 0.1 value is necessary due to the Dummy Players, as a Dummy Player has a 0 power index, thus it would lose any sharing reward which is not realistic. In the case of a Dictator, it results in a maximum reward increase of +50% when sharing with the alliance. For Veto players, it implies a moderate decrease because, in a Democratic alliance, all players must decide the fate of the vulnerability in the same way; accounting for the possibility that the alliance 10 G. Benk˝o, G. Bicz´ok Fig. 3: Left: Veto vs. Veto, R1=R2=0.9; Mid: Dict. vs. Veto, R1=R2=0.5; Right: Veto vs. Dummy, R1=0.9, R2=0.5. may make a decision unfavorable to the Veto player. If a Dummy player shares the vulnerability, they have very little influence over their subsequent fate and must execute the Dictator’s decision, which results in losing 90% of the reward. 4.2 Equilibrium analysis Veto vs. Veto (Democratic vs. Democratic). If two Veto players from different democratic alliances face each other, one player will almost always find sharing with the alliance to be profitable (left plot in Fig. 3). Therefore, the (S,A) (green) and (A,S) (red) strategy profiles dominate when alliances reward their members appropriately. In our setting, each member’s power index is Pi = 0.25; however, real-world alliances can have various compositions. In general, the higher a player’s power index, the lower the reward needs to be provided by the alliance for sharing. Dictator vs. Veto (Dictatorial vs. Democratic). In a standoff between a Dictator and a Veto player, the Veto player frequently opts for Attack, while the Dictator almost always chooses to share with the alliance (green area, middle plot in Fig. 3)). By increasing the reward for the Veto Player, the democratic alliance can make it less likely that the player will attack. Veto vs. Dummy (Democratic vs. Dictatorial). In the case of a Veto and Dummy player, it is not surprising that the Dummy prioritizes the Attack strat- egy. By increasing the reward for the Veto player, we can avoid the occurrence of the (A,A) strategy profile in cases of nearly identical technological development and aggressiveness. Naturally, increasing the reward for the Dummy player does not have an impact: it only chooses Sharing if both its technical sophistication and aggression are much lower compared to the Veto player (red area, right plot in Fig. 3 ). Dummy vs. Dummy (Dictatorial vs. Dictatorial). If two Dummy players from different dictatorial alliances face each other, the alliance’s reward practi- cally does not matter, regardless of how large it may be. In a dictatorial alliance, once a Dummy has shared its vulnerability, it can no longer have a say in how it will be handled going forward. Therefore, Dummies with balanced technological development and aggressiveness will find the all-attack (A,A) strategy profile optimal. The Cyber Alliance Game: How Alliances Influence Cyber-Warfare 11 Fig. 4: Left: Dict. vs. Dict., R1=0.9, R2=0.2; Right: Dict. vs. Dummy, R1=0.55, R2=0.4 Dictator vs. Dictator (Dictatorial vs. Dictatorial). When two leaders of dictatorial alliances face each other, even with moderate but symmetric re- wards, they almost always choose to share their discovered vulnerability with their alliance. This is because they alone decide the fate of vulnerability, and the members of the alliance are obliged to accept the directive. The (S,A) pro- file is optimal if R2 is low, and player 2 is not lagging much behind regarding technological development (green area, left plot in Fig. 4). Dictators only choose the (A,A) strategy profile against each other in the case of insufficient sharing incentives from their alliance. Dictator vs. Dummy (Dictatorial vs. Dictatorial). In situations where a Dictator and a Dummy from a different alliance are clashing, it is not surprising that the Dummy will typically choose to initiate the attack, while the Dictator, even in the presence of a moderate reward, will share the vulnerability with its alliance (green area, right plot in Fig. 4). Only in extreme cases, when the Dic- tator possesses overwhelming technological superiority and high aggressiveness, will the Dummy choose to share the vulnerability with its alliance. Summary. Their influence within their alliance greatly influences a player’s be- havior in specific decision-making situations. Knowing a player’s power position allows for more accurate prediction of their behavior in a cyber-conflict. Dictators wield total power within their own alliance. Discovered vulnerabili- ties are shared with the alliance at a very high rate, and attacks are chosen only in rare instances, as the alliance is leveraged to achieve the Dictator’s objectives. Consequently, most other players find aggression to be the most appropriate response when facing a Dictator. An exception to this is when the Dictator pos- sesses overwhelming technical and/or aggressiveness superiority. Therefore, if a Dictator wishes to avoid continuous attacks, they must demonstrate their su- periority and/or aggressiveness at significant real-world financial expenditures. This is in line with the behavior of dominant leaders in both human society and the animal world. Veto Players are driven by sharing rewards from their Democratic alliance. In case of low rewards, Veto Players are more likely to attack. Between Veto 12 G. Benk˝o, G. Bicz´ok players, the (S,A) or (A,S) strategy profiles often represent an NE, reducing the likelihood of conflict escalation. Veto players with lower power might have to be compensated excessively by their alliance in order to choose not to attack. Dummy players have no influence on alliance decisions; they essentially exe- cute the decisions of the Dictator within the alliance. Consequently, in the vast majority of cases, Dummy players choose to attack. In fact, a Dummy may be better off outside the alliance (regarding cyber-conflicts) if they are technologi- cally advanced (an unlikely situation). 5 Incorporating alliance policy Alliances, in addition to the rules and guidelines outlined in their founding docu- ments, are typically governed by numerous internal regulations and agreements. When an alliance admits a new member, the new member must adopt the al- liance’s guidelines and values. If this does not occur, the behavior of the alliance member reflects on the entire alliance, meaning that, e.g., launching an individ- ual cyberattack could potentially affect all members negatively. In order to avoid such inefficiency, alliances strive to nudge members towards closer cooperation or deter them from violating the rules. In the second extension of our model, we introduce the alliance’s policy, which is another tool at the alliance’s disposal to influence the decisions of its members. 5.1 Alliance posture In modern times, most alliances have had a defensive orientation. Their objective is not to initiate joint offensives but rather to deter enemies by demonstrating strength [12]. Nevertheless, we must not disregard alliances with an offensive orientation, which may arise along the lines of common interests in the event of a potentially escalated conflict or an already ongoing cyberwar. The defensive alliance aims to deter its members from deviating from the alliance’s guidelines, in this case, deterring from exploiting a vulnerability for individual gain rather than sharing it with the alliance. Therefore, the alliance applies a penalty in the event of an attempted attack, thus reducing the payoff of the deviating member state. On the other hand, the offensive alliance eval- uates the actions of its members, as this type of alliance typically forms during an ongoing or emerging conflict. Therefore, the offensive-oriented alliance also rewards successful attacks. 5.2 Parameters The meaning of parameters p, q, Ri, and Bi remain consistent with their def- initions established in the Cyber Alliance Game with Power Structure. We in- troduce a new parameter Ei that conveys the alliance’s punishment/reward on the payout generated by an individual cyberattack. For an offensive alliance, the values of Ei can range from 1.1 to 1.6 (reward), while for a defensive alliance, The Cyber Alliance Game: How Alliances Influence Cyber-Warfare 13 Fig. 5: Cyber Alliance Game with both power and policy structure in extensive form Fig. 6: Left: Defensive Dictator vs. Defensive Dictator ; Right: Defensive Dictator vs. Offensive Dictator this value ranges from 0.9 to 0.4 (penalty), i.e., a reward or penalty of ±10% to ±60%. Note that these value sets were determined only for demonstration purposes. The resulting extended game tree is shown in Fig. 5. 5.3 Equilibrium analysis Dictator vs. Dictator. In the case of Dictators, we could see in the first extension that sharing with the alliance often represents the most profitable decision for the players; they alone can decide as Dictators about the further fate of the vulnerability while also pocketing some sharing rewards. Therefore, the punishment for an attack in the case of a Dictator only encourages more sharing with the alliance (see the left plot in Fig. 6). In contrast, influencing the Dictator’s decision is possible with the reward for the attack. If the attack is sufficiently rewarded and the sharing reward of the alliance is low, then the 14 G. Benk˝o, G. Bicz´ok Fig. 7: Left: Defensive Dummy vs. Defensive Veto; Right: Defensive Dummy vs. Offensive Veto Fig. 8: Left: Defensive Dummy vs. Defensive Dummy; Right: Offensive Dummy vs. Defensive Dummy Dictator Player is more likely to attack, especially when being technologically more advanced than its enemy (red area, right plot in Fig. 6). Veto vs. Dummy. The actions of Veto players can be influenced to the greatest extent by the reward or punishment for an attack. Through the reward for sharing and the reward/punishment for an attack, the alliance is almost fully capable of controlling the decisions of Veto members in certain situations. With a low reward for sharing and a high reward for attacking, Veto Players can be encouraged to attack, while punishing the attack and rewarding high sharing can persuade them to cooperate with the alliance (see Fig. 7). Note that we chose to show Dummy vs. Veto to isolate the effects of alliance policy on the Veto player. Dummy vs. Dummy. As we have seen earlier, Dummy Players most often choose to attack because sharing their discovered vulnerability with the alliance brings them very little benefit. They have no influence over how the vulnerabil- ity is utilized, and as members of the alliance, they must accept the decision. Therefore, Dummies can be best persuaded to cooperate with the alliance via a stringent penalty for attacking. However, an all-sharing equilibrium emerges The Cyber Alliance Game: How Alliances Influence Cyber-Warfare 15 very rarely (see Fig. 8), as at least one of the Dummies will achieve a higher payoff attacking (with the exception of very high attack penalties). Summary. Changing the payout for attacks is a useful tool for alliances to influence the decisions of their members in certain situations. Dictators in an offensive-oriented alliance are more likely to attack than in a defensive alliance. Veto players can be greatly controlled by the alliance’s ability to change the pay- out for attacks. Dummies can be encouraged to cooperate based on punishments for attacks. By influencing the payout for attacks, alliance members are more exposed to the influence of their alliance. In a dictatorial alliance, the Dictator can shape the decisions of Dummy players according to their preferences. If the alliance provides a low reward for sharing but supports attacking, Dummy players will invariably choose the attack. On the contrary, with high attack penalties and high alliance rewards, they will choose to share. Thus, Dummy players are even more dependent on the will of the Dictator in such situations. 6 Conclusion The Cyber Alliance Game demonstrates that alliances can incentivize their mem- bers to cooperate with the alliance through rewards, as cooperation without such incentives would only occur in extreme cases, given that advantages achievable through attacks are only possible through payouts. However, members may have varying degrees of influence within the alliance. Introducing the concept of power to The Cyber Alliance Game with Power Structure, derived from the Banzhaf Power Index, allows us to model the differences among members. Dictator, Veto, and Dummy players have unique roles and fates within the life of an alliance, which can be exploited by either the opposing parties or the allies themselves. Ultimately, by considering the possibility of changing the payouts resulting from attacks, alliances can exert even greater control over their members. Defensive and offensive alliances could change the default behavior of their member states to the alliance’s own benefit by punishing or rewarding individual attacks. In real life, knowing the opponent well, understanding how their alliance operates, and their position within the alliance can help predict the decisions of a given nation-state. 6.1 Democratic defensive alliances In a Democratic alliance, the majority of members respond well to alliance re- wards and punishments, making defensive behavior sustainable for almost every member in practice. The alliance democratically decides on the exploitation of vulnerabilities, making vulnerability sharing favorable for members. Such an alliance is most useful during peacetime, as the balance can be maintained by adjusting reward parameters. If members engage in too many individual actions, the trend can be reversed by increasing penalties for attacks and/or increasing 16 G. Benk˝o, G. Bicz´ok rewards for sharing. On the other hand, if members share vulnerabilities exces- sively, meaning they do not carry out individual actions and overly direct their local problems toward the alliance globally, there is an opportunity to reduce the punishment for attacks. During peacetime, maintaining and joining the Democratic Defensive alliance is the optimal decision for a Veto player. The power values of Veto players may vary a little but not much; consequently, the alliance’s response to changes in rewards and punishments is almost uniform, rendering the alliance predictable. The behavior of alliance members formed by Veto players can be shifted towards a higher proportion of sharing and a higher proportion of attacks, although this incurs relatively high costs for the alliance. Therefore, Veto players in Demo- cratic alliances respond well to changes in parameters, but the alliance may only divert them from their individually preferred behavior with very high rewards or punishments; this strengthens the sovereignty of member states. 6.2 Dictatorial offensive alliances The formation of a Dictatorial Offensive alliance is usually advisable in cases of pre-existing conflicts. The alliance founder is typically the Dictator, who gathers weaker members into the alliance. Since members do not receive high rewards through sharing, they will constantly choose to attack, engaging in individual conflicts. In contrast, the Dictator almost always shares vulnerabilities with the alliance, forcing members to act based on the Dictator’s decision. If a Dictator discovers a very large number of vulnerabilities or a critical weakness, it is worth sharing them with the alliance, as this can prompt all members to engage in a large-scale coordinated cyberattack. During peacetime, it is recommended to incentivize Dummy players to bet- ter align with the alliance’s interests. However, this incurs significant costs. To address this, the Dictator must either increase the penalty stakes or, during peace, implement some form of democratization within the alliance, a subject not explored in this paper. Additionally, the Dictator must be vigilant regarding technological advancements or high levels of aggressiveness, as most adversaries would likely target the Dictator, given the knowledge that they almost always refrain from an individual attack. Therefore, the role of the Dictator is highly effective in an established conflict from the Dictator’s perspective but can be prohibitively costly during peacetime. 6.3 Limitations and future work We made several simplifications in order to i) provide tractable models and ii) be able to compare to the baseline Cyber Hawk game [17]. Attacks are always assumed successful, and there is no potential for retaliation against the attacker. The game is myopic, and we restrict the number of players to two. We did not delve into how the alliance generates player rewards, and we did not model the alliance’s decision after a vulnerability was shared. We restricted the alliances to two fixed types, Democratic and Dictatorial, although a mixed form may The Cyber Alliance Game: How Alliances Influence Cyber-Warfare 17 occur with an infinite number of combinations for member count and power index. Furthermore, when it comes to penalties in defensive alliances, we did not consider potential negative payouts or the exclusion of a player from the alliance. In future work, we plan to relax our assumptions and characterize long-sighted equilibria with repeated interactions, the potential for retaliation, heterogeneous alliances, and dynamic alliance posture. Acknowledgements. This work has been funded by Project no. 138903, imple- mented with the support provided by the Ministry of Innovation and Technology from the National Research, Development, and Innovation Fund, financed under the FK 21 funding scheme. Appendix A Real-world cyber-warfare Cyberattacks can be broadly categorized into two types: they could target mil- itary or civilian objects. Military targets entail the leadership and command of armed forces, as well as weapon guidance systems. Civilian targets encompass critical infrastructure, administrative systems, banking systems, the private sec- tor, and high-ranking political or economic leaders. In the current Ukrainian conflict, we are witnessing an unprecedented, prolonged, intensive cyberwar be- tween two nation-states; even involving civilian volunteers in the operations. In the following, we will examine the largest cyberattacks against civilian targets during the Russo-Ukrainian war. Ukraine power grid. In December 2015 and again in December 2016, Ukraine’s electrical grid experienced severe cyberattacks [6]. In both instances, the Super- visory Control and Data Acquisition (SCADA) system of the electricity trans- mission company was targeted. While the infrastructure of the electrical network was not physically harmed during the attack, approximately 200, 000 people were left without service for several hours. Due to their long lifespan, SCADA systems often carry unpatched vulnerabilities and become targets of attacks [1]. Kyivstar. The largest cyberattack in the telecommunications sector was suf- fered by Kyivstar [22]. The company, which had 24 million users, saw its phone and internet services and website become completely inaccessible due to the attacks. In some areas, even air raid alert systems became inoperative. Ad- ditionally, the attackers caused significant damage to the company’s systems, particularly concerning cloud-based virtual environments. VTB. Russia’s second-largest bank, VTB, was subjected to the largest DDoS attack in history3, during which most of its services, including the mobile app and website, became inaccessible. The company issued a brief statement informing its customers about the attack originating from “abroad”. 3 https://www.reuters.com/business/finance/russian-state-owned-bank-vtb- hit-by-largest-ddos-attack-its-history-2022-12-06/ 18 G. Benk˝o, G. Bicz´ok IPL Consulting. Russia’s largest and most advanced company specializing in the implementation of industrial IT systems was hit by a cyberattack 4. The attackers infiltrated the company’s IT systems, destroyed vast amounts of data, and rendered numerous servers and services inoperative. The company’s clients include major companies in the automotive, aerospace, and defense industries. B (Cyber-)alliances To complicate matters, most countries are part of some form of military or eco- nomic alliance. These alliances usually have strict admission criteria, internal rules, and a common purpose. The primary objectives of these alliances used to be defensive. Once a nation-state becomes a member of an alliance, it represents both its own interests and those of the alliance through its actions and behavior. If a member is under attack, the other members typically come to their aid ac- cording to internal regulations. Earlier, during collaborations, members aligned their military and economic objectives, and nowadays, a common cyber defense strategy has also been implemented in most alliances, blurring the lines between military and other alliances. The alliances presented below effectively demon- strate the diverse objectives, power structures, and internal regulations they can operate with. European Union. The European Parliament, the Council of the European Union, and the European Commission form the legislative branch of the al- liance. The EU has been advocating for harsh sanctions against cybercrime, the detection of abuse of non-paper-based payment instruments, the introduction of quantum encryption, as well as joint research and knowledge sharing [9]. A recent barrage of new cybersecurity-related regulations, including the Network and In- formation Security (NIS2), the Digital Operational Resilience Act (DORA), the Cyber Resilience Act (CRA), and others [26], compulsory to adopt in member states, ensure that cybersecurity (including building defensive capacity against cyberattacks, swiftly patching vulnerabilities, and reporting cyber-incidents to the national and EU authorities with a short deadline) is a first-order priority. BRICS+. In 2006, Brazil, Russia, India, and China created the “BRIC” al- liance. The group was designed to bring together the world’s most important developing countries and challenge the political and economic power of the wealthier nations of North America and Western Europe. Since its founding, 5 additional countries have joined the alliance, now referred to as BRICS+, with several other prospective members and interested countries. The economic al- liance encompasses more than 44% of the world’s population and over 28% of the world’s economic power. The member countries, within the framework of the CyberBRICS project [5], aim to create a uniformly structured and secure cyberspace. CyberBRICS is an international research project with three main areas: protection of personal data, secure digital transition, and regulation of artificial intelligence [10]. 4 https://kyivindependent.com/military-intelligence-claims-cyberattack- on-russian-defense-ministry-gave-access-to-classified-documents/ The Cyber Alliance Game: How Alliances Influence Cyber-Warfare 19 North Atlantic Treaty Organization (NATO). As the military alliance with the most member countries, NATO has prioritized the importance of infor- mation systems defense [13]. In 2012, NATO decided to centralize the protection of all communication networks within the alliance. Following a decision in 2016, NATO began to intensify its cooperation with the private sector, leading to the inclusion of “NATO-compatible” products among the top-tier offerings of most major manufacturers. The highest political decision-making body is the North Atlantic Council, where each member country is represented. Decisions affecting the operation of the alliance, such as admitting a new member, require the consent of every member country. However, the level of technological ad- vancement, the number of experts, the amount of resources allocated, etc., vary significantly across nations, resulting in widely differing power positions within the alliance. The alliance employs a policy of deterrence through cyber exercises and enhancing their capabilities [11]. Collective Security Treaty Organization (CSTO). The CSTO is a military alliance consisting of five former Soviet successor states alongside Russia. The organization’s operations, regulations, and guidelines have received less publicity compared to NATO [11]. Article 4 of the CSTO charter adopted in 2002 states that if one of the Member States undergoes aggression (armed attack menacing to safety, stability, territorial integrity, and sovereignty), it will be considered by the Member States as aggression to all the Member States of this Treaty. Neither the Article nor other agreements address how the alliance handles cyberattacks. Generally speaking, the organization pays significant attention to the develop- ment of cyber capabilities and the use of “hybrid technologies”. Additionally, there is a significant willingness for cooperation among the countries to combat domestic cybercrime and impose stricter cyber hygiene. Five Eyes. The alliance consisting of 5 Anglo-Saxon countries is one of the most successful intelligence cooperations since World War II [28]. The main area of cooperation among the countries is Signals Intelligence (SIGINT), within which they share information collected from adversarial countries. The key to successful collaboration is global reach, high technological readiness, similar legal systems, and, last but not least, a common language and culture. In most cases, the members follow and adhere to decisions made by their allies in a predictably disciplined manner. However, certain steps can cause tension and even public debate among the member countries. Recently, a divisive issue was the restriction of products from Chinese companies Huawei and ZTE [23]. References 1. Alanazi, M., Mahmood, A., Chowdhury, M.J.M.: Scada vulnerabilities and attacks: A review of the state-of-the-art and open issues. Computers & security 125, 103028 (2023) 2. Allodi, L.: Economic factors of vulnerability trade and exploitation. In: Proceedings of the 2017 ACM SIGSAC conference on computer and communications security. pp. 1483–1499 (2017) 20 G. Benk˝o, G. Bicz´ok 3. Bao, T., Shoshitaishvili, Y., Wang, R., Kruegel, C., Vigna, G., Brumley, D.: How shall we play a game?: A game-theoretical model for cyber-warfare games. In: 2017 IEEE 30th Computer Security Foundations Symposium (CSF). pp. 7–21 (2017). https://doi.org/10.1109/CSF.2017.34 4. Beckmann, K.B., Reimer, L.: Dynamics of military conflict: an economics perspec- tive. Review of Economics 65(2), 193–215 (2014). https://doi.org/doi:10.1515/roe- 2014-0205, https://doi.org/10.1515/roe-2014-0205 5. Belli, L.: CyberBRICS: Cybersecurity regulations in the BRICS countries. Springer Nature (2021) 6. Case, D.U.: Analysis of the cyber attack on the ukrainian power grid. Electricity Information Sharing and Analysis Center (E-ISAC) 388(1-29), 3 (2016) 7. Caulfield, T., Ioannidis, C., Pym, D.: The us vulnerabilities equities process: An economic perspective. In: Decision and Game Theory for Security: 8th Interna- tional Conference, GameSec 2017, Vienna, Austria, October 23-25, 2017, Proceed- ings. pp. 131–150. Springer (2017) 8. Chen, H., Han, Q., Jajodia, S., Lindelauf, R., Subrahmanian, V., Xiong, Y.: Dis- close or exploit? a game-theoretic approach to strategic decision making in cyber- warfare. IEEE Systems Journal 14(3), 3779–3790 (2020) 9. Christou, G.: The challenges of cybercrime governance in the european union. European Politics and Society 19(3), 355–375 (2018) 10. CyberBRICS: Cyberbrics: Policies and practices for cybersecurity and digital gov- ernance. https://cyberbrics.info/, accessed: 2024-06-24 11. Elamiryan, R., Bolgov, R.: Comparing cybersecurity in nato and csto: Legal and political aspects. In: GigaNet: Global Internet Governance Academic Network, Annual Symposium (2018) 12. Hoag, M.W.: Nato: Deterrent or shield? Foreign Affairs 36(2), 278–292 (1958), http://www.jstor.org/stable/20029283 13. Hunker, J.: Cyber war and cyber power. Issues for NATO doctrine (2010) 14. Hunt, K., Zhuang, J.: A review of attacker-defender games: Current state and paths forward. European Journal of Operational Research 313(2), 401–417 (2024). https://doi.org/https://doi.org/10.1016/j.ejor.2023.04.009, https://www. sciencedirect.com/science/article/pii/S0377221723002916 15. Kreps, D.M., Wilson, R.: Sequential equilibria. Econometrica 50(4), 863–894 (1982), http://www.jstor.org/stable/1912767 16. Merrick, K., Hardhienata, M., Shafi, K., Hu, J.: A survey of game theoretic ap- proaches to modelling decision-making in information warfare scenarios. Future Internet 8(3) (2016). https://doi.org/10.3390/fi8030034, https://www.mdpi.com/ 1999-5903/8/3/34 17. Moore, T., Friedman, A., Procaccia, A.D.: Would a’cyber warrior’protect us: ex- ploring trade-offs between attack and defense of information systems. In: Proceed- ings of the 2010 New Security Paradigms Workshop. pp. 85–94 (2010) 18. Nordmann, L., Pham, H.: Weighted voting systems. IEEE Transactions on Relia- bility 48(1), 42–49 (1999) 19. Ozment, A., Schechter, S.E.: Milk or wine: does software security improve with age? In: USENIX Security Symposium. vol. 6, pp. 10–5555 (2006) 20. Rescorla, E.: Is finding security holes a good idea? IEEE Security & Privacy 3(1), 14–19 (2005) 21. Robinson, M., Jones, K., Janicke, H.: Cyber warfare: Issues and challenges. Com- puters & security 49, 70–94 (2015) 22. Santora, M.: Huge cyberattack knocks ukraine’s largest mobile operator offline. The New York Times (Digital Edition) pp. NA–NA (2023) The Cyber Alliance Game: How Alliances Influence Cyber-Warfare 21 23. Shoebridge, M.: Chinese cyber espionage and the national security risks Huawei poses to 5G networks. Macdonald-Laurier Institute for Public Policy (2018) 24. Strafiin Jr, P.D.: The shapley—shubik and banzhaf power indices as probabilities. The Shapley value: essays in honor of Lloyd S. Shapley p. 71 (1988) 25. Tran, C.D.: Math C100: Liberal Arts Mathematics. Coastline College (2024) 26. Vandezande, N.: Cybersecurity in the eu: How the nis2-directive stacks up against its predecessor. Computer Law & Security Review 52, 105890 (2024) 27. Wang, G., Welburn, J.W., Hausken, K.: A two-period game theo- retic model of zero-day attacks with stockpiling. Games 11(4) (2020). https://doi.org/10.3390/g11040064, https://www.mdpi.com/2073-4336/11/4/64 28. Wells, A.R.: Between Five Eyes: 50 Years of Intelligence Sharing. Casemate Pub- lishers (2020)