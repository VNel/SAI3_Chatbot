Chapter 1 An Introduction of System-Scientiﬁc Approaches to Cognitive Security Linan Huang and Quanyan Zhu Abstract Human cognitive capacities and the needs of human-centric solutions for “Industry 5.0” make humans an indispensable component in Cyber-Physical Systems (CPSs), referred to as Human-Cyber-Physical Systems (HCPSs), where AI-powered technologies are incorporated to assist and augment humans. The close integration between humans and technologies in Section 1.1 and cognitive attacks in Section 1.2.4 poses emerging security challenges, where attacks can exploit vulnerabilities of human cognitive processes, aﬀect their behaviors, and ultimately damage the HCPS. Defending HCPSs against cognitive attacks requires a new security paradigm, which we refer to as “cognitive security” in Section 1.2.5. The vulnerabilities of human cognitive systems and the associated methods of exploitation distinguish cognitive security from “cognitive reliability” and give rise to a distinctive CIA triad, as shown in Sections 1.2.5.1 and 1.2.5.2, respectively. Section 1.2.5.3 introduces cognitive and technical defense methods that deter the kill chain of cognitive attacks and achieve cognitive security. System scientiﬁc perspectives in Section 1.3 oﬀer a promising direction to address the new challenges of cognitive security by developing quantitative, modular, multi-scale, and transferable solutions. Fig. 1.1 illustrates the structure of Chapter 1. Key words: Cognitive Security, Cognitive Reliability, Human-Cyber-Physical Sys- tems, Human-Centered AI, Cognitive Attacks, Cognitive Vulnerability, Cyber Secu- rity, Data Science, System Science, CIA Triad 1.1 AI-Powered Human-Cyber-Physical Systems Cyber-Physical Systems (CPSs) are “smart systems that include engineered interact- ing networks of physical and computational components”, as deﬁned by the National Institute of Standards and Technology (NIST) in 2017 [20]. Despite the increasing automation and intelligence in CPSs, humans play indispensable roles in accomplish- ing CPS tasks, as illustrated by the mission stack in Fig. 1.2. The rapid development 1 arXiv:2301.05920v1 [cs.CR] 14 Jan 2023 2 1 An Introduction of System-Scientiﬁc Approaches to Cognitive Security Cyber-Physical Systems (CPS) AI and Big Data Humans Cognitive Vulnerability Cognitive Attack Mitigation & Defense Section 1.3: System Science (Method) Probability Theory Control Theory Game Theory Simulation Learning Theory Section 1.1: AI-Powered HCPS (Object) Section 1.2: Cognitive Security (Goal) Fig. 1.1: The structure of Chapter 1 concerning AI-powered HCPS in Section 1.1, cognitive security in Section 1.2, and system science in Section 1.3 as the object, goal, and method of this book, respectively. of Artiﬁcial Intelligences (AIs) and big data has facilitated a close integration of AI-powered technologies along with the mission completion, as illustrated by the AI stack in Fig. 1.2. We elaborate on the human-involved mission stack and the AI stack in Sections 1.1.1 and 1.1.2, respectively. Stimulus Behavior Cognitive Process Cyber Process Physical Process AI Stack Mission Stack Externalities AI-Powered Technologies Human-Centered AI Fig. 1.2: The overview diagram of human roles and AI-powered technologies in Cyber-Physical Systems (CPSs). The mission stack at the top illustrates the task- driven ﬂow chart that consists of human, cyber, and physical processes in green, blue, and yellow, respectively. The AI stack at the bottom illustrates the AI-powered technologies that interact with the human-cyber-physical process to assist with mis- sion completion. The AI-powered technologies are designed to be scalable and transferable. In addition, they need to be customized, explainable, ethical, respectful of privacy, and trustworthy to achieve human-centric objectives. 1.1 AI-Powered Human-Cyber-Physical Systems 3 1.1.1 Human Roles in Mission Stack Humans cannot and should not be superseded in CPSs. On the one hand, due to their distinguished cognitive power and analytical capabilities (e.g., logical reasoning, symbolic abstraction, knowledge transfer, understanding others’ intent and emotions, etc.), humans have been playing irreplaceable roles, including determining demands, designing mechanisms, and responding to incidents. On the other hand, the inevitable progress of “Industry 5.0” [9] has reemphasized human-centric solutions to create personalized products, services, and experiences. The increased level of automation aims to support rather than supersede humans. The mission stack in Fig. 1.2 summarizes the system-level integration of hu- man touch with cyber and physical processes, referred to as Human-Cyber-Physical Systems (HCPSs), for mission completion. After a human participant receives a stim- ulus, he processes it and outputs responsive behaviors that inﬂuence the cyber and physical processes. The cognitive process can be aﬀected by externalities related to individual factors (e.g., personality, awareness, and expertise), environmental factors (e.g., workload and stress), and social factors (e.g., peer pressure and culture). Human participants have diﬀerent roles (e.g., users, operators, security analysts, and administrators) in mission completion, and the associated cognitive process can take diﬀerent forms. Some examples are provided as follows. Example 1 End users, including employees and contractors, use the computing facilities of the providers to maintain the corporation’s normal op- erations. For example, the stimulus for employees could be working emails. Their cognitive processes aﬀect the accuracy and timeliness of the phishing1 recognition, which results in either secure behaviors or falling victim to phishing. Example 2 Security analysts investigate alerts in real time for alert triage and response. The alerts, the triage process, and the response are the stim- ulus, the cognitive process, and the behaviors, respectively, in this alert management scenario. 1.1.2 Incorporating AI Stack into Mission Stack The advances in AI have accelerated the automation and smartiﬁcation process in cyber and physical layers, as shown by the blue and yellow double-headed arrows in Fig. 1.2. AI has been widely applied to sensing, control, communication, and data processing in a variety of applications such as biomedical monitoring, robotics systems, and digital twins [48, 42, 21, 15]. In these CPS applications, AI not only serves as a technology for reasoning, planning, learning, and processing, but also enables the manipulation of physical objects. For example, autonomous driving cars 1 Phishing is coined as a combination of the words “password” and “ﬁshing” to describe the practice of tricking Internet users into revealing sensitive data, including passwords. 4 1 An Introduction of System-Scientiﬁc Approaches to Cognitive Security adopt AI to sense the environment (e.g., road condition, weather, and the movement of pedestrians and other cars) and determine the optimal driving setting (e.g., speed, brake, and steer). AI-powered technologies in these CPS applications should be scalable [3] and transferable [38]. Compared to technology-based AI design that enables humans to adapt to the technical system, human-centered AI aims to design systems that are aware of human cognitive processes to augment human perception, cognition, and decision- making capabilities in the rapidly evolving, complex, and uncertain CPS environ- ment. Besides the desirable features of scalability and transferability for AI-powered technologies, we further require human-centered AI to be customized, explainable, ethical, respectful of privacy, and trustworthy. Such requirements are based on a thorough understanding of the human cognitive process and fulﬁlled by designing proper human-assistive technologies (e.g., Human Machine Interfaces (HMIs)), as shown by the down-side and up-side green arrows in Fig. 1.2, respectively. The design of human-centered AI should also be adaptive to CPS applications of diﬀerent functions, features, requirements, and constraints. For example, it is essen- tial for a driving-assistive system to be explainable to facilitate trust and minimize a driver’s decision time to take proper action [6]. Meanwhile, an AI-enabled HMI in the control room of a power grid should feature the following functions [35]: • Supporting eﬃcient invocation and dismissal because the number of actions an operator can do in a time window is limited, especially in a time-constrained environment. • Taking into account and learn from user behavior and feedback because grid operators are well-trained experts, capable of evaluating the assistant’s answers and providing feedback. • Conveying the consequences of user actions because operators may not be able to estimate the risk correctly and timely. 1.2 Cognitive Security in HCPS CPSs have been under threat of various attacks since their emergence. Established on the mission stack and the AI stack illustrated in Fig. 1.2, we incorporate the attack stack and the defense stack in Section 1.2.1 to form the four-stack dissection of HCPS security, as illustrated in Fig. 1.3. After the above panorama of HCPS security, we zoom into the focus of his book, i.e., cognitive process, cognitive vulnerability, cognitive attack, and cognitive security, in Sections 1.2.2, 1.2.3, 1.2.4, and 1.2.5, respectively. 1.2 Cognitive Security in HCPS 5 1.2.1 Attack and Defense Stack Fig. 1.3 illustrates the vertical dissection of HCPS security, including the attack stack and the defense stack in orange and gray, respectively. In the past decade, attacks have evolved to be targeted, intelligent, multi-staged, and multi-phased. The typical life cycle of these attacks consists of the following four stages. In the reconnaissance stage, attackers gather intelligence to determine the attack goal and identify vulner- abilities in the target network. In the planning stage, attackers tailor their strategies to the selected vulnerabilities and choose attack tools. In the execution stage, the attackers deploy the malware to gain an initial foothold, expand access, gain creden- tials, and escalate privilege. Finally, the attack in the exploitation stage exﬁltrates conﬁdential data, interrupts cyber services, or inﬂicts physical damage. The four gray boxes in the defense stack illustrate four defensive courses of action. The prevention stage includes the precautionary and proactive defense methods used in advance of attacks. Intrusion prevention techniques, including ﬁrewalls and demilitarized zones (DMZ), may be ineﬀective, especially for advanced attacks such as Advanced Persistent Threats (APTs). Therefore, intrusion detection and response are necessary to protect against them. The attribution stage includes post-event analysis, threat intelligence acquisition, and an accountability system. Stimulus Behavior Cognitive Process Cyber Process Physical Process AI Stack Mission Stack Attack Stack Defense Stack Reconnaissance Planning Exploitation Execution Externalities Prevention Detection Response Attribution AI-Powered Technologies Human-Centered AI Fig. 1.3: The vertical dissection of HCPS security consists of attack and defense stacks over the mission and AI stacks. The four orange boxes in the attack stack illustrate the typical life cycle of an attack. First, attackers tailor their attack strategies and select attack tools in the planning stage based on the reconnaissance results (e.g., exploitable human and technical vulnerabilities). Then, an attack is launched and inﬂicts damage in the execution and exploitation stages, respectively. As illustrated by the four gray boxes in the defense stack, a typical defense consists of four stages: prevention, detection, response, and attribution. 6 1 An Introduction of System-Scientiﬁc Approaches to Cognitive Security 1.2.2 Feedforward and Feedback Cognitive Processes Fig. 1.4 provides a zoomed-in version of the dynamic cognitive process that consists of feedforward and feedback processes, represented by solid and dashed arrows, respectively. We ﬁrst illustrate the feedforward cognitive process, where the stimulus is the input and the behavior is the output. First, perception [5] decodes and gathers the sensory information from external stimuli. Due to the limited cognitive capacity, attention is used to ﬁlter information and store essential or urgent items in working memory. Then, humans process the information for mental operations, including decision-making, reasoning, and learning, which lead to behaviors. Based on the tasks and scenarios, human mental operations may need to retrieve past experiences that are stored in the Long-Term Memory (LTM) The cognitive process also includes several feedback loops listed below: • Behaviors have an impact on the CPS and change the subsequent stimulus. • Mental operations learn new knowledge and store experience in the LTM. • Besides passively ﬁltering the collected information in the feedforward process, attention also actively aﬀects perception by directing our awareness to relevant stimuli while suppressing distracting information. Such selective attention [29] has been demonstrated in phenomena such as the cocktail party eﬀect [2]. • Selective attention is a result of the mental operations and is usually goal-driven and endogenous (referred to as the top-down attention), compared to the bottom- up attention that is endogenously driven by the stimuli. Behavior Stimulus Mental Operations (e.g., Decision-Making, Reasoning, Learning) Store and Retrieve Information Working Memory Long-Term Memory Process Information Sensation Gather Information Attention Filter Information Cognitive Process Fig. 1.4: A zoomed-in version of the cognitive process that includes sensation, atten- tion, memory, and mental operations. The feedforward path in solid arrows illustrates the information ﬂow of gathering, ﬁltering, storing, retrieving, and processing. In the feedback loops, behaviors alter future stimuli, mental operations aﬀect LTM and attention, and selective attention determines perception, respectively, as illustrated by the dashed arrows. 1.2 Cognitive Security in HCPS 7 1.2.3 Exploitable Cognitive Vulnerability Each component of the cognitive process in Fig. 1.4 possesses distinct vulnerabilities exploitable by attackers. [11] We discuss vulnerabilities concerning perception, at- tention, memory, and mental operations in Sections 1.2.3.1, 1.2.3.2, 1.2.3.3, 1.2.3.4, respectively. 1.2.3.1 Vulnerability of Perception Perception is a complex process that involves visual, auditory, somatosensory, ol- factory, gustatory, and vestibular systems. These systems follow patterns that can be exploited by attackers. For example, knowing the perception limits (e.g., it takes ap- proximately 0.3 and 1 seconds to see and hear a signal, respectively) and contributing factors (e.g., how light, color, and noise aﬀect human perception), attackers can cre- ate environments where humans are prone to perception errors. Human perception systems can sometimes undergo distortions of the senses (e.g., visual and auditory illusions) and produce false sensory information. By understanding the contributing factors and causes of these sensory illusions, attackers can craft phishing websites and emails with fewer identiﬁable phishing indicators. Besides exploitable patterns and illusions, human perception is also susceptible to manipulation. Attacks have adopted many psychological techniques, including prim- ing [37], to manipulate perception in HCPSs. Priming is a well-known phenomenon in psychology wherein the presence of a stimulus impacts how later stimuli are processed or interpreted (e.g., humans recognize the word “food” more quickly after the presentation of the word “kitchen” than the word “oﬃce”) [33]. The majority of priming is positive and increases the sensitivity of the related stimulus, while negative priming [51] slows down the processing speed. Both positive and negative priming can be weaponized for perception hacking. For example, attacks may use positive priming to emphasize certain ideas in phishing or use negative priming to deemphasize the phishing indicators. Based on whether the stimulus is consciously perceptible or not, priming is classiﬁed as supraliminal and subliminal, respectively [16]. Due to its stealthiness, subliminal priming can be a primary candidate for perception hacking. As shown in the experiment results [27], by subtly presenting words or images that are physically or semantically similar to the judgments pre- ferred by the attackers, attackers can inﬂuence the accuracy or false alarm rate of the inspectors. 1.2.3.2 Vulnerability of Attention Attention can be described as an overall level of alertness or ability to engage with surroundings [33]. Humans rely on their attention mechanisms to control their lim- ited computational resources in the brain for the maximum information acquisition. Despite the remarkable success of human attention, it suﬀers from reduced perfor- 8 1 An Introduction of System-Scientiﬁc Approaches to Cognitive Security mance under multitasking, long duration, stress, fatigue, and heavy cognitive load. Moreover, as the result of the selectiveness of our attention to prevent us from get- ting lost in irrelevant information, we can go through failures of selection in space and time. On the one hand, failures of selection in space has been demonstrated in experiments of change blindness [47] and change deafness [52], where observer does not notice a change in a visual and auditory stimulus, respectively. On the other hand, experiments of attentional blink [46] and repetition blindness [31] have shown that failures can occur along with time; i.e., when new information (even of small amount) continues to arrive, processing it leads to the miss of other information. Attacks can exploit these spatial and temporal attentional vulnerabilities either reactively or proactively. Reactive attention attacks exploit inattention to evade de- tection and do not attempt to change human attention patterns. For example, many Social Engineering (SE) and phishing attacks result from a lack of attention. We provide a defense framework against reactive attention attacks in [26]. In contrast, proactive attention attacks aim to strategically inﬂuence human attention patterns. For example, an attacker can generate a large volume of feints and hide real attacks among them to overload human operators, delay their responses, and reduce the ac- curacy of their judgements. We refer to this new form of attacks as the Informational Denial-of-Service (IDoS) attacks and present a formal description of IDoS attacks, their impacts, and associated defense methods in [23]. 1.2.3.3 Vulnerability of Memory Relying on networks of neurons in the brain, human memory suﬀers from restricted capacity, limited speed of information storage and retrieval, forgetting, and memory errors. While digital storage devices share the ﬁrst two memory vulnerabilities, the latter two are unique to human memory. According to Schacter [45], the latter two belong to the sins of omissio and commission, respectively. Forgetting is the spontaneous or gradual loss of information already stored in an individual’s short- or long-term memory. Unlike a digital storage device, humans cannot ‘forget on demand’; i.e., items will linger in memory even then they are no longer needed [43]. Memory errors refer to the wrong recall of information. This can include re- membering things that have not happened, giving the wrong source for a memory, or making up things that did not happen. Memory errors are caused in part by the structure of neuron networks as well as a feature of human memorization. As shown in the Deese–Roediger–McDermott paradigm [12], humans incorrectly recall an ab- sent word as it is related to a list of words that belong to a common theme. Many factors (e.g., the degree of attention, motivation, emotional state, and environment where memorization takes place) can aﬀect human memory. For example, the emo- tional enhancement of memory [22] has demonstrated that emotional stimuli are more easily remembered than neutral stimuli. Human memory vulnerabilities directly lead to security risks. For example, hu- mans use simple and meaningful passwords, reuse the same password over diﬀerent 1.2 Cognitive Security in HCPS 9 sites, and even write down the passwords to remember them, which makes the pass- words insecure. As will be introduced in Deﬁnition 1.2, cognitive reliability methods, including Single Sign-On (SSO)2 [40], cognitive passwords [57], and graphical pass- words [4], are introduced to mitigate memory vulnerability concerning passwords. Attackers can also actively exploit those memory vulnerabilities and manipulate the above factors to create attack vectors. For example, attackers can reduce the attack frequency to exploit the forgetting vulnerability. As demonstrated in [44] and [30], lower frequency and likelihood of phishing events increase victim’s susceptibility to phishing cyberattacks. Due to the suggestibility of human memory (i.e., humans are inclined to accept and act on the suggestions of others), attackers can design phishing emails to trigger memory errors and inject false memories by designing misleading hints. Moreover, they can use emotional language to enhance the operator’s false memory and facilitate trust. 1.2.3.4 Vulnerability of Mental Operations Mental operation vulnerabilities primarily refer to a variety of cognitive biases and exploitable traits. In the history of human development, we have developed cognitive shortcuts and biases for rapid, although less accurate or reasonable, responses to survive in highly dynamic and uncertain environments. However, those cognitive biases expand the attack surface and make humans susceptible to SE attacks. We list some of the cognitive biases and the potential adversarial exploitation [41] as follows. • Anchoring: An individual’s decisions are inﬂuenced by a particular reference point (i.e., an “anchor”). Pretexting SE can create a situation and initial context to increase the attack’s apparent legitimacy and the likelihood of success. Anchoring bias keeps people from questioning the initial impression and accepting the scam. • Framing: An individual can draw diﬀerent conclusions from the same informa- tion, depending on how that information is presented (e.g., as a loss or a gain). Attackers can utilize the framing eﬀect to craft the content of phishing emails and distort human risk perception. • Optimism bias: People tend to have unrealistic optimism; e.g., overestimating the likelihood of positive events and underestimating the likelihood of negative events. Users frequently believe others are more susceptible than they are [10]. Since they think they are immune to attacks, they tend to resist preventive defense measures, such as patching, virus scanning, clearing cache, checking for secure sites before entering credit card information, or paying attention to spear phishing. • Ingroup bias: People are social animals and give preferential treatment to in- group members over out-group ones. An attacker can pretend to be aﬃliated with the group to gain trust and inﬂuence the decisions of group members. 2 Single SSO allows a user to log in several related systems with a single ID and password, it reduces the total number of passwords to remember. 10 1 An Introduction of System-Scientiﬁc Approaches to Cognitive Security In marketing and persuasion, Cialdini [8] deduced six principles of inﬂuence from experimental and ﬁeld studies based on exploitable personal traits. Attackers can also take advantage of the following traits to complete the compromise. • Reciprocity: SE attackers frequently oﬀer victims something to set the stage for reciprocity. For example, people are less likely to refuse an inappropriate request from someone who has provided them with a gift in advance. • Social proof: Individuals are easily inﬂuenced by the decisions of a large group of people. An attacker can impersonate the involvement of a victim’s friends in order to compel victims to act. • Authority: People tend to conform to authority, and attackers can exploit that by pretending to be a system administrator or a security expert. • Liking: Since it is much easier to inﬂuence a person who likes you, attackers can attempt to be likeable by being polite and using concepts, languages, and appearances familiar to the target. • Scarcity: Something in short supply can increase its sense of value. Social engi- neers may use scarcity (e.g., a limited-time oﬀer) to create a feeling of urgency and spur the victim’s action. • Commitments and consistency: Once people make a choice, they receive pres- sure from others and themselves to adhere to it. SE attacks can induce the victim to make a seemingly insigniﬁcant commitment and then escalate the requests. People tend to accept the escalation of commitment as long as the subsequent requests are consistent with the prior commitment. 1.2.4 Cognitive Attack In Section 1.2.3, we discuss four types of exploitable vulnerabilities in the cogni- tive process. Cognitive attacks refer to the adversarial processes that involve the exploitation of these human vulnerabilities, as deﬁned in Deﬁnition 1.1. Deﬁnition 1.1 (Cognitive Attacks) Cognitive attacks are a class of cyber-physical- human processes that manipulate the behaviors of human actors for malicious pur- poses, including theft or damage of conﬁdential data and disruption or misdirection of the HCPS services, by exploiting their cognitive vulnerabilities. Analogous to cyber kill chains3, we present the kill chain of cognitive attacks in Section 1.2.4.1. Then, in Section 1.2.4.2, we zoom into the execution phase of the kill chain and use SE and IDoS attacks as two examples to illustrate the cross-layer attack paths of cognitive attacks. 3 An example cyber kill chains developed by Lockheed Martin in 2011 can be found at https: //www.lockheedmartin.com/en-us/capabilities/cyber/cyber-kill-chain.html 1.2 Cognitive Security in HCPS 11 1.2.4.1 Kill Chain of Cognitive Attacks Fig. 1.5 illustrates the conceptual kill chain of cognitive attacks that consists of six stages in blue arrows. We map the six kill-chain stages into the four attack phases of the attack stack in Fig. 1.3 at the bottom of Fig. 1.5 in orange. In the reconnaissance phase, the attacker analyzes the information collected from the HCPS. For example, an attacker can formulate the behavioral baseline of a user or an operator during the reconnaissance. Such a baseline can help the attack identify the human vulnerabilities of the target users and exploit them in the execution phase. In the planning phase, the attackers identify the valuable assets and tailor their Tactics, Techniques, and Procedures (TTP) accordingly. We divide the execution phase into three stages. First, attackers exploit human vulnerabilities directly or indirectly, where we show several examples of exploitation paths in Section 1.2.4.2. Second, attackers monitor the human target’s responses (e.g., emotions and behaviors) and adapt their TTP. For example, attackers can choose to increase or decrease the attack frequency for cautious and careless users, respectively. After the attackers obtain the optimal attack setting, they continue to reinforce the cognitive exploitation and propagate the compromise to other victims related to the initial human target. For example, after gaining trust, attackers can ask the initial victim to forward emails to his colleague, who will become less doubtful about the legitimacy of the phishing emails. In the exploitation phase, cognitive exploitation begins to take eﬀect in human behaviors and subsequently the cyber and physical layers. Collect and Analyze Information Specify Target and TTP Exploit Human Vulnerability Monitor &Adapt Reinforce &Propagate Take Effect in HCPS Kill Chain of Cognitive Attack Reconnaissance Planning Exploitation Execution Fig. 1.5: The illustration of the kill chain of cognitive attacks concerning the four- stage attack phases of reconnaissance, planning, execution, and exploitation. In the execution stage, cognitive attacks exploit human vulnerabilities, monitor their responses, and adapt the exploitation TTP accordingly. Then, they choose the best attack setting to reinforce the compromise eﬀect and spread it to a group of victims from the initial victim. 1.2.4.2 Examples Paths of Cognitive Attacks Exploiting human vulnerabilities is a critical step in the execution attack stage. It can take diﬀerent forms and involve one or many of the cognitive vulnerabilities 12 1 An Introduction of System-Scientiﬁc Approaches to Cognitive Security described in Section 1.2.3. In Fig. 1.6, we use SE and IDoS attacks as two examples to illustrate the various forms and procedures of cognitive attacks. SE attacks directly manipulate the stimulus (e.g., phishing content) and external factors (e.g., peer pressure) to compromise human users. In this type of cognitive attack, cognitive compromise is used as the stepping stone to enter the CPS and perpetrate the technical compromise. However, in other cognitive attacks, the technical compromise may also serve as a precondition to exploit human cognitive vulnerabilities, as illustrated by the attack path of IDoS attacks. IDoS attacks ﬁrst generate a lot of feint attacks to trigger cyber alerts that are displayed through a HMI. Human operators investigating these alerts in real-time can suﬀer from cognitive overload, which leads to reduced accuracy and speed in processing the alerts. Since human operators may be unable to respond to alerts associated with real and signiﬁcant attacks, these attacks have the potential to disrupt both cyber and physical processes. Examples of real-world IDoS attacks widely exist but are usually implicit in many attack incidents. The following three incidents in Examples 1.2.1, 1.2.2, and 1.2.3 use Distributed Denial- of-Service (DDoS) attacks as a “smoke shell” to attract security analysts’ attention while simultaneously launching other stealthy attacks. Example 1.2.1 (Sony PSN Data Breach 2011) In April 2011, the Security Operation Center (SOC) of Sony was occupied dealing with a DDoS attack, and they overlooked the extraction of conﬁdential information, including the names, addresses, dates of birth, and passwords, of 77 million PlayStation Network (PSN) customers. Authorities in the U.K. ﬁned the Sony company the equivalent of almost $400,000 over the failures in the PSN data breach [17]. Example 1.2.2 (BIPS BTC Stolen 2013) Europe’s primary bitcoin payment processor for merchants and free online wallet service, BIPS, became the target of a massive DDoS attack on November 15th, 2013. While the SOC was busy to get the system back online, the attacker launched a subsequent attack to gain access and compromise several wallets, resulting in the theft of 1,295 BTC (approximately 1 million dollars) [49]. Example 1.2.3 (Tesla Ransomware 2021) A recent thwarted cybersecurity attack against Tesla in 2021 planned to use DDoS attack to divert security analysts’ attention from malware that extracted conﬁdential data [50]. 1.2 Cognitive Security in HCPS 13 Stimulus Behavior Cognitive Process Cyber Process Physical Process AI Stack Mission Stack Attack Stack Externalities AI-Powered Technologies Human-Centered AI IDoS Attacks Social Engineering Fig. 1.6: Example paths of cognitive attacks are depicted in the dashed arrow. SE attacks directly exploit human cognitive vulnerabilities by changing stimuli and inﬂuencing external factors. IDoS attacks ﬁrst compromise the cyber process and use technical compromise as a stepping stone to aﬀect the HMI (e.g., by creating feints to increase the operator’s cognitive load), which indirectly manipulates the cognitive process. Both types of cognitive attacks have an impact on the cyber and physical processes. 1.2.5 Cognitive Security The development of the AI-powered CPS begins with reliability assurance to guar- antee that the system and AI technologies can remain trustworthy and eﬃcient under uncertainty, disturbances, and failures. The presence of attacks requires us to in- corporate defenses, which leads to the concept of security. Analogous to reliability and security in CPS, we deﬁne and distinguish cognitive reliability and cognitive security in Deﬁnitions 1.2 and 1.3, respectively, to form the four quadrants in Fig. 1.7. Deﬁnition 1.2 (Cognitive Reliability) Cognitive reliability is the capacity of a HCPS to maintain the continuity of operations, fulﬁl a designated mission, and provide services at the desired level under stated conditions, including challenging environments of uncertainty, disturbance, and error. Deﬁnition 1.3 (Cognitive Security) Cognitive security is the practice of deploying people, policies, processes, and technologies to withstand cognitive attacks in Deﬁ- nition 1.1 and defend essential HCPS components, including humans, critical system structures, services, and sensitive information. 1.2.5.1 Cognitive Reliability vs. Cognitive Security From Deﬁnition 1.2, cognitive reliability focuses on Human Reliability Analysis (HRA) and human-centered system design. On the one hand, HRA identiﬁes potential human error events, evaluates the contributing factors, estimates the probability of those errors, and analyzes their impact on the CPS. A variety of methods exist 14 1 An Introduction of System-Scientiﬁc Approaches to Cognitive Security Human Attacks Faults Cyber-Physical Systems Cognitive Reliability Cognitive Security CPS Security CPS Reliability Fig. 1.7: Four quadrants of security and reliability in CPSs and HCPSs. The horizon- tal arrows distinguish security and reliability based on whether attacks are present or absent, respectively. The vertical arrows distinguish security (or reliability) in HCPSs or CPSs based on whether cognitive vulnerabilities are involved or not. Cog- nitive security generalizes SE and its mitigation through the additional investigation of the cross-layer impact on HCPSs and the development of human-technical defense technologies to deter the kill chain of cognitive attacks. for HRA, including techniques based on probabilistic risk analysis and cognition control, where Di Pasquale et al. [14] refers to these two classes of techniques as the ﬁrst and second generations of HRA, respectively. These HRA techniques have been widely used in life-critical industrial control systems (e.g., nuclear power plants) to minimize the adverse consequences of human behaviors on the technical systems. On the other hand, human-centered system design includes ergonomics and be- havioral science to understand human cognition processes, adapt the system to human factors to enhance usability, and reduce erroneous behaviors. For example, based on the behavioral science ﬁndings that recognition is signiﬁcantly easier than recall, text-based challenge-response mechanisms have been applied in user-to-computer authentication as an improvement over unaided password recall [57]. Other cognitive science results have been used in user authentication and email encryption for usable 1.2 Cognitive Security in HCPS 15 security [39]; e.g., a graphical password emerges because people memorize pictures better than texts. Cognitive security in Deﬁnition 1.3 is a concept associated with cognitive attacks in Section 1.2.4. Unlike human-induced failures in cognitive reliability, cognitive attacks can directly take advantage of cognitive weaknesses and use them as step- ping stones to maximize the attack gain. The term “at the desired level under stated conditions” in Deﬁnition 1.2 indicates that cognitive reliability has a speciﬁc goal of system eﬃciency and usability for a set of deﬁned conditions. Performance un- der these conditions enables cognitive functions to “withstand attacks" or errors up to a certain capacity. For attacks that are beyond such capacity, defense methods are needed to provide further protection, as suggested in Deﬁnition 1.3. Protection methods come at the cost of reduced eﬃciency (e.g., false alarms of an Intrusion Detection System (IDS) disrupting normal operation) and usability (e.g., additional eﬀort needed to comply with security procedures). Security designs that aim to aug- ment the capacity needs to takes into account the tradeoﬀamong security, eﬃciency, and usability in a holistic manner. Such a rationale leads to the system-scientiﬁc perspectives, which will be discussed in Section 1.3. 1.2.5.2 CIA Triad of Cognitive Security In the context of cognitive security, we discuss conﬁdentiality, integrity, and avail- ability, i.e., the CIA triad, to provide a guide for theoretical foundations. Conﬁden- tiality prevents unauthorized users from accessing the sequential information ﬂow of the cognitive process shown in Fig. 1.4. Phishing attacks, for example, violate conﬁdentiality by masquerading as legitimate entities and collecting conﬁdential information. The attacker can use the information to acquire access credentials, steal data, and deploy malware (e.g., ransomware). The integrity of cognitive security assesses whether the cognitive process depicted in Fig. 1.4 has been manipulated to induce biased actions. Examples of cognitive attacks that compromise integrity include misinformation propagation and belief manipulation techniques (e.g., gaslighting). The availability of cognitive security guarantees the normal functioning of the cognitive process in Fig. 1.4. IDoS attacks compromise availability by depleting the limited cognitive resources, including attention, memory, and decision capacity. 1.2.5.3 Cognitive and Technical Defenses for Cognitive Security Cognitive security synthesizes cognitive and technical defenses to break the kill chain of cognitive attacks, as shown in Fig. 1.8. Since cognitive attacks include technical exploitation across the cyber and physical layers, as shown in the IDoS attack path in Section 1.2.4.2, cyber and physical defenses are indispensable components. Besides the cyber and physical defenses, cognitive security also focuses on de- fending humans and AI technologies. On the one hand, user training can help users 16 1 An Introduction of System-Scientiﬁc Approaches to Cognitive Security Stimulus Behavior Cognitive Process Cyber Process Physical Process Externalities AI-Powered Technologies Human-Centered AI Cyber Defense Physical Defense AI-Powered Enhancer User Training and Mechanism Design Fig. 1.8: The defense methods in blue dashed boxes to break the kill chain of cognitive attacks and achieve cognitive security. The cyber and physical defenses take eﬀect on the cyber and physical processes, respectively. User training and human-centered mechanism design aﬀect the cognitive process through externalities. Incorporating the AI stack, cognitive security includes the AI-powered enhancer to protect HCPSs from the adversarial exploitation of AI technologies. gain security knowledge, raise security awareness, and cultivate critical thinking, which consolidates the cognitive process. On the other hand, we can design mecha- nisms to avoid selﬁsh behaviors and incentivize users to behave securely. AI-technologies in AI stack can also be susceptible to cognitive attacks. Keeping the security requirement in mind, we need to design an AI-powered enhancer to guarantee the security and resilience of the AI-powered technologies. In particular, human-centered AI technologies in AI stack need to not only tilt the cognitive biases when augmenting human capacities, but also be aware of and defend against the cognitive attacks. For example, AI-enabled security assistive technologies can argument HMI to defend against the threat from IDoS attacks. To achieve the goal, we fuse various biosensor data, including optical, motion, and acoustic signals and electrical biosignals, to reﬂect the status of the current cognitive process in real-time. These signals can be fed back to the AI-enhancer for adaptive control. We can analogize the human process augmented by AI-powered technologies in Fig. 1.8 as children under the supervision of parents. While user training and mechanism design teach and motivate children to behave securely, these methods are subject to social and cognitive limitations. To break the limitation, the AI-powered enhancer alternatively lets parents be aware of and protect against the potential attacks on their children. 1.2 Cognitive Security in HCPS 17 1.2.5.4 Scope of Cognitive Security To better illustrate the scope of cognitive security, we distinguish the following related concepts from cognitive security in Deﬁnition 1.3 through two running examples. First, the exploitation and defense of human cognition are essential components of cognitive security, which is signiﬁcantly diﬀerent from the realm of CPS security and creates a new battleﬁeld of HCPS security. Second, as illustrated in Fig. 1.7, cognitive security generalizes the concept of SE and cognitive hacking [11] that usually rely on weaponized information and exploit vulnerabilities of mental operation. On top of the cognitive manipulation in the human-human interaction, we further investigate its impacts and dependency on the CPS during the human-machine interaction. As illustrated in the IDoS example, technical exploitation can exacerbate the attentional vulnerability. Such human- technical attacks that directly exploit human cognition limitations have not been considered in SE and cognitive hacking. Third, cognitive security in this book does not aim to enhance humans at the neuroscience or biological level through the means of medications or medical ther- apies. Instead, we focus on designing mechanisms and assistive technologies to non-intrusively inﬂuence and externally aﬀect human cognitive processes, change their behaviors, and ultimately enhance the security of the entire HCPS. Fourth, cognitive security does not aim to answer human-engineering questions such as how to craft convincing misinformation or how to design an anti-phishing interface. Instead, we leverage theories and empirical results from behavioral science and psychology at the system-level. Fifth, technical solutions for cognitive security are aware of and adapt to adverse exploitation of cognitive vulnerabilities. For example, under the threat of IDoS at- tacks, it may be insuﬃcient to adopt the traditional method of alert triage to indirectly reduce cognitive load. Therefore, we further de-emphasize alerts strategically to di- rectly manage attention and make the alert inspection process compatible with each operator’s cognitive load. Sixth, cognitive defense is an essential but not the only way to achieve cognitive security. We may not need to defend against all types of cognitive attacks. It is suﬃcient to break the kill chain of cognitive attacks. Moreover, since some types of cognitive attacks are not defensible or too costly to defend, we can focus on compensation and correction mechanisms to reduce the risk and impact of the attacks. Finally, cognitive security in this book does not mean developing security mea- sures to have human cognitive capacities (e.g., cognitive computing SOC [13], phishing detector [18], and incident management systems [1]), nor does it mean the exploitation of human cognitive strengths (e.g., creativity and ﬂexibility) to augment technical defense systems. Moreover, cognitive security does not focus on increasing the usability of the security measures [19, 39], despite its contribution to cognitive security. 18 1 An Introduction of System-Scientiﬁc Approaches to Cognitive Security 1.3 System-Scientiﬁc Perspectives for Cognitive Security Following Sections 1.1 and 1.2, humans are an essential component in accomplish- ing CPS missions, and cognitive security needs to incorporate rather than eschew human cognition. Human cognition, however, is of high complexity, uncertainty, and individual diﬀerence, which leads to the following research questions. How to in- corporate established theories of human factors into HCPSs for defensive purposes? How to customize the defense and make it adaptive to various security applications? What are useful metrics and measures to quantify the impact of human factors on a CPS and the eﬀectiveness of the defense methods? This book adopts system-scientiﬁc perspectives, including decision theory, opti- mization, game theory, AI, physiological metrics, and psychology theories to address these questions for the following reasons. • First, as illustrated in Section 1.2.4, cognitive attacks occur at the cognition level (e.g., SE) and the system level (e.g., IDoS attacks) rather than the neuronal level through medicine. Thus, the attack and defense interactions need to be investigated at the system level to understand the entire attack phase, anticipate the interaction of attacks with the HCPS, and ﬁnd defensible points among these phases. • Second, cognitive attacks (e.g., IDoS attacks) exploit distinct vulnerabilities in human, cyber, and physical processes. A single tool is not suﬃcient to deter, detect, and prevent these cross-layer, cross-disciplinary attacks. To safeguard diverse vulnerabilities, we need interdisciplinary tools to synthesize defense methods from multiple areas. • Third, since cognitive attacks have an impact on human, cyber, and physical processes, it is important to quantify the risk to each component, the prorogation of the risk, and the risk to the entire HCPS [24, 25, 7]. Moreover, we need to design optimal controllables to defend HCPSs cost-eﬀectively. Therefore, we need scientiﬁc and quantitative approaches to quantify security metrics and bounds, assess tradeoﬀs, characterize fundamental limits, and design optimal control [53, 36, 54]. • Fourth, since both cognitive attackers and defenders are intelligent players, they take actions based on the predictions of the others. Game theory becomes a natural tool to capture the interactions in adversarial environment for quantitative analysis and design [34, 55, 28, 56]. • Fifth, models may not accurately describe HCPS components (e.g., human cog- nition) that are highly dynamic and sometimes unobservable. Data collected by biosensors (e.g., electroencephalogram (EEG) and eye-tracking devices) and AI can be incorporated to provide system-level adaptive solutions in response to the measurable observations. • Finally, theories from psychology and social science can be adopted to understand perception, attention, memory, and decisions. As a multi-disciplinary methods, system-scientiﬁc approach incorporate those ﬁndings and results to create holistic hybrid data-driven and model-based system frameworks of HCPSs. References 19 1.3.1 Advantages of System-Scientiﬁc Approaches System-scientiﬁc approaches provide a new paradigm for cognitive security and bring the following advantages. • Emergence: Emergence widely appears in philosophy, psychology, and art, where “the whole is something else than the sum of its parts” [32]4. As shown in Fig. 1.2, the close integration of AI and humans in CPSs leads to the new concept of HCPSs. The interactions among human, cyber, physical, and AI components create new attack surfaces and attack paths, which potentially ampliﬁes the human cognitive vulnerabilities and promotes the need for research in the emerging ﬁeld of cognitive security. • Black Box and Function Simulation: A system perspective focuses on the input and output (or the transfer characteristics) of the system, where the system itself is treated as a black box without any knowledge of its internal workings. By treating human cognition systems as black boxes, we focus on the behavior-level impact rather than the cognitive- or neuro-level mechanisms that can be complicated and not well-understood. The input-output view also enables us to simulate a system’s function without establishing the internal model of the system. • Modular and Multi-Scale Design: A system can be divided into diﬀerent levels of subsystems that compose a multi-scale system model. For example, the HCPS system consists of human, cyber, and physical subsystems, where the human subsystem further contains cognition systems consisting of perception, attention, memory, and mental operations. We can zoom into the proper level of subsystems based on our goal. Since these subsystems interact through their inputs and outputs, each subsystem can be replaced and revised to achieve a modular design. • Quantitative Strategies and Optimization: The system-scientiﬁc models enable a quantitative description of the situation and thus the formulation of optimal design problems that lead to cost-eﬀective security mechanisms. The integration of multiple system-scientiﬁc approaches, including deterministic and stochastic methods, data-driven and model-based tools, and static and dynamic frameworks, strengthens their strong points and mitigates their weak points. References [1] Andrade R, Torres J, Cadena S (2019) Cognitive security for incident man- agement process. In: International Conference on Information Technology & Systems, Springer, pp 612–621 [2] Arons B (1992) A review of the cocktail party eﬀect. Journal of the American Voice I/O Society 12(7):35–50 4 often misquoted as ‘the whole is greater than the sum of its parts’. 20 1 An Introduction of System-Scientiﬁc Approaches to Cognitive Security [3] Barmer H, Dzombak R, Gaston M, Palat V, Redner F, Smith T, Wohlbier J (2021) Scalable AI DOI 10.1184/R1/16560273.v1, URL https:// kilthub.cmu.edu/articles/report/Scalable_AI/16560273 [4] Biddle R, Chiasson S, Van Oorschot PC (2012) Graphical passwords: Learning from the ﬁrst twelve years. ACM Computing Surveys (CSUR) 44(4):1–41 [5] Bruce V, Green PR, Georgeson MA (2003) Visual perception: Physiology, psychology, & ecology. Psychology Press [6] Chaczko Z, Kulbacki M, Gudzbeler G, Alsawwaf M, Thai-Chyzhykau I, Wajs- Chaczko P (2020) Exploration of explainable ai in context of human-machine interface for the assistive driving system. In: Asian Conference on Intelligent Information and Database Systems, Springer, pp 507–516 [7] Chen J, Zhu Q (2019) A game-and decision-theoretic approach to resilient interdependent network analysis and design. Springer [8] Cialdini RB (2007) Inﬂuence: The psychology of persuasion, vol 55. Collins New York [9] Commission E, for Research DG, Innovation, Breque M, De Nul L, Petridis A (2021) Industry 5.0 : towards a sustainable, human-centric and resilient European industry. Publications Oﬃce, DOI doi/10.2777/308407 [10] Cox EB, Zhu Q, Balcetis E (2020) Stuck on a phishing lure: Diﬀerential use of base rates in self and social judgments of susceptibility to cyber risk. Comprehensive Results in Social Psychology 4(1):25–52 [11] Cybenko G, Giani A, Thompson P (2002) Cognitive hacking: A battle for the mind. Computer 35(8):50–56 [12] Deese J (1959) On the prediction of occurrence of particular verbal intrusions in immediate recall. Journal of experimental psychology 58(1):17 [13] Demertzis K, Kikiras P, Tziritas N, Sanchez SL, Iliadis L (2018) The next generation cognitive security operations center: network ﬂow forensics using cybersecurity intelligence. Big Data and Cognitive Computing 2(4):35 [14] Di Pasquale V, Iannone R, Miranda S, Riemma S (2013) An overview of human reliability analysis techniques in manufacturing operations. Operations management pp 221–240 [15] Doghri W, Saddoud A, Chaari Fourati L (2022) Cyber-physical systems for structural health monitoring: sensing technologies and intelligent computing. The Journal of Supercomputing 78(1):766–809 [16] Elgendi M, Kumar P, Barbic S, Howard N, Abbott D, Cichocki A (2018) Sub- liminal priming—state of the art and future perspectives. Behavioral Sciences 8(6):54 [17] Fisher D (2013) Sony ﬁned £250,000 by uk over failures in playstation network breach. URL https://threatpost.com/sony-fined-250000-uk-over- failures-playstation-network-breach-012413/77446/ [18] Garcés IO, Cazares MF, Andrade RO (2019) Detection of phishing attacks with machine learning techniques in cognitive security architecture. In: 2019 Inter- national Conference on Computational Science and Computational Intelligence (CSCI), IEEE, pp 366–370 References 21 [19] Greenstadt R, Beal J (2008) Cognitive security for personal devices. In: Pro- ceedings of the 1st ACM workshop on Workshop on AISec, pp 27–30 [20] Griﬀor ER, Greer C, Wollman DA, Burns MJ, et al. (2017) Framework for cyber-physical systems: Volume 1, overview [21] Groshev M, Guimarães C, Martín-Pérez J, de la Oliva A (2021) Toward intel- ligent cyber-physical systems: Digital twin meets artiﬁcial intelligence. IEEE Communications Magazine 59(8):14–20 [22] Hamann S (2001) Cognitive and neural mechanisms of emotional memory. Trends in cognitive sciences 5(9):394–400 [23] Huang L, Zhu Q (2022) Radams: Resilient and adaptive alert and attention management strategy against informational denial-of-service (idos) attacks. Computers & Security 121:102844 [24] Huang L, Chen J, Zhu Q (2017) A large-scale markov game approach to dynamic protection of interdependent infrastructure networks. In: International Conference on Decision and Game Theory for Security, Springer, pp 357–376 [25] Huang L, Chen J, Zhu Q (2018) Distributed and optimal resilient planning of large-scale interdependent critical infrastructures. In: 2018 Winter Simulation Conference (WSC), IEEE, pp 1096–1107 [26] Huang L, Jia S, Balcetis E, Zhu Q (2022) Advert: An adaptive and data-driven attention enhancement mechanism for phishing prevention. IEEE Transactions on Information Forensics and Security 17:2585–2597 [27] Huang W, Chen X, Jin R, Lau N (2020) Detecting cognitive hacking in visual inspection with physiological measurements. Applied ergonomics 84:103022 [28] Huang Y, Chen J, Huang L, Zhu Q (2020) Dynamic games for secure and resilient control system design. National Science Review 7(7):1125–1141 [29] Johnston WA, Dark VJ (1986) Selective attention. Annual review of psychology [30] Kaivanto K (2014) The eﬀect of decentralized behavioral decision making on system-level risk. Risk Analysis 34(12):2121–2142 [31] Kanwisher NG (1987) Repetition blindness: Type recognition without token individuation. Cognition 27(2):117–143 [32] Koﬀka K (2013) Principles of Gestalt psychology. Routledge [33] Lindsay GW (2020) Attention in psychology, neuroscience, and machine learn- ing. Frontiers in computational neuroscience 14:29 [34] Manshaei MH, Zhu Q, Alpcan T, Bacşar T, Hubaux JP (2013) Game the- ory meets network security and privacy. ACM Computing Surveys (CSUR) 45(3):1–39 [35] Marot A, Rozier A, Dussartre M, Crochepierre L, Donnot B (2022) Towards an ai assistant for power grid operators pp 79–95 [36] Meadows DH (2008) Thinking in systems: A primer. chelsea green publishing [37] Molden DC (2014) Understanding priming eﬀects in social psychology. Guil- ford Publications [38] Pan SJ, Yang Q (2009) A survey on transfer learning. IEEE Transactions on knowledge and data engineering 22(10):1345–1359 [39] Payne BD, Edwards WK (2008) A brief introduction to usable security. IEEE Internet Computing 12(3):13–21 22 1 An Introduction of System-Scientiﬁc Approaches to Cognitive Security [40] Radha V, Reddy DH (2012) A survey on single sign-on techniques. Procedia Technology 4:134–139 [41] Rohleder K (2019) Cognitive biases as vulnerabilities. URL https: //www.linkedin.com/pulse/cognitive-biases-vulnerabilities- krinken-rohleder/ [42] Salau B, Rawal A, Rawat DB (2022) Recent advances in artiﬁcial intelligence for wireless internet of things and cyber-physical systems: A comprehensive survey. IEEE Internet of Things Journal [43] Sasse MA, BrostoﬀS, Weirich D (2001) Transforming the ‘weakest link’—a human/computer interaction approach to usable and eﬀective security. BT tech- nology journal 19(3):122–131 [44] Sawyer BD, Hancock PA (2018) Hacking the human: The prevalence paradox in cybersecurity. Human factors 60(5):597–609 [45] Schacter DL (2002) The seven sins of memory: How the mind forgets and remembers. HMH [46] Shapiro KL, Raymond JE, Arnell KM (1997) The attentional blink. Trends in cognitive sciences 1(8):291–296 [47] Simons DJ, Rensink RA (2005) Change blindness: Past, present, and future. Trends in cognitive sciences 9(1):16–20 [48] Song J, Lyu D, Zhang Z, Wang Z, Zhang T, Ma L (2022) When cyber-physical systems meet ai: A benchmark, an evaluation, and a way forward. ICSE 2022 SEIP [49] Southurst J (2013) Bitcoin payment processor bips attacked, over $1 mil- lion stolen. URL https://www.coindesk.com/markets/2013/11/25/ bitcoin-payment-processor-bips-attacked-over-1-million- stolen/ [50] Team SN (2021) Russian national pleads guilty after trying to hack a human at tesla. URL https://www.secureworld.io/industry-news/ tesla-hacker-charges-arrested [51] Tipper SP (1985) The negative priming eﬀect: Inhibitory priming by ignored objects. The quarterly journal of experimental psychology 37(4):571–590 [52] Vitevitch MS (2003) Change deafness: the inability to detect changes between two voices. Journal of Experimental Psychology: Human Perception and Per- formance 29(2):333 [53] Wiener N (2019) Cybernetics or Control and Communication in the Animal and the Machine. MIT press [54] Xu Z, Zhu Q (2016) Cross-layer secure cyber-physical control system design for networked 3d printers. In: 2016 American Control Conference (ACC), IEEE, pp 1191–1196 [55] Zhu Q, Basar T (2015) Game-theoretic methods for robustness, security, and resilience of cyberphysical control systems: games-in-games principle for op- timal cross-layer resilient control systems. IEEE Control Systems Magazine 35(1):46–65 References 23 [56] Zhu Q, Rass S (2018) Game theory meets network security: A tutorial. In: Proceedings of the 2018 ACM SIGSAC Conference on Computer and Com- munications Security, pp 2163–2165 [57] Zviran M, Haga WJ (1990) Cognitive passwords: The key to easy access control. Computers & Security 9(8):723–736