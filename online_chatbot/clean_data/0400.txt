Use of Graph Neural Networks in Aiding Defensive Cyber Operations SHASWATA MITRA, Mississippi State University, USA TRISHA CHAKRABORTY, Mississippi State University, USA SUBASH NEUPANE, Mississippi State University, USA ARITRAN PIPLAI, University of Texas at El Paso, USA SUDIP MITTAL, Mississippi State University, USA In an increasingly interconnected world, where information is the lifeblood of modern society, regular cyber-attacks sabotage the confidentiality, integrity, and availability of digital systems and information. Additionally, cyber-attacks differ depending on the objective and evolve rapidly to disguise defensive systems. However, a typical cyber-attack demonstrates a series of stages from attack initiation to final resolution, called an attack life cycle. These diverse characteristics and the relentless evolution of cyber attacks have led cyber defense to adopt modern approaches like Machine Learning to bolster defensive measures and break the attack life cycle. Among the adopted ML approaches, Graph Neural Networks have emerged as a promising approach for enhancing the effectiveness of defensive measures due to their ability to process and learn from heterogeneous cyber threat data. In this paper, we look into the application of GNNs in aiding to break each stage of one of the most renowned attack life cycles, the Lockheed Martin Cyber Kill Chain. We address each phase of CKC and discuss how GNNs contribute to preparing and preventing an attack from a defensive standpoint. Furthermore, We also discuss open research areas and further improvement scopes. CCS Concepts: • General and reference →Surveys and overviews; • Computing methodologies →Neural networks; • Security and privacy →Domain-specific security and privacy architectures. Additional Key Words and Phrases: Machine Learning, Graph Neural Network, Cybersecurity, Cyber Kill Chain ACM Reference Format: Shaswata Mitra, Trisha Chakraborty, Subash Neupane, Aritran Piplai, and Sudip Mittal. 2024. Use of Graph Neural Networks in Aiding Defensive Cyber Operations. ACM Trans. Priv. Sec. 0, 0, Article 1 (January 2024), 35 pages. https://doi.org/XXXXXXX. XXXXXXX 1 INTRODUCTION Cybersecurity is an ongoing practice dedicated to safeguarding systems and networks from cyberattacks that target unauthorized access, data alteration, information destruction, financial extortion, or disruption of regular business operations [1]. The significance of cybersecurity becomes more relevant with increased cyberattacks fueled by rapid digital expansion. Common avenues for cyberattacks encompass phishing, social engineering, password-related breaches, information misuse, man-in-the-middle attacks, denial-of-service (DoS) attacks, ransomware, and more. In response, cyber defense strategies incorporate a range of domains, network and Authors’ addresses: Shaswata Mitra, sm3843@msstate.edu, Mississippi State University, Mississippi State, MS, USA, 39762; Trisha Chakraborty, tc2006@msstate.edu, Mississippi State University, Mississippi State, MS, USA, 39762; Subash Neupane, sn922@msstate.edu, Mississippi State University, Mississippi State, MS, USA, 39762; Aritran Piplai, apiplai@utep.edu, University of Texas at El Paso, El Paso, TX, USA, 79968; Sudip Mittal, mittal@cse.msstate.edu, Mississippi State University, Mississippi State, MS, USA, 39762. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM 2471-2566/2024/1-ART1 https://doi.org/XXXXXXX.XXXXXXX ACM Trans. Priv. Sec., Vol. 0, No. 0, Article 1. Publication date: January 2024. arXiv:2401.05680v1 [cs.CR] 11 Jan 2024 1:2 • Mitra et al. perimeter security, endpoint security, application security, data security, identity & access management, zero trust architecture, and more. These defense measures collectively aim to prevent attackers from achieving their goal through cyberspace, referred to as cyber defense operations. In an era characterized by unprecedented interconnectedness and technological advancement, the cybersecurity landscape faces an escalating challenge: the ceaseless barrage of cyber threats that target critical infrastructures, sensitive information, and even the very fabric of societies. As the digital landscape expands, so does the complexity of cyber attacks, necessitating a paradigm shift in defensive strategies. According to Gartner experts, of all cybersecurity breaches by 2024, 80% will result from failures to prove the duty of due care [2]. In response to constantly evolving attack patterns, enormous knowledge space, cost, and consistency, the marriage of machine learning (ML) and cybersecurity has yielded innovative solutions, propelling the evolution of defensive cyber operations to tackle unprecedented scenarios. Therefore, along with keeping the systems secure from possible threats, cyber defense operations now include getting ahead of the attacker to predict its possible next move based on the data pattern. However, it is impossible to effectively utilize ML techniques without a comprehensive, rich, and complete approach to the underlying data. Among the cutting-edge ML solutions, Graph Neural Networks (GNNs) [3] have emerged as a promising contender, harnessing the power of neural networks to navigate and analyze intricate relationships within complex data structures. The introduction of GNN in defensive cyber operations introduces a new dimension of adaptive and intelligent defense mechanisms. Traditional cybersecurity approaches that rely on signature-based detection and rule-based techniques often struggle to keep pace with modern cyber threats’ rapid mutation and polymorphism. In contrast, GNNs excel in capturing nuanced patterns and dependencies within diverse datasets, enabling them to uncover hidden insights that evade conventional methods. By viewing cyber threat data through a graph-based lens, GNNs inherently recognize the interconnectedness of entities, lending themselves to the intricate nature of cyber threat landscapes. This survey paper aims to provide a comprehensive overview of the evolving cyber threat landscape where GNNs intersect with defensive cyber operations. To identify potential attack areas for a concrete countermeasure— we develop our taxonomy based on the Lockheed Martin cyber kill chain (CKC) [4] attack life cycle. The straightforward and simplistic approach is the primary reason behind appointing CKC as the skeleton behind our taxonomy. By exploration of relevant literature, this paper delves into the fundamental areas of cybersecurity following CKC and underpinning GNNs applications and the implications with opportunities for their integration into defensive strategies. By summarizing existing research and highlighting limitations, this survey aims to equip researchers with the capabilities and possible future research avenues in concretizing cyber defense operations through GNN. To the best of our knowledge, this survey is the first attempt that concentrates on the influence of GNN in overall cyber defense operations. In the following, we highlight our contributions in specific: • We demonstrate the application of GNNs in defensive cyber operations to detect and mitigate attacks by utilizing their knowledge propagation and learning capabilities. • A comprehensive summary of the state-of-the-art research articles utilizing GNNs, grouped according to cover complete defensive cyber operations life-cycle through each cyber kill chain (CKC) phase. • We address the persisting challenges and discuss improvement scopes with future research directions in the employment of GNN in designing defensive cyber operation models. The remainder of the paper is as follows: Section 2 offers a foundational overview of Graph Neural Networks, elucidating their architecture, principles, and capabilities. Section 3 delves into the intricate landscape of cyber attack and defensive cyber operations, providing the taxonomy of the integration of GNN. Section 4 presents a comprehensive summary of existing literature following our taxonomy, showcasing the diverse applications of GNNs in cybersecurity contexts. Section 5 critically examines the challenges and limitations of GNNs, addressing issues and potential improvement research directions. Finally, Section 6 concludes the survey by summarizing key findings, highlighting emergent trends, and proposing possible avenues for future research. ACM Trans. Priv. Sec., Vol. 0, No. 0, Article 1. Publication date: January 2024. Use of Graph Neural Networks in Aiding Defensive Cyber Operations • 1:3 2 GRAPH NEURAL NETWORKS The fundamental definition of graph neural network (GNN) [3] denotes the adaptation of classical neural network (NN) framework on graph data to perform one or a combination of traditional machine learning tasks, such as classification, regression, or clustering. Data representation in graph form provides the means to capture complex relationships between entities and utilize these relations using two basic components – nodes and edges. Existing vast literature in GNN has provided evidence for offering significant benefits to a broad range of domains that rely on artificial intelligence systems. Recently, systems based on variants of GNN have been well-explored on many tasks related to graph data, such as, social network [5] represents the interaction between social actors in the graph form where the vertices represent the social actors and the edges represent if there exists a relationship between two actors. In a citation network [6], two papers hold a relationship with each other via citations. In chemical sciences [7], molecules are modeled as graphs, where the nodes represent protein molecules and edges, represent if their bio-activity exists in the chemical component and many more. 2.1 Preliminaries In this section, we define the graph notations and provide intuition to translate a real-world problem into a classification task. Notations. We denote a graph as G = (V, E), where V = {𝑣1, 𝑣2, ..., 𝑣𝑛} is the set of nodes and E = {𝑒1,𝑒2, . . . ,𝑒𝑚} ⊆V × V is set of edges between nodes. The neighborhood of a node 𝑣is denoted by set of nodes N (𝑣) = {𝑢∈ V|(𝑣,𝑢) ∈E}. The node feature embeddings are represented by matrix 𝑋= [𝑥1, . . . ,𝑥𝑛]⊤∈R𝑛×𝑑, where the 𝑥𝑖∈R𝑑is the 𝑑-dimensional feature vector of node 𝑣𝑖. Table 1 provides a description of notations used following. Notation Description G Graph V Set of nodes E Set of edges N(v) Neighborhood of node v 𝑛 Number of nodes 𝑚 Number of edges deg(𝑣) Degree of node 𝑣 𝑋= [𝑥1, . . . ,𝑥𝑛]⊤ Feature matrix 𝑎(𝐿) 𝑣 Message vector in 𝐿-th iteration ℎ(𝐿) 𝑣 Node representation of node 𝑣in 𝐿-th iteration AGGREGATE(𝐿) (·) Aggregation function in 𝐿-th iteration UPDATE(𝐿) (·) Update function in 𝐿-th iteration Table 1. Description of Notation. Problem Statement. Recent literature has shown that GNNs can perform solve various challenging tasks on graph-structured data such as partition- ing of graphs into meaningful subgraphs based on their structural properties [8–11] or generate new graphs that possess similar characteristics and properties from an input graph [12–14]. In this survey, we begin by exploring classification tasks solved by GNN. Given a graph with nodes 𝑣𝑖∈V and edges 𝑒𝑖∈E representing entities and relationships, the task is to develop a GNN model that can effectively classify nodes, edges, or entire graphs into predefined 𝑦classes, where 𝑦∈{𝑦1,𝑦2, . . . ,𝑦𝑐} set of 𝑐classes. • Node-level Classification. In node-level classification, the GNN model assigns each node to one or more predefined classes or predicts a continuous value associated with the node based on its node feature embedding from the neighboring nodes. • Edge-level Classification. In edge-level classification, the GNN should learn to classify edges into different categories or predict continuous values associated with them. The goal is to determine the nature of the relationship between pairs of connected nodes based on their neighboring node features and the edge itself. • Graph-level Classification. In graph-level classification, the GNN should learn to classify entire graphs into specific categories. The GNN should effectively capture and aggregate information from all the nodes and edges in the graph to make predictions about the graph as a whole. ACM Trans. Priv. Sec., Vol. 0, No. 0, Article 1. Publication date: January 2024. 1:4 • Mitra et al. [ … h(1) u h(k) u av av ∑ av Relu ] wk h(k) u hv Input Graph Aggregate Update ∑ Prediction Neural network Fig. 1. Illustration of GNN aggregate and update functions. The nodes 𝑣of input graph 𝐺is aggregates the embeddings ℎ(𝑘) 𝑢 over 𝑘iteration from the neighbourhood N (𝑣). Then, the node embedding of node 𝑣is updated which is denoted by 𝑎𝑣. The final updated nodes are passed through a neural network for prediction. [Icons from [17]] 2.2 Major GNN Frameworks The ability of GNN to capture complex relationships originates from two prime components of the GNN framework: (1) aggregation and (2) update. Over multiple iterations, each node 𝑣∈V shares information containing the learned node feature with their neighborhood aggregates the node feature received from its neighborhood, and updates the node embedding using the learned/aggregated information [15, 16]. For a 𝐿-iteration, the general aggregation and updating function in 𝑘∈𝐿iteration is summarized as: 𝑎(𝑘) 𝑣 = AGGREGATE(𝑘) (ℎ(𝑘−1) 𝑢 |𝑢∈𝑁(𝑣)) (∀𝑘∈[𝐿], 𝑣∈𝑉), (1) ℎ(𝑘) 𝑣 = UPDATE(𝑘) (ℎ(𝑘−1) 𝑣 ,𝑎(𝑘) 𝑣 ) (∀𝑘∈[𝐿], 𝑣∈𝑉), (2) where 𝑎(𝑘) 𝑣 and ℎ(𝑘) 𝑣 represents message vector and the representation vector of node 𝑣at the 𝑘-th iteration, respectively. At the first iteration of GNN, the initial node representation vector ℎ(0) = 𝑋. AGGREGATE(·) and UPDATE(·) are parameterized functions. The final node representation 𝐻(𝐿) is fed into the classifier for identification, where 𝐻(𝐿) = [ℎ(𝐿) 𝑣 ]. With the advent of GNN frameworks in 2009 [18], several GNN frameworks have been proposed, wherein its core, different choices of AGGREGATE(·) and UPDATE(·) functions lead to different variants of the GNN model. We briefly summarize the major GNN frameworks and showcase different aggregation and update functions related to the summarized GNN approaches described in Section 4. 2.2.1 Graph Convolutional Network (GCN). Kipf et al. [19] proposed a framework that uses the convolution function on graph data to perform semi-supervised classification tasks. Each node in the graph learns the feature information from all its neighbors using the following aggregation and update function. AGGREGATE(𝑘) ({{ℎ(𝑘−1 𝑢 |𝑢∈N (𝑣)}}) = ∑︁ 𝑢∈N(𝑣) ℎ(𝑘−1) 𝑢 √︁ deg(𝑣)deg(𝑢) (3) UPDATE(𝑘) (ℎ(𝑘−1) 𝑣 ,𝑎(𝑘) 𝑣 ) = 𝜎(𝑊(𝑙)𝑎(𝑘) 𝑣 ). (4) The aggregation process (equation 3) for node 𝑣is a function of feature information ℎ𝑣of all neighboring nodes N (𝑣) from previous iteration 𝑘−1 iterations, where a non-parametric weight 1 √ 𝑑𝑒𝑔(𝑣)𝑑𝑒𝑔(𝑢) is assigned to any node 𝑢and 𝑣. The aggregated message 𝑎𝑣is used to update node 𝑣(equation 4) learned representation using activation function 𝜎, where 𝑊(𝑙) is a parameter matrix. While GCN provides a simplistic approach to learning graphical patterns, a major disadvantage of GCN is the overhead caused by computation for large graphs. 2.2.2 GraphSAGE-mean. Hamilton et al. [20] proposed a framework called GraphSAGE (SAmple and aggreGatE) to perform machine learning tasks on large graph-structured data (e.g. social network). GraphSAGE uses a random sampling strategy to aggregate information from a node’s neighbors to generate its embedding, unlike GCN [19] where all neighbors are considered. ACM Trans. Priv. Sec., Vol. 0, No. 0, Article 1. Publication date: January 2024. Use of Graph Neural Networks in Aiding Defensive Cyber Operations • 1:5 AGGREGATE(𝑘) ({{ℎ(𝑘−1) 𝑢 |𝑢∈N (𝑣)}}) = 1 deg(𝑣) ∑︁ 𝑢∈N(𝑣) ℎ(𝑘−1) 𝑢 (5) UPDATE(𝑘) (ℎ(𝑘−1) 𝑣 ,𝑎(𝑘) 𝑣 ) = 𝜎(𝑊(𝑙) [ℎ(𝑘−1) 𝑣 ,𝑎(𝑘) 𝑣 ]). (6) The aggregation process (equation 5) for node 𝑣is a function of node embedding ℎ𝑣of all neighboring nodes N (𝑣) from previous iteration 𝑘−1 iterations, where a non-parametric weight 1 𝑑𝑒𝑔(𝑣) . The update message 𝑎𝑣 (equation 6) is used to update node 𝑣learned representation using activation function 𝜎, where a random sample of the node from [ℎ,𝑎] is considered. The advantages of GraphSAGE include its ability to operate on large graphs with large numbers of nodes and edges. Due to the simplistic sampling technique that selects a subset of neighbors for each node, for a large graph, the process of aggregating is lightweight. Additionally, GraphSAGE can handle heterogeneous graphs where the dimensions of node features may differ. 2.2.3 Graph Attention network (GAT). Veličković et al. [21] proposed a graph attention network (GAT) that can learn the importance of each node when performing message passing. More specifically, when aggregating node information from neighboring nodes for each target node in the graph, the semantic similarity between the target node and each neighboring node will be considered by the multi-head attention mechanism, and important neighboring nodes will be assigned higher attention scores when performing the neighborhood aggregation. 𝛼(𝑙) 𝑢𝑣= exp(LEAKYRELU(𝑎(𝑙)𝑇[𝑊(𝑙)ℎ(𝑙−1) 𝑣 ,𝑊(𝑙)ℎ(𝑙−1) 𝑢 ])) Í 𝑢′∈N(𝑣) exp(LEAKYRELU(𝑎(𝑙)𝑇[𝑊(𝑙)ℎ(𝑙−1) 𝑣 ,𝑊(𝑙)ℎ(𝑙−1) 𝑢′ ])) (7) AGGREGATE(𝑘) ({{ℎ(𝑘−1 𝑢 |𝑢∈N (𝑣)}}) = ∑︁ 𝑢∈N(𝑣) 𝛼(𝑙) 𝑣𝑣ℎ(𝑘−1) 𝑢 (8) UPDATE(𝑘) (ℎ(𝑘−1) 𝑣 ,𝑎(𝑘) 𝑣 ) = 𝜎(𝑊(𝑙)𝑎(𝑘) 𝑣 ). (9) Unlike GCNs, GATs use attention mechanisms to assign different weights to different nodes in the graph when aggregating information from neighbors. This allows GATs to learn more fine-grained representations that capture the relative importance of different nodes for each node in the graph. Overall, GATs are a more powerful and flexible approach to node-level representation learning on graphs, but they can also be more computationally expensive than GCNs. The choice between GAT and GCN depends on the specific application and the computational resources available. 2.2.4 Gated Graph Neural Network (GGNN). GGNN is a variant of recurrent GNN, which aims to learn node representations with recurrent neural architectures. Li et al. [22] assumes that the node in a graph constantly exchanges information/message with its neighbors until a stable equilibrium is reached. AGGREGATE(𝑘) ({{ℎ(𝑘−1 𝑢 |𝑢∈N (𝑣)}}) = 𝐴𝑇 𝑖[ℎ(𝑘−1) 1 , . . . ,ℎ(𝑘−1) 𝑛 ]𝑇 (10) UPDATE(𝑘) (ℎ(𝑘−1) 𝑣 ,𝑎(𝑘) 𝑣 ) = GRU(𝑎(𝑘) 𝑖 ,ℎ(𝑘−1) 𝑖 ). (11) The aggregation process (equation 10) for node 𝑣is a function of node embedding ℎ𝑣of all neighboring nodes N (𝑣) from previous iteration𝑘−1 iterations, where 𝛼𝑢𝑣is the attention value for node𝑢and 𝑣. The update message 𝑎𝑣(equation 11) is used to update node 𝑣learned representation using activation function 𝜎. Unlike GCNs, GGNNs can handle dynamic graphs where the structure of the graph changes over time assisted by Gated Recurrent Units (GRU) that change in the graph structure over time. GGNNs are more interpretable due to gates control the flow of information into and out of each node, allowing for a more fine-grained understanding of how information is being processed. GGNNs are a more powerful and flexible approach to node-level representation learning on dynamic graphs with longer-range dependencies, but they can also be more computationally expensive than GCNs. The choice between GGNN and GCN depends on the specific application and the characteristics of the graph data. ACM Trans. Priv. Sec., Vol. 0, No. 0, Article 1. Publication date: January 2024. 1:6 • Mitra et al. 3 SURVEY OVERVIEW AND TAXONOMY The general definition of cyber operations refers to the employment of cyberspace capabilities by an entity or organization towards a specific objective [23]. For the scope of this survey, we will refer to cyber operations from a defensive objective. Furthermore, a cyber attack comprises a series of steps by the attacker, leading from attack inception to the intended resolution, referred to as attack life-cycle. Researchers have proposed several attack life-cycles [4, 24–28] to analyze the attack characteristics and design better cyber defense strategy. Among all these proposed attack life cycles, the diamond model [25], MITRE ATT&CK [24], and Lockheed Martin cyber kill chain (CKC) [4] are most adopted by the industry. The diamond model analyzes an attack by outlining the correlation between the attacker’s motivations, victim, and infrastructures in the form of a diamond shape. Specifically, the model characterizes an attack through four quadrants: adversary, infrastructure, capabilities, and victim. By examining the relationships between these quadrants, the diamond model helps understand the nature of the threat and develop strategies against it. MITRE ATT&CK model analyzes an attack by identifying detailed tactics, techniques, and procedures (TTPs) employed by the attacker throughout the entire attack life-cycle. It is organized as a matrix. Along the top row, it lists twelve tactical stages of an attack (initial access, execution, persistence, privilege escalation, defense evasion, credential access, discovery, lateral movement, collection, command & control, exfiltration, and impact) and possible techniques and procedures of each tactic in columns. It is comprehensive, covering a wide range of potential TTPs. Furthermore, the model gets regular updates to incorporate new attack TTPs as they are discovered. Lastly, Lockheed Martin’s Cyber kill Chain (CKC) describes the stages of a typical cyber attack as a linear chain of seven stages, namely: Reconnaissance, Weaponization, Delivery, Exploitation, Installation, Command & Control, and Actions on Objectives. This model provides a simplistic high-level view of the attack process, with a focus on the objective of the attacker in each stage. Due to the straightforward approach and wide acceptance throughout the industry, we will follow the CKC to analyze and develop our survey taxonomy. On the other hand, traditional prevention techniques primarily rely on signature-based static approaches to disrupt these attack life cycles. Despite performing well with restricted cost, it fails to detect novel attacks and is easy to bypass with signature spoofing techniques. One of the leading reasons for the upward trend of ML in cybersecurity stems from this drawback. The pattern analysis capability and adaptation to behavioral changes lead to hybrid analysis that relies on static logic driven by dynamic behavioral data. To fuel this approach, data must contain complete, relevant, and rich contextual information to represent all potential outcomes. It should also be rich enough to cover all the details and relations between various working components like devices, applications, protocols, and network sensors to derive the right decision. Graph data structure perfectly fulfills these requirements. However, due to its heterogeneous nature, traditional ML models like CNN cannot utilize graph data for learning. Addressing this issue, GNN has emerged as a promising ML technique that can leverage the valuable threat information represented as graphical data to disrupt the attack life cycle. Following this, we will look into adversary activities through the lens of CKC and how GNN contributes from a defensive standpoint to counter each stage. We provide a summarized version of our taxonomy in Figure 2. 3.1 Reconnaissance Reconnaissance is the first phase of the CKC, where the attacker identifies a victim and gathers information to discover vulnerabilities. It is accomplished by harvesting any information that can be useful to conduct an attack. For example, login credentials, user IDs, email addresses, system configuration, location, and others fall under the adversary’s radar. To develop a concrete defense strategy, the defender should engage in continuous privacy maintenance activities to prevent the adversary from gathering information. To ensure privacy, GNN can be used for link prediction, recommendation systems, and information embedding tasks to thwart adversaries from discovering sensitive information. ACM Trans. Priv. Sec., Vol. 0, No. 0, Article 1. Publication date: January 2024. Use of Graph Neural Networks in Aiding Defensive Cyber Operations • 1:7 CYBER KILL CHAIN STAGES & POSSIBLE ATTACKER ACTIVITIES RECONNOISSANCE WEAPONIZATION DELIVERY EXPLOITATION INSTALLATION COMMAND & CONTROL ACTION ON OBJECTIVES HARVEST EMAIL DISCOVER SERVER PORT SCANNING COMPILE EXPLOITS SIMULATION TESTING PHISING ATTACHMENT REMOVABLE MEDIA SOCIAL ENGINEERING CLIENT-SIDE ATTACK MALICIOUS LINK INSTALL BACKDOOR UPDATE REGISTRY AUTORUN KEY & SERVICES TWO-WAY CHANNEL ESCALATE PRIVILEDGE UPDATE PROTOCOL COLLECT CREDENTIALS LATERAL MOVEMENT PRIVACY MAINTENANCE RESEARCH ANOMALY DETECTION VULNERABILITY DETECTION INTRUSION DETECTION MALWARE DETECTION REPORT DATA OBFUSCATION INFORMATION SECURITY CYBER THREAT INTELLIGENCE ADVERSARIAL SIMULATION URL FILTER THREAT EXTRACTION ANTI SPAM SOFTWARE AUTHORIZING UPDATE SCANNING ENDPOINT SECURITY ANTIVIRUS PROXY FILTER FIREWALL ACCESS CONTROL ANTI BOT DOCUMENT SECURITY KNOWLEDGE GRAPH DEFENSIVE MEASURES TO BREAK CYBER KILL CHAIN Fig. 2. Overview of our proposed taxonomy. We considered seven phases of the cyber kill chain (CKC) [Reconnaissance, Weaponization, Delivery, Exploitation, Installation, Command & Control, Actions on Objectives] with possible attacker activi- ties. For prevention, we consider seven defensive phases [Privacy Maintenance, Research, Anomaly Detection, Vulnerability Detection, Intrusion Detection, Malware Detection, Report] with measures to counter and break the CKC from culmination. 3.2 Weaponization Weaponization is the second stage, where attackers create/modify payload to take advantage of the discovered vulnerabilities in the target infrastructure to carry out an attack. This developed payload can be anything from a threat agent to a piece of malware, packaged to get delivered via any means to cause damage. From a counter- proactive standpoint, defenders engage in continuous research by maintaining cyber threat intelligence (CTI) for possible attacks on the employed GNN models. By conducting such measures, defenders can maintain an upper hand in the ongoing cyber warfare and prevent significant damage. For example, simulated attacks on GNN utilizing known vulnerabilities can help discover and evaluate the effectiveness of existing security measures. 3.3 Delivery Delivery is the third stage, referring to the transfer of weaponized payload to the target system. Attackers execute various delivery mechanisms like phishing, removable media, and social engineering, depending on the objective, target vulnerability, and desired stealth. From a defensive standpoint, organizations safeguard themselves against the delivery of malicious payloads by monitoring network or system anomalies. These measures include anti- spam, URL or email filtering, and more. Hence, anomaly detection can be considered as a real-time malicious payload delivery prevention measure, aiming to detect suspicious items, network traffic, or observations. In such cases, GNNs play a vital role in detecting operational changes by learning network-system traffic activity graphs. 3.4 Exploitation Exploitation is the fourth stage that involves the utilization of the vulnerability in the target system to initiate unauthorized access. During this, the attacker uses the delivered payload to exploit the vulnerability in the target system to execute malicious code or commands for initial foothold establishment. Some standard vulnerabilities arise from software bugs, misconfigurations, and other areas. As a preventative measure, vulnerability detection involves identifying persisting loopholes to prevent exploitable scopes in source code, application patch updates, ACM Trans. Priv. Sec., Vol. 0, No. 0, Article 1. Publication date: January 2024. 1:8 • Mitra et al. and security policies & procedures. To fortify this, GNNs can learn the semantic flow of the application behavior and determine prevailing vulnerabilities before getting exploited by the delivered malicious payload. 3.5 Installation Installation is the fifth phase, where the attacker establishes a persistence channel to solidify their foothold by installing threat actors into the compromised infrastructure. Attackers may modify registries, execute malicious files, and perform other actions depending on objectives and infrastructure. For prevention, defenders conduct intrusion detection by reviewing signed certificates, application compile-time, analyzing privileges, and other relevant factors. Therefore, in a robust intrusion detection system, it is crucial to understand the system’s topological structure. GNNs’ ability to adapt and handle massive topological information makes them highly effective in identifying such malicious executions. 3.6 Command & Control Command & control (C2) is the sixth phase, referring to the communication and coordination infrastructure between attacker and victim’s system or network to maintain persistent control by the attacker. Installed malware and escalated privilege allow attackers to issue commands, receive data, and sustain control within victim’s environment. Hence, detecting and disrupting the C2 channel is essential in thwarting the ongoing attack. Security measures like malware detection help intercept the C2 communication channel, thus limiting the attacker’s control. Such detection requires a classification mechanism to identify system processes based on the execution pattern. GNN’s innate ability to learn program flow aids in detecting and eradicating malware. 3.7 Actions on Objectives Actions on objective is the final phase, during which an attacker accomplishes intended objectives such as data theft, sabotage, disruption, or other malicious goals. Attackers often erase or alter evidence of their presence and actions to maintain anonymity after goal accomplishment. Actions may be taken to impede security analysts from tracing, including deleting logs or manipulating timestamps. Reporting attack TTPs is critical for analysis and further prevention. Activity logs, after-action reports, and cybersecurity knowledge graphs (CKGs) are shared globally to learn and identify attack patterns. In such scenarios, GNNs play a valuable role in learning from a vast amount of graphical data to support other security tools with improved knowledge and contextual understanding. We define our taxonomy from a defensive cyber operations standpoint, where each category provides a direct countermeasure to the attack stage described above. Hence, our taxonomy is also divided into seven categories: privacy maintenance, research, anomaly detection, vulnerability detection, intrusion detection, malware detection, and report. As mentioned, GNN has contributed significantly by utilizing its innate ability to process and learn from a tremendous amount of relational data in all these scenarios. This constitutes the rationale of our survey on the implementation of GNN in aiding cyber defense. Our taxonomy is based on the applications of GNN to break down each phase of the CKC. In the next section 4, we will address the abilities and drawbacks of existing research utilizing GNN to counter each phase of the CKC following the taxonomy. Later in Section 5, we will discuss potential areas of improvement, covering the identified drawbacks and future research directions. 4 GNN’S USE IN CYBER In this section, we will discuss each preventive measure against the cyber kill chain in detail. First, we will discuss how the measures are beneficial in countering the attack phase using GNN. Then, we will delve deep into discussing some major recent developments in the last decade with a summarized table associated with each phase. We also provide a complete research information Table 9 containing each article with its respective category, employed GNN models, classification types, experimental datasets, research timeline, and accuracy. ACM Trans. Priv. Sec., Vol. 0, No. 0, Article 1. Publication date: January 2024. Use of Graph Neural Networks in Aiding Defensive Cyber Operations • 1:9 4.1 Privacy Maintenance In the context of ML, much like the stages of the CKC, vulnerabilities threaten the privacy and integrity of models. Recent study [29, 30] shows that ML models may suffer from the potential risk of leaking private information, are vulnerable to adversarial attacks [31], can inherit and magnify bias from training data, and lack interpretability [32]. In this section, we primarily emphasize the principle of privacy among other issues listed above. To safeguard privacy, researchers have developed privacy-preserving GNNs. These GNNs can be broadly categorized into four types: adversarial privacy preserving, federated learning, split learning, and differential privacy. Table 2 provides an overview of the various privacy-preserving GNNs and their respective categorizations including other notable works. In the following, we will discuss state-of-the-art methods within each category. Paper Title Focus/Objective Contributions Limitations Adversarial Privacy Preserving Adversarial privacy- preserving graph embed- ding against inference attack [33] Integration of graph em- bedding and privacy pro- tection into an end-to-end pipeline against inference attack. • Graph embedding algorithm against infer- ence attack. • Introduced Privacy-Disentangling and Privacy-Purging. • Full access of sensitive at- tribute might not be possible in real world. Privacy-preserving rep- resentation learning on graphs: A mutual informa- tion perspective [34] To learn node representa- tions to achieve high per- formance for the primary learning task. • Designs tractable algorithms to estimate intractable mutual information. • Reduces the leakage of sensi- tive attributes but increases GNN training cost Information obfuscation of graph neural net- works [35] Formulate and address the problem of information ob- fuscation on graphs with GNNs. • Creates a strong defense against informa- tion leakage while only suffering a mar- ginal loss in task performance. • To some context, use of cus- tom perturbations on node for AT. Federated Learning , Differential Privacy & Split Learning Fedgnn: Federated graph neural network for privacy-preserving recom- mendation [36] Leverages FL and member- ship inference for privacy assurance. • Designed novel federated framework for privacy-preserving GNN-based recom- mendation. • Introduced mechanism to protect model gradients in model training with local dif- ferential privacy. • This method fails to solve so- cial recommendations, and the clients models are not personalized Towards representa- tion identical privacy- preserving graph neural network via split learn- ing [37] To address privacy issue of decentralized graphs using split learning and horizon- tal FL. • Generates the same node embedding as the centralized counterpart. • Proposes a secure pooling mechanism in- stead of global pooling aggregator. • Do not use the formal no- tion of differential privacy and provide weaker privacy guarantees. Others Learning privacy- preserving graph convo- lutional network with partially observed sensi- tive attributes [38] Focuses on attribute infer- ence attacks on GNNs. • Formulates a model to mitigate the indi- vidual privacy leakage using partially ob- served sensitive attribute. • Did not give differential pri- vacy guarantees. SecGNN: Privacy- preserving graph neural network training and inference as a cloud service [39] Focuses on GNN training and inference services on cloud platforms. • First system supporting privacy preserv- ing GNN training and inference as a cloud service. • Model might be weak for so- phisticated adversaries. Table 2. A summary of the existing literature on privacy-preserving GNN with their scope, contribution, and limitations. ACM Trans. Priv. Sec., Vol. 0, No. 0, Article 1. Publication date: January 2024. 1:10 • Mitra et al. Significant efforts have been made in recent studies to enhance privacy protection and mitigate the risks of sensitive information leakage through modifications to the training process of GNNs. A notable example is the work of Li et al. [33], where the concept of Adversarial Privacy Graph Embedding (APGE) to counter attribute inference attacks is introduced. The approach incorporates disentangling and purging mechanisms aimed at eliminating users’ private information from the learned node representations. To achieve this, they integrate privacy-preserving regulation components into the loss function during the training phase. Experiments on Yale and Rochester datasets indicated the inclusion of disentangling and purging mechanisms brought significant gain in performance. Similarly, the authors in [34] present privacy protection utilizing adversarial privacy-preserving techniques. In the work, they propose a framework for privacy-preserving representation learning on graphs, adopting a perspective rooted in mutual information. Specifically, the framework is designed to address the concerns surrounding centralized training scenarios in GNNs and aims to prevent the inadvertent leakage of training data. To achieve this, they introduce bounding mechanisms that limit the exposure of sensitive information such as node features, node labels, and link status during GNN model training using three benchmark datasets including Cora [40], Citeseer [41], and Pubmed [42]. In a separate study [35], researchers present a solution to combat attribute inference attacks on GNNs through an adversarial learning approach. The proposed Graph Adversarial Networks (GAL) framework approach revolves around a Wasserstein distance-based mini-max game between a desired graph feature encoder and a worst-case attacker for information obfuscation of sensitive attributes, empirically evaluated across 6 graph benchmark datasets including Citeseer [41], Pubmed [42], M9, ML-1M [43], FB15K-237 [44], and WN18RR. Another way to ensure privacy preservation is by utilizing Federated Learning (FL). FedGNN [36], for instance, combines FL with GNNs in recommendation systems, aiming to safeguard users’ privacy. This system captures complex user-item interactions by constructing local user-item graphs. Additionally, to address privacy concerns, the implementation of local differential privacy techniques helps mitigate privacy risks at the local level. The authors used six widely used benchmark datasets for recommendation, including MovieLens11 (100K,1M, and 10M) [43], Flixster [45], Douban [46], and YahooMusic [47]. In recent years, Split Learning (SL) has emerged as another prominent method and has captured the interest of researchers in the field of privacy maintenance tasks. SL involves partitioning a complete model into multiple sections. Building upon this concept, [37] explores the integration of GNNs with SL to protect model privacy, specifically in node-level tasks, in scenarios where data is distributed horizontally across multiple silos and privacy is guaranteed via a secure min-max pooling aggregation mechanism. Similar to [34], the authors also utilize the three same datasets for evaluation. In another line of work, the authors in [38] delve into the realm of privacy-preserving GNNs, with a specific focus on handling partially observed sensitive attributes. Their primary objective is to address the issue of individual privacy leakage among private users. To achieve this, the authors propose a method that disentangles the node features into distinct latent representations of sensitive and non-sensitive attributes by imposing orthogonality within a suitable space. The authors evaluated their model on five benchmark datasets including two datasets with social networks, i.e., (Pokec-z and Pokec-n) [48], and three ethical datasets constructed in [49], i.e., German credit, Recidivism, and Credit defaulter. More recently, researchers have been focusing on deploying GNNs in cloud infrastructure to facilitate scalable and efficient graph analysis while maintaining privacy. One notable example is SecGNN [39], which enables privacy-preserving GNN training and inference services in the cloud. Unlike many existing approaches that rely on federated learning to protect privacy, with the primary emphasis on target system models and private training, SecGNN operates in an outsourced scenario. This means that the owner of the graph data can send its encrypted graph data to the cloud for secure training. In addition, SecGNN also supports secure GNN inference on encrypted GNNs and inputs, ensuring end-to-end security in the process. We further discuss the persisting loopholes and improvement areas in Section 5.1. ACM Trans. Priv. Sec., Vol. 0, No. 0, Article 1. Publication date: January 2024. Use of Graph Neural Networks in Aiding Defensive Cyber Operations • 1:11 4.2 Research In the weaponization phase, the adversary develops an attack aimed at exploiting the identified vulnerabilities in the target system. Therefore, to maintain an effective security posture in an organization, the defender’s job is to conduct adversarial simulations to determine possible drawbacks in the existing defensive ML models. One defensive approach is research, which allows defenders to evaluate and identify loopholes in end-systems or adopted models. This can be done by performing regular attack simulations using GNN on security ML models based on the reported threat intelligence. Information cover from globally documented cybersecurity databases (e.g., CVE) or scholarly articles. Below we discuss the research landscape and provide a summary in Table 3. A hierarchical reinforcement learning adversarial attack by modifying the graph combinatorial structure for graph- and node-level classification tasks was proposed by Dai et al. [50]. The modification is done by sequentially adding or dropping nodes or edges in the target graph. The attack is applicable in different adversarial settings with diverse GNN models for inductive and transductive learning tasks ([3, 19, 20, 59]). The model achieved a 40% to 60% success rate for graph-level attacks using randomized synthetic data and node-level attacks using Citeseer [41], Cora [40], Pubmed [42], and Finance datasets. In defense, the authors proposed incorporating adversarial samples in training, supported by the 1% decrease in attack accuracy. Similarly, Zügner et al. [51] investigated training time attacks using surrogate model meta-gradients on GNN for node classification tasks. Meta-learning helps the process to be more time and data-efficient by finding suitable hyperparameters. Evaluation in a black-box setting over Citeseer [41], Cora-ML [40], and POLBLOGS datasets [60] confirmed GNN perform worse than a simple baseline of up to 48% with a 5% change limit. However, gradient-based attacks are limited in achieving sub-optimal results. Lin et al. [52] proposed an exploratory adversarial attack (EpoAtk) on GNN to boost the gradient-based perturbations and sidestep the possible misinformation provided by the maximal gradient. Experiments on semi-supervised node classification tasks over modified Citeseer [41], Cora [40], and Cora-ML [61] datasets revealed a drop in GCN accuracy with fewer perturb edges, outperforming the state-of-the-art attacks. For white-box adversarial attacks against link prediction algorithms, Lin et al. [53] developed a transferable evasion attack on the greedy heuristic that exploits incremental computation against a state-of-the-art link prediction algorithm called SEAL. It uses degree distribution preservation on the adjacency and the node information matrix to ensure un-noticeable perturbations in the sub-graph by an un-noticeability threshold. Evaluations over US Air, NS [62], Celegans [63], and PB [64] datasets justify an approximated accuracy of 90% with defined constraints. On the other hand, for the semi-black box graph classification setting, Zhang et al. [54] developed a sub-graph-based backdoor attack. It injects a subset of polluted sub-graphs in the training set to influence GNN to draw a correlation between the target and the trigger and predict the target label. Experiments on Bitcoin [65], Twitter [66], and COLLAB [67] datasets concluded its high success rate. Additionally in defense, the authors demonstrated works on certified defense using randomized sub-sampling. However, the findings are not generic and have a minor preventative impact, indicating further research requirements. To elude black-box malware detectors, Zhang et al. [55] developed a semantic preserving reinforcement learning-based (SRL) attack. To maintain malware integrity, the model iteratively generates adversarial samples by sequentially injecting semantic Nops in the control flow graph (CFG). According to the results over labeled datasets from VXHeavens [68], VirusShare [69], and VirusTotal [70], SRL was able to achieve 100% evasion accuracy. Again, to attack GNN-based limited-budget IoT NIDS systems, Zhou et al. [56] developed a Hierarchical Adversarial Attack (HAA) generation method. A shadow GNN model based on the saliency map technique generates adversarial examples by identifying and modifying critical node features with minimal perturbations. Random Walk with Restart mechanism (RWR) determines hierarchical vulnerable nodes based on the structural features and overall loss. Finally, to alter the classification labels, an adversarial shadow GNN disguises malicious packets as regular or vice versa. Experiments with UNSW-SOSR2019 [71] dataset over three baseline approaches proved degrading accuracy by more than 30% against GCN and JK-Net. ACM Trans. Priv. Sec., Vol. 0, No. 0, Article 1. Publication date: January 2024. 1:12 • Mitra et al. Paper Title Focus/Objective Contributions Limitations Research on Adversarial Attacks Adversarial Attack on Graph Structured Data [50] Developed adversarial at- tack on GNN-based graph supervised classification algorithm that can learn attack policy. • Considered white box, practical black box, and black box attack settings. • Demonstrated attack with hierarchical re- inforcement learning, random sampling, gradient-based, and genetic algorithm. • Limited experiments on real- world datasets to prove ro- bustness and transferability. • Do not consider poisoning attacks. Adversarial Attacks on Graph Neural Networks via Meta Learning [51] Developed a training time meta-learning poisoning attack on GNN for node classification tasks. • Developed training time attack on attrib- uted graphs. • Used meta-gradient to solve bilevel training-time attacks. • Did not provide the working mechanism of the attack. • No defensive measure is pro- vided against such an attack. Exploratory Adversarial Attacks on Graph Neural Networks [52] Developed an exploratory adversarial attack method to boost the gradient- based attacks on GNN. • Developed an exploratory approach to boost the gradient-based adversarial at- tacks. • Does not provide any defen- sive measure against the pro- posed approach. Adversarial Attacks on Link Prediction Algo- rithms Based on Graph Neural Networks [53] Developed an adversarial attack framework that gen- erates perturbed graphs while preserving the over- all structure to fool GNN- based link prediction tasks. • Developed an adversarial attack to fool GNN on link-prediction tasks. • Generate perturbed graphs while preserv- ing the overall structure to influence tar- geted output errors. • Did not provide any defen- sive measure against the pro- posed attack. Backdoor Attacks to Graph Neural Net- works [54] Developed a subgraph- based backdoor attack to GNN for graph classifica- tion tasks. • GNN classifier predicts a targeted label if trained on the backdoor dataset. • The backdoor attack does not impact GNN’s accuracy over clean testing graphs. • Explored randomized smoothing-based certified defense but failed to provide a concrete solution. Semantics-preserving Re- inforcement Learning At- tack Against Graph Neural Networks for Malware De- tection [55] Developed reinforcement learning-based semantics preserving adversarial attack against black-box GNNs for malware detec- tion. • Used RL to insert Nops to preserve the program CFG semantics and elude GNN- based malware detectors. • The attack is designed considering a black- box scenario and is transferable to similar models that work on sequential data. • Did not provide any defen- sive measure against pro- posed attack approaches. Hierarchical Adversarial Attacks Against Graph Neural Network Based IoT Network Intrusion Detection System [56] Developed a hierarchical adversarial attack gener- ation method targeting state-of-the-art GNN- based black-box NIDS systems in IoT. • Developed framework for level-aware black-box attack strategy to generate sam- ples using shadow GNN models. • Used saliency map to identify critical fea- ture elements and RWR mechanism for hierarchical node selection. • Do not provide any defen- sive measure against the pro- posed attack approach. • The Proposed approach is limited to NIDS in the IoT do- main. Research on Adversarial Defense Developing graphical detection techniques for maintaining state esti- mation integrity against FDIA in integrated electric cyber-physical system[57] Developed an FDIA detec- tion method using GNN, combined with a capsule network to detect tam- pered measurements and attack locations. • Used GNN to detect tampered measure- ments without external knowledge. • Used Capsule scheme to detect precise at- tack location and adapt with frequently evolving network structure. • The GN detection model cannot adapt to frequently changing graphs. • More practical experimenta- tion is needed for robust im- plementation. Graph Neural Networks Based Detection of Stealth False Data Injection At- tacks in Smart Grids [58] Developed generic, local- ized, and stealth FDIA gen- eration methodology and a scalable real-time GNN- based detector model. • Developed a stealth FDIA methodology that can bypass BDD systems. • Developed a stochastic gradient descent- based stealth FDIA detection system. • Experiment is conducted over a randomly generated synthesized dataset. Table 3. Summary of the existing literature on adversarial research on GNN with scope, contribution, and limitations. ACM Trans. Priv. Sec., Vol. 0, No. 0, Article 1. Publication date: January 2024. Use of Graph Neural Networks in Aiding Defensive Cyber Operations • 1:13 As defensive research, to prevent false data injection attacks (FDIAs) and identify attack locations in electrical power networks, Li et al. [57] proposed a capsule scheme with GNN. The capsule scheme was combined with a dynamic routing mechanism to make GNN flexible to power topology changes and precisely identify attack locations. Experiments over different models with a consistent precision of 0.9939 and recall of 0.98231 on IEEE 30 [72] and 0.97131, and 0.97643 on IEEE 118-bus systems [73], showcased its robustness. Similarly, Boyaci et al. [58] proposed another FDIA detector using GNN for early warnings in smart grid systems. The model was designed to handle dynamic measurement data by learning the underlying topological structure alongside data patterns. Additionally, the authors developed a generic, localized, and stealth FDIA generation methodology and publicly accessible datasets for additional research. Experiments were conducted over synthetic data using Pandapower [74] over ERCOT’s load profiles for IEEE 14, 118, and 300 buses [73, 75, 76], and the proposed model outperformed the benchmark CNN models by 3.14%, 4.25%, and 4.41%. In Section 5.2, we further discuss persistent loopholes and areas for improvement. 4.3 Anomaly Detection Anomaly detection refers to identifying suspicious items, events, or observations that exhibit significantly distinctive characteristics from standard patterns or behaviors. In cybersecurity, anomalies can occur due to numerous factors, such as initiation/delivery of malware attacks, network intrusions, social engineering, or insider threats. Detecting these anomalies is critical for identifying and preventing the delivery of potential malicious payloads. Furthermore, anomaly detection can provide early warning signs of an attack, reduce false positives, and help to improve the overall security posture. Anomalies are of three types: point, contextual/conditional, and collective [77]. In the context of GNN, point anomaly refers to node or edge classification, whereas contextual and collective anomalies are primarily graph classification. The potential of GNN in anomaly detection tasks has proven beneficial, which we elaborate on in the following paragraphs with a summary in Table 4. Chaudhary et al. [78] developed a technique to detect point anomalies such as spam, fake reviews, or malicious activities within the social (Twitter [87]) and email (Enron [88]) networks utilizing GNN. Findings conclude that ‘degree’ and ‘between centrality’ work best for capturing anomalous nodes. A similar social anomalous user (bots, spammers) detection approach was developed by Li et al. [79], where they used a Relevance-Aware Anomalous Users Detection model using GNN (RAU-GNN). A GCN-based relation fusion layer first generates an unfined multiple user-node relation graph by extracting from all users and relations. Then, a multi-head GAT-based embedding layer produces high-level embeddings for GNN to learn and identify anomalous users. Experimental high accuracy over Twitter [87] API and YelpChi [89] dataset confirmed the claims. Ji et al. [80] proposed a contextual anomalous event detection method considering dynamic multi-source data for secure critical infrastructure domain. Different feature-space social anomaly data were extracted and fused into a single feature space based on the abnormal score obtained through spectral clustering. A deep graph neural network (Deep-GNN) was trained over the fused data and, was tested using multi-source data from micro-blog [90] and Sina social platform [91]. Test results compared with CNN and LSTM demonstrated robust and adaptive capabilities with an average accuracy of 95%. Similarly, to prevent spamming and detect spammers in social media, Song et al. [81] proposed a graph classification approach instead of node classification using GNN. The model is used to detect spammers from embedded interactive relationship graphs using a graph classification approach. Experiments were conducted using 10-fold cross-validation over the tagged.com dataset. Wang et al.[82] proposed a One Class Graph Neural Network (OCGNN) for collective graph anomaly detection (GAD). OCGNN maps the nodes and relationships into a hypersphere to generate node embeddings close to the center. Hence, the common factors are identified by the GNN layer. GCN, GAT, or GraphSAGE can act as a GNN layer in this framework. Due to hypersphere learning, it can also be considered a natural extension of a one-class support vector machine (OCSVM). Cora [40], Citeseer [41], and Pubmed [42] datasets were used for evaluation against twelve two-stage GAD methods and three SOTA GAE-based GAD approaches. To extend the previous ACM Trans. Priv. Sec., Vol. 0, No. 0, Article 1. Publication date: January 2024. 1:14 • Mitra et al. Paper Title Focus/Objective Contributions Limitations Point Anomaly Anomaly Detection using Graph Neural Net- works [78] Detecting spam, fake re- views, or malicious activ- ities in email (Enron) and social networks (Twitter). • Developed a GNN model to detect anom- alies in mail and social network graphs. • GNN encoding achieved a classification accuracy of over 98%. • Experiment was conducted over a limited data set. • Architecture was designed to cover specific scenarios. Relevance-Aware Anoma- lous Users Detection in So- cial Network via Graph Neural Network [79] Develop RAU-GNN to ac- quire fine-grained detec- tion results to identify ab- normal social users like bots, spammers, etc. • Fusion GCN layer is used for anomalous behavior classification. • Incorporated a Multi-head Graph Atten- tion Network (GAT) with GCN to detect camouflaging users. • GAT embeddings rely on GCN node representations. • Multiple computation-heavy (GAT, GCN) layers might in- crease computation. Contextual Anomalies An Anomaly Event De- tection Method Based on GNN Algorithm for Multi- data Sources [80] Detect anomalies in multi- source data in the secure critical infrastructure do- main. • Developed Deep-GNN model to incorpo- rate heterogeneous data set. • PCA was used in data pre-processing to increase robustness. • GNN heavily relies on spec- tral clustering for feature ex- traction and data fusion. Spammer Detection Using Graph-level Classification Model of Graph Neural Network [81] Developed a GNN model to detect spammers in so- cial media. • Converted user behavior graph to extract features for model training. • Used Bayesian optimization framework for hyperparameters tuning. • Used 10-fold cross-validation. • Experimental setup is lim- ited to a single dataset. • Time variations can be in- corporated to allow dynamic graph classification. Collective Anomaly One-class graph neural networks for anomaly de- tection in attributed net- works [82] Generate normal node em- bedding close to the center of the hypersphere for pre- cise anomaly detection. • OCGNN can generate more accurate em- beddings in close proximity. • Hypersphere learning allows the model to be robust from a usability standpoint. • The model cannot handle large dynamic graphs. One-class Temporal Graph Attention Neural Network for Dynamic Graph Anom- aly Detection [83] Generate natural node em- bedding close to the cen- ter of the hypersphere while incorporating dy- namic graphs. • TGAT is used to extract large dynamic graph representation. • The approach is capable of edge classifica- tion and link prediction. • The indirect classification mechanism and requirement of anomaly-free training data might make the model scope limited. Multi-layer Graph Neu- ral Network-Based Ran- dom Anomalous Behavior Detection [84] Developed a random anomalous edges de- tection model for an abundant edge graph. • Combined the GCN and GAT to learn ab- stract node features from the differenti- ated local structure influence. • The applicability of the model was tested with a diverse dataset. • The model was more in- clined towards random anomalous edge detection. Others GNN-based Graph Anom- aly Detection with Graph Anomaly Loss [85] To represent anomaly- detectable nodes for better anomaly and dense block detection using improved GNN loss function. • Developed an improved GAL function. • Improves the low-performing outlier de- tection algorithms for diverse graphs. • The algorithm indirectly in- creases the anomaly detec- tion accuracy by including outliers rather for the regu- lar values. Graph Neural Network- Based Anomaly Detection in Multivariate Time Se- ries [86] Developed a GDN to put together a structure learn- ing technique with atten- tion weights with GNN to explain anomalies in criti- cal infrastructure systems. • Sensor embedding is computed to find de- viations from normality. • Graph attention mechanism is used for forecasting, unlike other approaches. • Sensor embedding learning plays a crucial role in the overall model learning, mak- ing it less robust. Table 4. Summary of the existing literature on anomaly detection using GNN with scope, contribution, and limitations. ACM Trans. Priv. Sec., Vol. 0, No. 0, Article 1. Publication date: January 2024. Use of Graph Neural Networks in Aiding Defensive Cyber Operations • 1:15 work for large dynamic graphs, Huang et al.[83] proposed a one-class temporal graph attention neural network (OCTGAT) combining Temporal Graph Attention Network (TGAT)[92] with OCGNN. On top of the previous approach, TGAT was used to extract the dynamic graph representations and aggregate structural and time-based attributes using Bocher’s theorem with optimized computation. Anomalous nodes are detected by concatenating embeddings and feeding them to a feed-forward neural network. For such, the model requires to get trained with the non-anomalous dataset. According to the experiments over Wikipedia and Reddit datasets [93], OCTGAT surpassed the baseline approaches and can also execute edge classification and link prediction tasks. Shi et al. [84] proposed another collective anomaly detection approach that facilitates data analysis by detecting random anomalous behavior. The model combines GCN and GAT to learn the abstract features with more attention paid to the differentiated influence of the local structure. A two-layer GCN learns connected node attributes and GAT identifies the influence of nodes at different positions from the parameterized probability distribution. Experiments on six real-world networks (OpenFlights [94], Political blogs [60], Email-EU-core [95], Usairport, Jazz, and Highschool) alongside three benchmark models revealed its significant AUC edge over others. In a parallel research direction, motivated by the low-performing random walk (RW) based training approaches for diverse graphs, Zhao et al.[85] proposed an improved graph anomaly loss (GAL) function that helps GNN to represent outlier and unexpected dense blocks with improved accuracy. GAL uses global group patterns identified by graph mining algorithms to evaluate similarity and adjust margins for minority classes. Graph outlier loss, bounded test error, and dense block loss are key attributes for such tasks. Experiments on BitCoin [96] and Weibo [97] datasets validated its improvement by around 10%. GAL is also compatible with different GNN frameworks and has proven to keep the prediction error bounded by the proposed loss function. On the other hand, to determine the root cause of the detected anomalies in high dimensional time series graphs, Deng et al. [86] proposed a Graph Deviation Network (GDN) that utilizes structure learning with GNNs, alongside attention weights for critical infrastructure domain. The main components are sensor embedding, graph structure learning, graph attention-based forecasting, and graph deviation scoring. Experiments on real-world sensor dataset SWaT [98] & WADI [99] justify its improved detection [F1-Score: 0.99 (SWaT) & 0.98 (WADI)] and allow users to comprehend the root cause. We discuss persisting weaknesses and further research areas in Section 5.3. 4.4 Vulnerability Detection Software vulnerabilities are defects introduced in the source code during software development. These vulnera- bilities left unattended can be exploited by an attacker to disrupt the client side including halting the crucial execution, integrating backdoors, remote file execution, and more. During the pre-ML era, human experts were deployed to perform static, dynamic, or hybrid analysis on the source code to detect vulnerabilities [100, 101]. While these approaches were effective, they were mostly manual, which warranted intense labor and specialized expertise. With the advent of deep neural networks (DNNs), ML models could be trained on either expert-labeled patterns of vulnerability or fully automated techniques to detect vulnerability in source code. Vulnerability identification can be performed inter-procedural, which means identification of vulnerable code is analyzed on procedure or function level, whereas, intra-procedural vulnerability identification means the analysis is performed locally within a specific method scope. Several surveys summarize automated vulnerability detection using DNN techniques [102–105]. Table 5 captures the focus of our survey to summarize recent developments using GNNs. To automate the process of vulnerability detection, one major decision is to learn comprehensive program semantics which can capture both data and logical flow of the source code. Zhou et al. [106] proposed Devign that solves vulnerability identification problems as graph-level classification where the model learns from composite programming representation of the source code, such as (1) abstract syntax tree (AST), (2) control flow graph (CFG), (3) data flow graph (DFG), and (4) natural code sequence (NCS). The authors proposed a novel 1-D CNN- based pooling mechanism to translate node and link level classification for end-to-end graph level classification. Evaluation over LinuxKernel, QEMU, Wireshark, and FFmpeg datasets [114] attains accuracy of 72.26% and ACM Trans. Priv. Sec., Vol. 0, No. 0, Article 1. Publication date: January 2024. 1:16 • Mitra et al. Paper Title Focus/Objective Contributions Limitations Research on Vulnerability Detection in Source Code Devign: Effective Vul- nerability Identification by Learning Comprehen- sive Program Semantics via Graph Neural Net- works [106] Source code vulnerability identification problem. • Novel composite code representation with AST, CFG, DFG, and NCS. • Leveraged GGNN using 1-D CNN-based pooling (Conv module) to perform graph- level classification task. • Complex Code representa- tion leads to poor perfor- mance on large functions. • Difficult to find program- ming language-specific parsers. ReGVD: Revisiting Graph Neural Networks for Vul- nerability Detection [107] Vulnerability identifica- tion as an inductive text classification problem. • Flat sequence of token representation al- lows PL-independent code graph. • Introduced residual connection among GNN layers with sum and max poolings. • Code representation stage doesn’t includes CFG or DFG, missing out on relevant structural information. Combining Graph-Based Learning With Auto- mated Data Collection for Code Vulnerability Detection [108] Identifies software vulner- abilities at the function level from program source code. • Code representation using extended AST. • Leveraged GGNN with stacked GRU, which is passed to a standard fully- connected network to make a classifica- tion using a softmax layer. • Pre-processing functions us- ing extended AST adds sig- nificant complexity. BGNN4VD: Construct- ing Bidirectional Graph Neural-Network for Vul- nerability Detection [109] Vulnerability detection approach by constructing a Bidirectional Graph Neural-Network (BGNN) • Proposed CCG to capture source-code syn- tax and semantics. • Used BGNN to process information and classify using a CNN. • Accuracy is specific to re- ported vulnerabilities. • Non-reliable for large datasets. DeepWukong: Statically Detecting Software Vulnerabilities Using Deep Graph Neural Net- work [110] Precise interprocedural analysis for vulnerability detection in real-world programs. • Code representation is performed by gen- erating PDG containing control and data dependency of the program. • Leveraged GCN, GAN, and k-dimensional GNNs with top-k pooling. • Datasets are labeled by do- main experts, possibility of missing corner cases. • Limited to the top 10 vulner- abilities in C/C++ programs. CSGVD: A deep learning approach combining se- quence and graph embed- ding for source code vul- nerability detection [111] Function-level vulnerabil- ity detection as a graph bi- nary classification task. • Code representation using CFG. • Leveraged PE-BL module, a GNN layers with residual connectivity, and a graph- level mean biaffine attention (M-BFA) pooling to learn graph representation. • Information from DFG and AST was not considered. • Lack of interprocedural in- formation to understand the nature of vulnerability. A hybrid graph neural network approach for de- tecting PHP vulnerabili- ties [105] Vulnerability detection by capturing contextual infor- mation to reduce false pos- itives and false negatives. • Used intraprocedural CFGs to capture se- mantic code dependencies. • Leveraged bidirectional GRUs, GCN, and edge pooling. • The model works on only PHP source codes. • Experiments are run on sim- plistic SARD dataset. Predicting Vulnerabil- ity Inducing Function Versions Using Node Embeddings and Graph Neural Networks [112] Vulnerability prediction model, that runs after every code change and identifies vulnerability- inducing functions. • Code representation using AST • Leveraged GraphSAGE, GCN with average pooling and max pooling. • Tested on only one dataset. Research on Vulnerability Detection in Smart Contracts Smart Contract Vulnerabil- ity Detection Using Graph Neural Networks [113] Fully automated vulnera- bility analyzer for smart contracts. • Code represented using contract graph with the consideration of temporal order- ing. Node types include, i.e., major nodes, secondary nodes, and fallback nodes. • Leveraged DR-GCN and novel temporal message propagation network TMP. • Source code is considered as a text sequence instead of semantic blocks, failing to highlight critical variables in the data flow. Table 5. Summary of the existing literature on vulnerability detection using GNN with scope, contribution, and limitations. ACM Trans. Priv. Sec., Vol. 0, No. 0, Article 1. Publication date: January 2024. Use of Graph Neural Networks in Aiding Defensive Cyber Operations • 1:17 F1 score of 73.26%. The results outperform state-of-the-art [115] by a higher average of 10.51% accuracy and 8.68% F1 score. Devign is considered in the literature as one of the first and strongest baseline models for inter- procedural vulnerability detection. Nguyen et al. [107] claim the use of Devign [106] is impractical for complex programming languages, source codes, and libraries due to the difficult pre-processing step to transform source code into a multi-edged graph. The authors proposed ReGVD, a language-independent vulnerability identification mechanism, that represents the graph as a flat sequence of tokens. The represented graph is initialized by embeddings from pre-trained programming language (PL) models like CodeBERT or GraphCodeBERT. The GNN node-level embeddings are updated in each iteration by recursive aggregation using a residual connection. Finally, a graph-level readout layer aggregates node embeddings globally for each graph. Evaluation results over CodeXGLUE [116] show ReGVD achieving accuracy improvement of 1.61% over Devign. To unleash the full potential of DL-based vulnerability detection, Wang et al [108] proposed FUNDED, a mechanism that encodes multiple code relationships into different relation graphs, to learn relation-specific functions and their associated vulnerability. The model leverages GGNN with stacked GRU and a fully connected network to make classification. Evaluation results over LinuxKernel, FFmpeg, ImageMagick, rdesktop, and OpenSC datasets [117] show an improvement of 12.4% in accuracy over Devign. Tang et al [111] proposed CSGVD that uses a PE-BL module which inherits and enhances the knowledge from the pre-trained language model for node embedding and a BiLSTM to aggregate the local semantic information within a node. Additionally, a mean bi-affine attention pooling (M-BFA) for graph embedding. The evaluation results over the CodeXGLUE [116] dataset were compared with multiple baselines proving an improvement of 4.41% accuracy over Devign. Cao et al [109] proposed another bidirectional GNN to perform vulnerability identification using a code composite graph (CCG) by combining the AST, CFG, and DFG that captures various source code syntax and semantic information. Evaluation over LinuxKernel, FFmpeg, Wireshark, and Libav datasets [118] reported an accuracy of 74.7% and F1-score of 76.8%. Cheng et al. [110] introduced an interprocedural static vulnerability identification tool tailored for C/C++. This tool calculates control and data dependencies over CFG and Value-Flow Graphs (VFG), considering pointer aliases information. Additionally, it constructs the Program Dependence Graph (PDG). The model achieved an accuracy score of 97.4% and an F1-score of 95.6% across multiple datasets, including SARD [119], lua [120], and redis [121]. In another context, Rabheru et al. [105] tackled intra-procedural vulnerability detection in PHP. They employed a token-based approach, parsing linear token sequences to capture syntactic dependencies in source code using CFGs. Their model delivered an accuracy of 96.56% and an F1-score of 96.11% on both the SARD [119] dataset and real-world projects. These results were achieved by harnessing bidirectional Gated Recurrent Units (GRUs) in conjunction with Graph Convolutional Networks (GCNs). Şahin et al. [112] proposed a method for detecting change-level vulnerable code using Abstract Syntax Trees (AST) and incorporating GCNs. The model achieved an F1-score of 74.4% when evaluated on the Wireshark dataset [122]. Another avenue of vulnerability detection includes blockchain systems and other cryptocurrency networks. The rise of online wallets has popularized decentralized online ledgers for monitoring financial transactions. To ensure trustworthy and credible online transactions, organizations encode rules and policies in the form of source code, commonly referred to as smart contracts. Similar to any code snippet, smart contracts can be susceptible to vulnerabilities [123]. Zhuang et al. [113] presented a novel approach involving a degree-free Graph Convolutional Network (GCN) and a Temporal Message Propagation network (TMP) for detecting vulnerabilities in smart contracts. Their model achieved remarkable accuracy, scoring 84.48%, 83.45%, and 74.61% for identifying reentrancy, timestamp dependence, and infinite loop vulnerabilities. In the context of our survey, we refrain from an in-depth exploration of the literature on smart contract vulnerability detection due to the existance of substantial body of work, including comprehensive surveys [124–126] that offer profound insights into the landscape of smart contract vulnerabilities and the application of GNNs for their detection. In Section 5.4, we delve further into the persisting loopholes and areas for improvement. ACM Trans. Priv. Sec., Vol. 0, No. 0, Article 1. Publication date: January 2024. 1:18 • Mitra et al. 4.5 Intrusion Detection Intrusion detection refers to the process of monitoring and analyzing computer systems or networks to identify unauthorized or malicious activities. It involves the use of various TTPs to detect and respond to potential security breaches, such as unauthorized access, malware infections, or end-point security. It can be considered as a countermeasure against the installation phase of the CKC where the attacker tries to establish a backdoor for persistent communication. Intrusion Detection Systems (IDS) are mainly of two types, Network-based (NIDS) and Host-based (HIDS). NIDS monitors network traffic for suspicious patterns or anomalies, while HIDS focuses on individual systems or endpoints. There have been numerous studies on IDS utilizing GNN capabilities and is still an active area of research [127]. Some notable ones are discussed below with a summarized Table 6. Paper Title Focus/Objective Contributions Limitations Network Intrusion Detection System (NIDS) E-GraphSAGE: A Graph Neural Network based In- trusion Detection System for IoT [128] Developed GNN-based in- trusion detection system for IoT domain by captur- ing edge features and topo- logical information. • Considers flow-based features and topo- logical patterns to account for intercon- nected patterns of the network flow. • Modified GraphSAGE algorithm with mini-batch allows the model to consider edges with increased efficiency. • Neighborhood sampling can be used to improve the run- time of the model. • Investigation on explainable GNN algorithms is needed to get model output insights. Graph-based Solutions with Residuals for In- trusion Detection: the Modified E-GraphSAGE and E-ResGAT Algo- rithms [129] Integrated EGraphSAGE and E-ResGAT to incorpo- rate residual connections and attention mechanism to consider class imbal- ance. • Incorporated residual learning with EGraphSAGE to enhance performance. • Applied attention mechanism of GAT while considering residual learning and edge features to improve efficiency fur- ther. • Optimizing the construction of the batch neighborhood process can speed up the model performance. • More imbalanced data sets need to be tested. Unveiling the potential of Graph Neural Networks for robust Intrusion Detec- tion [130] Developed a GNN NIDS model that can process and learn from structural re- lationships and flow pat- terns to identify attacks. • Proposed host-connection graphs, to cap- ture structural flow relationships. • Proposed a GNN model that uses a non- standard message-passing architecture to learn from host-connection graphs. • Was only tested on CIC- IDS2017 dataset and synthe- sized adversarial attack sce- narios. Host Intrusion Detection System (HIDS) Using Graph Representa- tion in Host-Based Intru- sion Detection [131] Graph representation learning-based host in- trusion detection system (HIDS). • Used graph representation learning to de- velop HIDS. • Developed a sequence embedding method using graph structures to model a finite number of sequence items and represents the structural relationships between them. • Cannot generate graphs for sequences with multiple at- tributes or predefined rules. • Performance improvement of GRSE for larger full graphs needs to be explored. THREATRACE: Detecting and Tracing Host-Based Threats in Node Level Through Provenance Graph Learning [132] An anomaly-based HIDS at the system entity level without prior knowledge of any attack pattern. • Used GraphSAGE to learn benign entities’ role in provenance graph. • The model works in a real-time manner and can scale for long-term hosts. • Require benign data for training and cannot guaran- tee robustness. • May fail against poisoning and graph backdoor attacks. Table 6. Summary of the existing literature on intrusion detection on GNN with scope, contribution, and limitations. Weng et al. [128] presented NIDS using GNN to classify malicious network flows. The model captures edge and topological information in IoT networks for classification. The authors enhanced the GraphSAGE [20] algorithm to directly exploit the structural information of the network flow and encode it in a graph. The main changes in E-GraphSAGE are in the algorithm input, the message passing/aggregator function, and the output ACM Trans. Priv. Sec., Vol. 0, No. 0, Article 1. Publication date: January 2024. Use of Graph Neural Networks in Aiding Defensive Cyber Operations • 1:19 where the network flow edges have been considered instead of nodes. Experiments over the datasets created in [133–135] achieved an F-1 score of 0.97 for binary and 0.87 for multi-class classification. Chang et al. [129] further enhanced E-GraphSAGE to integrate residual learning and attention mechanism to increase efficiency. The authors utilized E-GraphSAGE with residual learning to target minority class imbalance and an edge-based residual graph attention network (E-ResGAT) to improve efficiency. They also proposed a fixed neighborhood in edge sampling and selection for aggregation using attention mechanism. Evaluation over CIC-DarkNet [136], ToN-IoT [137], UNSW-NB15 [138], and CSE-CIC-IDS [139, 140] datasets proved an overall increase in accuracy. To make the model robust against changing networks and evolving adversarial attacks, Pujol-Perich et al. [130] focused on the structural patterns of the attack by analyzing the flow features independently with intra-relations. They proposed a host-connection (HC) graph to keep the flow records and capture meaningful information with a GNN model based on a non-standard message-passing architecture capable of learning from the HC graph to recognize the structural flow patterns of attacks. Evaluation over CIC-IDS2017 [140] dataset against two adversarial attacks that modify packet size and inter-arrival times justified its superiority. While other traditional ML models degrade their accuracy (F1) up to 50%, the proposed model maintained its accuracy throughout. For HIDS from the system calls, Hu et al. [131] proposed a graph-based model that works by constructing graphs from system call traces for graph classification to detect intrusion. Graph random state embedding (GRSE) is another novel approach developed by the authors to generate graph embeddings, including graph transform, random state walk, subgraph extraction, and graph pooling. Hence, classification is done based on the embedded graph topology. Experiments on the ADFA-LD [141] dataset justify the performance improvement with the developed embedding. Wang et al. [132] developed another real-time HIDS framework based on system provenance graphs. The model utilized GraphSAGE algorithms for aggregation and node embedding generation, where each system entity is considered as nodes, and the system calls as edges. The model requires only benign data for training and works in the anomaly identification principle. Experiments over five public datasets (StreamSpot [142], Unicorn SC-1 and SC-2 [143], DARPA TC #3 and #5 [144]) against seven state-of-the-art HIDS models proved its potential. Persisting loopholes and improvement areas are discussed in Section 5.5. 4.6 Malware Detection Malware detection is a crucial countermeasure against the Command and Control (C2) phase. It phase involves attacker utilizing the persistent communication channels, set up by installed malware in the compromised systems to execute remote instruction. Hence, anti-malware solutions employ diverse methods to detect and block installed malware activities by learning system behavioral patterns through ML models. To capture behavioral relations, GNN has proven to be an attractive choice that enables the identification of malware presence by addressing suspicious behaviors. Additionally, behavior analysis can also indicate the presence of zero-day malwares. Wang et al. [145] developed a behavior-based malware detection approach (MatchGNet) using a heterogeneous graph matching mechanism. Invariant graph modeling (IGM) captures heterogeneous system interactions, then a hierarchical attention graph neural encoder (HAGNE) is employed to learn the representations. Finally, a similarity learning (SL) model via Siamese Network [153] trains the parameters and determines the similarity between the unknown and a benign program. Experiments revealed an increased accuracy of up to 97% while outperforming other state-of-the-art baseline models (LR, SVM, MLP, GCN, GraphSAGE) with 50% less false-positive (FP) rates at lower training time and cost. Yan et al.[146] proposed a malware classification tool that utilizes the graph mining capabilities of Deep Graph Convolution Network (DGCNN). Since the CFG has a heterogeneous data structure, it is represented as a tensor of variable size, requiring a graph machine learning approach. Experiments on MSKCFG [154] and YANCFG [70, 155] datasets were conducted and evaluated with 5-fold cross-validation. According to the evaluation, the model achieved an average F-1 score of 0.97 in MSKCFG and around 0.8 in YANCFG dataset. Due to its generic approach, it can also be deployed in the cloud for real-time classification. To avoid detection during execution, another technique malware uses is packing, which generates different CFGs. ACM Trans. Priv. Sec., Vol. 0, No. 0, Article 1. Publication date: January 2024. 1:20 • Mitra et al. Paper Title Focus/Objective Contributions Limitations General Malwares Heterogeneous Graph Matching Networks: Application to Unknown Malware Detection [145] Developed a heteroge- neous graph-matching network model to learn the graph representation and similarity metric simultaneously based on program execution. • Developed an invariant graph modeling to capture heterogeneous interactions. • HAGNE was used to learn from heteroge- neous invariant graphs. • Siamese network was used to perform sim- ilarity scoring. • Accuracy needs to be im- proved further. • Evaluation with more robust attack scenarios is needed for practical deployment. Classifying malware rep- resented as control flow graphs using deep graph convolutional neural net- work [146] Detect malware from CFG using DGCNN to be de- ployable in a variety of op- erational environments. • Used DGCNN for CFG analysis and classi- fication. • Developed generically to be deployable in the cloud and can be used by a common user. • Requires a high training time. • Requires testing with the lat- est malware samples for ro- bustness. Classifying Packed Mal- ware Represented as Con- trol Flow Graphs using Deep Graph Convolutional Neural Network [147] Develop malware classifier using DGCNN while con- sidering the unpacked and local CFG of applications. • Developed algorithm to strip from packed CFG to obtain unpacked local CFG. • Used DGCNN to learn and classify mal- ware from unpacked block CFGs. • Different adversarial CFG characteristics are required to be tested with the ap- proach for robust applicabil- ity. Intelligent malware detec- tion based on graph convo- lutional network [148] Develop a malware classi- fier using GCN to adapt to the different malware char- acteristics. • Used directed cyclic graph, constructed from API call sequence. • Used Markov chain and PCA for feature analysis. • Used GCN for malware classification. • Further research on GCN is required to make the model more adaptive with the de- velopment of novel malware. • Cost optimization also needs to be addressed. Android Malwares Android Malware Detec- tion via Graph Representa- tion Learning [149] Malware detection using graph representation learning, combined with NLP techniques. • Lightweight static analysis using graph representation learning. • Word2Vec generates function embedding to represent code characteristics. • Captures semantic information from call graphs without expert knowledge. • Cannot extract intra- function Smali instructions against obfuscation. • Cannot create precise ap- proximate call graphs for large-scale malware. NF-GNN: Network Flow Graph Neural Networks for Malware Detection and Classification [150] Developed a network flow feature-based GNN model for malware detection and classification. • Extracted directed edge attribute flow graphs from a set of network flows. • Developed a GNN model to learn from graph topology and edge attributes for malware classification. • Additional network archi- tectures such as attention, model temporal dynamics, and explainability need to be considered. Graph Neural Network- based Android Malware Classification with Jump- ing Knowledge [151] Android malware detec- tion through FCGs using GNN-JK. • Used GNN with JK technique to address GNN over-smoothing problem. • Topological information embedded in FCGs was utilized for malware classifica- tion. • The developed model is not optimized at all and explor- ing other GNN architectures might help. Industrial & IoT Malwares Cross-Architecture Internet-of-Things Mal- ware Detection Based on Graph Neural Net- work [152] Developed a cross- architecture IoT malware detection method using GNN. • Used NLP to extract semantic information and generate function embedding. • Used GraphSAGE to learn the structural information by GNN. • Used MLP with softmax to classify mali- cious binary files. • Pre-processing phase using IDA pro is time-consuming and requires significant ac- celeration. • Need to consider more fea- tures to increase robustness. Table 7. Summary of the existing literature on malware detection using GNN with scope, contribution, and limitations. ACM Trans. Priv. Sec., Vol. 0, No. 0, Article 1. Publication date: January 2024. Use of Graph Neural Networks in Aiding Defensive Cyber Operations • 1:21 Hua et al. [147] proposed to strip the unpacked CFG into local CFG for final classification using DGCNN. The unpack function calls do not relate to any malware local functions and vice-versa. Hence, the unpacked CFG can be stripped to the local CFG for classification. Finally, DGCNN learns the malicious local CFG for classification. Experiments covering six malware families from VirusShare [69] with 10-fold cross-validation yield an overall accuracy of 96.4%. To address the evolving malware characteristics, Li et al. [148] proposed a malware classifier using GCN. The objective is to learn different characteristics from directed API call graphs. The notable aspect of this approach is use of Markov chain and PCA for graph feature extraction. Experiments over VirusTotal [70] and VirusShare [69] concluded the highest accuracy of 98.32% with less FPR than other state-of-the-art models. To detect Android malware, Feng et al. [149] proposed a lightweight static analysis approach (CGDroid) that analyzes the source code to extract high-level semantic information. It constructs an approximate call graph from function invocation relationships and then pulls out intra-function attributes like permissions, security level, Smali instructions, etc. Word2Vec-embedded call graphs allow unsupervised training and classification using GNN. Evaluation over Drebin [156] and AndroZoo [157] datasets suggests promising capabilities with an accuracy of 97.1% for multi-class (20) classification. To leverage rich communication patterns and dynamically detect Android malware using network flow graphs while apprehending endpoint pairs using GNN, Busch et al. [150] developed three derived models: graph classifier, graph autoencoder, and one-class graph neural network (OCGNN). It extracts a communication graph for each execution of a candidate application and then classifies them using edge features. Evaluation results over CICAndMal2017 [158] dataset improved recall by 4.12%, 14.41%, and 24.78% for binary, category, and family classification while obtaining 95% detection accuracy. Additionally, the ablation study helped evaluate the influence of feature sets and network layers. Lo et al. [151] proposed another network-based approach using GNN with jumping knowledge (JK) by utilizing Android function call graphs (FCGs) to obtain meaningful intra-procedural call patterns. GCN, GraphSAGE, and Graph Isomorphism Network (GIN) [15] built a three-phase classification approach. Apart from traditional feature extraction and classification, JK is used in training concatenation layer to obtain graph embedding while preventing over-smoothing. Evaluations over 24 malware families from Malnet-Tiny [159] and Drebin [156] datasets proved to boost accuracy by 8%. An architecture-independent malware detection approach for IoT devices focusing on FCG was proposed by Li et al. [152]. The model can consider structural semantics information independent of the underlying architecture. Experiments covering five different processor architectures (MIPS, ARM, PowerPC, X86_64, i386) with datasets [69] covering diverse malware families over the years were used for evaluation and achieved an accuracy of 99.61%. Apart from solo GNN usage, researchers have proposed several hybrid and ensemble models with GNN for diverse domains. Catal et al. [160] proposed a GAT model for the transportation domain, and Dvorak et al. [161] for databases. Additionally, Wu et al. [162] proposed GNN paired with LSTM to help capture the structural information. In Section 5.6 we discuss the enduring drawbacks with enhancement opportunities. 4.7 Report Reporting is a possible countermeasure against the final CKC phase, Action on Objective (AOO). In AOO phase, the attacker executes its intended goals and often tries to destroy its footprints. To learn the attack TTPs and prevent similar future occurrences, the defensive models require rapid learning updates regarding the attacks. For this, organizations rely on robust reporting platforms such as CVE [163] to gather and disclose CTI, such as logs, traffic analysis, preventive measures, and other relevant data, related to novel security incidents and breaches. Cybersecurity analysts at the security operations center (SOC) parse these attack footprints to generate CKG, defensive rules, policies, etc., to update defensive cybersecurity models. Efficient information storage, propagation, and sharing of these security updates is crucial to maintain this pipeline. GNN can influence conducting efficient knowledge propagation, storage, and learning for the ML models from CKGs. Hence, by prompt reporting and efficient knowledge processing through GNN, organizations can collaborate and initiate incident response procedures to equip against novel attacks and prevent similar occurrences with appropriate countermeasures. ACM Trans. Priv. Sec., Vol. 0, No. 0, Article 1. Publication date: January 2024. 1:22 • Mitra et al. Paper Title Focus/Objective Contributions Limitations Fake-Data Detection in Social Media Graph Neural Networks with Continual Learning for Fake News Detection from Social Media [164] Propagation-based fake news detection using GNN • Used GNN to differentiate between propa- gation patterns of real and fake news. • Used continual learning to deal with cata- strophic forgetting problem. • Limited to the catastrophic forgetting phenomenon. • GEM and EWC causes in- creased computation time. Propagation-Based Fake News Detection Using Graph Neural Networks with Transformer [165] Fake news detection us- ing graph transformer net- work (GTN). • Developed a weight function to enhance the difference propagation pattern be- tween real and fake news. • Improved accuracy by the use of GTN. • Was compared against two GNN models. • Evaluation was done only us- ing Twitter data. Evidence-aware Fake News Detection with Graph Neural Net- works [166] Veracity and evidence- based fake news detection using GNN. • Can learn from complex graph-structured claims and evidence data. • Simple yet effective graph structure learn- ing approach for redundancy mitigation. • Including other datasets might increase robustness. • Improved performance is re- quired for deployment. Cybersecurity Knowledge Graph Improvement Cybersecurity Knowledge Graph Improvement with Graph Neural Net- works [167] Generate score for seman- tic triples in CKG for fake or outdated data detection. • Fake and outdated semantic triple detec- tion using authenticity score (0-1). • The scoring GCN model can work with other triples-generating ML models. • More research is needed to increase the accuracy. • Requires correct dataset for supervised learning. Table 8. Summary of the existing literature on reporting using GNN with scope, contribution, and limitations. To maintain the authenticity of the data source, Han et al. [164] proposed to identify fake data based on the propagation pattern. The authors trained GNN to learn the propagation pattern of tweets among users and classify faked tweets. Due to the vastly differing fake data landscape, ML models do not work well for unseen data using text-based identification methods. Hence, to allow continual learning using incremental training, the authors used Gradient Episodic Memory (GEM) and Elastic Weight Consolidation (EWC) techniques to achieve high detection accuracy for unseen data. Experiments utilizing the Twitter dataset from FakeNewsNet [168] evaluated the model’s ability to detect fake news with an average accuracy of 75%. To achieve the same objective with a similar approach, Matsumoto et al. [165] proposed a novel weight function to identify different propagation patterns between real and fake news in the graph. The authors used a graph transformer network (GTN) model that works using multi-head attention and message-passing mechanisms to search for usable connectivity relations for identification. Evaluation using the previous dataset [168] against two state-of-the-art propagation-based GNN methods demonstrated an improved accuracy of 93% to 95%. Contrary to the propagation pattern of data for fake data identification, Xu et al. [166] proposed to train GNN models with textual knowledge of evidence-based veracious claims. Multiple claims and evidence are modeled as graphs-structured data to capture the semantic dependency using GNN. Then, using structure learning, long-distance semantic dependencies are captured and mitigated. Finally, the learned model predicts using fine-grained semantic representations. Evaluations using Snopes [169] and PolitiFact [170] datasets against baseline state-of-the-art patterns and evidence-based approaches demonstrated its potential and robustness of being used as a plug-in-play approach with other models. Dasgupta et al. [167] proposed to improve CKG consistency by identifying fake or outdated data by computing a score for each CKG triple using GCN. The authors trained the GNN using manually curated correct data to identify faked or outdated data with a scoring mechanism. Experiments covering diverse malware information from numerous CTI sources and synthetic fake data obtained an F-1 score of 0.975. In Section 5.7, we address persisting loopholes with improvement areas. Following we provide our complete research information table 9 with critical research details such as GNN models, classification type, datasets, research timeline, and performance. ACM Trans. Priv. Sec., Vol. 0, No. 0, Article 1. Publication date: January 2024. Use of Graph Neural Networks in Aiding Defensive Cyber Operations • 1:23 Prevention Phase Category Classification node/edge/graph Paper Year GNN Models / Algorithm Dataset Performance graph [33] 2020 GAE, GCN, AAE Rochester Avg. F1 0.59 node [34] 2021 GCN, GAT, HGCN [40–42] AUC 95.18 % Adversarial Privacy Preserving graph [35] 2021 GCN, GAT, ChebNet [41–44] 0.959 𝑇1 Perf. graph [36] 2021 FedGNN [43, 45–47] 0.989 RMSE Federated Learning, Split Learning node, graph [37] 2021 GNN with BP [40–42] Avg. Acc. 75.33 % node, graph [38] 2022 GCN, DRL, NCL [48, 49] Acc. 90.62% Privacy Maintainence Others graph [39] 2023 GCN [40–42] Acc. 78.6 % node, graph [50] 2018 RL-S2V, 𝑄∗ [40–42] Acc. ↓: 60% node [51] 2019 Meta-learning [40, 41, 60] 48% ↓| 5% Change node [52] 2020 Exploratory [40, 41, 61] 10.7% ↓| 3% Change edge [53] 2020 Υ-decaying [62–64] 76.5% ASR | 25% Cng. graph [54] 2021 Backdoor [65–67] 74% Avg. ASR node [55] 2022 RL [68–70] Avg. ASR: 93% Adversarial Attack node [56] 2021 Saliency Map [71] Acc. ↓≥30% node, edge [57] 2020 Capsule Scheme [72, 73] Recall: 0.98 Adversarial Research Adversarial Defense node, edge [58] 2021 Chebyshev layer [73, 75, 76] F1 ↑4% > CNN node [78] 2019 Traditional GNN [87, 88] Accuracy: 98% Point Anomaly node [79] 2021 Fusion GCN, GAT [87, 89] Acc.> 79% | 20% train node, graph [80] 2021 Deep-GNN [90, 91] Accuracy: 95% Contextual Anomaly graph [81] 2021 Bayesian Optim. tagged.com Accuracy > 96% graph, node [82] 2021 OCGNN [40–42] AUC > 0.82 graph, node [83] 2021 TGAT+OCGNN [93] AUC > 0.86 Collective Anomaly edge [84] 2021 GCN+GAT [60, 94, 95] Avg. AUC ≈0.86 node [85] 2020 Graph Mining Alg. [96, 97] Acc. ↑≈10% Anomaly Detection Others node, edge [86] 2021 Attention [98, 99] F1 ≥0.98 graph [106] 2019 GGNN [114] Accuracy: 72.26% graph [107] 2022 Residual-GGNN [116] Accuracy: 63.69% graph [108] 2021 GGNN+stacked GRU [117] Accuracy: ↑12.6% graph [109] 2021 Bidirectional-GGNN [118] Accuracy: ↑4.9% graph [110] 2021 GCN,GAN,k-GNN [171] Accuracy: 97.4% graph [111] 2023 GNN with M-BFA [116] Accuracy: 64.46% node, graph [105] 2022 GCN+GRU [119] F1 score: 88.12% Source-code graph [112] 2022 GraphSAGE+GCN [122] F1 score: 74.4% Vulnerability Detection Smart Contracts node, edge [113] 2020 DR-GCN+TMP [172] Accuracy: 84.48% edge [128] 2021 GraphSAGE [133–135] F1 ≈0.97 node, edge [129] 2021 GraphSAGE+GAT [136–140] F1 ↑> 0.01 Network Based edge [130] 2022 Traditional GNN [140] F1 ≈0.99 graph [131] 2021 Sequence embed. [141] Acc. ↑≈2% Intrusion Detection Host Based node [132] 2022 GraphSAGE [142–144] F1 ≈0.85 graph [145] 2019 HAGNE+Siamese Net – Accuracy: 97% graph [146] 2019 DGCNN [70, 154, 155] F1 ≈0.97 & 0.8 graph [147] 2020 DGCNN [69] Accuracy: 96.4% General Malware graph [148] 2022 GCN+Markov chain [69, 70] Accuracy: 98.3% graph [149] 2021 GRL [156, 157] Accuracy: 97.1% edge, graph [150] 2021 OCGNN [158] Accuracy: 95% Android Malwares graph [151] 2022 GNN+JK [156, 159] Acc. ↑≈8% Malware Detection IoT graph [152] 2021 GraphSAGE [69] Accuracy: 99.61% graph [164] 2020 DiffPool [168] Accuracy: 75% edge, graph [165] 2021 GTN [168] Accuracy: 95% Fake Data node, graph [166] 2022 Structure Learning [169, 170] F1 ≈0.7 & 0.8 Threat Report Knowledge Graph node, edge [167] 2021 GCN – F1: 0.975 Table 9. Survey research information summary Table containing all articles following our taxonomy. Notations are following. [ASR: Attack Success Rate], [↑: Increase], [↓: Decrease], [|: At], [Acc. : Accuracy], [Cng. : Change], [Perf. : Performance] ACM Trans. Priv. Sec., Vol. 0, No. 0, Article 1. Publication date: January 2024. 1:24 • Mitra et al. 5 DISCUSSION In this section, we will discuss the ongoing research limitations and potential future research directions. We address the improvement scopes based on our summarized research findings in Section 4. 5.1 Privacy Maintenance Privacy indicates how private data, such as activity feed, system data, and security model parameters, can be protected to prevent it from being leaked. In an effort to prevent leakage, privacy-preserving GNNs are being developed. In the body of literature, these GNNs are categorized into various categories, such as adversarial privacy preservation [33–35], federated learning [36], differential privacy & split Learning [37], and others [38, 39]. RECONNOISSANCE Attacker INFORMATION PRIVACY MAINTENANCE OBSCURED DATA Victim Fig. 3. Privacy Maintenance as a security measure against reconnaissance to obfuscate victim information. Researchers are currently working on metrics to evaluate the effectiveness of privacy-preserving GNNs. These models, which are based on adversarial privacy-preserving techniques, such as those presented in [33–35], focus on obtaining high accuracy in predicting link and utility attributes while protecting privacy. Li et al. [33], for example, achieved superior privacy protection and utility retention, achieving an average Macro-F1 score of 0.549 on private attributes. On the other hand, despite effectively maintaining a high level of privacy, some authors observed a drop in link prediction accuracy when applying node privacy protection [34]. In a similar vein, Liao et al. [35] also reported a slight loss in task performance; nevertheless, their models demonstrated robustness against inference attacks. These approaches, however, fall short of effectively addressing how to achieve an ideal compromise between prediction performance and privacy protection. More research is required to thoroughly investigate this essential feature. Additionally, when employing privacy-preserving approaches such as federated learning and differential privacy [36], it is critical to carefully examine hyperparameters in order to strike the right balance between model performance and privacy protection. If the privacy budget is set too low, it can have a negative impact on the accuracy of model gradients. Conversely, work that emphasizes privacy preservation in a distributed setting, such as Split Learning [37], tends to ignore the formal notion of differential privacy, leading to considerably weaker privacy guarantees. Addressing these challenges and improving the overall privacy- performance trade-off is critical for achieving robust and effective privacy-preserving GNNs. In a separate line of work, Hu et al. [38] have made an effort to address the problem of privacy leakage concerning private user data by disentangling node features and enforcing orthogonality within a relevant space. Despite the fact that elements may be orthogonal, it is important to recognize that statistical correlations might exist that could potentially lead to privacy breaches. Similarly, Wang et al. [39] have presented a solution for privacy-preserving GNNs in an outsourced scenario. However, the approach might not offer sufficient resilience against sophisticated attacks. 5.2 Research GNNs have emerged as powerful tools for analyzing structured data, such as social networks, CFGs, DFGs, CKGs, etc. However, recent studies have highlighted the vulnerability of GNNs to adversarial attacks, where subtle perturbations to the input graph can lead to malicious node, edge, and graph predictions. Adversarial research has primarily focused on injecting continuous perturbations in the target graph without breaking the combinatorial structure [50–54, 56]. To understand the research landscape, we categorized it into the following: 5.2.1 Performance & Transferability. The impact of any developmental research is measured by comparing its performance matrix, which includes accuracy, robustness, transferability, etc. From an accuracy point of view, ACM Trans. Priv. Sec., Vol. 0, No. 0, Article 1. Publication date: January 2024. Use of Graph Neural Networks in Aiding Defensive Cyber Operations • 1:25 reinforcement learning, genetic algorithm, and gradient descent-based approaches [50] were able to achieve 40% to 60% misclassification, and 48% misclassification was achieved with 5% perturbed edges by Zügner et al. [51]. Another similar performance drop compared to state-of-the-art models was noted in the works of Lin et al. [52]. Contrary to black-box scenarios, misclassification accuracy in white-box settings was relatively higher, around 90% [53] to 100% [54]. Using such approaches misclassification accuracy was observed consistent throughout, justifying the severity. Apart from a consistent misclassification trend, another notable factor was transferability. Most of the attacks are model-independent and thus can be transferred and applied to other models. For example, the attack developed by Zhang et al. [55] can be operated on any GNN model that utilizes sequential data. Hence, the consistency and robustness of the adversarial attacks pose a severe threat to the employed GNN models. Victim Attacker WEAPONIZATION RESEARCH In-effective Payload CYBER THREAT INTELLIGENCE Fig. 4. Research as a proactive measure against weaponization to prepare against possible attack. 5.2.2 Defence mechanism & mitigation. Compared to the active research on developing adversarial attacks on GNN models, there are only a few in defense [57, 58]. Some methods include incorporating adversarial samples in the training data [50] or randomized smoothing [54] as a primary defense strategy. Furthermore, contrary to adversarial attacks, defensive approaches are not equally transferable and are mostly evaluated over some synthesized datasets. To address this, researchers attempted to increase the explainability of GNN models [173, 174]. However, such models are scope-dependent. From a defensive standpoint, robust explanations are needed. Therefore, immediate attention to robust explainability and defensive GNN research is needed. 5.3 Anomaly Detection Anomaly detection is a critical task in cyber defense to prevent the delivery of malicious payloads and ensure end-to-end security with significant impact in various domains, such as finance, healthcare, industrial systems, etc. Traditional anomaly detection methods often struggle to capture complex network patterns and dependencies present as graph-structured data. GNNs have shown promise in modeling and analyzing graph data, making them an attractive candidate for anomaly detection tasks. In a generic approach, by learning the standard behavioral relation between nodes, GNN is used to classify the deviant. Apart from generic GNN approaches, researchers have also proposed a few indirect ones to enhance GNNs’ functionality for anomaly detection [85, 86]. Other than conventional scenarios, researchers also addressed a few different long-standing ones such as DoS attacks [175] through anomaly detection. We evaluate the research landscape and potential improvement scopes from an implementable point of view through the following categories. Attacker DELIVERY ANOMALY DETECTION Victim Malicious Payload Detected Fig. 5. Anomaly Detection to detect malicious payload against weaponization to prepare against possible attack. 5.3.1 Scalability & Cost. Cyber defense systems often handle large-scale and dynamic graph data, posing challenges in terms of scalability and efficiency for GNN-based anomaly detection. Even with achieving impressive accuracy in limited testing data, models often struggle to handle large chunks of real-time data with significant accuracy [78, 79, 81, 82]. One of the root causes of such occurrences stems from higher dependency among various interconnected models designed to handle specific scenarios [77, 80]. Hence, developing scalable algorithms using modular architectures that can process and analyze large graphs from diverse aspects in real-time is crucial for deployment. Fortunately, from hardware standpoint, suppliers have started developing chips to support such ACM Trans. Priv. Sec., Vol. 0, No. 0, Article 1. Publication date: January 2024. 1:26 • Mitra et al. extensive computation [176]. On the other hand, few models require pre-curated data for training [83], increasing costs. Therefore, robust yet self-learning aspects during model development demand significant attention. 5.3.2 Interpretability & Explainability. Anomalies in cyber systems can exhibit diverse patterns, including rare events, stealthy attacks, and evolving behaviors. Additionally, existing models generate extensive alerts that cybersecurity analysts are not able to verify on time, known as threat alert fatigue problem [173]. Ensuring that GNNs only capture and identify genuine anomalies, requires careful modeling and innovative techniques. Researchers have tried to improve the fine-tuning functions [85, 86] to improve accuracy– instead of direct model improvement. Leveraging GNN explainability from different aspects [173, 174, 177] will facilitate model improve- ment research in a directed manner. Hence, contextualized and explainability-driven GNN model development will correctly interpret underlying anomalous patterns and reduce analyst intervention with low false-positives. 5.4 Vulnerability Detection GNN-driven vulnerability detection complements human expert-based vulnerability finding and identification of potential weaknesses and security risks in complex source code. Evidently, GNN has shown effective ways to capture the relationships among code elements, such as functions, and variables, enabling them to identify various types of vulnerabilities, such as buffer overflows, injection attacks, code injections, etc. More specialized applications of vulnerability detection exist in blockchain-based smart contract source code where considerable research has been performed [113, 123, 178, 179]. Based on recent progress, we will outline the possible directions. VULNERABILITY DETECTION Payload EXPLOITATION Vulnerability Exploitation Victim Patch Fig. 6. Vulnerability detection to detect vulnerabilities and prevent exploitation by malicious payload by developing patches. 5.4.1 Secure Coding & Development. The utilization of advanced Integrated Development Environments (IDEs) can wield a significant influence in thwarting the introduction of vulnerabilities within the source code. These IDEs offer supportive tools that adeptly steer developers toward crafting secure code. A variety of static code analysis tools offer capabilities tailored to identify vulnerabilities specific to programming languages. This is achieved by systematically considering edge cases, boundary conditions, etc., preemptively. However, to fully harness the capabilities of GNN-based techniques, it is crucial to explore their generalization potential across diverse domains such as software, network, and IoT. In a similar vein, enhancing the interpretability of GNN-based vulnerability detection [173] systems will provide the means to explain the reasoning behind the predictions made by these systems, which in turn, have greater trust impact, especially for human-in-the-loop systems. Additionally, the practice of efficient graph generation [106, 107] and code refactoring proposed by several research [180–182] can utilize modern large language models (LLMs) [183] to alleviate vulnerability introduction further. Another intriguing avenue for research involves investigating the seamless integration of GNNs with existing reverse engineering tools, such as IDA Pro [184] and GIDRA [185], could potentially be synergized with GNN-based approaches to enhance the overall efficacy of vulnerability management practices. 5.4.2 Dynamic & Heterogenous Benchmarking. The landscape of source code management is heterogeneous (i.e. includes various programming languages, libraries, frameworks) and dynamic (i.e. addition of new code to patch source code or addition of new logic). Since GNNs trained on one specific codebase might struggle to generalize effectively to different codebases that possess varying coding styles, languages, or domain-specific characteristics, the process of adapting GNNs from one project to another necessitates thorough retraining or fine-tuning. Hence, vulnerability detection in a heterogeneous and dynamic coding landscape poses unique challenges as current ACM Trans. Priv. Sec., Vol. 0, No. 0, Article 1. Publication date: January 2024. Use of Graph Neural Networks in Aiding Defensive Cyber Operations • 1:27 literature lacks in providing a diverse benchmark dataset. Many prior research [107, 110, 111, 178] is conducted on well-known datasets, such as SARD [119], CodeXGLUE [116], etc. Comparing the results from one with another may not hold due to the varying specifications of each of these datasets, hence requiring further investigation. 5.5 Intrusion Detection Intrusion detection plays a critical role in safeguarding our digital systems by identifying unauthorized or malicious activities within computer networks. As the complexity and sophistication of attacks continue to evolve, traditional intrusion detection methods often struggle to capture the complex and dynamic relationships among processes and network entities, making them susceptible to sophisticated attacks. For such reasons, GNNs have recently gained attention as a potential solution for intrusion detection [127]. By learning the network and system behavior, GNN models can identify occurring internal threats. However, there are still challenges requiring attention. Additionally, there have been very few works on Intrusion Response Systems (IRS) alongside detection– even when rapid response is necessary to complement efficient detection. For example, risk assessment, prioritization, and parallelization are critical areas that need to be addressed with effective IDS research [186]. Following, we’ll discuss the research landscape with challenges and future directions. INSTALLATION INTRUSION DETECTION Victim Malware Installation Failed Fig. 7. Intrusion detection to prevent malware installation and initial foothold establishment. 5.5.1 Dynamic Environments & Real-time Detection. Intrusion detection models need to handle dynamic network environments, adapt to changing network topologies, and efficiently process streaming data for timely detection and response. Even though GNN models have significantly improved detection accuracy, they still lack to adapt to dynamic environments [128, 129]. Insufficient open-source authentic data replicating the dynamic behavior remains a crucial blocker. Furthermore, intrusion detection requires real-time monitoring and response to rapidly evolving threats. For such, researchers propose advanced and complex GNN models that proportionally increase computation time [131]. On the other hand, performance is a critical factor in responding to active threats. Hence, computationally efficient yet robust hybrid model development remains open to possibilities. 5.5.2 Trust & Explainability. Trust plays a crucial factor in effective IDS deployment, as it needs full system access to work. Adversaries often target employed IDS systems as a part of reconnaissance activity [187]. Furthermore, advanced GNN model predictions have limited explainibility by security analysts [128]– few models require either authentic training data [132] or synthesized data [129] to train. Some of the models do address explainability without prior knowledge [174, 177], but fail to consider all attributes equally. Hence, data poisoning or adversarial attacks remain a significant threat to ensuring secure deployment and remain an active research direction. Moreover, multi-facet explainability [32] of GNN-based intrusion detection models can provide insights into the decision-making process, enhance trust, and facilitate collaboration between distributed detection systems. 5.6 Malware Detection Malware detection aims to identify and mitigate malicious software that poses a threat to computer systems and networks. GNNs have emerged as a promising technique for malware detection, leveraging the inherent graph structure of malware to capture intricate process relationships and dependencies. For example, most research focused on utilizing the malware application CFG [147, 149, 162] to map and learn the application’s behavior. Additionally, a few utilized network flow graphs (NFG) [150, 188] to learn the network communication pattern. However, there are still improvement scopes utilizing GNNs, discussed following. ACM Trans. Priv. Sec., Vol. 0, No. 0, Article 1. Publication date: January 2024. 1:28 • Mitra et al. 5.6.1 Dynamicity & Scalability. Malware detection systems operate on vast collections of malware samples, requiring efficient processing and analysis. Developing scalable architectures and algorithms that can handle large- scale system call graphs with real-time detection is crucial for deployment. To allow GNN process large graphs, researchers directed to incorporate advanced ML approaches like attention mechanism, JK, etc., [145–147, 151]. However, these often consume high training time [146] and become scenario-specific and less robust [146, 148, 149, 151, 152] to adapt with evolving malwares. Additionally, low computational devices like mobile or IoT cannot execute such heavy graph extraction and classifier models [189]. Hence, to improve performance with dynamic adaptability, more research is needed for powerful yet efficient graph extractors and ML classifiers. MALWARE DETECTION COMMAND & CONTROL Attacker Two-way Channel Broken Channel Victim Fig. 8. Malware detection and removal disrupts two-way communication channels and prevents persistent control. 5.6.2 Relation Modeling & Knowledge Sharing. GNNs’ capability to leverage heterogeneous graphical data to learn relationships between system-process interactions, such as function calls, control flow, or data dependencies, allows effective capture of system behavior information caused by malware samples and spot sophisticated obfus- cation techniques by polymorphic malware variants that would go undetected with signature-based approaches. However, GNN being a relatively novel research paradigm, even advanced models often suffer from completely learning the complex graph obfuscation techniques like NOP insertion, subroutine reordering, etc, [146, 149, 189]. A possible solution to allow different GNN and ML models learn diverse relationships on the fly, is through knowledge sharing. Encouraging collaboration and knowledge sharing among the deployed models can foster the development of standardized cybersecurity knowledge graphs [190], benchmarks, and evaluation metrics. Such efforts will facilitate addressing diverse behavioral aspects in real-time learning with collective advancements. 5.7 Report Reporting and knowledge sharing play vital roles in cyber defense, as they facilitate the dissemination of actionable intelligence, enable collaboration among cybersecurity professionals, and enhance the collective understanding of emerging threats. GNNs have demonstrated their effectiveness in modeling and analyzing graph-structured data, making them a potential tool for processing knowledge graphs and facilitating learned knowledge for defensive cyber operations. However, the usage of GNN for knowledge sharing has not been given much attention for a long time. Recently a few researchers have utilized the benefit of GNN in fake data detection [167] and knowledge sharing using federated learning [191, 192]. Following, we discuss the benefits, challenges, and future directions. REPORT Victim Attacker ACTION ON OBJECTIVES Attack Life-cycle Lateral Movement Future Prevention Fig. 9. Reporting to disclose attack information and prevent similar attack occurrences in future. 5.7.1 Data Integration & Collaboration. CTI is often accumulated from various sources, including network logs, threat intelligence feeds, security incident reports, and vulnerability databases. Integrating and fusing these heterogeneous data sources into a unified graph representation while maintaining authenticity presents a significant challenge. For authenticity, researchers proposed to use GNN for fake-data identification [164–166]. However, research on data integration from multiple sources is still left behind. The absence of evenly distributed open-source datasets [165, 166], the complexity of GNN models [164], and high computation costs [167] act ACM Trans. Priv. Sec., Vol. 0, No. 0, Article 1. Publication date: January 2024. Use of Graph Neural Networks in Aiding Defensive Cyber Operations • 1:29 as blockers and remain an open area of research. To mitigate this, researchers can leverage transfer learning techniques with GNN to share acquired knowledge among related domains or datasets [193]. 5.7.2 Privacy & Security. Ensuring confidentiality, integrity, and controlled access to shared knowledge while preserving individual and organizational privacy is crucial for successful reporting and knowledge-sharing. Due to the distribution of sensitive cyber defense knowledge across various sources, adversaries target such communications to steal information. Transfer of sensitive cybersecurity data and model gradients adhering to privacy and security concerns remains a significant challenge. In generic research, Mei et al. proposed to safeguard transferred knowledge by hiding the graph structure [192]. However, in cybersecurity, limited attention is given to secure knowledge-sharing among employed defensive ML models, and requires immediate attention. 6 CONCLUSION As our world becomes more interconnected and reliant on digital systems, the imperative to safeguard our information and digital infrastructure has never been greater. The relentless evolution of cyber threats has compelled us to explore innovative solutions, and among these, GNN has emerged as a beacon of promise. This paper has delved into the applications of GNNs in disrupting each stage of the Cyber Kill Chain, a well-established attack life-cycle framework for understanding cyberattacks. By addressing each phase and elucidating how GNNs bolster defensive cyber operations, we have underscored the potential of this technology. However, it is crucial to acknowledge that the cyber landscape is dynamic and ever-changing, and GNNs also need to adapt to the change. Undoubtedly there are open research areas and avenues for further improvements. This ongoing exploration is vital to stay ahead of increasingly sophisticated adversaries. With this essence, this paper underscores the contributions and further research directions for GNN to defend against cyber threats effectively. ACKNOWLEDGMENTS This work was supported by PATENT Lab (Predictive Analytics and TEchnology iNTegration Laboratory) at the Department of Computer Science and Engineering, Mississippi State University. We also acknowledge Kyanie Waters and La’Andrea Gates for their contributions. REFERENCES [1] [Online] Cisco. What is cybersecurity? https://www.cisco.com/c/en/us/products/security/what-is-cybersecurity.html, 2022. [2] [Online] Gartner. What is cybersecurity? https://www.gartner.com/en/topics/cybersecurity, 2022. [3] Franco Scarselli, Marco Gori, Ah Chung Tsoi, Markus Hagenbuchner, and Gabriele Monfardini. The graph neural network model. IEEE transactions on neural networks, 20(1):61–80, 2008. [4] Lockheed Martin. Cyber kill chain. https://www.lockheedmartin.com/en-us/capabilities/cyber/cyber-kill-chain.html, 2011. [5] Tuja Khaund, Baris Kirdemir, Nitin Agarwal, Huan Liu, and Fred Morstatter. Social bots and their coordination during online campaigns: A survey. IEEE Transactions on Computational Social Systems, 9(2):530–545, 2022. [6] Daniel Cummings and Marcel Nassar. Structured citation trend prediction using graph neural networks. In ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, may 2020. [7] Alex Fout, Jonathon Byrd, Basir Shariat, and Asa Ben-Hur. Protein interface prediction using graph convolutional networks. In I. Guyon, U. Von Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett, editors, Advances in Neural Information Processing Systems, volume 30. Curran Associates, Inc., 2017. [8] K-I Goh, Eulsik Oh, Byungnam Kahng, and Doochul Kim. Betweenness centrality correlation in social networks. Physical Review E, 67(1):017101, 2003. [9] Filippo Maria Bianchi, Daniele Grattarola, and Cesare Alippi. Spectral clustering with graph neural networks for graph pooling. In International conference on machine learning, pages 874–883. PMLR, 2020. [10] Emmanuel Müller. Graph clustering with graph neural networks. Journal of Machine Learning Research, 24:1–21, 2023. [11] Yixuan He, Gesine Reinert, Songchao Wang, and Mihai Cucuringu. Sssnet: semi-supervised signed network clustering. In Proceedings of the 2022 SIAM International Conference on Data Mining (SDM), pages 244–252. SIAM, 2022. [12] Lirong Wu, Haitao Lin, Cheng Tan, Zhangyang Gao, and Stan Z Li. Self-supervised learning on graphs: Contrastive, generative, or predictive. IEEE Transactions on Knowledge and Data Engineering, 2021. ACM Trans. Priv. Sec., Vol. 0, No. 0, Article 1. Publication date: January 2024. 1:30 • Mitra et al. [13] Xingping Xian, Tao Wu, Xiaoke Ma, Shaojie Qiao, Yabin Shao, Chao Wang, Lin Yuan, and Yu Wu. Generative graph neural networks for link prediction. arXiv preprint arXiv:2301.00169, 2022. [14] Chenhao Niu, Yang Song, Jiaming Song, Shengjia Zhao, Aditya Grover, and Stefano Ermon. Permutation invariant graph generation via score-based generative modeling. In International Conference on Artificial Intelligence and Statistics, pages 4474–4484. PMLR, 2020. [15] Keyulu Xu, Weihua Hu, Jure Leskovec, and Stefanie Jegelka. How powerful are graph neural networks? In International Conference on Learning Representations, 2019. [16] Ryoma Sato. A survey on the expressive power of graph neural networks, 2020. [17] [Online] Flaticon. Accessed:2023-08-30. https://www.flaticon.com/. [18] Franco Scarselli, Marco Gori, Ah Chung Tsoi, Markus Hagenbuchner, and Gabriele Monfardini. The graph neural network model. IEEE Transactions on Neural Networks, 20(1):61–80, 2009. [19] Thomas N Kipf and Max Welling. Semi-supervised classification with graph convolutional networks. arXiv preprint arXiv:1609.02907, 2016. [20] Will Hamilton, Zhitao Ying, and Jure Leskovec. Inductive representation learning on large graphs. Advances in neural information processing systems, 30, 2017. [21] Petar Veličković, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Liò, and Yoshua Bengio. Graph Attention Networks. International Conference on Learning Representations, 2018. [22] Yujia Li, Daniel Tarlow, Marc Brockschmidt, and Richard Zemel. Gated graph sequence neural networks, 2015. [23] NIST. cyberspace operations. https://csrc.nist.gov/glossary/term/cyberspace_operations, 2022. [24] [Online] MITRE. Mitre att&ck. https://attack.mitre.org/, 2011. [25] Sergio Caltagirone, Andrew Pendergast, and Christopher Betz. The diamond model of intrusion analysis. Technical report, Center For Cyber Intelligence Analysis and Threat Research Hanover Md, 2013. [26] [Online] NIST. Nist. https://www.nist.gov/cyberframework/online-learning/five-functions, 2014. [27] [Online]. Ibm security x-force cyberattack preparation and execution frameworks. https://www.ibm.com/downloads/cas/A27KQP8R. [28] [Online] LogRhythm. The threat lifecycle management framework. http://www.armana.co.uk/Guides/ARMANA-threat-lifecycle- management-whitepaper.pdf, 2016. [29] Maoguo Gong, Yu Xie, Ke Pan, Kaiyuan Feng, and Alex Kai Qin. A survey on differentially private machine learning. IEEE computational intelligence magazine, 15(2):49–64, 2020. [30] Subash Neupane, Ivan A Fernandez, Sudip Mittal, and Shahram Rahimi. Impacts and risk of generative ai technology on cyber defense. arXiv preprint arXiv:2306.13033, 2023. [31] Wilson Patterson, Ivan Fernandez, Subash Neupane, Milan Parmar, Sudip Mittal, and Shahram Rahimi. A white-box adversarial attack against a digital twin. arXiv preprint arXiv:2210.14018, 2022. [32] Subash Neupane, Jesse Ables, William Anderson, Sudip Mittal, Shahram Rahimi, Ioana Banicescu, and Maria Seale. Explainable intrusion detection systems (x-ids): A survey of current methods, challenges, and opportunities. IEEE Access, 10:112392–112415, 2022. [33] Kaiyang Li, Guangchun Luo, Yang Ye, Wei Li, Shihao Ji, and Zhipeng Cai. Adversarial privacy-preserving graph embedding against inference attack. IEEE Internet of Things Journal, 8(8):6904–6915, 2020. [34] Binghui Wang, Jiayi Guo, Ang Li, Yiran Chen, and Hai Li. Privacy-preserving representation learning on graphs: A mutual information perspective. In Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining, pages 1667–1676, 2021. [35] Peiyuan Liao, Han Zhao, Keyulu Xu, Tommi Jaakkola, Geoffrey J Gordon, Stefanie Jegelka, and Ruslan Salakhutdinov. Information obfuscation of graph neural networks. In International conference on machine learning, pages 6600–6610. PMLR, 2021. [36] Chuhan Wu, Fangzhao Wu, Yang Cao, Yongfeng Huang, and Xing Xie. Fedgnn: Federated graph neural network for privacy-preserving recommendation. arXiv preprint arXiv:2102.04925, 2021. [37] Chuanqiang Shan, Huiyun Jiao, and Jie Fu. Towards representation identical privacy-preserving graph neural network via split learning. arXiv preprint arXiv:2107.05917, 2021. [38] Hui Hu, Lu Cheng, Jayden Parker Vap, and Mike Borowczak. Learning privacy-preserving graph convolutional network with partially observed sensitive attributes. In Proceedings of the ACM Web Conference 2022, pages 3552–3561, 2022. [39] Songlei Wang, Yifeng Zheng, and Xiaohua Jia. Secgnn: Privacy-preserving graph neural network training and inference as a cloud service. IEEE Transactions on Services Computing, 2023. [40] Andrew Kachites McCallum, Kamal Nigam, Jason Rennie, and Kristie Seymore. Automating the construction of internet portals with machine learning. Information Retrieval, 3:127–163, 2000. [41] C Lee Giles, Kurt D Bollacker, and Steve Lawrence. Citeseer: An automatic citation indexing system. In Proceedings of the third ACM conference on Digital libraries, pages 89–98, 1998. [42] Prithviraj Sen, Galileo Namata, Mustafa Bilgic, Lise Getoor, Brian Galligher, and Tina Eliassi-Rad. Collective classification in network data. AI magazine, 29(3):93–93, 2008. [43] Joseph A Konstan, Bradley N Miller, David Maltz, Jonathan L Herlocker, Lee R Gordon, and John Riedl. Grouplens: Applying collaborative filtering to usenet news. Communications of the ACM, 40(3):77–87, 1997. ACM Trans. Priv. Sec., Vol. 0, No. 0, Article 1. Publication date: January 2024. Use of Graph Neural Networks in Aiding Defensive Cyber Operations • 1:31 [44] Kristina Toutanova, Danqi Chen, Patrick Pantel, Hoifung Poon, and Pallavi Choudhury. Representing text for joint embedding of text and knowledge bases. arXiv preprint arXiv:1503.01130, 2015. [45] Mohsen Jamali and Martin Ester. A matrix factorization technique with trust propagation for recommendation in social networks. In Proceedings of the fourth ACM conference on Recommender systems, pages 135–142, 2010. [46] Hao Ma, Dengyong Zhou, Chao Liu, Michael R Lyu, and Irwin King. Recommender systems with social regularization. In Proceedings of the fourth ACM international conference on Web search and data mining, pages 287–296, 2011. [47] Gideon Dror, Noam Koenigstein, Yehuda Koren, and Markus Weimer. The yahoo! music dataset and kdd-cup’11. In Proceedings of KDD Cup 2011, pages 3–18. PMLR, 2012. [48] Lubos Takac and Michal Zabovsky. Data analysis in public social networks. In International scientific conference and international workshop present day trends of innovations, 2012. [49] Chirag Agarwal, Himabindu Lakkaraju, and Marinka Zitnik. Towards a unified framework for fair and stable graph representation learning. In Uncertainty in Artificial Intelligence, pages 2114–2124. PMLR, 2021. [50] Hanjun Dai, Hui Li, Tian Tian, Xin Huang, Lin Wang, Jun Zhu, and Le Song. Adversarial attack on graph structured data. In International conference on machine learning, pages 1115–1124. PMLR, 2018. [51] Daniel Zügner and Stephan Günnemann. Adversarial attacks on graph neural networks via meta learning. arXiv:1902.08412, 2019. [52] Xixun Lin, Chuan Zhou, Hong Yang, Jia Wu, Haibo Wang, Yanan Cao, and Bin Wang. Exploratory adversarial attacks on graph neural networks. In IEEE International Conference On Data Mining (ICDM), 2020. [53] Wanyu Lin, Shengxiang Ji, and Baochun Li. Adversarial attacks on link prediction algorithms based on graph neural networks. In Proceedings of the 15th ACM Asia Conference on Computer and Communications Security, pages 370–380, 2020. [54] Zaixi Zhang, Jinyuan Jia, Binghui Wang, and Neil Zhenqiang Gong. Backdoor attacks to graph neural networks. In Proceedings of the 26th ACM Symposium on Access Control Models and Technologies, pages 15–26, 2021. [55] Lan Zhang, Peng Liu, Yoonho Choi, and Ping Chen. Semantics-preserving reinforcement learning attack against graph neural networks for malware detection. IEEE Transactions on Dependable and Secure Computing, 2022. [56] Xiaokang Zhou, Wei Liang, Weimin Li, Ke Yan, Shohei Shimizu, I Kevin, and Kai Wang. Hierarchical adversarial attacks against graph neural network based iot network intrusion detection system. IEEE Internet of Things Journal, 2021. [57] Yuancheng Li and Yuanyuan Wang. Developing graphical detection techniques for maintaining state estimation integrity against false data injection attack in integrated electric cyber-physical system. Journal of systems architecture, 105:101705, 2020. [58] Osman Boyaci, Amarachi Umunnakwe, Abhijeet Sahu, Mohammad Rasoul Narimani, Muhammad Ismail, Katherine R Davis, and Erchin Serpedin. Graph neural networks based detection of stealth false data injection attacks in smart grids. IEEE Systems Journal, 16(2):2946–2957, 2021. [59] Hanjun Dai, Bo Dai, and Le Song. Discriminative embeddings of latent variable models for structured data. In International conference on machine learning, pages 2702–2711. PMLR, 2016. [60] Lada A Adamic and Natalie Glance. The political blogosphere and the 2004 us election: divided they blog. In Proceedings of the 3rd international workshop on Link discovery, pages 36–43, 2005. [61] Aleksandar Bojchevski and Stephan Günnemann. Deep gaussian embedding of graphs: Unsupervised inductive learning via ranking. arXiv preprint arXiv:1707.03815, 2017. [62] Mark EJ Newman. Finding community structure in networks using the eigenvectors of matrices. Physical review E, 74(3):036104, 2006. [63] Duncan J Watts and Steven H Strogatz. Collective dynamics of ‘small-world’networks. nature, 393(6684):440–442, 1998. [64] Robert Ackland et al. Mapping the us political blogosphere: Are conservative bloggers more prominent? In BlogTalk Downunder 2005 Conference, Sydney. BlogTalk Downunder 2005 Conference, Sydney, 2005. [65] Mark Weber, Giacomo Domeniconi, Jie Chen, Daniel Karl I Weidele, Claudio Bellei, Tom Robinson, and Charles E Leiserson. Anti-money laundering in bitcoin: Experimenting with graph convolutional networks for financial forensics. arXiv preprint arXiv:1908.02591, 2019. [66] Binghui Wang, Le Zhang, and Neil Zhenqiang Gong. Sybilscar: Sybil detection in online social networks via local rule based propagation. In IEEE INFOCOM 2017-IEEE Conference on Computer Communications, pages 1–9. IEEE, 2017. [67] Pinar Yanardag and SVN Vishwanathan. Deep graph kernels. In Proceedings of the 21th ACM SIGKDD international conference on knowledge discovery and data mining, pages 1365–1374, 2015. [68] Ying Tan. Artificial immune system: applications in computer security. John Wiley & Sons, 2016. [69] [Online] Virusshare. Accessed:2023-08-30. https://virusshare.com. [70] [Online] VirusTotal. Accessed:2023-04-20. https://www.virustotal.com. [71] Ayyoob Hamza, Hassan Habibi Gharakheili, Theophilus A Benson, and Vijay Sivaraman. Detecting volumetric attacks on lot devices via sdn-based monitoring of mud activity. In Proceedings of the 2019 ACM Symposium on SDN Research, pages 36–48, 2019. [72] [Online] IEEE 30-Bus System. Accessed:2023-08-30. https://icseg.iti.illinois.edu/ieee-30-bus-system. [73] [Online] IEEE 118-Bus System. Accessed:2023-08-30. https://icseg.iti.illinois.edu/ieee-118-bus-system. [74] Leon Thurner, Alexander Scheidler, Florian Schäfer, Jan-Hendrik Menke, Julian Dollichon, Friederike Meier, Steffen Meinecke, and Martin Braun. pandapower—an open-source python tool for convenient modeling, analysis, and optimization of electric power systems. ACM Trans. Priv. Sec., Vol. 0, No. 0, Article 1. Publication date: January 2024. 1:32 • Mitra et al. IEEE Transactions on Power Systems, 33(6):6510–6521, 2018. [75] [Online] IEEE 14-Bus System. Accessed:2023-08-30. https://icseg.iti.illinois.edu/ieee-14-bus-system. [76] [Online] IEEE 300-Bus System. Accessed:2023-08-30. https://icseg.iti.illinois.edu/ieee-300-bus-system. [77] Yulei Wu, Hong-Ning Dai, and Haina Tang. Graph neural networks for anomaly detection in industrial internet of things. IEEE Internet of Things Journal, 2021. [78] Anshika Chaudhary, Himangi Mittal, and Anuja Arora. Anomaly detection using graph neural networks. In 2019 international conference on machine learning, big data, cloud and parallel computing (COMITCon), pages 346–350. IEEE, 2019. [79] Yangyang Li, Yipeng Ji, Shaoning Li, Shulong He, Yinhao Cao, Yifeng Liu, Hong Liu, Xiong Li, Jun Shi, and Yangchao Yang. Relevance- aware anomalous users detection in social network via graph neural network. In 2021 International Joint Conference on Neural Networks (IJCNN), 2021. [80] Yipeng Ji, Jingyi Wang, Shaoning Li, Yangyang Li, Shenwen Lin, and Xiong Li. An anomaly event detection method based on gnn algorithm for multi-data sources. In Proceedings of the 3rd ACM International Symposium on Blockchain and Secure Critical Infrastructure, 2021. [81] Zheng Song, Fengshan Bai, Jianfeng Zhao, and Jie Zhang. Spammer detection using graph-level classification model of graph neural network. In 2021 IEEE 2nd International Conference on Big Data, Artificial Intelligence and Internet of Things Engineering (ICBAIE), 2021. [82] Xuhong Wang, Baihong Jin, Ying Du, Ping Cui, Yingshui Tan, and Yupu Yang. One-class graph neural networks for anomaly detection in attributed networks. Neural computing and applications, 33(18):12073–12085, 2021. [83] Bin Huang, Xuhong Wang, Ping Cui, Wenjian Jiang, Yupu Yang, and Qifu Fan. One-class temporal graph attention neural network for dynamic graph anomaly detection. In 2021 2nd International Conference on Electronics, Communications and Information Technology (CECIT), 2021. [84] Haoran Shi, Lixin Ji, Shuxin Liu, and Kai Wang. Multi-layer graph neural network-based random anomalous behavior detection. In 2021 International Conference on Digital Society and Intelligent Systems (DSInS), pages 266–270. IEEE, 2021. [85] Tong Zhao, Chuchen Deng, Kaifeng Yu, Tianwen Jiang, Daheng Wang, and Meng Jiang. Gnn-based graph anomaly detection with graph anomaly loss. In The Second International Workshop on Deep Learning on Graphs: Methods and Applications, pages 1–7, 2020. [86] Ailin Deng and Bryan Hooi. Graph neural network-based anomaly detection in multivariate time series. In Proceedings of the AAAI Conference on Artificial Intelligence, 2021. [87] [Online] Higgs Twitter Dataset. Accessed:2023-08-30. https://snap.stanford.edu/data/higgs-twitter.html. [88] [Online] Enron Email Dataset. Accessed:2023-08-30. https://www.cs.cmu.edu/ ./enron. [89] [Online] Yelp Dataset. Accessed:2023-08-30. https://www.kaggle.com/datasets/yelp-dataset/yelp-dataset. [90] [Online] Micro Blog Dataset. Accessed:2023-08-30. https://dx.doi.org/10.21227/wzfk-w184. [91] Ryan A. Rossi and Nesreen K. Ahmed. The network data repository with interactive graph analytics and visualization. In AAAI, 2015. [92] Da Xu, Chuanwei Ruan, Evren Korpeoglu, Sushant Kumar, and Kannan Achan. Inductive representation learning on temporal graphs. arXiv preprint arXiv:2002.07962, 2020. [93] Srijan Kumar, Xikun Zhang, and Jure Leskovec. Predicting dynamic embedding trajectory in temporal interaction networks. In Proceedings of the 25th ACM SIGKDD international conference on knowledge discovery & data mining, pages 1269–1278, 2019. [94] [Online] OpenFlights Dataset. Accessed:2023-08-30. https://openflights.org. [95] [Online] Email-EU core Dataset. Accessed:2023-08-30. https://snap.stanford.edu/data/email-Eu-core.html. [96] Srijan Kumar, Francesca Spezzano, VS Subrahmanian, and Christos Faloutsos. Edge weight prediction in weighted signed networks. In 2016 IEEE 16th International Conference on Data Mining (ICDM), pages 221–230. IEEE, 2016. [97] Meng Jiang. Catching social media advertisers with strategy analysis. In Proceedings of the First International Workshop on Computational Methods for CyberSafety, pages 5–10, 2016. [98] Aditya P Mathur and Nils Ole Tippenhauer. Swat: A water treatment testbed for research and training on ics security. In 2016 international workshop on cyber-physical systems for smart water networks (CySWater), pages 31–36. IEEE, 2016. [99] Chuadhry Mujeeb Ahmed, Venkata Reddy Palleti, and Aditya P Mathur. Wadi: a water distribution testbed for research in the design of secure cyber physical systems. In Proceedings of the 3rd international workshop on cyber-physical systems for smart water networks, 2017. [100] Yunhui Zheng and Xiangyu Zhang. Path sensitive static analysis of web applications for remote code execution vulnerability detection. In 2013 35th International Conference on Software Engineering (ICSE), pages 652–661. IEEE, 2013. [101] Alexander Ivanov Sotirov. Automatic vulnerability detection using static source code analysis. PhD thesis, Citeseer, 2005. [102] Zhidong Shen and Si Chen. A survey of automatic software vulnerability detection, program repair, and defect prediction techniques. Security and Communication Networks, 2020:1–16, 2020. [103] Satpal Singh Kushwaha, Sandeep Joshi, Dilbag Singh, Manjit Kaur, and Heung-No Lee. Systematic review of security vulnerabilities in ethereum blockchain smart contract. IEEE Access, 10:6605–6621, 2022. [104] Hazim Hanif, Mohd Hairul Nizam Md Nasir, Mohd Faizal Ab Razak, Ahmad Firdaus, and Nor Badrul Anuar. The rise of software vulnerability: Taxonomy of software vulnerabilities detection and machine learning approaches. Journal of Network and Computer Applications, 179:103009, 2021. ACM Trans. Priv. Sec., Vol. 0, No. 0, Article 1. Publication date: January 2024. Use of Graph Neural Networks in Aiding Defensive Cyber Operations • 1:33 [105] Rishi Rabheru, Hazim Hanif, and Sergio Maffeis. A hybrid graph neural network approach for detecting php vulnerabilities. In 2022 IEEE Conference on Dependable and Secure Computing (DSC), pages 1–9. IEEE, 2022. [106] Yaqin Zhou, Shangqing Liu, Jingkai Siow, Xiaoning Du, and Yang Liu. Devign: Effective vulnerability identification by learning comprehensive program semantics via graph neural networks. Advances in neural information processing systems, 32, 2019. [107] Van-Anh Nguyen, Dai Quoc Nguyen, Van Nguyen, Trung Le, Quan Hung Tran, and Dinh Phung. Regvd: Revisiting graph neural networks for vulnerability detection. In Proceedings of the ACM/IEEE 44th International Conference on Software Engineering: Companion Proceedings, 2022. [108] Huanting Wang, Guixin Ye, Zhanyong Tang, Shin Hwei Tan, Songfang Huang, Dingyi Fang, Yansong Feng, Lizhong Bian, and Zheng Wang. Combining graph-based learning with automated data collection for code vulnerability detection. IEEE Transactions on Information Forensics and Security, 16:1943–1958, 2021. [109] Sicong Cao, Xiaobing Sun, Lili Bo, Ying Wei, and Bin Li. Bgnn4vd: Constructing bidirectional graph neural-network for vulnerability detection. Information and Software Technology, 136:106576, 2021. [110] Xiao Cheng, Haoyu Wang, Jiayi Hua, Guoai Xu, and Yulei Sui. Deepwukong: Statically detecting software vulnerabilities using deep graph neural network. ACM Trans. Softw. Eng. Methodol., 2021. [111] Wei Tang, Mingwei Tang, Minchao Ban, Ziguo Zhao, and Mingjun Feng. Csgvd: A deep learning approach combining sequence and graph embedding for source code vulnerability detection. Journal of Systems and Software, 2023. [112] Sefa Eren Şahin, Ecem Mine Özyedierler, and Ayse Tosun. Predicting vulnerability inducing function versions using node embeddings and graph neural networks. Inf. Softw. Technol., 145(C), may 2022. [113] Yuan Zhuang, Zhenguang Liu, Peng Qian, Qi Liu, Xiang Wang, and Qinming He. Smart contract vulnerability detection using graph neural networks. In Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence, IJCAI’20, 2021. [114] [Online] Devign Dataset. Accessed:2023-08-30. https://sites.google.com/view/devign. [115] Xiaoning Du, Bihuan Chen, Yuekang Li, Jianmin Guo, Yaqin Zhou, Yang Liu, and Yu Jiang. Leopard: Identifying vulnerable code for vulnerability assessment through program metrics. In 2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE), 2019. [116] Shuai Lu, Daya Guo, Shuo Ren, Junjie Huang, Alexey Svyatkovskiy, Ambrosio Blanco, Colin Clement, Dawn Drain, Daxin Jiang, Duyu Tang, et al. Codexglue: A machine learning benchmark dataset for code understanding and generation. arXiv preprint arXiv:2102.04664, 2021. [117] [Online] FUNDED Dataset. Accessed:2023-08-30. https://drive.google.com/drive/folders/1WFFV8uGi8oXpzYORyiqRCYyqJGiHSbZL. [118] [Online] BGNN4VD Dataset. Accessed:2023-08-30. https://github.com/SicongCao/BGNN4VD. [119] [Online] NIST SARD Dataset. Accessed:2023-08-30. https://samate.nist.gov/SARD. [120] [Online] Lua Dataset. Accessed:2023-08-30. https://www.lua.org. [121] [Online] Redis Dataset. Accessed:2023-08-30. https://redis.io. [122] A. Tosun S.E. Sahin, E.M. Ozyedierler. Predicting vulnerability inducing function versions using node embeddings and graph neural networks - wireshark dataset. https://data.mendeley.com/datasets/ymtf9znmfz/1, Jan 2023. [123] Jie Cai, Bin Li, Jiale Zhang, Xiaobing Sun, and Bing Chen. Combine sliced joint graph with graph neural networks for smart contract vulnerability detection. Journal of Systems and Software, 2023. [124] Peng Qian, Zhenguang Liu, Qinming He, Butian Huang, Duanzheng Tian, and Xun Wang. Smart contract vulnerability detection technique: A survey. arXiv preprint arXiv:2209.05872, 2022. [125] Hanting Chu, Pengcheng Zhang, Hai Dong, Yan Xiao, Shunhui Ji, and Wenrui Li. A survey on smart contract vulnerabilities: Data sources, detection and repair. Information and Software Technology, page 107221, 2023. [126] Zhonghua Zhang, Xifei Song, Lei Liu, Jie Yin, Yu Wang, and Dapeng Lan. Recent advances in blockchain and artificial intelligence integration: Feasibility analysis, research issues, applications, challenges, and future work. Security and Communication Networks, 2021. [127] Tristan Bilot, Nour El Madhoun, Khaldoun Al Agha, and Anis Zouaoui. Graph neural networks for intrusion detection: A survey. IEEE Access, 2023. [128] Wai Weng Lo, Siamak Layeghy, Mohanad Sarhan, Marcus Gallagher, and Marius Portmann. E-graphsage: A graph neural network based intrusion detection system for iot. In NOMS 2022-2022 IEEE/IFIP Network Operations and Management Symposium, 2022. [129] Liyan Chang and Paula Branco. Graph-based solutions with residuals for intrusion detection: The modified e-graphsage and e-resgat algorithms. arXiv preprint arXiv:2111.13597, 2021. [130] David Pujol-Perich, Jose Suarez-Varela, Albert Cabellos-Aparicio, and Pere Barlet-Ros. Unveiling the potential of graph neural networks for robust intrusion detection. ACM SIGMETRICS Performance Evaluation Review, 49(4):111–117, 2022. [131] Zhichao Hu, Likun Liu, Haining Yu, and Xiangzhan Yu. Using graph representation in host-based intrusion detection. Security and Communication Networks, 2021:1–13, 2021. [132] Su Wang, Zhiliang Wang, Tao Zhou, Hongbin Sun, Xia Yin, Dongqi Han, Han Zhang, Xingang Shi, and Jiahai Yang. Threatrace: Detecting and tracing host-based threats in node level through provenance graph learning. IEEE Transactions on Information Forensics and Security, 17:3972–3987, 2022. ACM Trans. Priv. Sec., Vol. 0, No. 0, Article 1. Publication date: January 2024. 1:34 • Mitra et al. [133] Nickolaos Koroniotis, Nour Moustafa, Elena Sitnikova, and Benjamin Turnbull. Towards the development of realistic botnet dataset in the internet of things for network forensic analytics: Bot-iot dataset. Future Generation Computer Systems, 100:779–796, 2019. [134] Abdullah Alsaedi, Nour Moustafa, Zahir Tari, Abdun Mahmood, and Adnan Anwar. Ton_iot telemetry dataset: A new generation dataset of iot and iiot for data-driven intrusion detection systems. IEEE Access, 8:165130–165150, 2020. [135] Mohanad Sarhan, Siamak Layeghy, Nour Moustafa, and Marius Portmann. Netflow datasets for machine learning-based network intrusion detection systems. In Big Data Technologies and Applications, pages 117–135. Springer, 2020. [136] [Online] CIC-Darknet Dataset. Accessed:2023-08-30. https://www.unb.ca/cic/datasets/darknet2020.html. [137] [Online] ToN-IoT Dataset. Accessed:2023-08-30. https://research.unsw.edu.au/projects/toniotunsw-nb15-datasets. [138] [Online] UNSW-NB15 Dataset. Accessed:2023-08-30. https://research.unsw.edu.au/projects/unsw-nb15-dataset. [139] [Online] CSE-CIC-IDS Dataset. Accessed:2023-08-30. https://www.unb.ca/cic/datasets/ids-2018.html. [140] Iman Sharafaldin, Arash Habibi Lashkari, and Ali A Ghorbani. Toward generating a new intrusion detection dataset and intrusion traffic characterization. ICISSp, 1:108–116, 2018. [141] Gideon Creech and Jiankun Hu. A semantic approach to host-based intrusion detection systems using contiguousand discontiguous system call patterns. IEEE Transactions on Computers, 63(4):807–819, 2013. [142] [Online] StreamSpot Dataset. Accessed:2023-08-30. https://github.com/sbustreamspot/sbustreamspot-data. [143] [Online] Unicorn SC Dataset. Accessed:2023-08-30. https://github.com/margoseltzer/shellshock-apt. [144] [Online] DARPA TC-3;5 SC. Accessed:2023-08-30. https://github.com/darpa-i2o/Transparent-Computing/blob/master/README-E3.md. [145] Shen Wang and S Yu Philip. Heterogeneous graph matching networks: Application to unknown malware detection. In 2019 IEEE International Conference on Big Data (Big Data), pages 5401–5408. IEEE, 2019. [146] Jiaqi Yan, Guanhua Yan, and Dong Jin. Classifying malware represented as control flow graphs using deep graph convolutional neural network. In 2019 49th annual IEEE/IFIP international conference on dependable systems and networks (DSN), pages 52–63. IEEE, 2019. [147] Yakang Hua, Yuanzheng Du, and Dongzhi He. Classifying packed malware represented as control flow graphs using deep graph convolutional neural network. In 2020 International Conference on Computer Engineering and Application (ICCEA), 2020. [148] Shanxi Li, Qingguo Zhou, Rui Zhou, and Qingquan Lv. Intelligent malware detection based on graph convolutional network. The Journal of Supercomputing, 78(3):4182–4198, 2022. [149] Pengbin Feng, Jianfeng Ma, Teng Li, Xindi Ma, Ning Xi, and Di Lu. Android malware detection via graph representation learning. Mobile Information Systems, 2021, 2021. [150] Julian Busch, Anton Kocheturov, Volker Tresp, and Thomas Seidl. Nf-gnn: network flow graph neural networks for malware detection and classification. In 33rd International Conference on Scientific and Statistical Database Management, pages 121–132, 2021. [151] Wai Weng Lo, Siamak Layeghy, Mohanad Sarhan, Marcus Gallagher, and Marius Portmann. Graph neural network-based android malware classification with jumping knowledge. arXiv e-prints, pages arXiv–2201, 2022. [152] Chuangfeng Li, Guangming Shen, and Wei Sun. Cross-architecture internet-of-things malware detection based on graph neural network. In 2021 International Joint Conference on Neural Networks (IJCNN), pages 1–7. IEEE, 2021. [153] Sergey Zagoruyko and Nikos Komodakis. Learning to compare image patches via convolutional neural networks. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 4353–4361, 2015. [154] Royi Ronen, Marian Radu, Corina Feuerstein, Elad Yom-Tov, and Mansour Ahmadi. Microsoft malware classification challenge. arXiv preprint arXiv:1802.10135, 2018. [155] [Online] YAN-CFG offensivecomputing. Accessed:2023-04-20. http://www.offensivecomputing.net. [156] Daniel Arp, Michael Spreitzenbarth, Malte Hubner, Hugo Gascon, Konrad Rieck, and CERT Siemens. Drebin: Effective and explainable detection of android malware in your pocket. In Ndss, volume 14, pages 23–26, 2014. [157] Kevin Allix, Tegawendé F Bissyandé, Jacques Klein, and Yves Le Traon. Androzoo: Collecting millions of android apps for the research community. In Proceedings of the 13th international conference on mining software repositories, pages 468–471, 2016. [158] Arash Habibi Lashkari, Andi Fitriah A Kadir, Laya Taheri, and Ali A Ghorbani. Toward developing a systematic approach to generate benchmark android malware datasets and classification. In 2018 International Carnahan conference on security technology (ICCST), 2018. [159] Scott Freitas, Yuxiao Dong, Joshua Neil, and Duen Horng Chau. A large-scale database for graph representation learning. arXiv preprint arXiv:2011.07682, 2020. [160] Cagatay Catal, Hakan Gunduz, and Alper Ozcan. Malware detection based on graph attention networks for intelligent transportation systems. Electronics, 10(20):2534, 2021. [161] Stepan Dvorak, Pavel Prochazka, and Lukas Bajer. Gnn-based malicious network entities identification in large-scale network data. In NOMS 2022-2022 IEEE/IFIP Network Operations and Management Symposium, pages 1–4. IEEE, 2022. [162] Yafei Wu, Jian Shi, Peicheng Wang, Dongrui Zeng, and Cong Sun. Deepcatra: Learning flow-and graph-based behaviours for android malware detection. IET Information Security, 17(1):118–130, 2023. [163] [Online]. Common vulnerabilities and exposures (cve®). https://cve.mitre.org. [164] Yi Han, Shanika Karunasekera, and Christopher Leckie. Graph neural networks with continual learning for fake news detection from social media. arXiv preprint arXiv:2007.03316, 2020. ACM Trans. Priv. Sec., Vol. 0, No. 0, Article 1. Publication date: January 2024. Use of Graph Neural Networks in Aiding Defensive Cyber Operations • 1:35 [165] Hayato Matsumoto, Soh Yoshida, and Mitsuji Muneyasu. Propagation-based fake news detection using graph neural networks with transformer. In 2021 IEEE 10th Global Conference on Consumer Electronics (GCCE), pages 19–20. IEEE, 2021. [166] Weizhi Xu, Junfei Wu, Qiang Liu, Shu Wu, and Liang Wang. Evidence-aware fake news detection with graph neural networks. In Proceedings of the ACM Web Conference 2022, pages 2501–2510, 2022. [167] Soham Dasgupta, Aritran Piplai, Priyanka Ranade, and Anupam Joshi. Cybersecurity knowledge graph improvement with graph neural networks. In 2021 IEEE International Conference on Big Data (Big Data), pages 3290–3297. IEEE, 2021. [168] Kai Shu, Deepak Mahudeswaran, Suhang Wang, Dongwon Lee, and Huan Liu. Fakenewsnet: A data repository with news content, social context, and spatiotemporal information for studying fake news on social media. Big data, 8(3):171–188, 2020. [169] Kashyap Popat, Subhabrata Mukherjee, Jannik Strötgen, and Gerhard Weikum. Where the truth lies: Explaining the credibility of emerging claims on the web and social media. In Proceedings of the 26th International Conference on World Wide Web Companion, 2017. [170] Andreas Vlachos and Sebastian Riedel. Fact checking: Task definition and dataset construction. In Proceedings of the ACL 2014 workshop on language technologies and computational social science, pages 18–22, 2014. [171] [Online] DeepWukong Dataset. Accessed:2023-08-02. https://github.com/jumormt/DeepWukong. [172] Vnt chain website. https://github.com/vntchain/go-vnt., Jan 2018. [173] Haoyu He, Yuede Ji, and H Howie Huang. Illuminati: Towards explaining graph neural networks for cybersecurity analysis. In 2022 IEEE 7th European Symposium on Security and Privacy (EuroS&P), pages 74–89. IEEE, 2022. [174] Zhitao Ying, Dylan Bourgeois, Jiaxuan You, Marinka Zitnik, and Jure Leskovec. Gnnexplainer: Generating explanations for graph neural networks. Advances in neural information processing systems, 32, 2019. [175] Trisha Chakraborty, Shaswata Mitra, and Sudip Mittal. Capow: Context-aware ai-assisted proof of work based ddos defense. arXiv preprint arXiv:2301.11767, 2023. [176] [Online]. Optimizing graph neural network training performance on intel® xeon. https://www.linkedin.com/pulse/optimizing-graph- neural-network-training-performance-intel-avancha, Feb 2022. [177] Hao Yuan, Haiyang Yu, Jie Wang, Kang Li, and Shuiwang Ji. On explainability of graph neural networks via subgraph explorations. In International conference on machine learning, pages 12241–12252. PMLR, 2021. [178] Zhenguang Liu, Peng Qian, Xiaoyang Wang, Yuan Zhuang, Lin Qiu, and Xun Wang. Combining graph neural networks with expert knowledge for smart contract vulnerability detection. IEEE Transactions on Knowledge and Data Engineering, 2021. [179] Qingren Zeng, Jiahao He, Gansen Zhao, Shuangyin Li, Jingji Yang, Hua Tang, and Haoyu Luo. Ethergis: a vulnerability detection framework for ethereum smart contracts based on graph learning features. In 2022 IEEE 46th Annual Computers, Software, and Applications Conference (COMPSAC), pages 1742–1749. IEEE, 2022. [180] Utkarsh Desai, Sambaran Bandyopadhyay, and Srikanth Tamilselvam. Graph neural network to dilute outliers for refactoring monolith application. In Proceedings of the AAAI Conference on Artificial Intelligence, 2021. [181] Sahil Suneja, Yunhui Zheng, Yufan Zhuang, Jim Laredo, and Alessandro Morari. Learning to map source code to software vulnerability using code-as-a-graph. arXiv preprint arXiv:2006.08614, 2020. [182] Alexander LeClair, Sakib Haque, Lingfei Wu, and Collin McMillan. Improved code summarization via a graph neural network. In Proceedings of the 28th international conference on program comprehension, 2020. [183] Ridhi Jain, Nicole Gervasoni, Mthandazo Ndhlovu, and Sanjay Rawat. A code centric evaluation of c/c++ vulnerability datasets for deep learning based vulnerability detection techniques. In Proceedings of the 16th Innovations in Software Engineering Conference, 2023. [184] hex rays. Ida pro [online]. https://hex-rays.com/ida-pro/. [185] Ghidra. Ghidra [online]. https://ghidra-sre.org/. [186] Shahid Anwar, Jasni Mohamad Zain, Mohamad Fadli Zolkipli, Zakira Inayat, Suleman Khan, Bokolo Anthony, and Victor Chang. From intrusion detection to an intrusion response system: fundamentals, requirements, and future directions. Algorithms, 10(2):39, 2017. [187] Igino Corona, Giorgio Giacinto, and Fabio Roli. Adversarial attacks against intrusion detection systems: Taxonomy, solutions and open issues. Information Sciences, 239:201–225, 2013. [188] Jiawei Zhou, Zhiying Xu, Alexander M Rush, and Minlan Yu. Automating botnet detection with graph neural networks. arXiv preprint arXiv:2003.06344, 2020. [189] Shaswata Mitra, Stephen A Torri, and Sudip Mittal. Survey of malware analysis through control flow graph using machine learning. arXiv preprint arXiv:2305.08993, 2023. [190] Shaswata Mitra, Aritran Piplai, Sudip Mittal, and Anupam Joshi. Combating fake cyber threat intelligence using provenance in cybersecurity knowledge graphs. In 2021 IEEE International Conference on Big Data (Big Data), pages 3316–3323. IEEE, 2021. [191] Chaoyang He, Keshav Balasubramanian, Emir Ceyani, Carl Yang, Han Xie, Lichao Sun, Lifang He, Liangwei Yang, Philip S Yu, Yu Rong, et al. Fedgraphnn: A federated learning system and benchmark for graph neural networks. arXiv preprint arXiv:2104.07145, 2021. [192] Guangxu Mei, Ziyu Guo, Shijun Liu, and Li Pan. Sgnn: A graph neural network based federated learning approach by hiding structure. In 2019 IEEE International Conference on Big Data (Big Data), pages 2560–2568. IEEE, 2019. [193] Xueting Han, Zhenhuan Huang, Bang An, and Jing Bai. Adaptive transfer learning on graph neural networks. In Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining, pages 565–574, 2021. ACM Trans. Priv. Sec., Vol. 0, No. 0, Article 1. Publication date: January 2024.