Quantitative Measurement of Cyber Resilience: Modeling and Experimentation Michael J. Weisman1, Alexander Kott1, Jason E. Ellis1, Brian J. Murphy2, Travis W. Parker3, Sidney Smith1, Joachim Vandekerckhove4 Distribution Statement A: Approved for public release; distribution is unlimited. Abstract Abstract Cyber resilience is the ability of a system to resist and recover from a cyber attack, thereby restoring the system’s functionality. Effective design and development of a cyber resilient system requires experimental methods and tools for quantitative measuring of cyber resilience. This paper describes an experimental method and test bed for obtaining resilience-relevant data as a system (in our case – a truck) traverses its route, in repeatable, systematic experiments. We model a truck equipped with an autonomous cyber-defense system and which also includes inherent physical resilience features. When attacked by malware, this ensemble of cyber-physical features (i.e., “bonware”) strives to resist and recover from the performance degradation caused by the malware’s attack. We propose parsimonious mathematical models to aid in quantifying systems’ resilience to cyber attacks. Using the models, we identify quantitative characteristics obtainable from experimental data, and show that these characteristics can serve as useful quantitative measures of cyber resilience. I. INTRODUCTION Resilience continues to gain attention as a key property of cyber and cyber-physical systems, for the purposes of cyber defense. Although definitions vary, it is generally agreed that cyber resilience refers to the ability of a system to resist and recover from a cyber compromise that degrades the performance of the system [1], [2], [3]. One way to conceptualize resilience is as the ability of a system to absorb stress elastically and return to the original functionality once the stress is removed or nullified [4]. Resilience should not be conflated with risk or security [5]. To make the discussion more concrete, consider the example of a truck which attempts to complete its goal of delivering heavy cargo. The cyber adversary’s malware successfully gains access to the Controller Area Network (CAN bus) of the truck [6]. Then, the malware executes cyber attacks by sending a combination of messages intended to degrade the truck’s performance and diminish its ability to complete its goal. We assume that the malware is at least partly successful, and the truck indeed begins to experience a degradation of its goal-relevant performance. At this point, we expect the truck’s resilience-relevant elements to resist the degradation and then to recover its performance to a satisfactory level, within an acceptably short time period. These “resilience-relevant elements” might be of several kinds. First, because the truck is a cyber-physical system, certain physical characteristics of the truck’s mechanisms will provide a degree of resilience. For example, the cooling system of an internal combustion engine will exhibit a significant resistance to overheating even if the malware succeeds in misrepresenting the temperature sensors data, especially with a passive cooling system and with mechanical thermostats that do not depend on electronic manipulation of sensor data [7]. Second, appropriate defensive software residing on the truck continually monitors and analyzes the information passing through the CAN bus [8]. When the situation appears suspicious, it may take actions such as blocking or correcting potentially malicious messages. Third, it is possible that a remote monitoring center, staffed with experienced human cyber defenders, will detect a cyber compromise and will provide corrective actions remotely [9]. For the purposes of this paper, we assume that the remote monitoring and resilience via external intervention is impossible [10]. This may be the case if the truck cannot use radio communications due to environmental constraints (e.g., operating in a This work was partially funded by Cyber Technologies, Deputy CTO for Critical Technologies/Applied Technology, Office of the Under Secretary of Defense Research and Engineering. 4Research was sponsored by the Army Research Laboratory and was accomplished under Cooperative Agreement Number W911NF-21-2-0284. JV was additionally supported by NSF #1850849 and #2051186. The views and conclusions contained in this document are those of the authors and should not be interpreted as representing the official policies, either expressed or implied, of the Army Research Laboratory or the U.S. Government. The U.S. Government is authorized to reproduce and distribute reprints for Government purposes notwithstanding any copyright notation herein. 1DEVCOM Army Research Laboratory 2Pennsylvania State University 3ICF International 4University of California, Irvine 1 arXiv:2303.16307v3 [cs.CR] 30 Dec 2024 remote mountainous area), or if the malware spoofs or blocks communication channels of the truck. Therefore, in this paper we assume that resilience is provided by the first two classes of resilience-relevant elements. Here, by analogy with malware, we call these “bonware” – a combination of physical and cyber features of the truck that serve to resist and recover from a cyber compromise. A key challenge in the field of cyber resilience is quantifying or measuring resilience. Indeed, no engineering discipline achieved significant maturity without being able to measure the properties of phenomena relevant to the discipline [9]. Developers of systems like a truck must be able to quantify the resilience of the truck under development in order to know whether the features they introduce in the truck improve its cyber resilience, or make it worse. Similarly, buyers of the truck need to know how to specify quantitatively the resilience of the truck, and how to test resilience quantitatively in order to determine whether the product meets their specifications. In this paper, we report results of a project called Quantitative Measurement of Cyber Resilience (QMoCR) in which our research team seeks to identify quantitative characteristics of systems’ responses to cyber compromises that can be derived from repeatable, systematic experiments. Briefly, we have constructed a test-bed in which a surrogate truck is subjected to controlled cyber attacks produced by malware. The truck is equipped with an autonomous cyber-defense system [8], [10] and also has some inherent physical resilience features. This ensemble of cyber-physical features (i.e., bonware) strives to resist and recover from the performance degradation caused by the malware’s attack. The test bed is instrumented in such a way that we can measure observable manifestations of this contest between malware and bonware, especially the performance parameters of the truck, even if the performance of the malware and bonware are not well known (e.g., if the system uses components not designed by the system designer). The remainder of the paper is organized as follows. In Section II, we briefly describe prior work related to quantification of cyber resilience. In Sections III and IV, we propose a class of parsimonious models in which effects of both malware and bonware are approximated as deterministic, continuous differentiable variables, and we explore several variations of such models. In addition, we discuss how parameters of such models can be obtained from experimental data and whether these parameters might be considered quantitative characteristics (i.e., measurements) of the bonware’s cyber resilience. In Section V, we introduce the experimental approach we used to obtain resiliency-relevant data; we describe various components of the overall experimental apparatus and the process of performing experiments. Then, in Section VI, we illustrate the experimentation and analysis using a case study, discuss the experimental results. Finally, in Section VII, we offer conclusions. II. PRIOR WORK A growing body of literature explores quantification of resilience in general and cyber resilience in particular. Resilience has been studied for decades in multiple domains and classes of systems and organisms: in sociology, biology, medicine, forestry, urban planning, economics, as well as technical artifacts. That research looked at definitions of resilience and it’s differentiation from other properties of systems, manifestations of resilience, factors that enhance or degrade resilience, and means to characterize resilence, e.g., [11], [12], [13], [14], [15]. Research interest in the field cyber resilience emerged more recently. Multiple works explored the definitions of cyber resilience, relations between cyber resilience and cyber security, proposals for improving cyber resilience (or cyber security with which it is often conflated), and methods to characterize, assess and quantify cyber resilience. Examples include[16], [17], [18], [19], [20], [21] It is specifically the last topic –quantification of cyber resilience – that is the scope of our paper, and therefore we now found on the body of prior work on quantification of cyber resilience. Approximately, the literature can be divided into two categories: (1) qualitative assessments of a system (actually existing or its design) by subject matter experts (SMEs) [22], [23] and (2) quantitative measurements based on empirical or experimental observations of how a system (or its high-fidelity model) responds to a cyber compromise [3], [24]. In the first category, a well-cited example is the approach called the cyber-resilience matrix [25]. In this approach, a system is considered as spanning four domains: (1) physical (i.e., the physical resources of the system, and the design, capabilities, features and characteristics of those resources); (2) informational (i.e., the system’s availability, storage, and use of information); (3) cognitive (i.e., the ways in which informational and physical resources are used to comprehend the situation and make pertinent decisions); and (4) social (i.e., structure, relations, and communications of social nature within and around the system). For each of these domains of the system, SMEs are asked to assess, and to express in metrics, the extent to which the system exhibits the ability to (1) plan and prepare for an adverse cyber incident; (2) absorb the impact of the adverse cyber incident; (3) recover from the effects of the adverse cyber incident; and (4) adapt to the ramifications of the adverse cyber incident. In this way, the approach defines a 4-by-4 matrix that serves as a framework for structured assessments by SMEs. Another example within the same category (i.e., qualitative assessments of a system by SMEs) is a recent, elaborate approach proposed by [26]. The approach is called Framework for Operational Resilience in Engineering and System Test (FOREST), and a key methodology within FOREST is called Testable Resilience Efficacy Elements (TREE). For a given system or subsystem, the methodology requires SMEs to assess, among others, how well the resilience solution is able to (1) sense or discover a successful cyber-attack; (2) identify the part of the system that has been successfully attacked; (3) reconfigure the system in order to mitigate and contain the consequences of the attack. Assessment may include tests of the system, although the methodology does not prescribe the tests. 2 Undoubtedly, such methodologies can be valuable in finding opportunities in improvements of cyber-resilience in a system that is either at the design stage or is already constructed. Still, these are essentially qualitative assessments, not quantitative measurements derived from an experiment. As such, these are not the lines of inquiry we pursue in this paper. In the second category (i.e., quantitative measurements based on empirical or experimental observations of how a system, or its high-fidelity model, responds to a cyber compromise), most approaches tend to revolve around a common idea we call here the area under the curve (AUC) method [27], [28]. The general idea is depicted in Fig. 1. The functionality is plotted over time t. At time t = t0, a cyber attack begins to degrade the functionality of the system, as compared to the normal level of functionality. The system resists the effects of the cyber attack, and eventually stabilizes the functionality at a reduced level. At t = t1, the system resilience mechanisms begin to overcome the effect of the attack and eventually recover the functionality to a normal level. The area under the curve (AUC) reflects the degree of resilience – the closer AUC is to its normal level, the higher is the system’s resilience. t = 0 t0 t1 tend = T Time t F(t) Cyber-attack degrades functionality Functionality recovers Area under the curve Normal level of functionality System Functionality Fig. 1: The functionality F(t) of a system is plotted in yellow and normal functionality is plotted in light blue. In this example, there is a cyber attack at time t0 which degrades functionality, and the system’s resilience allows the functionality to begin recovering at time t1. The area under the curve (AUC) is defined as the normalized area under the curve from time t0 to time T, the end time of measured system performance. In an experiment/test, a system engages in the performance of a representative goal, and then is subjected to an ensemble or sequence of representative cyber attacks. A goal-relevant quantitative functionality of the system is observed and recorded. The resulting average functionality, divided by normal functionality, can be used as a measure of resilience. In this paper, we build on and extend the idea of AUC, and aim to evaluate its feasibility and efficacy for quantifying resilience. In particular, we are not aware of prior work where the idea of AUC has been experimentally investigated in the context of cyber resilience. However, AUC-based resilience measures are inherently cumulative, aggregate measures, and do not tell us much about the underlying processes. For example, is it possible to quantify the resilience effectiveness of the bonware of the given system? Similarly, is it possible to quantify the effectiveness of malware? In addition, is it possible to gain insights into how these values of effectiveness vary over time during an incident? We will offer steps toward answering such questions in addition to evaluating the AUC as a resilience measure. With respect to experimental approaches, much of the early experimental work on the cybersecurity of automobiles used actual vehicles [29], [30], [31], [32], [33]. This approach offers high fidelity but also high costs, especially when multiple experimental runs are required. Other approaches avoided the expensive use of actual vehicles by connecting multiple electronic control units (ECUs) together on a Controller Area Network (CAN) bus independent of a vehicle [34], [35], [36]. This is an inexpensive method to test malware and bonware in a vehicular network; however, it cannot characterize impacts on the vehicle’s performance parameters. Yet another experimental approach is to use a Digital Twin: a system to reproduce real-world events in a digital environment, e.g., [37]. A virtualized vehicle with realistic virtual performance would provide high fidelity at low cost in terms of time to test and measure cyber resilience. However, constructing a virtual vehicle can be prohibitively expensive, too. In our research, we strove to find an effective compromise that minimizes disadvantages on the above approaches. We use real, physical electronic and computing elements of a vehicle (thereby improving the fidelity of cyber effects) and integrate it with virtual model (a digital twin) of the remainder of the vehicle. This physical-digital twin of a vehicle combines fidelity and relative affordability. To summarize, our work differs from prior work in the following aspects. Unlike much prior work, our focus is on quantitative, not qualitative characterization of resilience. Unlike the prior work that aims at quantitative characterization, we propose specific parsimonious mathematical models to aid in quantifying systems’ resilience to cyber attacks. Furthermore, building on the models, we propose and implement an experimental method and test bed for obtaining resilience-relevant data of 3 an example system in repeatable, systematic experiments. Unlike prior work, we identify quantitative characteristics obtainable from experimental data, and show that these characteristics can serve as useful quantitative measures of cyber resilience. With respect to practical contributions to the field, we have proposed a new practical method for measuring cyber resilience of a system under test. The details of the method go beyond the scope of this paper, but are described in a separate publication [38]. In what follows, we will first describe our formal treatment of cyber resilience, with a focus on quantification of key concepts. We will then describe how changes in performance over time may be expressed through mathematical models, which will then be used to estimate other features of the cyber-physical system, such as the effectiveness of its bonware. III. QUANTITATIVE MEASUREMENT OF CYBER RESILIENCE In this section, we will first formalize our thinking about cyber resilience, and then use our new formalism to define the AUC-based measures of resilience as well as the mathematical models that we will apply to our experimental runs. Table I lists variables used in the discussion along with their defintions. TABLE I: A Short Table of Terms and Definitions Term Definition A Accomplishment: Cummulative sum of functionality over time Aattack Accomplishment achieved during the course of an attack Abaseline Baseline accomplishment achieved when no attack is present AUC Area under the curve: A normalized measure of accomplishment B Bonware effectiveness F Functionality of system being studied Fattack Functionality while system is under attack Fbaseline Baseline functionality dFB dt Time rate of change of functionality due to bonware present in the system dFM dt Time rate of change of functionality due to malware attacking the system FN Nominal functionality M Malware effectiveness Q The sum of malware effectiveness and bonware effectiveness R A measure of resilience computed as the ratio of accomplishment under attack to baseline accomplishment A. Formal Definition of Concepts We define goal-relevant resilience as the ability of a system to accomplish its goal—or at least maximize the degree of accomplishment of its goal—in spite of effects of a cyber attack, as a run unfolds over time. To this end, we postulate that for a given run, there exists a function A(t) that represents accomplishment and that is cumulative from the run start time t0 up until the present time t. We define functionality, F(t), to be the time derivative of goal accomplishment. Thus, F(t) = dA dt , A(t) = Z t t0 F(τ) dτ. (1) Note that, in practice, functionality may vary with time, even when the system performs normally and is not experiencing the effects of a cyber attack. To be able to account for this, we will often distinguish between performance under baseline conditions, Fbaseline(t) and performance during an attack scenario, Fattack(t). We will require Fbaseline(t) > 0 everywhere where it is defined. The purpose of this definition is to take a step towards a more formal treatment of the term ‘functionality’, unlike in prior work where the term is introduced informally and is merely illustrated by domain-specific examples. Also note that we use the expression “goal-relevant" resilience in order to emphasize that the same system may be assigned different goals (e.g., a truck might be sent to deliver maximum load at reduced speed or alternatively to deliver a modest load in shortest time), and resilience does depend on a goal the system is pursuing. Needless to say, cyber resilience of a system does depend on cyber attacks imposed on the system. That is, a system may have excellent resilience against one attack, and poor resilience against another attack. Even with the same attack and the same goal pursued under different conditions, the system may exhibit different level of resilience (see Fig. 7 where cyber resilience of a truck depends on roads and terrain). Therefore, for practical applications, cyber resilience should be measured in the context of defined ensembles of attacks and scenarios of use (see [38] for discussion of practical formulation of such ensembles). Furthermore, a goal may imply multiple objectives as we discuss in Subsection 3.2. At the same time, the general approach and methodology for measuring resilience does not appear to require changes for applications to different types of systems and scenarios. 4 B. Resilience Based on Area Under the Curve As mentioned in Section II, our research is based on – and aims to extend and experimentally investigate – the idea of area under the curve (AUC) that has been frequently discussed in prior work. Note that when considered over the entire period of a system performance (from t0 to T), AUC is precisely AUC = 1 T −t0 Z T t0 F(τ) dτ. Here we expand on this concept to make a measure of resilience that calculates the accomplishment—that is, the area under the functionality curve—in a cyber attack scenario relative to the accomplishment in a baseline scenario: R = R T t0 Fattack(τ) dτ R T t0 Fbaseline(τ) dτ = Aattack(T) Abaseline(T). (2) As a measure of resilience, R has a number of advantages. By contrasting behavior in an attack scenario to behavior in a comparable baseline scenario, it is able to account for idiosyncratic differences between vehicles, terrain, or any other features we hold constant between the two scenarios. To illustrate, consider Figs. 6 and 7 later in the article, where we use the fuel efficiency of trucks as the performance measure influenced by cyber attacks. Imagine two trucks – one twice bigger and heavier than another, but otherwise with exactly the same design of cyber-relevant systems. The lighter truck would have approximately twice greater fuel efficiency (in km per liter) and the impact of a cyber attack on its AUC would be twice greater. This might imply that the cyber resilience of the lighter truck is twice worse, which is incorrect. On the other hand, the dimensionless R would be roughly the same for both trucks, as it should be. R can be interpreted as the fraction of normal functionality maintained during a cyber attack. If it is close to 1.0, then the effect of the attack was small; if it is 0.0, then functionality was completely disrupted. However, it is important to note that R is closely related to AUC, as it reflects the ratio of AUC occurring in presence of a cyber attack to the AUC without an attack. In other words, R is a normalized and dimensionless variation of the AUC measure. IV. MATHEMATICAL MODELING Here we introduce a class of parsimonious models in which effects of both malware and bonware on goal accomplishments are approximated as deterministic, continuous differentiable variables. Our models describe the behavior of a system’s functionality over the course of a run during which it is being attacked by malware and defended by bonware. To simplify our modeling, we assume the normal functionality to be constant in time, FN(t) = FN = 1. Normal functionality here refers to the value of a system characteristic exhibited under baseline conditions without the impact of a cyber attack. For example, in Fig. 6, the cyan line describes fuel efficiency of a truck measured in a baseline run without a cyber attack. Naturally, it depends on time-varying conditions (e.g., the terrain profile, turning and acceleration of the truck) and is not constant, in general.When we apply our mathematical models to our experimental results in Section VI, we will ensure this assumption by explicitly dividing the functionality during a cyber attack scenario, Fattack(t), by the functionality during a baseline scenario, Fbaseline(t), to obtain F(t). Without loss of generality, for ease of notation, in Subsections 4.1, 4.3, 4.5, and 4.7 we assume t0 = 0. In the first set of models, we assume that there is an observable, sufficiently smooth function representing goal accom- plishment, and we define functionality to be its time derivative. Then, we motivate a parsimonious model for the differential equation governing functionality, give the general solution, and discuss a few specific cases. A. Linear Differential Equation and General Solution In what follows we develop a differential equation to model system functionality and how it is influenced by malware and bonware. Imposing the least restrictions on functionality, we require functionality to be continuosly differentiable (F ∈C1), and thus, accomplishment, obtained by integrating functionality over an interval of time, must be twice continuously differentiable (A ∈C2). Although this does not allow jumps or corners or the like in accomplishment, the restriction to twice continuously differentiable functions is reasonable for a continuous differential equation model. We do not anticipate that this assumption will exclude any practical systems, because even in systems where, e.g., functionality might have near instantenous changes due to a cyber attack, it can be approximated by a continuously differentiable function sufficiently closely for the purposes of our research. Indeed, we did not observe any difficulties of such nature in our experimental data. When considering more sophisticated models, such as stochastic differential equations with jump processes, we may relax this assumption. Both malware effectiveness and bonware effectiveness are continuous functions of time: M, B ∈C0. We further assume that malware degrades the system’s functionality while bonware aims to increase functionality over time. Thus, both M and B are nonnegative. Later, in Subsections 4.3 and 4.5, we will model M and B as piecewise continous functions and allow them to jump at a finite set of points in time. Although it is possible that a malware inadvertently increases system’s functionality (perhaps due to an error in the malware’s design) we expect such cases to be very unusual and do not consider them in this paper. The same applies to an errant bonware that happens to decrease the system’s functionality. We model the effectivenesses 5 of malware and bonware independently, and relate them by adding their effects to give us the overall change in functionality due to these two competing quantities. We define the effectiveness of malware, M, to be a function that, when multiplied by the functionality at the present time, causes the time rate of change in functionality to decrease by that amount: dFM(t) dt = −M(t)F(t). (3) Similarly, we define the effectiveness of bonware B via the following equation. dFB(t) dt = B(t)(FN(t) −F(t)). (4) With this definition, B serves to restore the functionality by causing the time rate of change in functionality to increase by the product of B with the difference between normal and current functionality. The effectiveness on functionality is the sum of the effectivenesses of malware and bonware: dF(t) dt = dFM(t) dt + dFB(t) dt . Thus dF dt + Q(t)F(t) = FNB(t), where Q(t) = M(t) + B(t). (5) Since we expect bonware to help (or at least not harm) and malware to not help, we assume B(t) ≥0 and M(t) ≥0. We also assume normal functionality is positive, FN > 0, i.e., that the system was designed in its normal operation to increase the accomplishment of the system’s intended goals over time (note Eq. (1)) and functionality is always positive and less than or equal to normal functionality, 0 < F(t) ≤FN. Although it might be possible that a cyber attack subverts a system to such an extent that its functionally becomes negative, i.e., it works against its intended goals, we exclude such cases from the scope of this paper. Under the assumptions, the first order linear differential equation Eq. (5) has the following solution: F(t) = e− R t 0 Q(p) dp  F(0) + FN Z t 0 e R τ 0 Q(p) dpB(τ) dτ  . In Appendix A, we will discuss the stability of Eq. (5) and show that it is stable due to the non-negativity of both M(t) and B(t). estWe have not yet explored the possibility of an adversary intruducing multiple switchings of M. It was suggested to us, by our reviewers that this could cause an instability. Proposition 2 in [39] may prove helpful to those wishing to replicate results here and/or study more sophisticated attacks. To help us understand how the model works, in Sections 4.2—4.5 we find explicit solutions for a number of examples. B. Constant model Assuming M, B, and Q are constant, we have dF dt + QF(t) = FNB. (6) 1) No bonware: If B = 0, then Eq. (6) reduces to dF dt + MF(t) = 0 and F(t) = F(0)e−Mt. If also M = 0 (no bonware and no malware), then dF dt = 0 and F(t) = F(0). 2) Bonware: With bonware present, the solution is F(t) =  F(0) −FNB Q  e−Qt + FNB Q . (7) If F(0) > FNB/Q, then F(t), initially at F(0) at time t = 0, will decrease to FNB/Q (see Fig. 2). If F(0) = FNB/Q, then the function F(t) = F(0) will be constant. If F(0) < FNB/Q, the function will start at F = F(0) and increase to FNB/Q. The plots for M > 0 in Fig. 2 show that even in the presence of bonware, malware has an impact on the system. The steady-state of the system is obtained either by setting dF dt = 0 in Eq. (6) or letting t →∞: F∞= lim t→∞F(t) = FN B M + B (8) so that the antidote to malware is to overwhelm it with bonware. The exponent, −Qt = (−M −B)t in the solution given by Eq. (7) indicates that increasing the effectiveness of either malware or bonware will cause the system to more quickly approach steady-state. At steady-state, FN −F∞ FN = M M + B . (9) Eq. (9) gives us further insight into the trade-off between effectivenesses of both malware and bonware. The relative decrease of the function from normal functionality is equal to the ratio of malware effectiveness to the sum of malware and bonware effectivenesses. 6 0 1 2 3 4 5 6 7 Time t 0.0 0.2 0.4 0.6 0.8 1.0 F(t)/FN M = 1.0, B = 0.0 M = 1.0, B = 0.5 M = 1.0, B = 1.0 M = 0.5, B = 1.0 M = 0.0, B = 1.0 Functionality: F(t)/FN Fig. 2: Normalized functionality, F(t)/FN, is shown for various constant values of M (malware attacking) and B (bonware defending) and with initial condition F(0) = FN. The functionality over time depends on the relative strengths of bonware and malware. With the system initially at normal functionality and malware effectiveness nonzero, functionality exhibits exponential decay. C. Piecewise constant model If either malware’s or bonware’s effectiveness diminishes at some point in the incident, the model may switch from one set of constants defining malware and bonware to another set of constants. The differential equation (Eq. (5)) may now be expressed as dF dt = N−1 X j=0 [(FN −F(t))Bj −F(t)Mj] Πtjtj+1(t), (10) where the vectors M = (M0, M1, . . . , MN−1) and B = (B0, B1, . . . , BN−1) contain the malware effectivenesses and bonware effectivenesses within time windows whose end points are defined by {t0, t1, . . . , tN} and where Πab(t) = ( 1, a ≤t < b, 0, otherwise. The assumption F ∈C1 holds within each time interval. Functionality F(t) is continuous, but we no longer assume F(t) is differentiable at the time window endpoints {t0, t1, . . . , tN}. The solution will be a function which, in each time interval, is the solution found in Eq. (7): F(t) =  F(tj) −FNBj Qj  e−Qj(t−tj) + FNBj Qj , (tj ≤t < tj+1), (j = 0, . . . , N −1) where Qj = Mj + Bj. The model is general enough so that we have the ability to handle instantiations where malware’s and bonware’s effectiveness are out of sync. For example, If t1 < t2 < t3 < t4 and malware’s effectiveness is nonzero in time window (t1, t3) and bonware’s effectiveness is nonzero in time window (t2, t4), then we have M =      M1(t), t1 ≤t < t2 M2(t), t2 ≤t < t3 0, t3 ≤t < t4. and B =      0, t1 ≤t < t2 B2(t), t2 ≤t < t3 B3(t), t3 ≤t < t4. D. Linear time varying (LTV) model The effectivenesses of malware and bonware may also be linear functions of t, so that M(t) = ν −µt, B(t) = α −β t, and Q(t) = λ −ωt, where λ = α + ν and ω = β + µ. Under this linear time varying model, Eq. (5) becomes dF dt + (λ −ωt)F(t) = FN(α −βt). (11) The solution is derived in Appendix B and is expressed in terms of the error function erf(z) = 2 √π R z 0 e−τ 2 dτ: F(t) FN = 1 Ω(t) F(0) FN −β ω (1 −Ω(t)) + (αω −βλ) p π 2 eΛ2 ω3/2  erf (Λ) + erf  ωt √ 2ω −Λ ) (12) where Ω(t) = eλt−1 2 ωt2, and Λ = λ/ √ 2ω. 7 The LTV model is helpful when the effectiveness of malware M and of the bonware B are dependent. The dependency may or may not be strong. In our experiments, we did not notice such a dependency, but in other systems it might be too strong to ignore it. Although the LTV model does not capture such a dependency explicitly, it may help to reflect the results of the dependency. Future research should address the ways to model the dependency and to incorporate it into our approach. E. Piecewise linear time varying (PLTV) model Both malware and bonware effectivenesses may initially be linear, but if the situation changes and a different linear model holds after a time, the model should be able to account for it. In particular, if malware effectiveness is decreasing over time, at some point we will reach M = 0 and the model switches to a new linear model. Eq. (11) can be written dF dt = N−1 X j=0 [(λj −ωjt)F(t) −FN(αj −βjt)] Πtjtj+1(t). The solution follows from Eq. (12): F(t) FN = 1 Ωj(t) F(tj) FN −βj ωj (1 −Ωj(t)) + (αjωj −βjλj) p π 2 eΛ2 j ω3/2 j  erf (Λj) + erf ωj(t −tj) √2ωj −Λj ) , (tj ≤t < tj+1), (j = 0, . . . , N−1) where Ωj(t) = eλj(t−tj)−1 2 ωj(t−tj)2 and Λj = λj/p 2ωj. Example realizations of the piecewise linear time varying models are shown in Fig. 3. 0.0 2.5 5.0 7.5 10.0 12.5 15.0 17.5 20.0 Time t 0.4 0.5 0.6 0.7 0.8 0.9 1.0 F(t)/FN Functionality: Piecewise Linear Time Varying Model b0 = 0.00 b0 = 0.20 b0 = 0.40 b0 = 0.60 b0 = 0.80 Fig. 3: Normalized functionality, F(t)/FN, is shown for piecewise linear time varying models and initial condition F(0) = FN. Both malware and bonware effectivenesses are initially linear functions of time: M = max(0.5 −0.1t, 0), B = b0 + 0.04t. When malware effectiveness reaches M = 0, bonware effectiveness continues to increase. V. EXPERIMENTAL TESTBED AND METHOD A key role of the mathematical models presented above is to help analyze results of actual experimental measurements of resilience. In this section, we introduce the experimental test bed and experimental process we use to observe and characterize cyber resilience of a truck [40]. In a typical resilience-measuring experiment, the following occurs, conceptually: (1) The truck is assigned a goal (delivering a cargo to a destination, along a specified route). The truck begins to accomplish the goal. The driver controls the truck aiming to maximize probability of the goal’s success. (2) At some point along the route, an adversarial cyber effect is activated and begins to degrade goal-relevant performance of the truck. (3) Physical and cyber elements within the truck begin to resist the impact of the cyber effect. After some time, these elements (i.e., bonware, collectively) may succeed in recovering some or all of the degraded performance. (4) The data collection and logging system obtains and records the performance parameters of the truck over time, from the beginning of the run until its end (successful or otherwise). The data are later analyzed using the models presented earlier. These processes and functions are implemented in several components of the test bed, which include automotive hardware and simulation software: the Toyota Portable Automotive Security Testbed with Adaptability (PASTA) by Toyota Motor Corporation, the Unity game development platform, Active Defense Framework (ADF) developed at the DEVCOM Army Research Laboratory, and the OpenTAP test automation framework by Keysight Technologies. These components and their roles are described in Subsections 5.1—5.4 below. In terms of interactions between the components, Unity generates messages via the Message Queue Telemetry Transport (MQTT) publish-subscribe network protocol. ADF ingests these messages and translates them to Controller Area Network (CAN) format, which are then injected onto the appropriate CAN bus within PASTA. Fig. 4 illustrates the flow of data between components. 8 Fig. 4: A high-level overview of the data flow between components. Portions are derived from [41]. Unity handles the interactions between the simulated trucks and the terrain, provides driver inputs to maintain pathing and speed over a pre- determined course across the terrain, and simulates many aspects of the vehicle to provide high-fidelity vehicle performance. PASTA is hardware-in-the-loop that generates actual CAN bus traffic in response to the inputs from Unity, and provides three vehicle ECUs (powertrain, body, and chassis). ADF allows for communication translation between Unity and PASTA, provides simulated ECU plugins for additional sensor information not present in PASTA, and implements simulated cyber attacks and defenses. A. PASTA PASTA is a cyber-physical product by Toyota, intended to develop and evaluate new vehicle security technology and approaches on realistic “white-box” electronic control units (ECUs) [41]. There are three vehicle ECUs provided within the product, each with its own CAN bus: powertrain, body, and chassis. These three ECUs are responsible for their respective group of messages, each generating and responding to traffic on their bus. A fourth ECU, the central gateway (CGW), acts as a junction between the three previously mentioned buses. Based on the message and source bus, the CGW ferries messages to their appropriate destination bus. The firmware for all ECUs is open-source, and is accompanied by an integrated development environment (IDE). PASTA includes simulation boards which calculate how the current CAN messages on the buses would physically influence a commercial sedan. These boards then update the vehicle ECUs with appropriate values. For example, when acceleration pedal operation is inputted, the chassis ECU sends a message with the indicated value. The simulation boards observe this message and calculate the physical effects that would result from the input. The results are used to update the values reported by the powertrain ECU, which it outputs onto its bus. In this instance, the powertrain ECU would send messages indicating the new engine throttle position, revolutions per minute (RPM), and speed. Unfortunately, we found the simulation boards rather constraining, for our purposes. We cannot alter, for instance, the parameters involving the engine (e.g., torque and horsepower), the weight of the vehicle, or the terrain that the boards are assuming is being traversed. To overcome these constraints, we integrated a simulation engine (Unity, see below) that would allow for user-defined vehicle details as well as custom terrain. In this configuration, PASTA becomes hardware-in-the-loop for the simulation engine. Cyber attacks or defenses that affect the ECUs present in PASTA will also affect the performance of the truck within the simulation. B. Unity Unity is a widely used game development platform [42]. In particular, Unity provides built-in assets and classes regarding vehicle physics, which we leverage to model interactions between our simulated truck and custom terrain. 1) Simulated Trucks: We implemented three types of truck within Unity – light, medium, and heavy. They are designed to interface with data inputs from the white-box ECUs within PASTA. In an experiment, the current chosen truck produces inputs in response to the simulated terrain. These inputs are sent to the corresponding ECUs within PASTA. We then gather responses to these inputs from the ECUs and send them back to the truck, which it uses to calculate parameters like torque and fuel consumption. For example, assume the truck reports that the accelerator is set to 50%. This message is injected into 9 PASTA as if the chassis ECU had generated it. The powertrain ECU responds to the message with the corresponding amount of engine throttle. A message with the engine throttle is sent back to Unity, which is then applied to engine power calculations. With this flow, any cyber attacks impacting the ECUs within PASTA will affect the truck. An automated driver is responsible for generating steering, acceleration, and braking inputs as the truck traverses the terrain. Steering is guided using a waypoint system. Both acceleration and braking inputs are calculated via a proportional-integral- derivative (PID) controller guided by a target speed. The controller responds to changes in the terrain or truck performance, and maintains the target speed while preventing oscillation. Optional target speed variability simulates driver attention drift, which may be used to generate multiple unique realizations of the simulation under otherwise identical conditions. Engine performance is calculated through the use of torque, horsepower, and brake-specific fuel consumption (BSFC) curves. Engine RPM is derived using the speed, wheel circumference, and effective gear ratio. Using this RPM value, the curves are evaluated to discern the corresponding torque, horsepower, and BSFC value. Torque is multiplied by the throttle and the current effective gear ratio to obtain the total amount of torque that can be applied to the wheels. Since our trucks are all-wheel drive (AWD), each wheel receives the total amount of torque divided by the number of wheels on the truck. Horsepower and the BSFC value are used in conjunction to calculate the amount of fuel that has been used per physics update. The truck is capable of providing sensor information that is either not present in PASTA or needs its functionality altered for our purposes. Currently, this applies to the engine coolant temperature, attitude sensor, and a set of backup engine ECUs. Engine temperature is present in PASTA, but is aligned to the temperature characteristics of a static commercial sedan. Within Unity, we implemented a temperature model that can be controlled by an external fan controller ECU. The fan controller monitors the coolant temperature reported by the truck and dictates the operation of a simulated fan on the truck. The fan itself takes significant power to operate, which results in a drop in the available torque that can be applied to the wheels. 2) Terrain: The truck within Unity traverses a custom terrain map that is roughly 81.8 km by 100 km with altitudes up to 910 m. We crafted a course approximately 151 km in length across the map that encompasses multiple terrain types: flat main road, flat off-road, hilly, prolonged ascent, and prolonged descent. On a flat main road, the target speed is 60 km per hour. Otherwise, the target speed is 40 km per hour. C. Active Defense Framework ADF is a government-developed framework for prototyping active cyber-defense techniques. ADF currently supports Internet Protocol (IP) networks and vehicle control networks, namely the CAN bus and Society of Automotive Engineers (SAE) J1708 bus. The framework acts as an intermediary for network traffic, as depicted in Fig. 4, allowing it to control network message flow, as well as inspect, modify, drop, or generate network messages. In our experimental test bed, ADF enables communication between PASTA and Unity by translating CAN messages to and from MQTT, a standard publish-subscribe IP-based messaging protocol. ADF plugins are also used to provide simulated ECU hardware, and to implement cyber attack and defense methods on the CAN bus via ADF’s ability to monitor, modify, inject, or drop CAN traffic. 1) Unity-to-PASTA Message Translation: ADF and Unity run on a standalone laptop and are connected to PASTA via two universal serial bus (USB) CAN over Serial (SLCAN) interface modules. One module is connected to the powertrain CAN bus, and the other module is connected to the chassis CAN bus. The PASTA CGW is disconnected from the CAN buses for our experiments, and the body CAN bus and body ECU are not used. ADF is configured to serve as a CGW between Unity and PASTA. Since Unity does not natively communicate with CAN interfaces, ADF translates CAN messages in real-time to MQTT messages and back. Unlike the PASTA CGW, ADF does not relay messages between the powertrain and chassis CAN buses themselves. ADF relays powertrain CAN messages between Unity and PASTA, and sends parameters from Unity to the chassis CAN bus for display on the PASTA instrument cluster. All communication channels are two-way. 2) Virtual ECUs within ADF: For some cyber attacks, a virtual ECU is needed. For example, as mentioned before, the PASTA platform does not simulate a controllable cooling fan or provide fan controller ECU functionality. Therefore, we simulate a fan controller ECU using an ADF plugin. The fan controller utilizes hysteresis control. When the engine coolant temperature is above the hysteresis band for normal operation, the controller engages the engine cooling fan. When the temperature is below, the controller disengages the fan. For the purposes of our experiments, the fan controller ECU plugin can simulate an attack on its own firmware, stop the attack, or reset/“re-flash” itself (i.e., replace the ECU firmware). During a reset, the fan controller is offline for a period of time. Use of ADF enables creation of other simulated ECUs and corresponding cyber attacks. 3) Performing Cyber Attacks via ADF: A class of attacks on a vehicle bus involves injecting messages. Messages are broadcast on a CAN bus, so one message injected at any point on the bus will reach all ECUs on the bus. While injection attacks cannot block or modify normal CAN bus traffic, they can impact vehicle performance if injected messages cause undesired vehicle behavior. If an attacker can physically sever the CAN bus wiring at a strategic point and place additional hardware there, it is possible to block or modify the normal bus traffic. Cyber attacks that block or modify messages can prevent ECUs from controlling the vehicle or falsify vehicle data. As a man-in-the-middle between PASTA and Unity, ADF can execute any of these bus-level attack types. Cyber attacks on ECU firmware, by embedding malware, are also feasible. We have simulated the effects of embedded malware in three instances: on the fan controller, the suspension controller, and the main engine ECU. Malware on the fan 10 controller simulates a “stuck fan” attack in which malware has modified the fan control ECU to not disengage the fan once engaged, even when the coolant temperature has dropped below the minimum operational temperature; the suspension controller attack creates the appareance that the truck is abnormally tilted, forcing the truck into a safe “limp home” mode that reduces the amount of available gears; the main engine ECU attack causes erratic performance behavior. 4) Performing Cyber Defensive Actions via ADF: Defending against message injection, blocking, and modification at the bus-level requires detecting and filtering injected messages before they reach the ECU. The CAN bus can be split at potential access points and hardware placed in-line, hardware can be placed between the CAN bus and critical ECUs, or defenses can be integrated into the ECUs themselves. Examples of these defenses implemented previously using ADF cryptographic watermarking and modeling observable vehicle states to compare current parameters to the model’s prediction. Cyber attacks on ECUs themselves must be approached differently. If an ECU is compromised, measures need be taken to restore proper ECU function. Many ECUs can be re-flashed while the vehicle is operational. The ECU may or may not be functional for some duration while being reset or re-flashed, and the impact this will have on vehicle performance depends on the function of the ECU. For the ECUs simulated by ADF plugins, the behavior is to make the ECU unresponsive for a set duration, after which normal ECU operation is restored. Note, for ECUs like the main engine ECU, this is not possible because the vehicle will become inoperable in its absence. To address this, a manually-crafted ECU backup is used while the main ECU is re-flashed. To mitigate the chance and effect of a potential supply chain attack, the backup ECU is not a complete copy of the true main ECU in terms hardware, software, or performance, since if it was, then the cyber attack affecting the main ECU would also affect the backup. This means that the backup ECU will not be as optimized as the main ECU, thus exhibiting worse engine performance while the backup is active. D. OpenTAP and Data Collection OpenTAP is an open-source test automation framework developed by Keysight Technologies [43]. It provides a test sequencer to promote test repeatability, a customizable plugin facility capable of integrating plugin classes implemented in C# or Python, and result listeners responsible for capturing test data for further analysis. OpenTAP is used to automate the execution of experiments and provide a GUI for testing practitioners to configure experiment steps. Data are captured from the truck. Examples of data are fuel efficiency, speed, engine torque, and acceleration pedal input; each data value comes with a timestamp of the value occurrence. E. Execution of Experiments Each individual experimental run follows the same set of steps. During setup, we establish CAN connections to PASTA, ensure the messaging infrastructure is running, and start Unity. During parameter selection, we determine the truck type, cargo weight, type of cyber attack, etc., and designate the number of runs. During execution, we run automated test scripts with the given parameters and capture the data in a desired format. Finally, we parse and preprocess the data, fit our mathematical models, and generate graphs and results. An experiment reflects execution of a single run as described in the beginning of this section. On our terrain, a typical run would take 2-3 hours to traverse in its entirety. However, we focus on shorter 15-minute runs that encompass a cyber attack at variable moments within the run and a potential recovery. Note that it may take the truck several minutes to recover from the attack. We are also capable of executing faster-than-real-time when using solely simulated components, further decreasing execution time of experiment runs. VI. EXPERIMENTAL APPROACH AND DISCUSSION Using our test bed, we conducted a series of experimental runs in which a truck is subjected to a cyber attack. To form a series of experiments, within our test bed, there are multiple parameters that can be configured at the start of a run to generate varied data captures. Currently, these include: truck type, experiment duration, cyber attack start time, terrain type(s), starting location, ending location, target speed, cyber attack-defense pairings, cargo weight, and target speed variability in the form of random seeds used in the generation of “driver attention drift” as described in Subsection V-B1. These random seeds are logged so that corresponding baseline and attack run pairs of the same parameter configuration use the same random seed. For example, when examining the effect of the engine ECU attack on a light truck with medium cargo weight on a flat road, both the baseline run and the corresponding run with the attack active will use the same random seed for the target speed variability. This seed will then be be changed, and both runs re-executed to gather more corresponding baseline and attack run pairs. Here, we focus on one of these series. In this series of experiments, we considered three types of trucks with four possible cargo weights including 0, the five unique terrains described above, and three types of cyber attacks, including one “baseline” scenario with no cyber attack (see Table II). For each combination of these, we conducted 30 experimental runs and recorded the truck’s speed, fuel efficiency, and other operating parameters. The 30 runs were made unique by adding random variability to the driver’s interaction with the accelerator. 11 TABLE II: Overview of Experimental Design Independent variable Possible values 3 trucks { Light, Medium, Heavy } 5 terrains { Steady Descent, Flat Road, Flat Off- Road, Hilly, Steady Ascent } 4 cyber attack scenarios { Baseline, Fan, ECU, Suspension } 4 cargo weights { None, Light, Medium, Heavy } 30 random seeds {1 . . . 30} Considering the large scope of our experiment, we focus on examples of the types of conclusions we are able to draw in Subsections VI-C and VI-B. Namely, our cyber attacks cause decreases in performance in the expected parameters at the expected times. For example, the cyber attack on the suspension causes a reduction in fuel efficiency and speed compared to the baseline scenario. We also see that fuel efficiency decreases as cargo weight increases. A. Data Pre-processing The operating parameters were recorded at a relatively high frequency of about 50 Hz, which sometimes causes numerical instability (e.g., in calculating fuel efficiency over a 20 ms period). For this reason, we first applied a smoothing filter to the data. We chose a running median filter with a window of 72 s. This length was chosen because the engine cooling fan has a typical rhythm of turning on and off as the engine heats up with normal use. This causes the fuel efficiency to exhibit a slight sqaure-wave pattern with a period 72 s, so our chosen filter computes the median over one period of this cycle. The running median also has the advantage that it downweights extreme values that might result from numerical inaccuracy. We then took the mean of the 30 runs in each condition to obtain the relatively smooth time series seen in Fig. 5. 0.65 0.70 0.75 0.80 Fuel Eff. (km/l) Heavy Truck (0kg cargo) Hilly, Engine ECU Cyber Attack Baseline run Attack run 100 200 300 400 500 600 700 Time (s) 35.00 36.00 37.00 38.00 Speed (km/h) Baseline run Attack run 100 200 300 400 500 600 700 Time (s) 0.40 0.50 0.60 0.70 0.80 Fuel Eff. (km/l) Heavy Truck Hilly, Engine ECU Cyber Attack 0kg 3000kg 6000kg 9000kg Fig. 5: Examples of experimental data, illustrating that cyber attacks reduce performance both in fuel efficiency (top left panel) and speed (bottom left panel), and that changes in cargo weight reduce fuel efficiency in the expected manner (right panel). Top left panel: The fuel efficiency of a heavy truck, carrying no cargo, during a run on hilly terrain. The orange curve indicates the fuel efficiency in the “engine ECU attack” run, which is contrasted with the (partly occluded) cyan curve that indicates the baseline run. Bottom left panel: Recorded speed during the same run. Right panel: Fuel efficiency, now for all four cargo conditions (from top to bottom: 0, 3,000, 6,000, and 9,000kg). The three panels of Fig. 5 each show the time course of a performance parameter. The left two panels each show one curve for the baseline run (cyan) and one for an attack run (orange). The right panel shows four attack runs with different cargo weights. B. Modeling Approach Our modeling approach requires one further data processing step, which is illustrated in Fig. 6. The top panel shows a baseline and attack performance curve. The ratio of these curves (i.e., performance under attack divided by the baseline value) is shown in the bottom panel – this ratio is close to 1.0 when performance under cyber attack is similar to the baseline performance, and less than 1.0 when the cyber attack is detrimental to performance. This performance ratio is the measure of functionality that we use for our modeling. Also in the bottom panel, we show the fitted “piecewise constant” model that is described in Subsection IV-C. The red and green intervals indicate the activity periods of the malware and bonware, respectively. When 12 they are inactive, these effectiveness parameters are 0, otherwise they are M and B respectively. We can see that the model captures the drop in performance when the malware is active. To summarize and interpret our data, we applied this model to the 100 200 300 400 500 600 700 Time (s) 0.900 0.925 0.950 0.975 1.000 Fuel Eff. ratio M = 0.0019 B = 0.0222 Fuel efficiency ratio Continuous model fit Bonware active period Malware active period Fig. 6: Progression of data over time. Top panel: Fuel efficiency of a heavy truck, carrying no cargo, during a run on steadily descending terrain (orange: Engine ECU attack run; cyan: baseline run). Bottom panel: The fuel efficiency ratio (solid grey line) is the performance in the attack run divided by the performance in the baseline run. The overlaid, blue dashed line, is the fit of the continuous model. The green and red horizontal lines at the top and bottom indicate the times when the bonware and malware (resp.) are active. The model captures the rapid decline to an equilibrium state around 92% performance as well as the more gradual recovery after the cyber attack. data from each experimental condition separately. In order to automate the parameter estimation process, we implemented our piecewise constant model using a Bayesian inference engine [44], [45].1 To further facilitate the automation, we additionally allowed the model to estimate the time points where performance begins to decline (t1) and recover (t2). This implementation lets us quantify the uncertainty in parameter estimates and has the advantage of being fully automatic and easily extendable for future projects. As illustrated in Fig. 6, our mathematical model and the experimental data exhibit a similar pattern and the model produces a good fit. Moreover, the estimates of parameters M and B attain values that reflect the temporal behaviors of experimental data (e.g., high B is associated with rapid recovery, and the ratio of B/(M + B) approximates the performance equilibrium when the cyber attack is active). The modeling approach allows us to summarize complex time series with two interpretable parameters: the malware effectiveness M and the bonware effectiveness B. This facilitates comparison of the cyber resilience of our trucks under various conditions. For example, Fig. 7 shows the pattern of results of an engine ECU cyber attack on a heavy truck (note: higher B means more effective bonware and higher M means more effective malware). At a glance at the top panel, we can determine that the truck resists the cyber attack better when it is not hauling cargo (blue markers are always higher), and especially so when the terrain is a steady ascent (the difference is especially pronounced in that subroute). The bottom panel shows that the cyber attack is relatively more effective when the cargo is light (blue markers are often higher) and especially the road is flat (the blue line has its peak there). Comparing the magnitude of the parameter estimates between the two panels (B is greater than M by at least an order of magnitude) tells us that this cyber attack, even at its most effective, only has a modest effect on functionality. 1JAGS uses Markov chain Monte Carlo (MCMC) methods to estimate parameters. We confirmed convergence of four MCMC chains using a potential scale reduction factor (often called ˆR; [46]) criterion of 1.05. 13 0.0200 0.0400 0.0600 0.0800 0.1000 0.1200 Bonware effectiveness B Heavy Truck Speed under Engine ECU Cyber Attack 0kg 3000kg 6000kg 9000kg Hilly 0.0002 0.0004 0.0006 0.0008 0.0010 0.0012 Malware effectiveness M 0kg 3000kg 6000kg 9000kg Steady Ascent Steady Descent Flat Off-Road Flat Road Fig. 7: Parameter estimates of the piecewise continuous model applied to performance of a heavy truck under a cyber attack on the engine ECU. The top panel displays the effectiveness of the bonware as a function of terrain and cargo weight, while the bottom panel displays effectiveness of the malware. One observation is that the effectiveness of the bonware is generally much higher than that of the malware, largely due to the physical resilience of the truck machinery. Round markers indicate parameter estimates, the intervals around the markers are 95% credible intervals. Each panel summarizes 1,200 runs (5 terrains by 4 cargo weights by 30 repetitions, once under baseline and once under cyber attack). C. Resilience R We will use the experimental data to compute the R statistic introduced in Eq. (2) in subsection III-B. The calculation involves (1) finding the area Aattack under the performance curve during the time when the cyber attack is active, then (2) finding the corresponding area Abaseline under the baseline performance curve, and (3) dividing the former by the latter. If the resulting R is 1.0, then the cyber attack had no detrimental effect on performance. R of 0.0 means that performance was reduced by 100%. Fig. 8 illustrates that the resilience measure R (based on the area under the curve concept) follows our intuitive understanding of what a measure of cyber resilience should do: it is higher if performance is impacted by cyber attack less, and lower if it is impacted more. It is relatively unimpacted in cases where no impact was expected (e.g., on the flat road subroutes in Fig. 8, there is no difference between cargo weight conditions), and it gives orderly results when differences are expected (e.g., when in Fig. 8 the R is affected by cargo weights, it is consistently lower for heavier cargo). Fig. 9 shows results for the same truck when it is subjected to the cyber attack on the engine fan controller. Here, we see a different pattern of results, with the effect generally being greater when the cargo is lighter. This, too, accords with our intuitions about resilience and the nature of the attack, which ultimately forces the truck to require more engine power to maintain vehicle speed: In a baseline run, with lighter cargo and flatter terrain, the truck requires comparatively less engine power to maintain vehicle speed than with heavier cargo and difficult terrain. Consequently, the difference in required engine power between corresponding baseline and fan attack runs will be greater and more pronounce on lighter cargo and flatter terrain than with heavier cargo and more challenging terrain. Regardless, the results remain ordered and show a great deal of consistency. There seems to be much less difference between subroutes during this attack. Also, on average, the loss of functionality due to this attack is smaller than that due to the attack on the engine ECU. 14 1.0 1.5 2.0 2.5 0.8 1.0 1.2 1.5 1.8 0.6 0.8 1.0 1.2 0.4 0.6 0.8 Flat Road Flat Off-Road Steady Descent Steady Ascent Hilly 0.75 0.80 0.85 0.90 0.95 1.00 Resilience R Resilience R for Fuel Efficiency Medium Truck Under Suspension Cyber Attack 0kg 1000kg 2000kg 3000kg A B C D 0kg 3000kg 0kg 3000kg Hilly Steady Descent A B C D Diﬀerent degradation Similar degradation Time Time Fig. 8: An illustration of the resilience measure R. The central panel shows the value of R for 20 different conditions (five subroutes and four cargo weights). Each marker shows R computed using the average of 30 runs of a suspension cyber attack and the average of 30 baseline runs (error bars indicating 95% confidence intervals), in this case by a medium-weight truck. The panel thus summarizes 1,200 experimental runs. The four side panels illustrate the construction of R. Each side panel shows the construction of one marker in the central panel. The blue (upper) curve indicates functionality under the baseline scenario. Note that the baseline functionality differs between subroutes (left vs. right panels) and between cargo weight conditions (top vs. bottom). The orange (bottom) curve indicates the functionality during the cyber attack. The shaded yellow region between the curves is the effect of the attack: a temporary reduction in functionality. R is the ratio of area under the orange curve to that under the blue curve (Eq. (2)) and can be interpreted as a measure of resilience: it is the remaining fraction of functionality while under attack. Those values of R are displayed in the central panel, which shows that resilience is high on flat road, but lower on hilly terrain. It further shows a notable effect of cargo weight in the hilly terrain as well as during the steady ascent, but no effect of cargo weight in the steady descent, flat road, or flat off-road subroutes. Hilly Steady Ascent Steady Descent Flat Off-Road Flat Road 0.8800 0.9000 0.9200 0.9400 0.9600 0.9800 1.0000 Resilience R Medium Truck Fuel Efficiency under Fan Cyber Attack 0kg 1000kg 2000kg 3000kg Fig. 9: The R measure for a medium truck subjected to a fan cyber attack. Round markers indicate parameter estimates, the intervals around the markers are 95% credible intervals. Each panel summarizes 1,200 runs (5 terrains by 4 cargo weights by 30 repetitions, once under baseline and once under cyber attack). Taken together, our experimental data support the validity of the R measure as a quantitative measure of cyber resilience. VII. CONCLUSIONS AND FUTURE WORK We have reported results of the Quantitative Measurement of Cyber Resilience project, in which we obtain experimental data with physical-digital twins of several cargo trucks and analyze the data with mathematical modeling of time series in order to quantify and measure the cyber resilience of the trucks. We were successful in generating data with apparent fidelity, showing that changes in the setup of the experimental runs (e.g., heavier cargo, more challenging terrain) result in differences in performance that accord with our subject matter expertise as well as common-sense expectations. 15 We proposed two types of summary statistics. One is a measure of resilience based on the area under the performance curve. Another type is based on fits of a mathematical model to temporal evolution of the performance curve, and measures the effectiveness of malware and bonware. These measures seem to capture the salient patterns in the experimental data succinctly, supporting their use as quantitative measures of cyber resilience. Based on the results reported in this paper, we have formulated a proposed practical method for measuring cyber resilience of a system under test. The details of the method go beyond the scope of this paper, but are described in a separate publication [38]. We believe there is much that could still be learned with our (or a similar) test bed. Data is relatively easy and fast to gather, and more variables can still be introduced. Additionally, similar test beds could be constructed for other types of vehicles, but also for other diverse types of complex equipment, infrastructure, or critical digital services. For the trucks, the test bed could still be augmented with additional derived measures of functionality, such as maneuverability. Similarly, there are further potential developments in the mathematical modeling aspect. New models could be implemented to allow for multivariate functionality, to account for trade-offs between different performance parameters. Besides the practical significance of such measures, our research makes broader theoretical contributions. We offer an explicit conceptualization of cyber resilience as a characteristic of the process – the “battle” between malware and bonware of a system under consideration. We further offer that this battle might be usefully modeled in a system-dynamic paradigm and illustrate this perspective with a specific class of models. Furthermore, we introduce notions of malware effectiveness and bonware effectiveness and of their temporal dynamics as key determinants of cyber resilience. APPENDIX A STABILITY A linear differential equation is said to be stable, in the sense of Laplace [47], [48], if all solutions are bounded as t →∞. We will show that Equation (5) is stable due to the non-negativity of both M(t) and B(t). Our approach is to consider the simplified cases where each of M(t) and B(t) are zero, show that each of these equations is stable, and then show that this implies Equation (5) is stable. Consider Equation (5) with B(t) = 0. dF dt + M(t)F(t) = 0. (13) The solution is F(t) = F0e− R t 0 M(p) dp, (14) and since M(t) ≥0, F(t) is bounded everywhere (0 ≤F(t) ≤F(0)). Let us now discuss Equation (5) with M(t) = 0. Then dF dt + B(t)(F(t) −FN) = 0. (15) or dΦ dt + B(t)Φ(t) = 0. where Φ(t) = F(t) −FN (16) Equation (16) has solution Φ(t) = (F(0) −FN)e− R t 0 B(p) dp. so that F(t) = FN + (F(0) −FN)e− R t 0 B(p) dp. Since we require B(t) ≥0, F(t) is bounded everywhere (F(0) ≤F(t) ≤FN). We’ve shown that in intervals when either M(t) or B(t) are zero, the solution to the differential equation is bounded. Now consider the case where both M(t) and B(t) are strictly positive on an interval (t1, t2), initially with F(t1) > 0 Let F(t) be a solution to (5) and let F1(t) be a solution to (15). Subtracting, we obtain: d dt(F1(t) −F(t)) + B(t)(F1(t) −F(t)) = M(t)F(t). (17) Assume that there exists a time that F(t) = 0. Then by (17), dF1(t) dt + B(t)F1(t) = 0. But F1(t) satisfies equation (15). So B(t) must be zero contradicting our assumption that both M(t) and B(t) are positive. Thus F(t) > 0 on (t1, t2) and thus is bounded below. 16 Assuming again that F(t) satisfies (5) and F1(t) satisfies (15). We further assume, F1(t1) = F(t1). Then at t1, we have dF (t) dt < dF1(t) dt implying that at time t⋆> t1, F(t⋆) < F1(t⋆). So FN ≥F1(t) ≥F(t) everywhere, and F(t) is bounded above by FN. We have thus shown that if F(t) is a solution to (5), then FN ≥F(t) ≥0 and thus Equation (5) is stable in the sense of Laplace. APPENDIX B OBTAINING THE SOLUTION TO THE LTV MODEL Here, we develop the solution (Equation (12)), to the LTV model, (Equation 11)), in Section IV-C. We start with Equation 11: dF dt + (λ −ωt)F(t) = FN(α −βt). Multiplying both sides of this equation by the integrating factor ω(t) = eλt−ωt2 2 and combining terms, we obtain: d dt  F FN eλt−ωt2 2  = (α −βt)eλt−ωt2 2 . Integrating both sides of this equation with respect to t: F(t) FN eλt−ωt2 2 −F(0) FN = Z t 0 (α −βτ)eλτ−ωτ2 2 dτ. Completing the square in the exponent: F(t) FN = e ωt2 2 −λt F(0) FN + e λ2 2ω Z t 0 (α −βτ)e−( λ √ 2ω −√ω 2 τ)2 dτ  . With the change of variables setting the quadratic in the exponent to p2: F(t) FN = e ωt2 2 −λt F(0) FN + r 2 ω e λ2 2ω Z √ω 2 t− λ √ 2ω − λ √ 2ω α −βλ ω −β r 2 ω p ! e−p2dp ! . The second term of the integral can be integrated immediately, and the first term can be written in terms of the error function. With erf(z) = 2 √π R z 0 e−τ 2dτ, the result is F(t) FN = e ωt2 2 −λt  F(0) FN + p π 2 e λ2 2ω (αω −βλ)  erf  λ √ 2ω  + erf  tω−λ √ 2ω  ω3/2 + β  eλt−ωt2 2 −1  ω  . REFERENCES [1] A. Kott, M. Weisman, and J. Vandekerckhove, “Mathematical modeling of cyber resilience,” Proceedings of IEEE Military Communications Conference, pp. 835–840, Dec. 2022. [2] M. Weisman, A. Kott, and J. Vandekerckhove, “Piecewise linear and stochastic models for the analysis of cyber resilience,” 57th Annual Conference on Information Sciences and Systems, Mar. 2023. [3] A. Kott and I. Linkov, Cyber resilience of systems and networks. New York, NY: Springer International Publishing, 2019. [4] S. Smith, “Towards a scientific definition of cyber resilience,” in 18th International Conference on Cyber Warfare and Security (ICCWS 2023). Red Hook, NY: Academic Conferences Ltd, Mar.9–10 2023, pp. 1–9. [5] I. Linkov, B. D. Trump, and J. Keisler, “Risk and resilience must be independently managed,” Nature, vol. 555, p. 7694, 2018. [6] M. Bozdal, M. Samie, and I. Jennions, “A survey on CAN bus protocol: Attacks, challenges, and potential solutions.” in 2018 International Conference on Computing, Electronics & Communications Engineering. Ieee, August 2018, pp. 201–205. [7] H. Pang and C. Brace, “Review of engine cooling technologies for modern engines,” Proceedings of the Institution of Mechanical Engineers, Part D: Journal of Automobile Engineering, vol. 11, no. 218, pp. 1209–1215, 2004. [8] A. Kott, P. Théron, M. Drašar, E. Dushku, B. LeBlanc, P. Losiewicz, ..., and K. Rzadca, “Autonomous intelligent cyber-defense agent (aica) reference architecture,” 2018, arXiv:1803.10664. [9] A. Kott, M. S. Golan, B. D. Trump, and I. Linkov, “Cyber resilience: by design or by intervention?” Computer, vol. 54, no. 8, pp. 112–117, 2021. [10] A. Kott and P. Theron, “Doers, not watchers: Intelligent autonomous agents are a path to cyber resilience,” IEEE Security & Privacy, vol. 18, no. 3, pp. 62–66, 2020. [11] J. Dillon, “Resilience of fibers and fabrics,” Textile Research Journal, vol. 17, no. 4, pp. 207–213, 1947. [12] R. Hoffman, “A generalized concept of resilience,” Textile Research Journal, vol. 18, no. 3, pp. 141–148, 1948. [13] H. Herrman, D. Stewart, N. Diaz-Granados, E. Berger, B. Jackson, and T. Yuen, “What is resilience?” The Canadian Journal of Psychiatry, vol. 56, no. 5, pp. 258–265, 2011. [14] G. Wu, A. Feder, H. Cohen, J. Kim, S. Calderon, D. Charney, and A. Mathé, “Understanding resilience,” Frontiers in behavioral neuroscience, vol. 7, p. 10, 2013. [15] C. Folke, S. Carpenter, B. Walker, M. Scheffer, T. Chapin, and J. Rockström, “Resilience thinking: integrating resilience, adaptability and transformability,” Ecology and society, vol. 15, no. 4, 2010. [16] B. Dupont, “The cyber-resilience of financial institutions: significance and applicability,” Journal of cybersecurity, vol. 5, no. 1, p. tyz013, 2019. [17] K. Hausken, “Cyber resilience in firms, organizations and societies,” Internet of Things, vol. 11, p. 100204, 2020. [18] L. Herrington and R. Aldrich, “The future of cyber-resilience in an age of global complexity,” Politics, vol. 33, no. 4, pp. 299–310, 2013. [19] Y. Huang, L. Huang, and Q. Zhu, “Reinforcement learning for feedback-enabled cyber resilience,” Annual reviews in control, vol. 53, pp. 273–295, 2022. [20] L. Jensen, “Challenges in maritime cyber-resilience,” Technology Innovation Management Review, vol. 5, no. 4, p. 35, 2015. [21] B. Zou, P. Choobchian, and J. Rozenberg, “Cyber resilience of autonomous mobility systems: cyber-attacks and resilience-enhancing strategies,” Journal of transportation security, pp. 1–19, 2021. 17 [22] A. Alexeev, D. Henshel, K. Levitt, P. McDaniel, B. Rivera, S. Templeton, and M. Weisman, “Constructing a science of cyber-resilience for military systems,” in NATO IST-153 Workshop on Cyber Resilience, 2017, pp. 23–25. [23] D. S. Henshel, K. Levitt, S. Templeton, M. G. Cains, A. Alexeev, B. Blakely, P. McDaniel, G. Wehner, J. Rowell, and M. Weisman, “The science of cyber resilience: Characteristics and initial system taxonomy,” Fifth World Conference on Risk, 2019. [24] A. K. Ligo, A. Kott, and I. Linkov, “How to measure cyber-resilience of a system with autonomous agents: Approaches and challenges,” IEEE Engineering Management Review, vol. 49, no. 2, pp. 89–97, 2021. [25] I. Linkov, D. Eisenberg, K. Plourde, T. Seager, J. Allen, and A. Kott, “Resilience metrics for cyber systems,” Environment Systems and Decisions, vol. 33, no. 4, pp. 471–476, 2013. [26] P. Beling, B. Horowitz, and T. McDermott, “Developmental test and evaluation (DTE&A) and cyberattack resilient systems,” Systems Engineering Research Center, Hoboken, NJ, Technical Report Serc-2021-tr-015, September 2021. [27] S. Hosseini, K. Barker, and J. Ramirez-Marquez, “A review of definitions and measures of system resilience,” Reliability Engineering & System Safety, vol. 145, pp. 47–61, 2016. [28] A. Kott and I. Linkov, “To improve cyber resilience, measure it,” Computer, vol. 54, no. 2, pp. 80–85, Feb. 2021. [29] T. Hoppe and J. Dittman, “Sniffing/replay attacks on CAN buses: A simulated attack on the electric window lift classified using an adapted cert taxonomy,” in Proceedings of the 2nd workshop on embedded systems security (WESS), 2007, pp. 1–6. [30] K. Koscher, A. Czeskis, F. Roesner, S. Patel, T. Kohno, S. Checkoway, D. McCoy, B. Kantor, D. Anderson, H. Shacham et al., “Experimental security analysis of a modern automobile,” in 2010 IEEE symposium on security and privacy. Ieee, 2010, pp. 447–462. [31] C. Miller and C. Valasek, “Adventures in automotive networks and control units,” Def Con, vol. 21, no. 260-264, pp. 15–31, 2013. [32] ——, “Remote exploitation of an unaltered passenger vehicle,” Black Hat USA, vol. 2015, no. S 91, 2015. [33] I. Foster, A. Prudhomme, K. Koscher, and S. Savage, “Fast and vulnerable: A story of telematic failures,” in 9th USENIX Workshop on Offensive Technologies (WOOT 15). Washington, D.C.: USENIX Association, Aug. 2015. [Online]. Available: https://www.usenix.org/conference/woot15/ workshop-program/presentation/foster [34] J. Daily, R. Gamble, S. Moffitt, C. Raines, P. Harris, J. Miran, I. Ray, S. Mukherjee, H. Shirazi, and J. Johnson, “Towards a cyber assurance testbed for heavy vehicle electronic controls,” SAE International Journal of Commercial Vehicles, vol. 9, no. 2, pp. 339–349, 2016. [35] M. Bozdal, M. Randa, M. Samie, and I. Jennions, “Hardware trojan enabled denial of service attack on CAN bus,” Procedia Manufacturing, vol. 16, pp. 47–52, 2018. [36] Q. Wang, Y. Qian, Z. Lu, Y. Shoukry, and G. Qu, “A delay based plug-in-monitor for intrusion detection in controller area network,” in 2018 Asian Hardware Oriented Security and Trust Symposium (AsianHOST), Dec 2018, pp. 86–91. [37] H. Shikata, T. Yamashita, K. Arai, T. Nakano, K. Hatanaka, and H. Fujikawa, “Digital twin environment to integrate vehicle simulation and physical verification,” SEI Technical Review, vol. 88, pp. 18–21, 2019. [38] A. Kott, M. Weisman, J. Vandekerckhove, J. Ellis, T. Parker, B. Murphy, and S. Smith, “A methodology for quantitative measurement of cyber resilience (qmocr),” ARL-TR-9672, 2023. [39] H. Lin and P. Antsaklis, “Stability and stabilizability of switched linear systems: A short survey of recent results,” in Proceedings of the 2005 IEEE International Symposium on, Mediterrean Conference on Control and Automation Intelligent Control, 2005., 2005, pp. 24–29. [40] J. Ellis, T. Parker, J. Vandekerckhove, B. Murphy, S. Smith, A. Kott, and M. Weisman, “Experimental infrastructure for study of measurements of resilience,” Proceedings of IEEE Military Communications Conference, pp. 841–846, Dec. 2022. [41] T. Toyama, T. Yoshida, H. Oguma, and T. Matsumoto, “PASTA: Portable automotive security testbed with adaptability,” Black Hat Europe 2018, Dec. 3–6, 2018. [42] Unity Technologies. (2021) The leading platform for creating interactive, real-time content. (v2020.3.18f1). [Online]. Available: https://unity.com/ [43] Keysight Technologies. (2021) “Open source in test automation”. [Online]. Available: https://opentap.io/assets/Open-Source-in-Test-Automation-v3.pdf/ [44] T. Miasko, “pyjags (version 1.3.8),” 2017, [computer software] (available at: https://github.com/tmiasko/pyjags. [45] D. Matzke, U. Boehm, and J. Vandekerckhove, “Bayesian inference for psychology, part III: Parameter estimation in nonstandard models,” Psychonomic Bulletin & Review, vol. 25, no. 1, pp. 77–101, Nov. 2017. [Online]. Available: https://doi.org/10.3758/s13423-017-1394-5 [46] A. Gelman, J. Carlin, H. Stern, and D. Rubin, Bayesian data analysis. Chapman and Hall/CRC, 1995. [47] R. Struble, Nonlinear differential equations. McGraw-Hill, 1962. [48] G. Teschl, Ordinary Differential Equations and Dynamical Systems, ser. Graduate studies in mathematics. American Mathematical Society, 2012. 18