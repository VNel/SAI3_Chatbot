Foundations of Cyber Resilience: The Confluence of Game, Control, and Learning Theories Quanyan Zhu April 8, 2024 Abstract Cyber resilience is a complementary concept to cybersecurity, focusing on the prepa- ration, response, and recovery from cyber threats that are challenging to prevent. Organizations increasingly face such threats in an evolving cyber threat landscape. Understanding and establishing foundations for cyber resilience provide a quantitative and systematic approach to cyber risk assessment, mitigation policy evaluation, and risk-informed defense design. A systems-scientific view toward cyber risks provides holistic and system-level solutions. This chapter starts with a systemic view toward cyber risks and presents the confluence of game theory, control theory, and learning theories, which are three major pillars for the design of cyber resilience mechanisms to counteract increasingly sophisticated and evolving threats in our networks and orga- nizations. Game and control theoretic methods provide a set of modeling frameworks to capture the strategic and dynamic interactions between defenders and attackers. Control and learning frameworks together provide a feedback-driven mechanism that enables autonomous and adaptive responses to threats. Game and learning frame- works offer a data-driven approach to proactively reason about adversarial behaviors and resilient strategies. The confluence of the three lays the theoretical foundations for the analysis and design of cyber resilience. This chapter presents various theoretical paradigms, including dynamic asymmetric games, moving horizon control, conjectural learning, and meta-learning, as recent advances at the intersection. This chapter con- cludes with future directions and discussions of the role of neurosymbolic learning and the synergy between foundation models and game models in cyber resilience. 1 Introduction to Cyber Resilience Cyber resilience of a network or organization refers to its ability to prepare for, respond to, and recover from cyber threats or incidents [24, 92, 72, 73]. It represents a departure 1 arXiv:2404.01205v2 [eess.SY] 5 Apr 2024 from classical cybersecurity measures, including cryptography, firewalls, and intrusion detection systems, which aim to prevent attackers from infiltrating or causing harm to the network. Instead, cyber resilience focuses on the capacity to respond to and recover from threats. Cyber resilience and cybersecurity are complementary to each other. Despite efforts and investments in cybersecurity for protection, perfect security cannot be guaranteed. There will always be threats that cannot be fully mitigated. These threats may include zero-day attacks, which are unknown to the network, or black swan events that are costly to secure against. Therefore, with limited resources and budgets, networks must decide how to protect themselves from threats to ensure the continuity of their applications and missions. As illustrated in Figure 1, resilience provides a complementary approach [97, 105, 48]. When threats are difficult to prevent successfully, there is a need to find ways to respond to them after they have gained initial access to the network, deter further infiltration by attackers, and recover from any damage incurred. Additionally, it is important to recognize that the success of security mechanisms is probabilistic. A higher probability of success will require a greater allocation of resources. Despite the careful deployment of cybersecurity measures, there will still be a probability, albeit small, for attackers to succeed in bypassing cryptographic protocols and firewalls to gain access to the network. Figure 1: Cybersecurity and cyber resilience focus on different sets of issues. Cybersecu- rity primarily concentrates on safeguarding assets from unauthorized access, attacks, and damages. On the other hand, cyber resilience aims to both deter attackers and recover the network from the initial success of attacks. Both strive to enhance the confidentiality, integrity, and availability (CIA) of information and resources. Cyber resilience specifically aims to mitigate the impact on the CIA triad despite the initial compromise. Despite their differences, there are overlaps between the two in terms of the techniques used to provide security and resilience. For instance, detection plays a critical role in both security and resilience efforts. 2 The tradeoffs between cyber resilience and cybersecurity stem from economic and technological considerations. As illustrated in Figure 1, common threats that occur fre- quently or are easily exploited by attackers often require defensive security mechanisms to protect the network with a high probability of success. Conversely, sophisticated threats that demand advanced skill sets and occur less frequently can be mitigated through defensive resilience. The decision on resource allocation across the entire threat landscape depends on factors such as budget, application domains, and avail- able technology. For instance, mission-critical applications like nuclear power plants or oil and gas manufacturing plants require investment not only in designing security mechanisms but also in crafting resilience mechanisms to counter highly sophisticated attackers and mitigate the exploitation of unknown vulnerabilities. The decision regarding which threats to defend against is not solely limited by budgetary constraints; it also involves human resources, such as the time and effort required for defense, as well as the availability of technologies that can facilitate or en- able such defense. For instance, defending against Advanced Persistent Threat (APT) attacks requires a coordinated effort from various aspects of missions, including human, cyber, and physical assets, to ensure assurance. This defense may require AI technolo- gies, which may still be in their infancy, particularly those that can be employed to mitigate the exploitation of human cognitive vulnerabilities leading to successful social engineering attacks. Within the set of exploitable vulnerabilities, we categorize them into two types of risks: avertable risk and elastic risk. Elastic risks are those triggered by events that can only be mitigated elastically through resilience strategies. Conversely, avertable risks are triggered by events that can be prevented with high probability using security mechanisms. 2 Cyber Risks and Resilience Mechanisms The first step toward understanding cyber resilience is to comprehend and quantify cyber risks. Just like all other risks, cyber risks are characterized by three primary components. First and foremost, cyber risk stems from the existence of vulnerabili- ties within the network. These vulnerabilities can manifest as software bugs, human biases, interface errors, system integration failures, inadequate preparedness, or hard- ware fragility. They serve as sources of susceptibility or exposure for both the network and the organization to identified threats. These vulnerabilities create risks because they represent opportunities for threats to exploit them. Hence, the threat constitutes the second component of the risk. A threat refers to an event or circumstance created by an adversary to exploit vulnerabilities 3 Figure 2: The vulnerabilities and their associated threats on the attack surface are repre- sented in two dimensions: their exploitability and their impact. They span across cyber, physical, and human layers of networks or organizations. These vulnerabilities are catego- rized into two types of risks. One type is avertable risks, which are managed by defensive security mechanisms, while the other type is elastic risks, which are addressed through re- silience mechanisms. within the system, triggering further events that lead to harm, loss, or damage. For instance, an attacker may craft a phishing email to exploit the cognitive vulnerability of a user, leading to the disclosure of passwords or access credentials to the attacker, or the unwitting download of malware to spread within the network. Alternatively, an attacker may exploit a buffer overflow bug in software to execute malicious code. The intersection of vulnerabilities and threats forms what we term the attack sur- face. This represents the collection of vulnerabilities and entry points within the net- work or organization that attackers can potentially leverage to gain unauthorized ac- cess, disrupt operations, steal data, or carry out other malicious activities. When an adversarial event exploits a vulnerability within the attack surface, con- sequences ensue. Consequences represent the outcomes of the interaction between threats and vulnerabilities. They can encompass performance degradation, disrup- tions to operations, financial losses, reputational damage, legal liabilities, and other adverse effects. The vulnerabilities, threats, and consequences constitute the landscape of cyber 4 risks, all of which can evolve over time. As illustrated in Figure 2, the set of vulner- abilities at time t is denoted by Vt, while the set of threats is denoted by Tt. One immediate consequence of the exploitation by an adversary event, Et, is the change of the network system state, Xt, which subsequently influences the consequences for the network, denoted by Yt. A vulnerability (3) is one that resides on the attack surface. For each vulnerability on the surface, there exists an event that leads to exploitation. However, a vulnerability, as exemplified in (2), is a threat that does not result in an event capable of exploiting a vulnerability within the network. This could be due to the network being well protected against that threat or the threat being irrelevant to the system under focus. A vulnerability (2) is one that cannot be exploited by a threat, either because the adversary is unaware of it or the vulnerability is difficult to exploit. A cyber resilience mechanism is one that supports the network system in dynami- cally reducing its risk over time through three distinct types of cyber resilience mech- anisms. One such mechanism is the proactive approach, which focuses on directly changing the attack surface to reduce the risk. Proactive measures may involve cre- ating secure network policies, such as network segmentation, patch management, and zero trust access control to minimize potential threat vectors. For example, network segmentation involves dividing a network into smaller, isolated segments, organizations can limit the scope of potential attacks. Network segmentation allows for stricter ac- cess controls and segmentation of sensitive resources, preventing lateral movement by attackers within the network. Regularly updating and patching software and systems helps address known vulnerabilities and weaknesses. Patch management programs en- sure that critical security patches are applied promptly to reduce the risk of exploita- tion by attackers. Zero-trust access control verifies the identity of users and devices attempting to access resources, regardless of their location or network connection. This involves implementing strong authentication methods such as multi-factor authentica- tion (MFA) and biometric authentication to ensure that only authorized individuals gain access. By proactively implementing these policies, the set of vulnerabilities Vt or threats Tt can be reduced, subsequently shrinking the attack surface. Another one is responsive resilience mechanisms that involve continuous monitoring and assessment of the threat landscape to identify emerging risks and vulnerabilities and dynamic defense strategies that evolve in real-time based on contextual factors and situational awareness. By leveraging predictive analytics and threat intelligence, organizations can anticipate potential attack vectors and vulnerabilities, allowing them to strengthen their defenses before adversaries can exploit them. The dynamic adapt- ability enables organizations to quickly adjust their security posture in response to evolving threats and changing environmental conditions. Leveraging machine learning 5 and control algorithms, these adaptive defenses can autonomously analyze incoming threats, assess their impact, and dynamically allocate resources to mitigate them ef- fectively. One notable example is adaptive cyber deception [40, 61, 87, 65], aimed at thwarting attackers from achieving their objectives by deploying decoys, such as hon- eypots or other traps, to divert their attention from critical assets. The effectiveness of cyber deception schemes relies on their adaptability, achieved through continuous learning of attackers’ objectives and tactics. By dynamically configuring and deploy- ing deception techniques based on this acquired knowledge, organizations can enhance their ability to mislead and deter adversaries effectively. Moving target defense is an- other example that can also be tailored to counteract attackers’ evolving tactics and behaviors. Moving target defense such as network address randomization, where IP addresses and network configurations are frequently shuffled to prevent attackers from mapping out the network topology and identifying vulnerable entry points. System administrators can employ dynamic service migration, automatically moving critical services and applications between different hosts or cloud instances to evade detection and mitigate the impact of targeted attacks. The third mechanism is retrospective, which focuses on restoring the system after an attacker has successfully compromised it. One immediate retrospective mechanism is cleaning up the network following a shutdown. Consider a manufacturing plant that falls victim to a sophisticated ransomware attack. As a result of the attack, critical systems controlling production lines and machinery are rendered inoperable. To contain the spread of the ransomware and prevent further damage, the plant is forced to initiate a complete shutdown of its operations. This entails halting production, isolating infected systems, and disconnecting the compromised network from external connections. The restoration process involves restoring encrypted data from backups, rebuilding compromised systems, and implementing enhanced security measures to prevent future incidents. The recovery process incurs a significant investment of time, resources, and financial costs. Another retrospective mechanism is post-incident analysis and remediation efforts aimed at understanding the root cause of the breach and implementing measures to prevent similar incidents in the future. This involves conducting thorough forensic investigations to identify the entry point of the attack, the techniques used by the adversary, and any vulnerabilities exploited. By analyzing the attack vector and iden- tifying weaknesses in the security infrastructure, organizations can implement targeted security enhancements and patches to strengthen their defenses against future threats. Cyber insurance is another example of a retrospective mechanism by organizations to mitigate the financial fallout of a cybersecurity incident [51, 93]. In the aftermath of a data breach or network intrusion, businesses may face a multitude of costs, including 6 forensic investigations, legal fees, regulatory fines, and loss of revenue. Cyber insurance policies provide a financial safety net by offering coverage for these expenses and com- pensating organizations for the losses incurred as a result of the incident. By having a cyber insurance policy in place, organizations can alleviate the financial burden of cybersecurity incidents and safeguard their long-term viability. While retrospective mechanisms are often a last resort, they become necessary when facing a formidable adversary. Proper preparation and design are essential to minimize recovery time and mitigate financial and technical risks to the network. Figure 3: Cyber risk at time t arises from vulnerabilities within the system itself, denoted by the set Vt, and potential threats posed by adversaries Tt. The intersection of these threats and vulnerabilities forms the attack surface of the network. An adversary can launch an event, Et, to exploit a vulnerability on the attack surface, resulting in changes to the system states. The consequences are expressed as outcomes of these changes in system state. The goal of resilience mechanisms is to mitigate the impact of such attacks. There are three types of resilience mechanisms: proactive, responsive, and retrospective. Proactive mechanisms aim to reduce the attack surface and create a more resilient network that is harder for attackers to exploit. Responsive mechanisms involve equipping the network with adaptive and automated responses to attack behaviors in real-time. Retrospective mechanisms focus on reducing the impact after the consequences of the attack, Yt , are realized and observed. They can involve restoring the system to its previous state or recovering financially from losses incurred. 7 3 Network and Dynamic Effects on Cyber Risks A large network can consist of multiple interconnected subnetworks. The risk within one subnetwork can be influenced by others, as they are interconnected. A threat to one subnetwork can lead to consequences within that subnetwork and may also impact other connected subnetworks. As illustrated in Figure 3, the states of other subnet- works are aggregated as Σt, and the well-being of these other subnetworks can affect the state of the subnetwork Xt. The interdependencies among subnetworks pose a significant challenge in managing cyber risks. Risk in one subnetwork can propagate to other subnetworks and vice versa. These interdependencies can arise from three sources. Firstly, threats can exploit the connectivity between subnetworks, making it more convenient for attackers to deploy threats. For instance, attackers may com- promise neighboring subnetworks before targeting the intended one. In this way, the threat space Tt is expanded for the targeted network as threats to connected networks also affect its security. Secondly, vulnerabilities in the connections with neighboring subnetworks bring in new vulnerabilities of the subnetwork itself. Additionally, vul- nerabilities in the nodes connected to it become potential threats that the subnetwork must address. In this way, the vulnerability space Vt is expanded for the targeted network. Thirdly, interdependencies can arise through consequences. Risks can propa- gate through state influence, where the state of one subsystem influences others through physical dynamics. In this way, the consequence Xt or Yt is directly affected. Such interdependencies have been vastly investigated in critical infrastructure net- works [12, 35, 106, 34, 107] and communication networks [21, 20, 23, 41]. Defending against threats originating from within the network itself is challenging, and prepar- ing for risks from connected networks is even more complex. Subnetworks may face threats from other networks for which they are not directly prepared. Therefore, re- silience is critical in addressing these challenges, particularly due to the unknown risks that propagate through network connections. Resilience mechanisms must be dynamic in nature as they operate within dynamic environments. Firstly, threats evolve over time. Unlike natural threats, adversaries can discover new vulnerabilities and acquire new knowledge to expand the attack sur- face. Figure 3 depicts the security landscape at time 1, denoted by threat set T1 and vulnerability set V1. Figure 3 also illustrates the security landscape at time 2, with the corresponding threat set T2 and vulnerability set V2. It is evident that the threat set expands as adversaries learn and enhance their skill sets over time. Conversely, the defender’s vulnerability set increases as the network introduces new vulnerabilities due to software and patch updates, as well as changes in connectivity. Consequently, the attack surface dynamically grows from time 1 to time 2. Such growth can be strategically directed by the actions taken by both parties. The attacker may choose 8 Figure 4: In a networked environment, the system states are influenced not only by its own risk factors but also by the system states of other nodes connected to it. Σt denotes the aggregate state of other nodes, while Xt represents the state of the system itself. The risk of a network system arises from not only local internal risks but also interdependent risks due to these connections. Studies on interdependent risks have been explored in the literature. One way to understand such risks is through game-theoretic methods, which have been studied for systemic risks [1] and holonic risks [49, 77]. actions to expand its set of attack vectors by probing the network, while defenders can take actions to increase or decrease their vulnerabilities through the implementation of defense mechanisms over time. Therefore, resilience mechanisms must adapt over time to address the evolving landscape of threats and the dynamics of the system itself. This adaptation encompasses not only responsive mechanisms but also proactive and retrospective ones. One distinction is that they may evolve at different time scales. Resilience mechanisms must also consider incomplete knowledge and uncertainties associated with threats and vulnerabilities. The complete set of vulnerabilities, as depicted in Figure 3, is not always known to the agents. Agents possess varying degrees of knowledge regarding vulnerabilities. One example is zero-day vulnerabilities, where the network defends itself without awareness of their existence in the software or hardware. If an attacker exploits zero-day vulnerabilities, they can create unexpected events that the defender did not anticipate, leaving the network defenseless. In such cases, resilience mechanisms become the last resort to mitigate such exploitation. The asymmetric information or knowledge between the attacker and defender adds another layer of complexity that resilience mechanisms must address. In addition to knowledge asymmetry, uncertainties exist in the network environment such as user behaviors, traffic patterns, and topology changes. For example, in a battlefield communication network [19, 22, 18], uncertainties in terrain features, such as hills, forests, and urban structures, can lead to signal interference, propagation losses, and unpredictable coverage areas. In addition, uncertainties in military unit movements, deployments, and formations can disrupt communication links. These uncertainties can affect the probability of threat event success and consequently impact the state of the network. Resilience mechanisms require tools capable of handling such 9 uncertainties. While investing in defense can reduce the probability of certain events succeeding or the attacker advancing to the next level of attacks, the risk may still persist, and resilience is the key approach to mitigate it. Figure 5: The vulnerability set V1 can be significantly larger, unbeknownst to the network defender, due to incomplete knowledge of vulnerabilities. This implies that the attack surface can be much broader than what is currently known. Attackers may exploit vulnerabilities on the attack surface that are unknown to defenders. These types of vulnerabilities must be addressed through cyber resilience strategies. Figure 6: At stage 2, the network may acquire new vulnerabilities through the installation of new software, patching, or the addition of new interfaces. Consequently, the attack surface expands accordingly. The security landscape evolves from stage 1 to stage 2. There is a need for cyber resilience to ready the network for newly introduced vulnerabilities. Preparing to protect against these vulnerabilities in real-time is challenging due to the dynamic nature of network changes. 10 To design dynamic mechanisms, control and learning tools are indispensable. This entails monitoring systems and gathering information about adversaries. Based on this data, reasoning frameworks are developed to respond to the system, as illustrated in Figure 3. The sequential events initiated by the attacker and the resilience policies implemented by the defender both influence the state of the network. The objective of resilience mechanism design is to regulate the state of the network to achieve acceptable performance in its evolution. Figure 7: Sequential interactions between the adversarial exploitation events E1, E2 and the actions taken by the resilience mechanisms R1, R2, R3. They affect how the system states evolve over time X1, X2, X3. 4 Cyber Resilience and Cyber Risk Metrics Before designing, it is essential to establish metrics for quantifying performance and design criteria. Figure 4 illustrates the evolution of network performance over time, driven by sequential interactions between the attacker and the defender, as depicted in Figure 3. Performance over time is represented by the measurable performance Yt across various stages. The evolutionary process is divided into three phases: proactive, responsive, and retrospective. At t1, the proactive mechanism is implemented. Sub- sequently, at t2, an adversary exploits vulnerabilities in the attack surface, leading to performance degradation at t3. Responsive defensive measures at t4 restore the net- work’s performance from level M to level D. The retrospective mechanism engages at t5 to address post-incident damage and restore performance. Numerous metrics can be proposed to quantify resilience, which can be classified 11 into three categories. The first category is performance-based metrics. These metrics require the monitoring of system states and provide accurate measures of resilience when credible information about system states is available. For example, the total losses incurred between t2 and t5, denoted by JE, reflect the impact of the event initiated by the attacker. Other metrics in this category include M and D, which assess the severity of damage and the effectiveness of recovery during the responsive stage. The second category comprises latency-based metrics, which are dependent on timing. These metrics measure the speed or frequency of reaction against risks. For instance, the response time t4 −t2 indicates how quickly recovery measures take effect, while the retrospective time t5 −t2 reflects the time taken for the system to rectify the problem retrospectively. The third category consists of knowledge-based metrics, which are associated with the known area of the attack surface (AS). Resilience in this context depends on the comprehensiveness of the knowledge about the system. For example, the percentage of the system model that can be expressed deterministically. Resilience metrics offer a means to gauge risk within our network under a specified resilience mechanism. The risk associated with vulnerability vE comprises two key com- ponents: impact and the probability of successful exploitation. With the integration of resilience mechanisms into the network, impact can be quantified by the total loss JE resulting from the successful exploitation of vE. The probability of success, denoted by pt E, is influenced by security mechanisms and proactive resilience measures. Risk is expressed as the product rt E = pt E × Jt E, and overall risk is evaluated by aggregating rt E across all events in the attack surface (AS), which is denoted by rt = X E∈AS rt E. (1) While this formula does not consider the cumulative effect of events, it serves as a fundamental metric for evaluating cyber risk. It is noteworthy that pt E evolves over time and is shaped by the tactics employed by both attackers and defenders. The security and resilience strategies employed by the parties not only impact the probability but also affect the magnitude of impact. Thus, the objective of cyber resilience, considering the implemented security strategies, is to mitigate both overall and long-term risks, as captured by 1. A baseline design problem can be finding resilience policies {Rt} that minimize PH t=1 rt over the horizon from stage 1 to stage H. It is evident that the problem presents an optimal control challenge, wherein the dynamics are governed by the evolution of cyber states, manipulated by both parties as depicted in Figure 3. However, solving this problem is inherently difficult. Firstly, it is necessary to incorporate the attacker’s behavior into the control problem to more accurately represent the dynamics. To achieve this, adopting a game-theoretic perspec- 12 tive towards this fundamental problem is essential. The evolving interactions over time can be captured through a dynamic game framework involving two players. Secondly, the defender does not possess complete knowledge of the dynamics and the attacker’s behaviors. Despite employing game-theoretic models, there persists a challenge in ac- curately determining the parameters of the underlying game. Thus, learning becomes indispensable in bridging the gap between theoretical game frameworks and practi- cal implementation. Consequently, the framework of cyber resilience and its design is built upon the intertwined principles of control, game theory, and learning, which are essential for assessing, analyzing, and designing for cyber resilience. Figure 8: The metrics of cyber resilience in the time domain divide the performance of the network into three stages: proactive, responsive, and retrospective. In the proactive stage, resilience mechanisms prepare strategies to deter potential attacks. The responsive stage involves online, adaptive responses to adversarial behaviors. The retrospective stage focuses on resolving problems or minimizing further impact after an incident has occurred and caused damage. t1 represents the time when the preparation mechanism is deployed and implemented. t2 marks the beginning of an event initiated by the adversary to exploit vulnerabilities on the attack surface. t3 indicates the point when performance degradation begins. t4 is the moment when responsive defense measures facilitate the network’s recov- ery to performance level D after a significant performance drop to level M. Without the responsive resilience mechanism, performance degradation would have continued. The ret- rospective mechanism becomes active at t5, aiming to restore performance after the incident has caused damage. 13 5 Theoretical Foundations Following the discussion above, control theory, game theory, and learning provide the- oretical foundations for understanding cyber resilience. Control theory addresses the dynamic nature of threat landscapes and network systems by offering tools to shape the metrics associated with cyber resilience. Game theory naturally captures the adversar- ial and strategic interactions between defenders and attackers, providing models and tools to analyze and predict the outcomes of these interactions and to design resilience mechanisms and associated strategies to achieve performance objectives despite strate- gic exploitations and disruptions by attackers. Learning is indispensable for enabling the system to assimilate data, information, and knowledge, allowing the integration of control and game-theoretic algorithms with them. Learning leads to implementable algorithms despite unknowns and uncertainties in the model. In this section, we dis- cuss these foundations separately and argue that their confluence provides theoretical foundations for quantifying, analyzing, predicting, and designing cyber resilience for networks. 5.1 Control-theoretic foundations The formulated control problem provides a baseline for understanding and designing cyber resilience mechanisms. In Figure 5.1, we illustrate the evolution of the attack surface over time. The attacker exploits vulnerabilities on this surface, progressing stage by stage towards the targeted asset. A resilience mechanism can eliminate the vulnerability targeted by the attacker in stage 2, thereby deterring their progress. An example is the moving target defense, which alters the attack surface by changing net- work attributes such as IP addresses, ports, or software configurations. Importantly, this process is dynamic. A successful attack at stage 1 results in a new attack surface at stage 2. To shift the attack surface or eliminate targeted vulnerabilities, defenders must understand the current situation, including the vulnerability set, successful at- tacker exploits, and the network’s new state. Additionally, defenders can analyze the attacker’s objectives and intended assets to determine how best to alter the attack sur- face. However, reconfiguring and changing networks to shift the attack surface incurs costs. Thus, there is a need to find implementable approaches that maintain system performance while minimizing defense costs. This approach coincides with the concept of feedback in control theory, where sens- ing, control, and actuation form the core components. This provides an essential building block for cyber resilience mechanisms. There is a need for situational aware- ness to comprehend the network’s state, reasoning to configure responses subject to system constraints, and triggers to initiate changes. The concept of feedback loop can 14 Figure 9: The evolution of the security landscape results in different attack surfaces at various stages. The attacker can exploit the initial vulnerability at stage 1, causing the system state to transition from X1 to X2. This attack can be thwarted by resilience mechanisms if proactive measures eliminate a vulnerability (targeted by the attacker) from the attack surface at stage 2, thereby disrupting the entire attack progression. Reactive mechanisms also enable the system to reconfigure and present a different attack surface (e.g., through moving target defense or cyber deception), deterring the attacker from further progression. Resilience mechanisms, by nature, must consider multi-stage dynamic behavior, with control theory being an appropriate framework for effectively addressing this aspect. be further extended to an OODA loop consisting of the stages of “Observe”, “Orient”, “Decide”, and “Act”, [83, 6]. The “Observe” stage involves gathering information about the network, including identifying threats, vulnerabilities, and changes in the landscape. Observations are made through various means, such as monitoring network traffic, analyzing system logs, and gathering threat intelligence. The “Orient” stage, the collected information is analyzed and interpreted to understand the current situa- tion and assess its implications. This includes evaluating the capabilities of adversaries, identifying potential risks, and understanding the context in which decisions need to be made. In the “Decide” stage, based on the observations and orientation, decisions are made regarding the appropriate course of action. This stage involves evaluating different options, weighing their potential outcomes, and selecting the most effective response strategy. Finally, in the “Act” stage, the decided course of action is imple- mented. This may involve deploying security measures, executing response plans, or initiating countermeasures to mitigate threats and vulnerabilities. The control-inspired OODA loop allows for continuous improvement and adaptation, enabling organizations to stay ahead of evolving threats and maintain a resilient posture in the face of cyber challenges. Besides the concept of feedback, many control tools can become available to solve 15 the problem. For example, the problem can be addressed using moving horizon tech- niques, which is a control strategy used in dynamic systems to optimize future control actions while considering a finite prediction horizon. The system’s current state is ob- served, and a prediction model is used to forecast the system’s behavior over a certain time horizon into the future. Based on this prediction, an optimization problem is formulated to determine the optimal control inputs over this finite horizon that mini- mizes a certain cost function or satisfies a set of constraints. In [27], moving horizon computation has been used to solve a partially observable Markov decision process, continuously updating and adjusting its trust evaluation based on the latest available information. Additionally, dynamic trust allows for access control decisions over time, creating a zero-trust architecture for 5G networks in the face of evolving threats. Moreover, [69] studies the problem of assessing the effectiveness of a proactive defense-by-detection policy with a network-based moving target defense. A moving horizon planning algorithm proposed in [69] is employed to compute the attacker’s strategy for security evaluation. This approach involves continually updating the at- tacker’s plan over a finite time horizon based on real-time information and changing conditions. As the planning horizon advances, the algorithm recalculates the optimal strategy, taking into account the latest insights and observations. 5.2 Game-theoretic foundations As cyber risk emerges from strategic interactions between players, resilience mecha- nisms aiming to mitigate such risks must integrate a game-theoretic model to effectively capture these interactions [53, 99, 70]. Illustrated in Figure 3, the dynamics between the defender and the attacker need a dynamic game, as depicted in Figure 5.2, denoted by a sequence of games G1, G2, · · · , G6. Each game Gt encapsulates the local inter- action at stage t. A fundamental game comprises three key components: the set of players, their action sets, and their payoff functions. The sequences of games can cap- ture different stages of resilience [100]. For example, proactive resilience mechanisms can be captured by one game, while responsive resilience mechanisms can be captured by another. Retrospective resilience can also be captured by a separate game. Each mechanism involves different types of players and different actions. For example, re- sponsive resilience involves the sequential tactics and procedures of the attacker aimed at advancing toward the target. Proactive resilience involves the attacker’s strategy to exploit vulnerabilities on the attack surface, while retrospective resilience involves analyzing the entirety of the attacker’s operation. Hence, the defender’s tactics and strategies will vary according to the stage involved. Each described game represents the outcome of the interplay between threats posed by adversaries and defense mechanisms employed by defenders. The equilibrium of 16 Figure 10: The interactions between the attacker and the defender utilizing resilience mech- anisms can be depicted through a sequence of games at various stages. The actions taken by both parties shape the progression of the games in subsequent steps. Resilience mechanisms can be augmented by an AI stack that facilitates the analysis of adversarial behaviors and strategically adjusts its own policies throughout the stages of the games. these games, often described using Nash equilibrium, which is a point of strategies where no players have incentives to deviate from unilaterally. It serves as a primary metric to gauge the consequence of these interactions, as depicted in Figure 4. This equilibrium offers insights into the predicted outcome Yt. Here, the risk r can be thor- oughly assessed, not just on an average basis across all threat events, but also consider- ing the strategic maneuvers of the attacker, who intelligently selects the most impactful vulnerability and associated event Et at time t to achieve their goal GA(Et, Rt). Here, GA is the attacker’s reward function, which takes as input the threat event chosen at the attacker at time t and the defender’s resilience action Rt at time t. It yields a reward that indicates the proximity toward the goal. Similarly, the defender’s objective is to select a resilience mechanism Rt at time t to achieve their own goal GR(Et, Rt). Here GR is the defender’s resilience reward function, which is influenced not only by the defense action Rt but also by the attacker’s action Et. Both players aim to maximize their reward by choosing respective policies. The equilibrium outcome, denoted by E∗ t and R∗ t , is a point where no players can benefit from deviating from their actions. As suggested in Figure 2, this outcome will further result in the equilibrium state X∗ t and the associated consequence Y ∗ t . This consequence Y ∗ t serves as a key metric for risk evaluation within this paradigm. We call this risk as strategic cyber risk. Its evaluation considers the strategic behaviors of both attackers and defenders, offering meaningful predictions when agents behave rationally and engage in sufficient reasoning over time. Strategic risk is particularly valuable when event probabilities are unavailable, a common occurrence in cybersecurity scenarios. Obtaining data to assess how frequently attackers exploit the attack surface can be challenging, and often the precise attack surface is not fully understood. Consequently, 17 strategic risk offers an alternative approach. Its evaluation needs an attacker model that quantifies attacker actions and motivations. Risk assessment involves considering potential outcomes given both the rational behaviors of attackers and the network’s best effort defense. While assuming rationality and understanding exact incentives may be difficult, these assumptions provide a foundational framework. Nevertheless, this framework can be enhanced through the incorporation of bounded rationality models [13, 33, 32, 76, 71] and learning methodologies [103, 102, 98], allowing for continual refinement and improvement. The games depicted in Figure 5.2 are interleaved, with the outcome of a game at stage t determining the subsequent game. The dynamic game is characterized by a transition kernel that outlines the transition between games. Dynamic games can man- ifest in various forms contingent upon the players’ information structure, the dynamics’ structure, and the uncertainties in the games. For instance, in [95, 101], a dynamic stochastic game has been employed to configure intrusion detection systems across dif- ferent system states. This intrusion detection game involves a defender configuring rules to detect the attacker, who, in turn, aims to evade detection. Bayesian games are utilized to capture situations where players have incomplete information about the game. One source of uncertainty arises from the payoff of the game. The players do not know the exact payoff of the game but rather the probabilities of the outcomes. Sometimes, the players may not know the exact game they are playing, including the actions they can take and the other players’ actions. Harsanyi has provided methods to understand such games with uncertainties by adopting a Bayesian approach [29]. The unknowns of a player are characterized by the notion of type, representing the private information or characteristics that affect one player’s payoffs or strategies in the game. Each player’s type is drawn from a probability distribution known to the player but not necessarily to others. It is often assumed that the players share beliefs about the distribution of types or the uncertainty in the game. This assumption is known as the common prior, which serves as a basis for reasoning and decision-making in the game. Another approach is based on Aumann’s knowledge models [2, 4, 5, 3]. It makes use of epistemic logic to deal with reasoning about knowledge and belief. Epistemic logic provides formal tools for representing and reasoning about agents’ knowledge and be- liefs, as well as the interactions between them. One key notion of Aumann’s approach is the notion of an information partition. This partition divides the set of possible states of the world into distinct subsets, each corresponding to a particular piece of information available to players. The partition captures the structure of players’ in- formation and determines how it influences their beliefs and strategies. In Aumann’s approach, common knowledge is defined as the information that is not only known 18 by an individual agent but is also known to be known by all agents, and so on iter- atively. It connects with the common prior assumption in Harsanyi’s model. It has been shown that Harsanyi’s Bayesian games and Aumann’s epistemic approach are equivalent representations of games of incomplete information. In cases where one agent holds more information than the other, asymmetric infor- mation games arise, often used to model cyber deception contexts. For example, they have been used in honeypot deployment and design [30], where the attacker is assumed to have incomplete information about the honeypot’s location, but the defender has complete information about it. On the other hand, in the application of designing insider threat mitigation programs, the attacker has complete knowledge of whether they are an insider or not, but the defender has incomplete information about who the insiders are [37, 36]. Asymmetric information games provide a modeling framework to understand the information advantage of the players and find ways to either reduce this advantage gap or leverage it to mitigate cyber risks. One special class of asymmetric information games is signaling games [8, 88, 54, 66, 31], wherein a sender observes the true state of the world, crafts a message, and sends it to a receiver to elicit a response aligned with the sender’s intentions. The receiver, upon observing the message, must estimate the true state of the world based on the sender’s strategies. Lack of consistency arises if the receiver’s belief about the true state of the world is not supported by the messages sent by the sender as per the sender’s strategy. Hence, the equilibrium concept of this game involves not only strategies that do not allow unilateral deviation but also the sender’s associated belief with these strategies. This equilibrium concept is called Bayesian Nash equilibrium. This class of games has contributed to understanding information manipulation, man-in-the-middle attacks, and misinformation over networks. For example, in [78, 63, 105], a man-in-the-middle attack between an industrial control system and a cloud is described. An industrial control system sends a compu- tation task to the cloud for heavy computations, including image processing, control computation, or state estimation. The cloud then sends back the results to the con- trol systems, which will utilize the results to actuate the system. The cloud-enabled control system leverages the computational power at the edge to reduce the computa- tion burden on the system itself, which has limited real-time computation power due to hardware constraints. However, the attacker can manipulate the result and send a false result to mislead the control system into a failure mode of operation. One approach to creating resilience in case cryptography fails is to implement a checking mechanism to verify whether the sent message is coherent. Utilizing a belief system can aid in this verification process. The signaling game framework naturally captures the fact that the attacker has complete information and sends a message to the control 19 system, which then must decide whether to utilize the result or discard it. Developing a strategy to screen the inputs provides a layer of resilience to the system against such attacks. Another example is the zero-trust access control problem [26, 28, 44]. In this scenario, the attacker knows their type, but the network does not. The network must decide whether to grant or revoke access based on the behavior or footprint of the user. This situation corresponds to a dynamic signaling game where the attacker has complete information about their type, but the network does not. A game-theoretic approach offers a strategy for authentication based on the dynamic formation of a belief process, which relies on continuous monitoring. This plays a critical role in providing zero-trust security to modern networks, where access is determined through continuous monitoring. Game theory not only captures scenarios of interactions and provides a way to determine the optimal strategy to defend against threats but also facilitates the design and deployment of overarching resilience mechanisms. In this regard, mechanism design theory [55, 7] becomes essential as it enables us to shape the equilibrium or outcome of the game to a desirable one through the design of the game’s rules. One such framework is Stackelberg games [50, 52, 64]. Stackelberg games typically consist of a leader and several followers. The leader, acting as a designer, anticipates the outcomes of the game played by the followers. The followers interact with each other based on the input from the leader. The leader then designs an appropriate input to the game to shift the outcome to achieve the goal of the design. Such designs have been utilized in insurance schemes for computer networks [86, 84, 85]. The insurer must design a scheme that enhances the network’s security ecosystem and resilience. To achieve this, the insurer needs to assess risks by considering the interactions between attackers and defenders. The equilibrium of the game framework indicates the risks associated with the network under the designed insurance mechanism. The objective of the design is to minimize the insurer’s costs while aligning with the cyber risks of the insuree. This framework has been extended to dynamic and network settings. Bayesian mechanism design theory plays another pivotal role in shaping game out- comes to achieve cyber resilience. It has been employed to understand and influence player behaviors within a novel game-theoretic framework known as the duplicity game [37], aimed at designing effective deception mechanisms. This framework, comprising a generator, an incentive modulator, and a trust manipulator, collectively referred to as the GMM mechanism, is formulated as a mathematical programming problem. Its ob- jectives include computing the optimal GMM mechanism, quantifying the upper limit of enforceable security policies, and characterizing conditions for user identifiability and manageability in terms of cyber attribution and user management. 20 Dynamic game modeling provides a foundational framework for understanding the cyber environment, as illustrated in Figure 2. Various games capture distinct types of interactions within this environment. The dynamic game framework needs an investi- gation with a forward-looking perspective, meaning actions taken now must consider not only the current stage but also subsequent stages of the game. Equilibrium analysis of dynamic games within this forward-looking context often employs dynamic programming principles or moving-horizon schemes, which are funda- mental control-theoretic techniques utilized to tackle long-term problems. The control framework introduced in 1 is extended to a dynamic game framework with a more intricate modeling of adversarial behaviors, thereby creating a multi-player control problem. Such analysis yields a risk trajectory of the network environment in the face of adversaries. This analysis facilitates the measurement of network risks based on the prescribed attack model. The sequence of stage-by-stage risks corresponds to the cyber resilience metric depicted in Figure 4. In essence, at each stage, a game can assess risks by predicting the consequences of interactions between threats and defenses. The strategies associated with dynamic games offer a means to manage the eval- uated risks under given attack models. If the assessed risks meet the performance criterion, the game strategies can inform the design of cyber resilience mechanisms at the operational and tactical levels, informing network actions how to act to maintain an acceptable level of risk. However, if the assessed risks do not meet the performance criterion, mechanism design theory enables a further step towards planning and de- signing resilience mechanisms to ensure the game arrives at a desirable set of outcomes with acceptable risks. These designed games correspond to the design of networks, rules, and policies, thereby informing the strategic-level planning and deployment of resilience mechanisms. 5.3 Learning Foundations Despite advances in game-theoretic modeling and related computational and mecha- nism tools, challenges persist in utilizing game theory for cyber resilience. One key challenge is the imprecise modeling or capture of threat models. Attack behaviors can surpass prescribed models, leading to inaccurate risk assessments and potentially misleading designs due to misalignment between actual threats and prescribed ones. This issue is inevitable as networks face zero-day threats. Even if models initially cap- ture exact attack behavior, the rapidly evolving threat landscape poses challenges for modeling to keep pace. In addition to the epistemic uncertainties associated with threat models, aleatoric uncertainties related to game parameters such as payoffs, action sets, common priors, and dynamics remain challenging to precisely determine. Therefore, learning emerges 21 as a crucial approach to enhance the game and control framework, enabling data-driven, autonomous, and agile defense strategies for resilience. There is a pressing need to de- velop an AI stack, as depicted in Figure X, which utilizes dynamic game models to facilitate advanced reasoning about attackers. This stack should also incorporate com- putational and control techniques to compute lookahead policies, allowing for online observations to adapt resilience policies dynamically and defend against attackers. Recent advances in learning and AI have introduced numerous models and ap- proaches to cybersecurity. For instance, leveraging large language models can expedite information processing and learning, facilitating rapid parsing of network log and traffic data for improved decision-making. Deep neural networks have also notably enhanced intrusion detection. Among learning paradigms, reinforcement learning emerges as a vital element for enabling autonomous and data-driven resilience mechanisms. Fig- ure 5.3 illustrates the feedback structure of reinforcement learning. In this paradigm, the network system is subject to continuous monitoring, ensuring a continuous watch over its operations and interactions. This monitoring is followed by a sophisticated reasoning framework, designed to analyze incoming data and promptly identify any deviations or anomalies within the network’s behavior. Leveraging this analytical ca- pability, the framework dynamically updates network policies in real-time, tailoring responses to specific network events as they unfold. This adaptive approach not only enables fast detection of potential threats but also facilitates proactive risk mitigation strategies. This paradigm aligns well with the control framework detailed in Section X, where a feedback structure is integral for enabling dynamic responses and automated mechanisms. Figure 11: Reinforcement learning offers a paradigm for achieving adaptive resilience mech- anisms. The network system undergoes continuous monitoring, with a reasoning framework employed to update network policies in response to events within the network. This adap- tation aims to mitigate risks to the network system. In [25], meta-learning reinforcement has been used to create network defense adapt- 22 able to various attack scenarios. Meta-learning is a machine learning technique that focuses on learning how to learn. It involves training models on a variety of tasks or datasets, with the goal of enabling the model to quickly adapt to new tasks or scenarios with minimal additional training. In the context of defense strategies, meta- learning is used to enhance the adaptability and generalization capabilities of the sys- tem in response to evolving and diverse attack scenarios. A meta policy is first learned through meta-learning. This meta policy encapsulates a high-level strategy for mak- ing trust-related decisions based on partial observations of the system and potential attack scenarios. Along with the meta policy, an adaptation mapping is learned using meta-learning techniques. This mapping allows the system to quickly adjust the meta policy based on new information or unseen attack scenarios, enabling rapid adaptation to changing threat landscapes. By leveraging meta-learning, the defense system can efficiently adapt to new and unknown attack scenarios using insights gained from pre- vious training data. This adaptive capability reduces the need for extensive retraining or manual intervention when faced with novel threats. In [42], Conjectural Online Learning (COL) has been proposed as a learning scheme designed for generic Asymmetric Information Stochastic Games (AISGs) where decision- making entities have limited or asymmetric information. COL utilizes a forecaster- actor-critic (FAC) architecture to update strategies in an online manner by incorpo- rating first-order beliefs and subjective forecasts of opponent strategies. In the context of security, COL can be applied to enhance cyber resilience in IT infrastructures. For example, in defending against Advanced Persistent Threats (APTs), COL can help in formulating strategies for the defender to protect the infrastructure and respond to intrusions effectively. By utilizing Bayesian learning and online adaptability, COL can enable defenders to adjust their strategies based on evolving threats and nonstationary attack patterns, leading to improved resilience against cyber threats. In [47], the interconnections among foundation models (FMs), game models, and learning are explored. FMs serve as essential components for constructing customized machine learning models tailored to diverse cybersecurity applications. Game-theoretic models provide a foundational framework for comprehensively modeling adversarial in- teractions, facilitating the encapsulation of adversarial knowledge and domain-specific insights. The synergy between GMs and FMs can yield proactive and automated cy- ber defense mechanisms. These mechanisms not only aim to secure networks against attacks but also endeavor to enhance resilience against well-planned operations. It has been highlighted that one promising direction is the multi-agent neurosymbolic conjec- tural learning (MANSCOL) approach, which empowers defenders to predict adversarial behaviors, design adaptive defensive deception tactics, and synthesize knowledge for operational-level synthesis and adaptation. FMs assume a pivotal role in various func- 23 tions within MANSCOL, encompassing reinforcement learning, knowledge assimilation, formation of conjectures, and contextual representation. 5.4 Confluences of Control, Games, and Learning Meth- ods Control, game, and learning methods each play pivotal roles in bolstering cyber re- silience. Control-theoretic methods offer a dynamic systems perspective, framing cy- ber resilience as a continual process where defense mechanisms must operate over time across multiple stages to mitigate risks stemming from the attack surface. Conversely, game-theoretic methods distinguish cyber resilience from resilience to natural disasters by modeling adversarial behaviors of attackers. These methods facilitate the assess- ment of strategic risks faced by defenders under the strategic behaviors of attackers. Additionally, leveraging mechanism design and computation tools from game theory and control theory enables the dynamic design of cyber resilience mechanisms. Their confluences are central to the theoretic foundations of cyber resilience as illustrated in Figure 5.4. Figure 12: The convergence of game, control, and learning methods is essential. Game and control methods establish the groundwork for modeling and computations in cyber risk and its mitigation. Control and learning methods are pivotal in the development of feedback-driven and adaptive resilience mechanisms. Game and learning methods offer data- driven strategic reasoning mechanisms utilizing both symbolic and data information. Their convergence enables the analysis and design capabilities crucial for cyber resilience. Furthermore, learning methods facilitate the integration of data and symbolic in- formation from models, enabling the creation of an implementable AI stack. This stack 24 enables analysis of adversarial behaviors, real-time response of defenses, and adaptive design and planning of mechanisms. By integrating these three methods, machine in- telligence can be harnessed to address threats in an automated, adaptive, and agile manner, fostering new innovations in the realm of AI and cyber resilience solutions. Recent advances in predictive learning with adversarial thinking exemplify the syn- thesis of control, game, and learning methods. By effectively learning the adversarial model, valuable insights into adversaries’ tactics are gained, enabling the development of robust response strategies. Predictive control methods, such as roll-out and forward- looking strategies, complement predictive learning by facilitating rapid adaptation and decision-making in dynamic environments. This advance is closely tied to the concept of conjectural learning [42, 43], wherein agents hypothesize about adversaries’ behavior based on observed actions and out- comes. Incorporating conjectural learning enhances the ability to anticipate and re- spond to adversarial maneuvers, thereby improving overall resilience and adaptive ca- pacity. Additionally, meta-learning, which involves learning to learn, plays a significant role in this synthesis [58, 25]. By leveraging meta-learning techniques, adaptability and op- timization of response strategies based on evolving threats and changing environmental conditions are enhanced. Meta-learning facilitates the extraction of meaningful pat- terns and insights from past experiences, enabling more effective decision-making and strategy formulation. An essential aspect of this synthesis involves coordinating and managing tradeoffs among different stages of the resilience process. Each stage, from proactive preparation to reactive response and retrospective analysis, presents its own set of challenges and considerations. Effective coordination between these stages is crucial for ensuring a cohesive and comprehensive approach to resilience. By carefully balancing tradeoffs and leveraging insights from each stage, resource allocation can be optimized, actions prioritized, and overall resilience effectiveness maximized. 5.5 Cyber deception as a case study Modern advances in cyber deception for cyber resilience is an example of the integration of control, games, and learning within the cybersecurity domain. By deploying decep- tive techniques, organizations can manipulate the behavior of adversaries, influence the dynamics of the cyber environment, and enhance their resilience against threats. Control mechanisms play a crucial role in cyber deception by governing the deploy- ment and management of deceptive techniques and assets. Through control mecha- nisms, organizations can strategically design and implement deceptive environments to manipulate adversary behavior and mitigate threats [17, 16, 16, 68]. Control aspects 25 ensure that deceptive measures are deployed effectively and efficiently, maximizing their impact on adversaries while minimizing the risk to legitimate systems and data. In the context of resilience, control enables defenders to adapt and optimize their decep- tion strategies in response to evolving threats and changing environmental conditions, thereby enhancing overall cyber resilience. Game theory provides a strategic framework for understanding and influencing the interactions between defenders and adversaries in the cyber domain [62, 67, 62]. In the context of cyber deception, game theory principles guide the design and implemen- tation of deceptive strategies to outmaneuver adversaries and increase the defender’s advantage. By presenting adversaries with strategic dilemmas and uncertainties, de- fenders can exploit decision-making vulnerabilities and manipulate adversary behavior to their advantage. Game theory also facilitates the analysis of adversary strategies and the identification of optimal deception strategies for enhancing resilience against cyber threats. Learning mechanisms enable defenders to adapt and improve their deception strate- gies based on insights gained from past experiences and interactions with adversaries [45, 46, 38]. Through machine learning algorithms and data analytics, defenders can analyze adversary behavior, identify patterns, and refine deception tactics over time. Learning enables defenders to anticipate evolving threats, proactively adjust deception strategies, and continuously enhance resilience against cyber attacks. By incorporating learning mechanisms into cyber deception and resilience strategies, organizations can improve their ability to detect, deter, and mitigate threats in dynamic and evolving cyber environments. The integration of control, game theory, and learning principles enhances the effec- tiveness of cyber deception and resilience strategies. Control mechanisms govern the deployment and management of deceptive assets, ensuring strategic placement and uti- lization. Game theory principles guide the design of deceptive environments to exploit adversary decision-making vulnerabilities. Learning mechanisms enable defenders to adapt and optimize deception strategies based on insights gained from past interac- tions with adversaries. Together, these integrated approaches enable organizations to enhance their cyber deception capabilities and resilience against evolving cyber threats. 6 Future Directions Cyber resilience encompasses a diverse array of challenges. This domain transcends mere technicalities, extending to the intersections of cyber, physical, and human com- ponents within systems. Many of these challenges are interdisciplinary, necessitating a systems-scientific approach for resolution. Furthermore, within the realm of tools, 26 there exists a wealth of opportunities at the intersection of game theory, control the- ory, and machine learning. Numerous methods can draw inspiration from emerging applications and be developed to tackle a wide range of issues. On the methodological front, non-equilibrium learning, large language models, and foundation models are emerging as promising tools to enhance the intelligence associ- ated with cyber resilience mechanisms. Nonequilibrium learning is a novel approach in machine learning and artificial intelligence that diverges from traditional equilibrium- based models [60, 59]. Unlike equilibrium-based approaches that assume stable states and predictable outcomes, nonequilibrium learning focuses on dynamic, non-stationary environments where conditions are constantly evolving. This approach is particularly relevant in cybersecurity, where adversaries continually adapt their tactics to circum- vent defenses. Nonequilibrium learning algorithms are designed to adapt to changing conditions in real-time, enabling defenders to detect and respond to emerging threats more effectively. By leveraging nonequilibrium learning, organizations can enhance their ability to anticipate and mitigate cyber attacks in dynamic and unpredictable environments. Large language models (LLMs), such as Generative Pre-trained Transformer (GPT) models, have revolutionized natural language processing. These models, trained on vast amounts of text data, possess advanced capabilities in generating human-like text and understanding contextual nuances. In cybersecurity, LLMs are increasingly being ap- plied to analyze and understand adversarial behavior in strategic games. By training LLMs on extensive datasets of cyber threat intelligence and historical attack patterns, researchers can develop models capable of predicting adversary strategies and identi- fying potential vulnerabilities. These LLM-based approaches provide valuable insights into the strategic dynamics of cyber conflicts, enabling defenders to anticipate and counteract adversarial actions more effectively. Foundation models with strategic learning represent a paradigm shift in the devel- opment of AI and machine learning algorithms for cybersecurity [47]. Unlike traditional models that focus solely on optimizing specific tasks or objectives, foundation mod- els with strategic learning incorporate strategic decision-making capabilities inspired by game theory and multi-agent systems. These models are designed to analyze and predict the behavior of multiple actors in complex cyber environments, taking into ac- count their strategic interactions and incentives. By integrating strategic learning into foundation models, researchers can develop more robust and adaptive cybersecurity solutions capable of addressing the strategic challenges posed by sophisticated adver- saries. These models enable defenders to anticipate adversary tactics, identify strategic vulnerabilities, and devise effective countermeasures to enhance cyber resilience. Besides the advances in methodologies, there are also increasingly challenging cyber 27 risk issues that we need to address. One key challenge associated with cyber resilience is the interdependencies among the risks within the subnetworks. Developing resilience mechanisms for the entire network itself is not a scalable solution. Instead, creating decentralized mechanisms for individuals is more plausible. However, in this case, the resilience mechanisms need to coordinate with each other due to the interdependen- cies, while simultaneously controlling and managing the cyber risks within their own network. The cyber risk of the entire network under this cyber resilience architecture is called holonic risk. Holons are entities that constitute the whole system, but each is capable of autonomous functions [77]. Holonic risks refer to the risk of the whole network, in which each constituent subnetwork autonomously manages its risk. This type of risk is becoming more common as the network grows larger and more het- erogeneous, and each subnetwork is owned by different entities who have the right to control it. One way to deal with such issues relies on game-theoretic, control-theoretic, and learning tools. The interdependencies among the subnetworks can be viewed as a game in which individuals respond to each other. In this case, a subnetwork not only needs to dynamically respond to threats but also to the behaviors of other subnetworks, bringing a new layer of complexity into the cyber resilient framework. Similarly, the associated learning involves not only learning the behaviors of adversaries but also the behaviors of other networks through communications and cooperation. The consequences of cyber risks in critical infrastructures and industrial networks often extend to risks within physical systems. Consequently, the risk is not solely confined to the cyber domain but incorporates both cyber and physical domains, mak- ing it a cyber-physical challenge. Thus, associated resilience mechanisms must not only address cyber threats but also consider the implications for physical systems. Therefore, the design of resilience mechanisms needs to be physics-informed, i.e., inte- grating insights from physics to ensure compliance with operational level constraints. Additionally, it is essential to develop physical-level resilient mechanisms, such as controllers, to mitigate impacts on physical systems. Consequently, cyber resilience must be jointly designed with physical resilience, emphasizing a co-design paradigm for networks [105, 39, 80, 82, 36]. This approach is crucial and has been applied in understanding cyber-physical resilience across various domains, including nuclear systems [91, 90, 75], power systems [96, 97, 10, 94, 104], industrial control systems [15, 14, 89, 81, 79, 20], multi-agent systems [92, 56, 72, 11, 56, 57], and interdependent infrastructures [12, 9, 35, 36, 74]. Incorporating emerging methods into cybersecurity research and practice holds great promise for advancing our understanding of cyber threats and improving our ability to defend against them. By leveraging nonequilibrium learning, large language models, and foundation models with strategic learning, organizations can stay ahead 28 of evolving threats and improve their cyber resilience in an increasingly complex and dynamic threat landscape. 7 Conclusions Dealing with cyber risk in today’s world is increasingly challenging. Mitigating cyber risk should not only involve cyber security defense mechanisms but also cyber resilience mechanisms, which complement each other to strengthen the cyber risk posture of the network. Understanding cyber risk and the associated resilience mechanisms requires the development of fundamental principles, metrics, and tools to analyze and design networks to achieve resilience goals. This chapter introduces game theory, control the- ory, and learning theory as the foundation for cyber resilience. Game theory has been shown to be suitable for modeling strategic interactions. Control theory has been piv- otal in dealing with dynamics and designing dynamic defenses. Learning theory plays an important role in bridging theory and practice through autonomous adaptation and dealing with uncertainties. The confluence of game theory, control theory, and learning theory emerges as a cornerstone for cyber resilience, enabling organizations to improve their cyber resilience posture. As cyber threats continue to escalate in complexity and frequency, the interdisciplinary framework presented in this chapter serves as a roadmap for organizations seeking to enhance their cyber resilience capabilities and navigate the intricate dynamics of modern cybersecurity challenges. References [1] V. V. Acharya, L. H. Pedersen, T. Philippon, and M. Richardson. Measuring systemic risk. The review of financial studies, 30(1):2–47, 2017. [2] R. Aumann and A. Brandenburger. Epistemic conditions for nash equilibrium. Econometrica: Journal of the Econometric Society, pages 1161–1180, 1995. [3] R. J. Aumann. Subjectivity and correlation in randomized strategies. Journal of mathematical Economics, 1(1):67–96, 1974. [4] R. J. Aumann. Agreeing to disagree. The Annals of Statistics, 4(6):1236–1239, 1976. [5] R. J. Aumann and A. Heifetz. Incomplete information. Handbook of game theory with economic applications, 3:1665–1686, 2002. [6] T. Bodstr¨om and T. H¨am¨al¨ainen. A novel method for detecting apt attacks by using ooda loop and black swan theory. In Computational Data and Social Net- 29 works: 7th International Conference, CSoNet 2018, Shanghai, China, December 18–20, 2018, Proceedings 7, pages 498–509. Springer, 2018. [7] T. B¨orgers. An introduction to the theory of mechanism design. Oxford University Press, USA, 2015. [8] W. Casey, J. A. Morales, E. Wright, Q. Zhu, and B. Mishra. Compliance signaling games: toward modeling the deterrence of insider threats. Computational and Mathematical Organization Theory, 22:318–349, 2016. [9] J. Chen, C. Touati, and Q. Zhu. A dynamic game approach to strategic design of secure and resilient infrastructure network. IEEE Transactions on Information Forensics and security, 15:462–474, 2019. [10] J. Chen and Q. Zhu. A game-theoretic framework for resilient and distributed generation control of renewable energies in microgrids. IEEE Transactions on Smart Grid, 8(1):285–295, 2016. [11] J. Chen and Q. Zhu. Control of multilayer mobile autonomous systems in adver- sarial environments: A games-in-games approach. IEEE Transactions on Control of Network Systems, 7(3):1056–1068, 2019. [12] J. Chen and Q. Zhu. A game-and decision-theoretic approach to resilient inter- dependent network analysis and design. Springer, 2019. [13] J. Chen and Q. Zhu. Interdependent strategic security risk management with bounded rationality in the internet of things. IEEE Transactions on Information Forensics and Security, 14(11):2958–2971, 2019. [14] J. Chen, Q. Zhu, and T. Ba¸sar. Dynamic contract design for systemic cyber risk management of interdependent enterprise networks. Dynamic Games and Applications, 11:294–325, 2021. [15] Z. A. Collier, M. Panwar, A. A. Ganin, A. Kott, and I. Linkov. Security metrics in industrial control systems. Cyber-security of SCADA and other industrial control systems, pages 167–185, 2016. [16] S. Fang and Q. Zhu. Fundamental limits of obfuscation for linear gaussian dy- namical systems: An information-theoretic approach. In 2021 American Control Conference (ACC), pages 4574–4579. IEEE, 2021. [17] S. Fang and Q. Zhu. Fundamental stealthiness–distortion trade-offs in cyber- physical systems. In Security and Resilience in Cyber-Physical Systems: Detec- tion, Estimation and Control, pages 37–60. Springer, 2022. [18] J. Farooq and Q. Zhu. Resource management for on-demand mission-critical internet of things applications. John Wiley & Sons, 2021. 30 [19] M. J. Farooq and Q. Zhu. Secure and reconfigurable network design for critical information dissemination in the internet of battlefield things (iobt). In 2017 15th International Symposium on Modeling and Optimization in Mobile, Ad Hoc, and Wireless Networks (WiOpt), pages 1–8. IEEE, 2017. [20] M. J. Farooq and Q. Zhu. Adaptive and resilient revenue maximizing dynamic resource allocation and pricing for cloud-enabled iot systems. In 2018 Annual American Control Conference (ACC), pages 5292–5297. IEEE, 2018. [21] M. J. Farooq and Q. Zhu. A multi-layer feedback system approach to resilient connectivity of remotely deployed mobile internet of things. IEEE Transactions on Cognitive Communications and Networking, 4(2):422–432, 2018. [22] M. J. Farooq and Q. Zhu. On the secure and reconfigurable multi-layer network design for critical information dissemination in the internet of battlefield things (iobt). IEEE Transactions on Wireless Communications, 17(4):2618–2632, 2018. [23] M. J. Farooq and Q. Zhu. Modeling, analysis, and mitigation of dynamic botnet formation in wireless iot networks. IEEE Transactions on Information Forensics and Security, 14(9):2412–2426, 2019. [24] A. A. Ganin, E. Massaro, A. Gutfraind, N. Steen, J. M. Keisler, A. Kott, R. Man- goubi, and I. Linkov. Operational resilience: concepts, design and analysis. Sci- entific reports, 6(1):1–12, 2016. [25] Y. Ge, T. Li, and Q. Zhu. Scenario-Agnostic Zero-Trust Defense with Explainable Threshold Policy: A Meta-Learning Approach. IEEE INFOCOM 2023 - IEEE Conference on Computer Communications Workshops (INFOCOM WKSHPS), 00:1–6, 2023. [26] Y. Ge and Q. Zhu. Mufaza: Multi-source fast and autonomous zero-trust authen- tication for 5g networks. In MILCOM 2022-2022 IEEE Military Communications Conference (MILCOM), pages 571–576. IEEE, 2022. [27] Y. Ge and Q. Zhu. Gazeta: Game-theoretic zero-trust authentication for defense against lateral movement in 5g iot networks. IEEE Transactions on Information Forensics and Security, 2023. [28] Y. Ge and Q. Zhu. Zero trust for cyber resilience. arXiv preprint arXiv:2312.02882, 2023. [29] J. C. Harsanyi. Games with incomplete information played by “bayesian” players, i–iii part i. the basic model. Management science, 14(3):159–182, 1967. [30] K. Hor´ak, Q. Zhu, and B. Boˇsansk`y. Manipulating adversary’s belief: A dynamic game approach to deception by design for proactive network security. In Decision and Game Theory for Security: 8th International Conference, GameSec 2017, 31 Vienna, Austria, October 23-25, 2017, Proceedings, pages 273–294. Springer, 2017. [31] Y. Hu and Q. Zhu. Evasion-aware neyman-pearson detectors: A game-theoretic approach. In 2022 IEEE 61st Conference on Decision and Control (CDC), pages 6111–6117. IEEE, 2022. [32] Y. Hu and Q. Zhu. Detection in human-sensor systems under quantum prospect theory using bayesian persuasion frameworks. In 2023 IEEE Statistical Signal Processing Workshop (SSP), pages 36–40. IEEE, 2023. [33] Y. Hu and Q. Zhu. Game of travesty: Decoy-based psychological cyber deception for proactive human agents. arXiv preprint arXiv:2309.13403, 2023. [34] L. Huang, J. Chen, and Q. Zhu. A large-scale markov game approach to dynamic protection of interdependent infrastructure networks. In International Confer- ence on Decision and Game Theory for Security, pages 357–376. Springer, 2017. [35] L. Huang, J. Chen, and Q. Zhu. Distributed and optimal resilient planning of large-scale interdependent critical infrastructures. In 2018 winter simulation conference (WSC), pages 1096–1107. IEEE, 2018. [36] L. Huang and Q. Zhu. A dynamic games approach to proactive defense strategies against advanced persistent threats in cyber-physical systems. Computers & Security, 89:101660, 2020. [37] L. Huang and Q. Zhu. Duplicity games for deception design with an application to insider threat mitigation. IEEE Transactions on Information Forensics and Security, 16:4843–4856, 2021. [38] Y. Huang, L. Huang, and Q. Zhu. Reinforcement learning for feedback-enabled cyber resilience. Annual reviews in control, 53:273–295, 2022. [39] Y. Huang, Z. Xiong, and Q. Zhu. Cross-layer coordinated attacks on cyber- physical systems: A lqg game framework with controlled observations. In 2021 European Control Conference (ECC), pages 521–528. IEEE, 2021. [40] S. Jajodia, V. Subrahmanian, V. Swarup, and C. Wang. Cyber deception. Cham, Switzerland: Springer, 2016. [41] T. Kieras, J. Farooq, and Q. Zhu. IoT supply chain security risk analysis and mitigation: Modeling, computations, and software tools. Springer Nature, 2022. [42] T. Li, K. Hammar, R. Stadler, and Q. Zhu. Conjectural online learning with first-order beliefs in asymmetric information stochastic games. arXiv preprint arXiv:2402.18781, 2024. 32 [43] T. Li, H. Lei, and Q. Zhu. Self-Adaptive Driving in Nonstationary Environments through Conjectural Online Lookahead Adaptation. 2023 IEEE International Conference on Robotics and Automation (ICRA), 00:7205–7211, 2023. [44] T. Li, Y. Pan, and Q. Zhu. Decision-dominant strategic defense against lateral movement for 5g zero-trust multi-domain networks. arXiv preprint arXiv:2310.01675, 2023. [45] T. Li, G. Peng, and Q. Zhu. Blackwell Online Learning for Markov Decision Processes. 2021 55th Annual Conference on Information Sciences and Systems (CISS), 00:1–6, 2021. [46] T. Li, G. Peng, Q. Zhu, and T. Baar. The Confluence of Networks, Games, and Learning a Game-Theoretic Framework for Multiagent Decision Making Over Networks. IEEE Control Systems, 42(4):35–67, 2022. [47] T. Li and Q. Zhu. Symbiotic game and foundation models for cyber deception operations in strategic cyber warfare. arXiv preprint arXiv:2403.10570, 2024. [48] I. Linkov, A. Ligo, K. Stoddard, B. Perez, A. Strelzoffx, E. Bellini, and A. Kott. Cyber efficiency and cyber resilience. Commun. ACM, 66(4):33–37, mar 2023. [49] S. Liu, Y. Zhao, and Q. Zhu. Herd behaviors in epidemics: A dynamics-coupled evolutionary games approach. Dynamic Games and Applications, 12(1):183–213, 2022. [50] S. Liu and Q. Zhu. Stackelberg risk preference design. arXiv preprint arXiv:2206.12938, 2022. [51] S. Liu and Q. Zhu. Cyber insurance for cyber resilience. arXiv preprint arXiv:2312.02921, 2023. [52] S. Maharjan, Q. Zhu, Y. Zhang, S. Gjessing, and T. Basar. Dependable demand response management in the smart grid: A stackelberg game approach. IEEE Transactions on Smart Grid, 4(1):120–132, 2013. [53] M. H. Manshaei, Q. Zhu, T. Alpcan, T. Bac¸sar, and J.-P. Hubaux. Game theory meets network security and privacy. ACM Computing Surveys (CSUR), 45(3):1– 39, 2013. [54] M. Mohebbi Moghaddam, M. H. Manshaei, and Q. Zhu. To trust or not: A secu- rity signaling game between service provider and client. In Decision and Game Theory for Security: 6th International Conference, GameSec 2015, London, UK, November 4-5, 2015, Proceedings 6, pages 322–333. Springer, 2015. [55] R. B. Myerson. Mechanism design. Springer, 1989. 33 [56] Y. Nugraha, A. Cetinkaya, T. Hayakawa, H. Ishii, and Q. Zhu. Dynamic resilient network games with applications to multiagent consensus. IEEE Transactions on Control of Network Systems, 8(1):246–259, 2020. [57] Y. Nugraha, A. Cetinkaya, T. Hayakawa, H. Ishii, and Q. Zhu. Rolling horizon games for cluster formation of resilient multiagent systems. In 2021 60th IEEE Conference on Decision and Control (CDC), pages 4829–4834. IEEE, 2021. [58] Y. Pan, T. Li, H. Li, T. Xu, Z. Zheng, and Q. Zhu. A First Order Meta Stackel- berg Method for Robust Federated Learning. In Adversarial Machine Learning Frontiers Workshop at 40th International Conference on Machine Learning, 6 2023. [59] Y. Pan, T. Li, and Q. Zhu. Is Stochastic Mirror Descent Vulnerable to Adver- sarial Delay Attacks? A Traffic Assignment Resilience Study. 2023 62nd IEEE Conference on Decision and Control (CDC), 00:8328–8333, 2023. [60] Y. Pan, T. Li, and Q. Zhu. On the Resilience of Traffic Networks under Non- Equilibrium Learning. 2023 American Control Conference (ACC), 00:3484–3489, 2023. [61] J. Pawlick, E. Colbert, and Q. Zhu. Modeling and analysis of leaky deception us- ing signaling games with evidence. IEEE Transactions on Information Forensics and Security, 14(7):1871–1886, 2018. [62] J. Pawlick, E. Colbert, and Q. Zhu. A game-theoretic taxonomy and survey of defensive deception for cybersecurity and privacy. ACM Computing Surveys (CSUR), 52(4):1–28, 2019. [63] J. Pawlick, S. Farhang, and Q. Zhu. Flip the cloud: Cyber-physical signaling games in the presence of advanced persistent threats. In Decision and Game Theory for Security: 6th International Conference, GameSec 2015, London, UK, November 4-5, 2015, Proceedings 6, pages 289–308. Springer, 2015. [64] J. Pawlick and Q. Zhu. A stackelberg game perspective on the conflict between machine learning and data obfuscation. In 2016 IEEE International Workshop on Information Forensics and Security (WIFS), pages 1–6. IEEE, 2016. [65] J. Pawlick and Q. Zhu. Proactive defense against physical denial of service attacks using poisson signaling games. In International Conference on Decision and Game Theory for Security, pages 336–356. Springer, 2017. [66] J. Pawlick and Q. Zhu. Strategic trust in cloud-enabled cyber-physical systems with an application to glucose control. IEEE Transactions on Information Foren- sics and Security, 12(12):2906–2919, 2017. [67] J. Pawlick, Q. Zhu, et al. Game theory for cyber deception. Springer, 2021. 34 [68] G. Peng and Q. Zhu. Game-theoretic analysis of optimal control and sampling for linear stochastic systems. In 2019 57th Annual Allerton Conference on Com- munication, Control, and Computing (Allerton), pages 647–654. IEEE, 2019. [69] Z. Qian, J. Fu, and Q. Zhu. A receding-horizon mdp approach for performance evaluation of moving target defense in networks. In 2020 IEEE Conference on Control Technology and Applications (CCTA), pages 1–7. IEEE, 2020. [70] S. Rass, S. Schauer, S. K¨onig, and Q. Zhu. Cyber-security in critical infrastruc- tures, volume 297. Springer, 2020. [71] S. Rass, S. Schauer, S. K¨onig, Q. Zhu, S. Rass, S. Schauer, S. K¨onig, and Q. Zhu. Bounded rationality. Cyber-Security in Critical Infrastructures: A Game- Theoretic Approach, pages 99–114, 2020. [72] C. Rieger, Q. Zhu, and T. Ba¸sar. Agent-based cyber control strategy design for resilient control systems: Concepts, architecture and methodologies. In 2012 5th International Symposium on Resilient Control Systems, pages 40–47. IEEE, 2012. [73] C. G. Rieger, D. I. Gertman, and M. A. McQueen. Resilient control systems: Next generation design research. In 2009 2nd Conference on Human System Interactions, pages 632–636. IEEE, 2009. [74] S. M. Rinaldi, J. P. Peerenboom, and T. K. Kelly. Identifying, understanding, and analyzing critical infrastructure interdependencies. IEEE control systems magazine, 21(6):11–25, 2001. [75] C. Smidts, I. Ray, Q. Zhu, P. K. Vaddi, Y. Zhao, L. Huang, X. Diao, R. Talukdar, and M. C. Pietrykowski. Cyber-security threats and response models in nuclear power plants. Springer, 2022. [76] O. Thakoor, S. Jabbari, P. Aggarwal, C. Gonzalez, M. Tambe, and P. Vayanos. Exploiting bounded rationality in risk-based cyber camouflage games. In Decision and Game Theory for Security: 11th International Conference, GameSec 2020, College Park, MD, USA, October 28–30, 2020, Proceedings 11, pages 103–124. Springer, 2020. [77] H. Van Brussel, J. Wyns, P. Valckenaers, L. Bongaerts, and P. Peeters. Reference architecture for holonic manufacturing systems: Prosa. Computers in industry, 37(3):255–274, 1998. [78] Z. Xu and Q. Zhu. A cyber-physical game framework for secure and resilient multi-agent autonomous systems. In 2015 54th IEEE Conference on Decision and Control (CDC), pages 5156–5161. IEEE, 2015. 35 [79] Z. Xu and Q. Zhu. Secure and resilient control design for cloud enabled networked control systems. In Proceedings of the first ACM workshop on cyber-physical systems-security and/or privacy, pages 31–42, 2015. [80] Z. Xu and Q. Zhu. Cross-layer secure and resilient control of delay-sensitive networked robot operating systems. In 2018 IEEE Conference on Control Tech- nology and Applications (CCTA), pages 1712–1717. IEEE, 2018. [81] Z. Xu and Q. Zhu. Secure and resilient control of iot-based 3d printers. Modeling and Design of Secure Internet of Things, pages 383–405, 2020. [82] Y. Yuan, Q. Zhu, F. Sun, Q. Wang, and T. Ba¸sar. Resilient control of cyber- physical systems against denial-of-service attacks. In 2013 6th International Sym- posium on Resilient Control Systems (ISRCS), pages 54–59. IEEE, 2013. [83] R. Zager and J. Zager. Ooda loops in cyberspace: A new cyber-defense model. J. Article, 21(12), 2017. [84] R. Zhang and Q. Zhu. FlipIn: A game-theoretic cyber insurance framework for incentive-compatible cyber risk management of internet of things. IEEE Transactions on Information Forensics and Security, 15:2026–2041, 2019. [85] R. Zhang and Q. Zhu. Optimal cyber-insurance contract design for dynamic risk management and mitigation. IEEE Transactions on Computational Social Systems, 9(4):1087–1100, 2021. [86] R. Zhang, Q. Zhu, and Y. Hayel. A bi-level game approach to attack-aware cyber insurance of computer networks. IEEE Journal on Selected Areas in Communi- cations, 35(3):779–794, 2017. [87] T. Zhang, L. Huang, J. Pawlick, and Q. Zhu. Game-theoretic analysis of cyber deception: Evidence-based strategies and dynamic risk mitigation. Modeling and Design of secure Internet of Things, pages 27–58, 2020. [88] T. Zhang and Q. Zhu. Hypothesis testing game for cyber deception. In Decision and Game Theory for Security: 9th International Conference, GameSec 2018, Seattle, WA, USA, October 29–31, 2018, Proceedings 9, pages 540–555. Springer, 2018. [89] Y. Zhao, J. Chen, and Q. Zhu. Integrated cyber-physical resiliency for power grids under iot-enabled dynamic botnet attacks. arXiv preprint arXiv:2401.01963, 2024. [90] Y. Zhao, L. Huang, C. Smidts, and Q. Zhu. A game theoretic approach for responding to cyber-attacks on nuclear power plants. In 11th Nuclear Plant Instrumentation, Control, and Human-Machine Interface Technologies, NPIC and HMIT 2019, pages 399–410. American Nuclear Society, 2019. 36 [91] Y. Zhao, L. Huang, C. Smidts, and Q. Zhu. Finite-horizon semi-markov game for time-sensitive attack response and probabilistic risk assessment in nuclear power plants. Reliability Engineering & System Safety, 201:106878, 2020. [92] Y. Zhao, C. Rieger, and Q. Zhu. Multi-agent learning for resilient distributed control systems. arXiv preprint arXiv:2208.05060, 2022. [93] Q. Zhu. Cyber insurance. arXiv preprint arXiv:1810.00290, 2018. [94] Q. Zhu. Multilayer cyber-physical security and resilience for smart grid. Smart grid control: overview and research opportunities, pages 225–239, 2019. [95] Q. Zhu and T. Ba¸sar. Dynamic policy-based ids configuration. In Proceedings of the 48h IEEE Conference on Decision and Control (CDC) held jointly with 2009 28th Chinese Control Conference, pages 8600–8605. IEEE, 2009. [96] Q. Zhu and T. Ba¸sar. Robust and resilient control design for cyber-physical systems with an application to power systems. In 2011 50th IEEE Conference on Decision and Control and European Control Conference, pages 4066–4071. IEEE, 2011. [97] Q. Zhu and T. Basar. Game-theoretic methods for robustness, security, and resilience of cyberphysical control systems: games-in-games principle for optimal cross-layer resilient control systems. IEEE Control Systems Magazine, 35(1):46– 65, 2015. [98] Q. Zhu and H. Ishii. Introduction to the special section on learning and security for multi-agent systems. Annual Reviews in Control, 53:249–251, 2022. [99] Q. Zhu and S. Rass. Game theory meets network security: A tutorial. In Pro- ceedings of the 2018 ACM SIGSAC conference on computer and communications security, pages 2163–2165, 2018. [100] Q. Zhu and S. Rass. On multi-phase and multi-stage game-theoretic modeling of advanced persistent threats. IEEE Access, 6:13958–13971, 2018. [101] Q. Zhu, H. Tembine, and T. Ba¸sar. Network security configurations: A nonzero- sum stochastic game approach. In Proceedings of the 2010 American control conference, pages 1059–1064. IEEE, 2010. [102] Q. Zhu, H. Tembine, and T. Ba¸sar. Distributed strategic learning with applica- tion to network security. In Proceedings of the 2011 American control conference, pages 4057–4062. IEEE, 2011. [103] Q. Zhu, H. Tembine, and T. Ba¸sar. Hybrid learning in stochastic games and its application in network security. Reinforcement Learning and Approximate Dynamic Programming for Feedback Control, pages 303–329, 2012. 37 [104] Q. Zhu, D. Wei, and T. Basar. Secure routing in smart grids. In Workshop on Foundations of Dependable and Secure Cyber-Physical Systems (FDSCPS), pages 55–59, 2011. [105] Q. Zhu and Z. Xu. Cross-layer design for secure and resilient cyber-physical systems. Springer, 2020. [106] R. Zimmerman, Q. Zhu, F. de Leon, and Z. Guo. Conceptual modeling frame- work to integrate resilient and interdependent infrastructure in extreme weather. Journal of Infrastructure Systems, 23(4):04017034, 2017. [107] R. Zimmerman, Q. Zhu, and C. Dimitri. Promoting resilience for food, energy, and water interdependencies. Journal of Environmental Studies and Sciences, 6:50–61, 2016. 38