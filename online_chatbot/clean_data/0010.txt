1 Attack Detection and Identiﬁcation in Cyber-Physical Systems – Part I: Models and Fundamental Limitations Fabio Pasqualetti, Florian D¨orﬂer, and Francesco Bullo Abstract—Cyber-physical systems integrate computation, com- munication, and physical capabilities to interact with the physical world and humans. Besides failures of components, cyber- physical systems are prone to malignant attacks, and speciﬁc analysis tools as well as monitoring mechanisms need to be developed to enforce system security and reliability. This paper proposes a uniﬁed framework to analyze the resilience of cyber- physical systems against attacks cast by an omniscient adversary. We model cyber-physical systems as linear descriptor systems, and attacks as exogenous unknown inputs. Despite its simplicity, our model captures various real-world cyber-physical systems, and it includes and generalizes many prototypical attacks, in- cluding stealth, (dynamic) false-data injection and replay attacks. First, we characterize fundamental limitations of static, dynamic, and active monitors for attack detection and identiﬁcation. Second, we provide constructive algebraic conditions to cast undetectable and unidentiﬁable attacks. Third, by using the system interconnection structure, we describe graph-theoretic conditions for the existence of undetectable and unidentiﬁable attacks. Finally, we validate our ﬁndings through some illustra- tive examples with different cyber-physical systems, such as a municipal water supply network and two electrical power grids. I. INTRODUCTION Cyber-physical systems arise from the tight integration of physical processes, computational resources, and communi- cation capabilities. More precisely, processing units monitor and control physical processes by means of sensors and actu- ators networks. Examples of cyber-physical systems include transportation networks, power generation and distribution networks, water and gas distribution networks, and advanced communication systems. Due to the crucial role of cyber- physical systems in everyday life, cyber-physical security needs to be promptly addressed. Besides failures and attacks on the physical infrastructure, cyber-physical systems are also prone to cyber attacks on their data management and communication layer. Recent studies and real-world incidents have demonstrated the inability of existing security methods to ensure a safe and reliable func- tionality of cyber-physical infrastructures against unforeseen failures and, possibly, external attacks [1]–[4]. The protection This material is based upon work supported in part by NSF grant CNS- 1135819 and by the Institute for Collaborative Biotechnologies through grant W911NF-09-0001 from the U.S. Army Research Ofﬁce. Fabio Pasqualetti, Florian D¨orﬂer, and Francesco Bullo are with the Center for Control, Dynamical Systems and Computation, University of California at Santa Barbara, {fabiopas,dorfler,bullo}@engineering.ucsb.edu of critical infrastructures is, as of today, one of the main focus of the Department of Homeland Security [5]. Concerns about security of control systems are not new, as the numerous manuscripts on systems fault detection, isolation, and recovery testify; see for example [6], [7]. Cyber- physical systems, however, suffer from speciﬁc vulnerabilities which do not affect classical control systems, and for which appropriate detection and identiﬁcation techniques need to be developed. For instance, the reliance on communication networks and standard communication protocols to transmit measurements and control packets increases the possibility of intentional and worst-case (cyber) attacks against physical plants. On the other hand, information security methods, such as authentication, access control, message integrity, and cryptography methods, appear inadequate for a satisfactory protection of cyber-physical systems. Indeed, these security methods do not exploit the compatibility of the measurements with the underlying physical process and control mechanism, which are the ultimate objective of a protection scheme [8]. Moreover, such information security methods are not effective against insider attacks carried out by authorized entities, as in the famous Maroochy Water Breach case [3], and they also fail against attacks targeting directly the physical dynamics [9]. Related work. The analysis of vulnerabilities of cyber- physical systems to external attacks has received increasing attention in the last years. The general approach has been to study the effect of speciﬁc attacks against particular sys- tems. For instance, in [10] deception and denial of service attacks against a networked control system are introduced, and, for the latter ones, a countermeasure based on semi- deﬁnite programming is proposed. Deception attacks refer to the possibility of compromising the integrity of control packets or measurements, and they are cast by altering the behavior of sensors and actuators. Denial of service attacks, instead, compromise the availability of resources by, for instance, jam- ming the communication channel. In [11] false data injection attacks against static state estimators are introduced. False data injection attacks are speciﬁc deception attacks in the context of static estimators. It is shown that undetectable false data injection attacks can be designed even when the attacker has limited resources. In a similar fashion, stealthy deception attacks against the Supervisory Control and Data Acquisition system are studied, among others, in [12], [13]. In [14] the effect of replay attacks on a control system is discussed. Replay attacks are cast by hijacking the sensors, recording the readings for a certain amount of time, and repeating such arXiv:1202.6144v2 [math.OC] 10 Mar 2012 2 readings while injecting an exogenous signal into the system. It is shown that this type of attack can be detected by injecting a signal unknown to the attacker into the system. In [15] the effect of covert attacks against networked control sys- tems is investigated. Speciﬁcally, a parameterized decoupling structure allows a covert agent to alter the behavior of the physical plant while remaining undetected from the original controller. In [16] a resilient control problem is studied, in which control packets transmitted over a network are corrupted by a human adversary. A receding-horizon Stackelberg control law is proposed to stabilize the control system despite the attack. Recently the problem of estimating the state of a linear system with corrupted measurements has been studied [17]. More precisely, the maximum number of faulty sensors that can be tolerated is characterized, and a decoding algorithm is proposed to detect corrupted measurements. Finally, security issues of some speciﬁc cyber-physical systems have received considerable attention, such as power networks [1], [2], [9], [12], [18]–[22], linear networks with misbehaving components [23], [24], and water networks [3], [13], [15], [25]. Contributions. The contributions of this paper are as fol- lows. First, we describe a uniﬁed modeling framework for cyber-physical systems and attacks. Motivated by existing cyber-physical systems and proposed attack scenarios, we model a cyber-physical system under attack as a descriptor system subject to unknown inputs affecting the state and the measurements. For our model, we deﬁne the notions of detectability and identiﬁability of an attack by its effect on output measurements. Informed by the classic work on geometric control theory [26], our framework includes the deterministic static detection problem considered in [11], [12], and the prototypical deception and denial of service [10], stealth [18], (dynamic) false-data injection [27], replay [14], and covert attacks [15] as special cases. Second, we show the fundamental limitations of static, dynamic, and active detection and identiﬁcation procedures. Speciﬁcally, we show that static detection procedures are unable to detect any attack affecting the dynamics, and that attacks corrupting the measurements can be easily designed to be undetectable. On the contrary, we show that undetectability in a dynamic setting is much harder to achieve for an attacker. Speciﬁ- cally, a cyber-physical attack is undetectable if and only if the attackers’ signal excites uniquely the zero dynamics of the input/output system. Additionally, we show that active monitors capable of injecting test signals are as powerful as dynamic (passive) monitors, since an attacker can design undetectable and unidentiﬁable attacks without knowing the signal injected by the monitor into the system. This analysis bring us also to the conclusion that undetectable attacks can be cast even without knowledge of system noise. Third, we provide a graph theoretic characterization of undetectable attacks. Speciﬁcally, we borrow some tools from the theory of structured systems, and we identify conditions on the system interconnection structure for the existence of undetectable attacks. These conditions are generic, in the sense that they hold for almost all numerical systems with the same structure, and they can be efﬁciently veriﬁed. As a complementary result, we extend a result of [28] on structural left-invertibility to regular descriptor systems. Fourth and ﬁnally, we illustrate the potential impact of our theoretical ﬁndings through compelling examples. In particular, we design (i) an undetectable state attack to destabilize the WSSC 3-machine 6-bus power system, (ii) an undetectable output attack for the IEEE 14 bus system, and (iii) an undetectable state and output attack to steal water from a reservoir of the EPANET network model 3. Through these examples we show the advantages of dynamic monitors against static ones, and we provide insight on the design of attacks. Paper organization. The remainder of the paper is organized as follows. Section II presents some examples of cyber- physical systems. Section III contains our models of cyber- physical systems, attacks, and monitors. Our main results are presented in Section IV and in Section V. In particular, in Section IV we describe the fundamental limitations of static, dynamic, and active detectors, and we provide constructive algebraic conditions for the existence of undetectable and unidentiﬁable attacks. In Section V, instead, we derive graph- theoretic conditions for the existence of undetectable and unidentiﬁable attacks. Finally, Section VI and Section VII con- tain, respectively, our illustrative examples and our conclusion. II. EXAMPLES OF CYBER-PHYSICAL SYSTEMS We now motivate our study by introducing important cyber- physical systems requiring advanced security mechanisms. A. Power networks Future power grids will combine physical dynamics with a sophisticated coordination infrastructure. The cyber-physical security of the grid has been identiﬁed as an issue of primary concern [1], [2], which has recently attracted the interest of the control and power systems communities, see [12], [18]–[22]. We adopt the small-signal version of the classical structure- preserving power network model; see [19], [20] for a de- tailed derivation from the full nonlinear structure-preserving power network model. Consider a connected power network consisting of n generators {g1, . . . , gn} and m load buses {bn+1, . . . , bn+m}. The interconnection structure of the power network is encoded by a connected susceptance-weighted graph. The generators gi and buses bi are the vertex set of this graph, and the edges are the transmission lines {bi, bj} weighted by the susceptance between buses bi and bj, as well as the connections {gi, bi} weighted by the transient susceptance between generator gi and its adjacent bus bi. The Laplacian associated with the susceptance-weighted graph is the symmetric susceptance matrix L = h Lgg Lgl Llg Lll i ∈ R(n+m)×(n+m), where the ﬁrst n rows are associated with the generators and the last m rows correspond to the buses. The dynamic model of the power network is   I 0 0 0 Mg 0 0 0 0     ˙δ(t) ˙ω(t) ˙θ(t)  =−   0 −I 0 Lgg Dg Lgl Llg 0 Lll     δ(t) ω(t) θ(t)  +   0 Pω(t) Pθ(t)  , (1) where δ(t) ∈Rn and ω(t) ∈Rn denote the generator rotor angles and frequencies, and θ(t) ∈Rm are the voltage angles 3 at the buses. The terms Mg and Dg are the diagonal matrices of the generator inertial and damping coefﬁcients, and the inputs Pω(t) and Pθ(t) are due to known changes in mechanical input power to the generators or real power demand at the loads. B. Mass transport networks Mass transport networks are prototypical examples of cyber- physical systems modeled by differential-algebraic equations, such as gas transmission and distribution networks [29], large- scale process engineering plants [30], and water networks. Examples of water networks include open channel ﬂows [31] for irrigation purposes and municipal water networks [32], [33]. The vulnerability of open channel networks to cyber- physical attacks has been studied in [13], [15], and municipal water networks are also known to be susceptible to attacks on the hydraulics [3] and biochemical contamination threats [25]. We focus on the hydraulics of a municipal water distribution network, as modeled in [32], [33]. The water network can be modeled as a directed graph with node set consisting of reservoirs, junctions, and storage tanks, and with edge set given by pipes, pumps, and valves that are used to convey water from source points to consumers. The key variables are the pressure head hi at each node i in the network as well as the ﬂows Qij from node i to j. The hydraulic model governing the network dynamics includes constant reservoir heads, ﬂow balance equations at junctions and tanks, and pressure difference equations along all edges: reservoir i : hi = hi reservoir = constant , junction i : di = X j→iQji − X i→kQik , tank i : Ai ˙hi = X j→iQji − X i→kQik , pipe (i, j) : Qij = Qij(hi −hj) , pump (i, j) : hj −hi = +∆hij pump = constant , valve (i, j) : hj −hi = −∆hij valve = constant . (2) Here di is the demand at junction i, Ai is the (constant) cross- sectional area of storage tank i, and the notation “j →i” denotes the set of nodes j connected to node i. The ﬂow Qij depends on the pressure drop hi −hj along pipe according to the Hazen-Williams equation Qij(hi −hj) = gij|hi − hj|1/1.85−1 ·(hi −hj), where gij > 0 is the pipe conductance. Other interesting examples of cyber-physical systems cap- tured by our modeling framework are sensor networks, dy- namic Leontief models of multi-sector economies, mixed gas- power energy networks, and large-scale control systems. III. MATHEMATICAL MODELING OF CYBER-PHYSICAL SYSTEMS, MONITORS, AND ATTACKS In this section we model cyber-physical systems under attack as linear time-invariant descriptor systems subject to unknown inputs. This modeling framework is very general and includes most of the existing cyber-physical models, attacks, and fault scenarios. Indeed, as shown in Section II, many interesting real-world cyber-physical systems contain conserved physical quantities leading to differential-algebraic system descriptions, and, as we show later, most attack and fault scenarios can be modeled by additive inputs affecting the state and the measurements. Model of cyber-physical systems under attack. We consider the linear time-invariant descriptor system1 E ˙x(t) = Ax(t) + Bu(t), y(t) = Cx(t) + Du(t), (3) where x(t) ∈Rn, y(t) ∈Rp, E ∈Rn×n, A ∈Rn×n, B ∈ Rn×m, C ∈ Rp×n, and D ∈ Rp×m. Here the matrix E is possibly singular, and the input terms Bu(t) and Du(t) are unknown signals describing disturbances af- fecting the plant. Besides reﬂecting the genuine failure of systems components, these disturbances model the effect of an attack against the cyber-physical system (see below for our attack model). For notational convenience and without affecting generality, we assume that each state and output variable can be independently compromised by an attacker. Thus, we let B = I, 0 and D = 0, I be partitioned into identity and zero matrices of appropriate dimensions, and, accordingly, u(t) =  ux(t)T, uy(t)TT. Hence, the attack (Bu(t), Du(t)) = (ux(t), uy(t)) can be classiﬁed as state attack affecting the system dynamics and as output attack corrupting directly the measurements vector. The attack signal t 7→u(t) ∈Rn+p depends upon the speciﬁc attack strategy. In the presence of k ∈N0, k ≤n + p, attackers indexed by the attack set K ⊆{1, . . . , n + p} only and all the entries K of u(t) are nonzero over time. To underline this sparsity relation, we sometimes use uK(t) to denote the attack mode, that is the subvector of u(t) indexed by K. Accordingly, the pair (BK, DK), where BK and DK are the submatrices of B and D with columns in K, to denote the attack signature. Hence, Bu(t) = BKuK(t), and Du(t) = DKuK(t). Since the matrix E may be singular, we make the following assumptions on system (3): (A1) the pair (E, A) is regular, that is, det(sE −A) does not vanish identically, (A2) the initial condition x(0) ∈Rn is consistent, that is, (Ax(0) + Bu(0)) ⊥Ker(ET) = 0; and (A3) the input signal u(t) is smooth. The regularity assumption (A1) assures the existence of a unique solution x(t) to (3). Assumptions (A2) and (A3) simplify the technical presentation in this paper since they guarantee smoothness of the state trajectory x(t) and the measurements y(t); see [34, Lemma 2.5] for further details. The degree of smoothness in assumption (A3) depends on the index of (E, A), see [35, Theorem 2.42], and continuity of u(t) is sufﬁcient for the index-one examples presented in Section II. In Section IV-E we discuss the results in this paper if assumptions (A2) and (A3) are dropped. Model of static, dynamic, and active monitors. A monitor is a pair (Φ, γ(t)), where Φ : Λ →Ψ is an algorithm, and γ : R 7→Rn+p is a signal. In particular, Λ is the 1The results stated in this paper for continuous-time descriptor systems hold also for discrete-time descriptor systems and nonsingular systems. Moreover, we neglect the presence of known inputs, since, due to the linearity of system (3), they do not affect our results on the detectability and identiﬁability of unknown input attacks. 4 algorithm input to be speciﬁed later, Ψ = {ψ1, ψ2}, with ψ1 ∈{True, False} and ψ2 ⊆{1, . . . , n + p}, is the algorithm output, and (Bγ(t), Dγ(t)) is an auxiliary input injected by the monitor into the system (3). In this work we consider the following classes of monitors for the system (3). Deﬁnition 1: (Static monitor) A static monitor is a monitor with γ(t) = 0 ∀t ∈R≥0, and Λ = {C, y(t) ∀t ∈N}. Note that static monitors do not exploit relations among measurements taken at different time instants. An example of static monitor is the bad data detector [36]. Deﬁnition 2: (Dynamic monitor) A dynamic monitor is a monitor with γ(t) = 0 ∀t ∈ R≥0, and Λ = {E, A, C, y(t) ∀t ∈R≥0}. Differently from static monitors, dynamic monitors have knowledge of the system dynamics generating y(t) and may exploit temporal relations among different measurements. The ﬁlters deﬁned in [21] are examples of dynamic monitors. Deﬁnition 3: (Active monitor) An active monitor is a monitor with γ(t) ̸= 0 for some t ∈R≥0, and Λ = {E, A, C, y(t) ∀t ∈R≥0}. Active monitors are dynamic monitors with the ability of modifying the system dynamics through an input. An example of active monitor is presented in [14] to detect replay attacks. The objective of a monitor is twofold: Deﬁnition 4: (Attack detection) A nonzero attack (BKuK(t), DKuK(t)) is detected by a monitor if ψ1 = True. Deﬁnition 5: (Attack identiﬁcation) A nonzero attack (BKuK(t), DKuK(t)) is identiﬁed by a monitor if ψ2 = K. An attack is called undetectable (respectively unidentiﬁable) by a monitor if it fails to be detected (respectively identiﬁed) by every monitor in the same class. Of course, an undetectable attack is also unidentiﬁable, since it cannot be distinguished from the zero attack. By extension, an attack set K is unde- tectable (respectively unidentiﬁable) if there exists an unde- tectable (respectively unidentiﬁable) attack (BKuK, DKuK). Model of attacks. In this work we consider colluding omni- scient attackers with the ability of altering the cyber-physical dynamics through exogenous inputs. In particular we let the attack (Bu(t), Du(t)) in (3) be designed based on knowledge of the system structure and parameters E, A, C, and the full state x(t) at all times. Additionally, attackers have unlimited computation capabilities, and their objective is to disrupt the physical state or the measurements while avoiding detection. Remark 1: (Existing attack strategies as subcases) The following prototypical attacks can be modeled and analyzed through our theoretical framework: (i) stealth attacks deﬁned in [18] correspond to output attacks compatible with the measurements equation; (ii) replay attacks deﬁned in [14] are state and output attacks which affect the system dynamics and reset the measurements; (iii) covert attacks deﬁned in [15] are closed-loop replay attacks, where the output attack is chosen to cancel out the effect on the measurements of the state attack; and (iv) (dynamic) false-data injection attacks deﬁned in [27] are output attacks rendering an unstable mode (if any) of the system unobservable. + y(t) Du(t) C x(t) C ˜u(t) (a) Static stealth attack (sE −A)−1 C x(t) + y(t) x(0) B¯u(t) Du(t) ˜x(0) +− (sE −A)−1 C (b) Replay attack (sE −A)−1 C x(t) + y(t) x(0) B¯u(t) Du(t) − (sE −A)−1 C (c) Covert attack (sE −A)−1 C x(t) + y(t) x(0) Du(t) C(sE −A)−1￿ (s −p) −1 ￿ (d) Dynamic false data injection Fig. 1. A block diagram illustration of prototypical attacks is here reported. In Fig. 1(a) the attacker corrupts the measurements y(t) with the signal DKuK(t) ∈Im(C). Notice that in this attack the dynamics of the system are not considered. In Fig. 1(a) the attacker affects the output so that y(t) = y(x(0), [¯uT K uT K]T, t) = y(˜x(0), 0, t). The covert attack in Fig. 1(c) is a feedback version of the replay attack, and it can be explained analogously. In Fig. 1(d) the attack is such that the unstable pole p is made unobservable. A possible implementation of the above attacks in our model is illustrated in Fig. 1. □ To conclude this section we remark that the examples presented in Section II are captured in our framework. In particular, classical power networks failures modeled by ad- ditive inputs include sudden change in the mechanical power input to generators, lines outage, and sensors failure; see [21] for a detailed discussion. Analogously, for a water network, faults modeled by additive inputs include leakages, variation in demand, and failures of pumps and sensors. Possible cyber- physical attacks in both power and water networks include comprising measurements [11]–[13] and attacks on the control architecture or the physical state itself [2], [3], [9], [22]. IV. LIMITATIONS OF STATIC, DYNAMIC AND ACTIVE MONITORS FOR DETECTION AND IDENTIFICATION The objective of this section is to highlight fundamental detection and identiﬁcation limitations of static, dynamic, and active monitors. In particular, we show that the performance of widely used static monitors can be greatly improved by exploiting the system dynamics. On the other hand, the pos- sibility of injecting monitoring signals does not improve the detection capabilities of a (passive) dynamic monitor. Observe that a cyber-physical attack is undetectable if there exists a normal operating condition of the system under which the output would be the same as under the perturbation due to the attacker. Let y(x0, u, t) be the output sequence generated from the initial state x0 under the attack signal u(t). Lemma 4.1: (Undetectable attack) For the linear descriptor system (3), the attack (BKuK, DKuK) is undetectable by a static monitor if and only if y(x1, uK, t) = y(x2, 0, t) for some initial condition x1, x2 ∈Rn and for t ∈N0. If the same holds for t ∈R≥0, then the attack is also undetectable by a dynamic monitor. Lemma 4.1 follows from the fact that our monitors are deterministic, so that y(x1, uK, t) and y(x2, 0, t) lead to the same output ψ1. A more general concern than detectability is identiﬁability of attackers, that is, the possibility to distinguish 5 from measurements between the action of two distinct attacks. We quantify the strength of an attack through the cardinality of the attack set. Since an attacker can independently compromise any state variable or measurement, every subset of the states and measurements of ﬁxed cardinality is a possible attack set. Lemma 4.2: (Unidentiﬁable attack) For the linear descrip- tor system (3), the attack (BKuK, DKuK) is unidentiﬁable by a static monitor if and only if y(x1, uK, t) = y(x2, uR, t) for some initial condition x1, x2 ∈Rn, attack (BRuR, DRuR) with |R| ≤|K| and R ̸= K, and for t ∈N0. If the same holds for t ∈R≥0, then the attack is also unidentiﬁable by a dynamic monitor. Lemma 4.2 follows analogously to Lemma 4.1. We now elaborate on the above lemmas to derive fundamental detection and identiﬁcation limitations for the considered monitors. A. Fundamental limitations of static monitors Following Lemma 4.1, an attack is undetectable by a static monitor if and only if, for all t ∈N0, there exists a vector ξ(t) such that y(t) = Cξ(t). Notice that this condition is compatible with [11], where an attack is detected if and only if the residual r(t) = y(t)−˜Cˆx(t) is nonzero for some t ∈N0, where ˆx(t) = C†y(t). In the following, let ∥v∥0 denote the number of nonzero components of the vector v. Theorem 4.3: (Static detectability of cyber-physical at- tacks) For the cyber-physical descriptor system (3) and an attack set K, the following statements are equivalent: (i) the attack set K is undetectable by a static monitor; (ii) there exists an attack mode uK(t) satisfying, for some x(t) and at every t ∈N0, Cx(t) + DKuK(t) = 0. (4) Moreover, there exists an attack set K, with |K| = k ∈N0, undetectable by a static monitor if and only if there exist x ∈ Rn such that ∥Cx∥0 = k. Before presenting a proof of the above theorem, we high- light that a necessary and sufﬁcient condition for the equation (4) to be satisﬁed is that DKuK(t) = uy,K(t) ∈Im(C) at all times t ∈N0, where uy,K(t) is the vector of the last p components of uK(t). Hence, statement (ii) in Theorem 4.3 implies that no state attack can be detected by a static detection procedure, and that an undetectable output attack exists if and only if Im(DK) ∩Im(C) ̸= {0}. Proof of Theorem 4.3: As previously discussed, the attack K is undetectable by a static monitor if and only if for each t ∈N there exists x(t), and uK(t) such that r(t) = y(t) −CC†y(t) = (I −CC†) (Cx(t) + DKuK(t)) vanishes. Consequently, r(t) = (I −CC†)DKuK(t), and the attack set K is undetectable if and only if DKuK(t) ∈Im(C), which is equivalent to statement (ii). The last necessary and sufﬁcient condition in the theorem follows from (ii), and the fact that every output variable can be attacked independently of each other since D = 0, I . We now focus on the static identiﬁcation problem. Follow- ing Lemma 4.2, the following result can be asserted. Theorem 4.4: (Static identiﬁcation of cyber-physical at- tacks) For the cyber-physical descriptor system (3) and an attack set K, the following statements are equivalent: (i) the attack set K is unidentiﬁable by a static monitor; (ii) there exists an attack set R, with |R| ≤|K| and R ̸= K, and attack modes uK(t), uR(t) satisfying, for some x(t) and at every t ∈N0, Cx(t) + DK (uK(t) + uR(t)) = 0. Moreover, there exists an attack set K, with |K| = k ∈N0, unidentiﬁable by a static monitor if and only if there exists an attack set ¯K, with | ¯K| ≤2k, which is undetectable by a static monitor. Similar to the fundamental limitations of static detectability in Theorem 4.3, Theorem 4.4 implies that, for instance, state attacks cannot be identiﬁed and that an undetectable output attack of cardinality k exists if and only if Im(D ¯ K)∩Im(C) ̸= {0}, for some attack set ¯K with | ¯K| ≤2k. Proof of Theorem 4.4: Due to linearity of the system (3), the unidentiﬁability condition in Lemma 4.2 is equivalent to y(xK −xR, uK −uR, t) = 0, for some initial conditions xK, xR, and attack modes uK(t), uR(t). The equivalence between statements (i) and (ii) follows. The last statement follows from Theorem 4.3. B. Fundamental limitations of dynamic monitors As opposed to a static monitor, a dynamic monitor checks for the presence of attacks at every time t ∈R≥0. Intuitively, a dynamic monitor is harder to mislead than a static monitor. The following theorem formalizes this expected result. Theorem 4.5: (Dynamic detectability of cyber-physical at- tacks) For the cyber-physical descriptor system (3) and an attack set K, the following statements are equivalent: (i) the attack set K is undetectable by a dynamic monitor; (ii) there exists an attack mode uK(t) satisfying, for some x(0) and for every t ∈R≥0, E ˙x(t) = Ax(t) + BKuK(t) , 0 = Cx(t) + DKuK(t) ; (iii) there exist s ∈C, g ∈R|K|, and x ∈Rn, with x ̸= 0, such that (sE −A)x −BKg = 0 and Cx + DKg = 0. Moreover, there exists an attack set K, with |K| = k, undetectable by a dynamic monitor if and only if there exist s ∈C and x ∈Rn such that ∥(sE −A)x∥0 + ∥Cx∥0 = k. Before proving Theorem 4.5, some comments are in order. First, differently from the static case, state attacks can be detected in the dynamic case. Second, in order to mislead a dynamic monitor an attacker needs to inject a signal which is consistent with the system dynamics at every instant of time. Hence, as opposed to the static case, the condition DKuK(t) = uy,K(t) ∈Im(C) needs to be satisﬁed for every t ∈R≥0, and it is only necessary for the undetectability of an output attack. Indeed, for instance, state attacks can be detected even though they automatically satisfy the condition DKuK(t) = 0 ∈Im(C). Third and ﬁnally, according to 6 the last statement of Theorem 4.5, the existence of invariant zeros2 for the system (E, A, BK, C, DK) is equivalent to the existence of undetectable attacks. As a consequence, a dynamic monitor performs better than a static monitor, while requiring, possibly, fewer measurements. We refer to Section VI-B for an illustrative example of this last statement. Proof of Theorem 4.5: By Lemma 4.1 and linearity of the system (7), the attack mode uK(t) is undetectable by a dynamic monitor if and only if there exists x0 such that y(x0, uK, t) = 0 for all t ∈R≥0, that is, if and only if the system (3) features zero dynamics. Hence, statements (i) and (ii) are equivalent. For a linear descriptor system with smooth input and consistent initial condition, the existence of zero dynamics is equivalent to the existence of invariant zeros [34, Theorem 3.2 and Proposition 3.4]. The equivalence of statements (ii) and (iii) follows. The last statement follows from (iii), and the fact that B = I, 0 and D = 0, I . We now consider the identiﬁcation problem. Theorem 4.6: (Dynamic identiﬁability of cyber-physical attacks) For the cyber-physical descriptor system (3) and an attack set K, the following statements are equivalent: (i) the attack set K is unidentiﬁable by a dynamic monitor; (ii) there exists an attack set R, with |R| ≤|K| and R ̸= K, and attack modes uK(t), uR(t) satisfying, for some x(0) and for every t ∈R≥0, E ˙x(t) = Ax(t) + BKuK(t) + BRuR(t) , 0 = Cx(t) + DKuK(t) + DRuR(t) ; (iii) there exists an attack set R, with |R| ≤|K| and R ̸= K, s ∈C, gK ∈R|K|, gR ∈R|R|, and x ∈Rn, with x ̸= 0, such that (sE −A)x −BKgK −BRgR = 0 and Cx + DKgK + DRgR = 0. Moreover, there exists an attack set K, with |K| = k ∈N0, unidentiﬁable by a dynamic monitor if and only if there exists an attack set ¯K, with | ¯K| ≤2k, which is undetectable by a dynamic monitor. Proof: Notice that, because of the linearity of the system (3), the unidentiﬁability condition in Lemma 4.2 is equivalent to the condition y(xK −xR, uK −uR, t) = 0, for some initial conditions xK, xR, and attack modes uK(t), uR(t). The equivalence between statements (i) and (ii) follows. Finally, the last two statements follow from Theorem 4.5, and the fact that B = I, 0 and D = 0, I . In other words, the existence of an unidentiﬁable attack set K of cardinality k is equivalent to the existence of invariant zeros for the system (E, A, B ¯ K, C, D ¯ K), for some attack set ¯K with | ¯K| ≤2k. We conclude this section with the following remarks. The existence condition in Theorem 3.4 is hard to verify because of its combinatorial complexity: in order to check if there exists an unidentiﬁable attack set K, with |K| = k, one needs to certify the absence of invariant zeros for all possible 2k-dimensional attack sets. Thus, a conservative 2For the system (E, A, BK, C, DK), the value s ∈C is an invariant zero if there exists x ∈Rn, with x ̸= 0, g ∈R|K|, such that (sE−A)x−BKg = 0 and Cx + DKg = 0. veriﬁcation scheme requires  n+p 2k  tests. In Section V we present intuitive graph-theoretic conditions for the existence of undetectable and unidentiﬁable attack sets for a given sparsity pattern of the system matrices and generic system parameters. Finally, Theorem 4.6 includes as a special case Proposition 4 in [17], which considers exclusively output attacks. C. Fundamental limitations of active monitors An active monitor uses a control signal (unknown to the attacker) to reveal the presence of attacks; see [14] for the case of replay attacks. In the presence of an active monitor with input signal w(t) = [wT x(t) wT y (t)]T, the system (3) reads as E ˙x(t) = Ax(t) + BKuK(t) + wx(t), y(t) = Cx(t) + DKuK(t) + wy(t). Although the attacker is unaware of the signal w(t), active and dynamic monitors share the same limitations. Theorem 4.7: (Limitations of active monitors) For the cyber-physical descriptor system (3), let w(t) be an additive signal injected by an active monitor. The existence of unde- tectable (respectively unidentiﬁable) attacks does not depend upon the signal w(t). Moreover, undetectable (respectively unidentiﬁable) attacks can be designed independently of w(t). Proof: For the system (3), let u(t) be the attack mode, and let w(t) be the monitoring input. Let y(x, u, w, t) denotes the output generated by the inputs u(t) and w(t) with initial condition x = x1 + x2. Observe that, because of the linearity of (3), we have y(x, u, w, t) = y(x1, u, 0, t) + y(x2, 0, w, t), with consistent initial conditions x1 and x2. Then, an attack u(t) is undetectable if and only if y(x, u, w, t) = y(¯x, 0, w, t), or equivalently y(x1, u, 0, t) + y(x2, 0, w, t) = y(¯x1, 0, 0, t) + y(x2, 0, w, t), for some initial conditions x and ¯x = ¯x1 + x2. The statement follows, since, from the equality above, the detectability of u(t) does not depend upon w(t). As a consequence of Theorem 4.7, the existence of un- detectable attacks is independent of the presence of known control signals. Therefore, in a worst-case scenario, active monitors are as powerful as dynamic monitors. Since replay attacks are detectable by an active monitor [14], Theorem 4.7 shows that replay attacks are not worst-case attacks. Remark 2: (Undetectable attacks in the presence of state and measurements noise) The input w(t) in Theorem 4.7 may represent sensors and actuators noise. In this case, Theorem 4.7 states that the existence of undetectable attacks for a noise- free system implies the existence of undetectable attacks for the same system driven by noise. The converse does not hold, since attackers may remain undetected by injecting a signal compatible with the noise statistics. □ D. Speciﬁc results for index-one singular systems For many interesting real-world descriptor systems, includ- ing the examples in Section II-A and II-B, the algebraic system equations can be solved explicitly, and the descriptor system (3) can be reduced to a nonsingular state space system. For this reason, this section presents speciﬁc results for the case of 7 index-one systems [37]. In this case, without loss of generality, we assume the system (3) to be written in the canonical form E11 0 0 0   ˙x1 ˙x2  = A11 A12 A21 A22  x1 x2  + B1 B2  uK(t), y(t) = C1 C2   x1 x2  + DKuK(t), (5) where E11 is nonsingular and A22 is nonsingular. Conse- quently, the state x1 and x2 are referred to as dynamic state and algebraic state, respectively. The algebraic state can be expressed via the dynamic state and the attack mode as x2(t) = −A−1 22 A21x1(t) −A−1 22 B2uK(t). (6) The elimination of the algebraic state x2 in the descriptor system (5) leads to the nonsingular state space system ˙x1 = E−1 11  A11 −A12A−1 22 A21  | {z } ˜ A x1(t) + E−1 11  B1 −A12A−1 22 B2  | {z } ˜ BK uK(t), (7) y(t) =  C1 −C2A−1 22 A21  | {z } ˜ C x1(t) +  DK −C2A−1 22 B2  | {z } ˜ DK uK(t). This reduction of the algebraic states is known as Kron reduction in the literature on power networks and circuit theory [38]. Hence, we refer to (7) as the Kron-reduced system. Clearly, for any state trajectory x1(t) of the Kron-reduced system (7), the corresponding state trajectory [xT 1 (t) xT 2 (t)]T of the (non-reduced) cyber-physical descriptor system (3) can be recovered by identity (6) and given knowledge of the input uK(t). The following subtle issues are easily visible in the Kron-reduced system (6). First, a state attack affects directly the output y(t), provided that C2A−1 22 B2uK(t) ̸= 0. Second, since the matrix A−1 22 is generally fully populated, an attack on a single algebraic component can affect not only the locally attacked state or its vicinity but larger parts of the system. According to the transformations in (7), for each attack set K, the attack signature (BK, DK) is mapped to the corre- sponding signature ( ˜BK, ˜DK) in the Kron-reduced system. As an apparent disadvantage, the sparsity pattern of the original (non-reduced) cyber-physical descriptor system (3) is lost in the Kron-reduced representation (7), and so is, possibly, the physical interpretation of the state and the direct representation of system components. However, as we show in the following lemma, the notions of detectability and identiﬁability of an attack set K deﬁned for the original descriptor system (3) are equivalent for the Kron-reduced system (7). This property renders the low-dimensional and nonsingular Kron-reduced system (7) attractive from a computational point of view to design attack detection and identiﬁcation monitors; see [39]. Lemma 4.8: (Equivalence of detectability and identiﬁabil- ity under Kron reduction) For the cyber-physical descriptor system (3), the attack set K is detectable (respectively identi- ﬁable) if and only if it is detectable (respectively identiﬁable) for the associated Kron-reduced system (7). Proof: The lemma follows from the fact that the input and initial condition to output map for the system (3) coincides with the corresponding map for the Kron-reduced system (7) and equation (6). Indeed, according to Theorem 4.5, the attack set K is undetectable if and only if there exist s ∈C, g ∈ R|K|, and x = [xT 1 xT 2 ]T ∈Rn, with x ̸= 0, such that (sE −A)x −BKg = 0 and Cx + DKg = 0 . Equivalently, by eliminating the algebraic constraints as in (6), the attack set K is undetectable if and only if the conditons (sI −˜A)x1 −˜BKg = 0 and ˜Cx1 + ˜DKg = 0 are satisﬁed together with x2 = −A−1 22 A21x1 −A−1 22 B2g. Notice that the latter equation is always satisﬁed due to the consistency assumption (A2), and the equivalence of detectability of the attack set K follows. The equivalence of attack identiﬁability follows by analogous arguments. E. Attack detection and identiﬁcation in presence of inconsis- tent initial conditions and impulsive attack signals We now discuss the case of non-smooth attack signal and inconsistent initial condition. If the consistency assumption (A3) is dropped, then discontinuities in the state x(t ↓0) may affect the measurements y(t ↓0). For instance for index-one systems, an inconsistent initial condition leads to an initial jump for the algebraic variable x2(t ↓0) to obey equation (6). Consequently, the inconsistent initial value [0T x2(0)T]T ∈ Ker(E) cannot be recovered through measurements. Assumption (A4) requires the attack signal to be sufﬁciently smooth such that x(t) and y(t) are at least continuous. Suppose that assumption (A4) is dropped and the input u(t) belongs to the class of impulsive smooth distributions Cimp = Csmooth ∪Cp-imp, that is, loosely speaking, the class of functions given by the linear combination of a smooth function on R≥0 (denoted by Csmooth) and Dirac impulses and their derivatives at t = 0 (denoted by Cp-imp), see [34], [35, Section 2.4]. In this case, an attacker commanding an impulsive input u(0) ∈Cimp can reset the initial state x(0) and, possibly, evade detection. The discussion in the previous two paragraphs can be formalized as follows. Let Vc be the subspace of points x0 ∈Rn of consistent initial conditions for which there exists an input u ∈Cm smooth and a state trajectory x ∈Cn smooth to the descriptor system (3) such that y(t) = 0 for all t ∈R≥0. Let Vd (respectively W) be the subspace of points x0 ∈Rn for which there exists an input u ∈Cn+p imp (respectively u ∈Cn+p p-imp) and a state trajectory x ∈Cn imp (respectively x ∈Cn p-imp) to the descriptor system (3) such that y(t) = 0 for all t ∈R≥0. The output-nulling subspace Vd can be decomposed as follows: Lemma 4.9: (Decomposition of output-nulling space [34, Theorem 3.2 and Proposition 3.4])) Vd = Vc +W +Ker(E). In words, from an initial condition x(0) ∈Vd the output can be nulliﬁed by a smooth input or by an impulsive input (with consistent or inconsistent initial conditions in Ker(E)). In this work we focus on the smooth output-nulling sub- space Vc, which is exactly space of zero dynamics identiﬁed in Theorems 4.5 and 4.6. Hence, by Lemma 4.9, for inconsistent initial conditions, the results presented in this section are valid only for strictly positive times t > 0. On the other hand, if an attacker is capable of injecting impulsive signals, then it can avoid detection for initial conditions x(0) ∈W. 8 V. GRAPH THEORETIC DETECTABILITY CONDITIONS In this section we characterize undetectable attacks against cyber-physical systems from a structural perspective. In par- ticular we will derive detectability conditions based upon a connectivity property of a graph associated with the system. For ease of notation, we now drop the subscript K from BK, DK, and uK(t). A. Preliminary notions We start by recalling some useful facts about structured systems and structural properties [26], [40]. Let a structure matrix [M] be a matrix in which each entry is either a ﬁxed zero or an indeterminate parameter. The system [E] ˙x(t) = [A]x(t) + [B]u(t), y(t) = [C]x(t) + [D]u(t). (8) is called structured system, and it is sometimes referred to with the tuple ([E], [A], [B], [C], [D]) of structure matrices. A system (E, A, B, C, D) is an admissible realization of ([E], [A], [B], [C], [D]) if it can be obtained from the latter by ﬁxing the indeterminate entries at some particular value. Two systems are structurally equivalent if they are both an admissible realization of the same structured system. Let d be the number of indeterminate entries of a structured system altogether. By collecting the indeterminate parameters into a vector, an admissible realization is mapped to a point in the Euclidean space Rd. A property which can be asserted on a dynamical system is called structural if, informally, it holds for almost all admissible realizations. To be more precise, we say that a property is structural if and only if the set of admissible realizations satisfying such property forms a dense subset of the parameters space.3 For instance, left-invertibility of a nonsingular system is a structural property with respect to Rd [41]. Consider the structured cyber-physical system (8). It is often the case that, for the tuple (E, A, B, C, D) to be an admissible realization of (8), the numerical entries need to satisfy certain algebraic relations. For instance, for (E, A, B, C, D) to be an admissible power network realization, the matrices E and A need to be of the form (1). Let S ⊆Rd be the admissible parameter space. We make the following assumption: (A4) the admissible parameters space S is a polytope of Rd, that is, S = {x ∈Rd : Mx ≥0} for some matrix M. It should be noticed that assumption (A4) is automatically veriﬁed for the case of power networks [20, Lemma 3.1]. Unfortunately, if the admissible parameters space is a subset of Rd, then classical structural system-theoretic results are, in general, not valid [40, Section 15]. We now deﬁne a mapping between dynamical systems in descriptor form and digraphs. Let ([E],[A],[B],[C],[D]) be a structured cyber-physical system under attack. We associate a directed graph G = (V, E) with the tuple ([E],[A],[B],[C],[D]). The vertex set is V = U ∪X ∪Y, where U = {u1, . . . , um} is the set of input vertices, X = 3A subset S ⊆P ⊆Rd is dense in P if, for each r ∈P and every ε > 0, there exists s ∈S such that the Euclidean distance ∥s −r∥≤ε. g1 g2 g3 b4 b1 b5 b2 b6 b3 P4 P5 P6 P2 P3 P1 Fig. 2. WSSC power system with 3 generators and 6 buses. The numerical value of the network parameters can be found in [19]. θ1 ω1 δ1 y2 u2 θ5 δ3 ω3 θ3 u1 θ4 δ2 ω2 θ2 y1 θ6 Fig. 3. The digraph associated with the network in Fig. 2. The self-loops of the vertices {δ1, δ2, δ3}, {ω1, ω2, ω3}, and {θ1, . . . , θ6} are not drawn. The inputs u1 and u2 affect respectively the bus b4 and the bus b5. The measured variables are the rotor angle and frequency of the ﬁrst generator. {x1, . . . , xn} is the set of state vertices, and Y = {y1, . . . , yp} is the set of output vertices. If (i, j) denotes the edge from the vertex i to the vertex j, then the edge set E is E[E] ∪ E[A] ∪E[B] ∪E[C] ∪E[D], with E[E] = {(xj, xi) : [E]ij ̸= 0}, E[A] = {(xj, xi) : [A]ij ̸= 0}, E[B] = {(uj, xi) : [B]ij ̸= 0}, E[C] = {(xj, yi) : [C]ij ̸= 0}, and E[D] = {(uj, yi) : [D]ij ̸= 0}. In the latter, for instance, the expression [E]ij ̸= 0 means that the (i, j)-th entry of [E] is a free parameter. Example 1: (Power network structural analysis) Con- sider the power network illustrated in Fig. 2, where, being ei the i-th canonical vector, we take [E] = blkdiag(1, 1, 1, M1, M2, M3, 0, 0, 0, 0, 0, 0), [B] = [e8 e9], [C] = [e1 e4]T, [D] = 0, and [A] equal to   0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 a4,1 0 0 a4,4 0 0 a4,7 0 0 0 0 0 0 a5,2 0 0 a5,5 0 0 a5,8 0 0 0 0 0 0 a6,3 0 0 a6,6 0 0 a6,9 0 0 0 a7,1 0 0 0 0 0 a7,7 0 0 a7,10 a7,11 0 0 a8,2 0 0 0 0 0 a8,8 0 a8,10 0 a8,12 0 0 a9,3 0 0 0 0 0 a9,9 0 a9,11 a9,12 0 0 0 0 0 0 a10,7 a10,8 0 a10,10 0 0 0 0 0 0 0 0 a11,7 0 a11,9 0 a11,11 0 0 0 0 0 0 0 0 a12,8 a12,9 0 0 a12,12   The digraph associated with the structure matrices ([E], [A], [B], [C], [D]) is shown in Fig. 3. □ 9 B. Network vulnerability with known initial state We derive graph-theoretic detectability conditions for two different scenarios. Recall from Lemma 4.1 that an attack u(t) is undetectable if y(x1, u, t) = y(x2, 0, t) for some initial states x1 and x2. In this section, we assume that the system state is known at the failure initial time,4 so that an attack u(t) is undetectable if y(x0, u, t) = y(x0, 0, t) for some system initial state x0. The complementary case of unknown initial state is studied in Section V-C. Consider the cyber-physical system described by the ma- trices (E, A, B, C, D), and notice that, if the initial state is known, then the attack undetectability condition y(x0, u, t) = y(x0, 0, t) coincides with the system being not left-invertible.5 Recall that a subset S ⊆Rd is an algebraic variety if it coincides with the locus of common zeros of a ﬁnite number of polynomials [26]. Consider the following observation. Lemma 5.1: (Polytopes and algebraic varieties) Let S ⊆ Rd be a polytope, and let T ⊆Rd be an algebraic variety. Then, either S ⊆T, or S \ (S ∩T) is dense in S. Proof: Let T ⊆ Rd be the algebraic variety de- scribed by the locus of common zeros of the polynomials {φ1(x), . . . , φt(x)}, with t ∈N, t < ∞. Let P ⊆Rd be the smallest vector subspace containing the polytope S. Then P ⊆T if and only if every polynomial φi vanishes identically on P. Suppose that the polynomial φi does not vanish identically on P. Then, the set T ∩P is contained in the algebraic variety {x ∈P : φi(x) = 0}, and, therefore [26], the complement P \ (P ∩T) is dense in P. By deﬁnition of a dense set, the set S \ (S ∩T) is also dense in S. In Lemma 5.1 interpret the polytope S as the admissible parameters space of a structured cyber-physical system. Then we have shown that left-invertibility of a cyber-physical system is a structural property even when the admissible parameters space is a polytope of the whole parameters space. Conse- quently, given a structured cyber-physical system, either every admissible realization admits an undetectable attack, or there is no undetectable attack in almost all admissible realizations. Moreover, in order to show that almost all realizations have no undetectable attacks, it is sufﬁcient to prove that this is the case for some speciﬁc admissible realizations. Before presenting our main result, we recall the following result. Let ¯E and ¯A be N-dimensional square matrices, and let G(s ¯E −¯A) be the graph associated with the matrix s ¯E −¯A that consists of N vertices, and an edge from vertex j to i if ¯Aij ̸= 0 or ¯Eij ̸= 0. The matrix s[ ¯E] −[ ¯A] is said to be structurally degenerate if, for any admissible realization ¯E (respectively ¯A) of [ ¯E] (respectively [ ¯A]), the determinant |s ¯E −¯A| vanishes for all s ∈C. Recall the following deﬁnitions from [41]. For a given graph G, a path is a sequence of vertices where each vertex is connected to the following one in the sequence. A path is simple if every vertex on the path (except possibly the ﬁrst and the last vertex) occurs only once. Two paths are disjoint if they consist of disjoint sets of vertices. A set of l mutually 4The failure initial state can be estimated through a state observer [19]. 5A regular descriptor system is left-invertible if and only if its transfer matrix G(s) is of full column rank for all almost all s ∈C, or if and only if  sE−A −B C D  has full column rank for almost all s ∈C [34, Theorem 4.2]. disjoint and simple paths between two sets of vertices S1 and S2 is called a linking of size l from S1 to S2. A simple path in which the ﬁrst and the last vertex coincide is called cycle; a cycle family of size l is a set of l mutually disjoint cycles. The length of a cycle family equals the total number of edges in the family. Theorem 5.2: (Structural rank of a square matrix [42]) The structure N-dimensional matrix s[ ¯E] −[ ¯A] is structurally degenerate if and only if there exists no cycle family of length N in G(s[ ¯E] −[ ¯A]). We are now able to state our main result on structural detectability. Theorem 5.3: (Structurally undetectable attack) Let the parameters space of the structured cyber-physical system ([E], [A], [B], [C], [D]) deﬁne a polytope in Rd for some d ∈ N0. Assume that s[E]−[A] is structurally non-degenerate. The system ([E], [A], [B], [C], [D]) is structurally left-invertible if and only if there exists a linking of size |U| from U to Y. Theorem 5.3 can be interpreted in the context of cyber- physical systems. Indeed, since |sE −A| ̸= 0 by assumption (A1), and because of assumption (A4), Theorem 5.3 states that there exists a structural undetectable attack if and only if there is no linking of size |U| from U to Y, provided that the network state at the failure time is known. Proof: Because of Lemma 5.1, we need to show that, if there are |U| disjoint paths from U to Y, then there exists admissible left-invertible realizations. Conversely, if there are at most |U| −1 disjoint paths from U to Y, then every admissible realization is not left-invertible. (If) Let (E, A, B, C, D), with |sE −A| ̸= 0, be an admissible realization, and suppose there exists a linking of size |U| from U to Y. Without affecting generality, assume |Y| = |U|. For the left-invertibility property we need sE −A −B C D  = |sE −A| D + C(sE −A)−1B ̸= 0, and hence we need D + C(sE −A)−1B ̸= 0. Notice that D + C(sE −A)−1B corresponds to the transfer matrix of the cyber-physical system. Since there are |U| independent paths from U to Y, the matrix D + C(sE −A)−1B can be made nonsingular and diagonal by removing some connection lines from the network. In particular, for a given linking of size |U| from U to Y, a nonsingular and diagonal transfer matrix is obtained by setting to zero the entries of E and A corresponding to the edges not in the linking. Then there exist admissible left-invertible realizations, and thus the system ([E], [A], [D], [C], [D]) is structurally left-invertible. (Only if) Take any subset of |U| output vertices, and let |U| −1 be the maximum size of a linking from U to Y. Let [ ¯E] and [ ¯A] be such that s[ ¯E] −[ ¯A] = h s[E]−[A] [B] [C] [D] i . Consider the previously deﬁned graph G(s[ ¯E] −[ ¯A]), and notice that a path from U to Y in the digraph associated with the structured system corresponds, possibly after relabeling the output variables, to a cycle in involving input/output vertices in G(s[ ¯E] −[ ¯A]). Observe that there are only |U| −1 such (disjoint) cycles. Hence, there is no cycle family of length N, being N the size of [ ¯A], and the statement follows from Theorem 5.2. 10 To conclude this section, note that Theorem 5.3 extends [28] to regular descriptor systems with constraints on parameters. C. Network vulnerability with unknown initial state If the failure initial state is unknown, then a vulnerability is identiﬁed by the existence of a pair of initial conditions x1 and x2, and an attack u(t) such that y(x1, 0, t) = y(x2, u, t), or, equivalently, by the existence of invariant zeros for the given cyber-physical system. We will now show that, provided that a cyber-physical system is left-invertible, its invariant zeros can be computed by simply looking at an associated nonsingular state space system. Let the state vector x of the descriptor system (3) be partitioned as [xT 1 xT 2 ]T, where x1 corresponds to the dynamic variables. Let the network matrices E, A, B, C, and D be partitioned accordingly, and assume, without loss of generality, that E is given as E = blkdiag(E11, 0), where E11 is nonsingular. In this case, the descriptor model (3) reads as E11 ˙x1(t) = A11x1(t) + B1u(t) + A12x2(t) , 0 = A21x1(t) + A22x2(t) + B2u(t) , y(t) = C1x1(t) + C2x2(t) + Du(t) . (9) Consider now the associated nonsingular state space system which is obtained by regarding x2(t) as an external input to the descriptor system (9) and the algebraic constraint as output: ˙x1(t) = E−1 11 A11x1(t) + E−1 11 B1u(t) + E−1 11 A12x2(t), ˜y(t) =  A21 C1  x1(t) +  A22 B2 C2 D   x2(t) u(t)  . (10) Theorem 5.4: (Equivalence of invariant zeros) Consider the descriptor system (3) partitioned as in (9). Assume that, for the corresponding structured system ([E], [A], [B], [C], [D]), there exists a linking of size |U| from U to Y. Then, in almost all admissible realizations, the invariant zeros of the descriptor system (9) coincide with those of the associated nonsingular system (10). Proof: From Theorem 5.3, the structured descriptor sys- tem ([E], [A], [B], [C], [D]) is structurally left-invertible. Let (E, A, B, C, D) be a left-invertible realization. The proof now follows a procedure similar to [43, Proposi- tion 8.4]. Let s ∈C be an invariant zero for the nonsingular system (10) with state-zero direction x1 ̸= 0 and input-zero direction u, that is   0 0 0  =   sI −E−1 11 A11 −E11A12 −E−1 11 B1 A21 A22 B2 C1 C2 D   | {z } Pnonsingular(s)   x1 x2 u  . A multiplication of the above equation by blkdiag(E11, −I, I) and a re-partioning of the resulting matrix yields   0 0 0  =   sE11 −A11 −A12 −B1 −A21 −A22 −B2 C1 C2 D   | {z } Psingular(s)   x1 x2 u  . (11) Since x1 ̸= 0, we also have x = [xT 1 xT 2 ]T ̸= 0. Then, equation (11) implies that s ∈C is an invariant zero of the θ1 ω1 δ1 y2 u2 θ5 δ3 ω3 θ3 u1 θ4 δ2 ω2 θ2 y1 θ6 Fig. 4. In the above network, there is no linking of size 2 from the input to the output vertices. Indeed, the vertices θ1 and ω1 belong to every path from {u1, u2} to {y1, y2}. Two input to output paths are depicted in red. descriptor system (9) with state-zero direction x ̸= 0 and input-zero direction u. We conclude that the invariant zeros of the nonsingular system (10) are a subset of the zeros of the descriptor system (9). In order to continue, suppose that there is s ∈C which is an invariant zero of the descriptor system (9) but not of the nonsingular system (10). Let x = [xT 1 xT 2 ]T ̸= 0 and u be the associated state-zero and input-zero direction, respectively. Since Ker(Psingular(s)) = Ker(Pnonsingular(s)) and s is not a zero of the nonsingular system (10), it follows that x1 = 0 and x2 ̸= 0. Accordingly, we have that Ker     −A12 −B1 −A22 −B2 C2 D    ̸= {∅} . It follows that the vector [0T xT 2 uT]T lies in the nullspace of Psingular(s) for each s ∈C, and thus the descriptor system (9) is not left-invertible. In conclusion, if the descriptor system (9) is left-invertible, then its invariant zeros coincide with those of the nonsingular system (10). It should be noticed that, because of Theorem 5.4, under the assumption of left-invertibility, classical linear systems results can be used to investigate the presence of structural undetectable attacks in a cyber-physical system; see [41] for a survey of results on generic properties of linear systems. VI. ILLUSTRATIVE EXAMPLES A. An example of state attack against a power network Consider the power network model analyzed in Example 1 and illustrated in Fig. 2, and let the variables θ4 and θ5 be affected, respectively, by the unknown and unmeasurable signals u1(t) and u2(t). Suppose that a monitoring unit is allowed to measure directly the state variables of the ﬁrst generator, that is, y1(t) = δ1(t) and y2(t) = ω1(t). Notice from Fig. 4 that the maximum size of a linking from the failure to the output vertices is 1, so that, by Theorem 5.3, there exists a structural vulnerability. In other words, for every choice of the network matrices, there exist nonzero u1(t) and u2(t) that are not detectable through the measurements.6 We now consider a numerical realization of this system. Let the input matrices be B = [e8 e9] and D = [0 0]T, the 6When these ouput-nulling inputs u1(t), u2(t) are regarded as additional loads, then they are entirely sustained by the second and third generator. 11 t1 t2 t3 ω1 ω2 ω3 Fig. 5. The velocities ω2 and ω3 are driven unstable by the signals u1(t) and u2(t), which are undetectable from the measurements of ω1 and δ1. measurement matrix be C = [e1 e4]T, and the system matrix A be as in equation (1) with Mg = blkdiag(.125, .034, .016), Dg = blkdiag(.125, .068, .048), and L =   .058 0 0 −.058 0 0 0 0 0 0 .063 0 0 −.063 0 0 0 0 0 0 .059 0 0 −.059 0 0 0 −.058 0 0 .235 0 0 −.085 −.092 0 0 −.063 0 0 .296 0 −.161 0 −.072 0 0 −.059 0 0 .330 0 −.170 −.101 0 0 0 −.085 −.161 0 .246 0 0 0 0 0 −.092 0 −.170 0 .262 0 0 0 0 0 −.072 −.101 0 0 .173   . Let U1(s) and U2(s) be the Laplace transform of the attack signals u1(t) and u2(t), and let  U1(s) U2(s)  =  −1.024s4−5.121s3−10.34s2−9.584s−3.531 s4+5s3+9.865s2+9.173s+3.531 1  | {z } N(s) ¯U(s), for some arbitrary nonzero signal ¯U(s). Then it can be veriﬁed that the failure cannot be detected through the measurements y1(t) and y2(t). In fact, N(s) coincides with the null space of the input/output transfer matrix. An example is in Fig. 5, where the second and the third generator are driven unstable by the attack, but yet the ﬁrst generator does not deviate from the nominal operating condition. Suppose now that the rotor angle of the ﬁrst generator and the voltage angle at the 6-th bus are measured, that is, C = [e1 e12]T. Then, there exists a linking of size 2 from U to Y, and the system (E, A, B, C) is left-invertible. Following Theorem 5.4, the invariant zeros of the power network can be computed by looking at its reduced system, and they are −1.6864 ± 1.8070i and −0.8136 ± 0.2258i. Consequently, if the network state is unknown at the failure time, there exists vulnerabilities that an attacker may exploit to affect the network while remaining undetected. Finally, we remark that such state attacks are entirely realizable by cyber attacks [22]. B. An example of output attack against a power network Let the IEEE 14 bus power network (Fig. 6) be modeled as a descriptor system as in Section II-A. Following [11], let the measurement matrix C consist of the real power injections at all buses, of the real power ﬂows of all branches, and of one rotor angle (or one bus angle). We assume that an attacker can compromise all the measurements, independently of each other, except for one referring to the rotor angle. Let k ∈N0 be the cardinality of the attack set. It is known that an attack undetectable to a static detector exists if k ≥4 [11]. In other words, due to the sparsity pattern of C, there exists a signal uK(t), with (the same) four nonzero entries G G G G G bus 1 bus 2 bus 3 bus 4 bus 5 bus 6 bus 7 bus 8 bus 9 bus 10 bus 11 bus 12 bus 13 bus 14 Fig. 6. For the here represented IEEE 14 bus system, if the voltage angle of one bus is measured exactly, then a cyber attack against the measurements data is always detectable by our dynamic detection procedure. In contrary, as shown in [11], a cyber attack may remain undetected by a static procedure if it compromises as few as four measurements. R1 R2 T2 T1 T3 P1 P2 S1 S2 S3 S4 S5 S6 u2 u1 u3 S7 Fig. 7. This ﬁgure shows the structure of the EPANET water supply network model # 3, which features 3 tanks (T1, T2, T3), 2 reservoirs (R1, R2), 2 pumps (P1, P2), 96 junctions, and 119 pipes. Seven pressure sensors (S1, . . . , S7) have been installed to monitor the network functionalities. A cyber-physical attack to steal water from the reservoir R2 is reported. Notice that the cyber- physical attack features two state attacks (u1, u2) and one output attack (u3). at all times, such that DuK(t) ∈Im(C) at all times. By Theorem 4.3 the attack set K remains undetected by a Static Detector through the attack mode uK(t). On the other hand, following Theorem 4.5, it can be veriﬁed that, for the same output matrix C, and independent of the value of k, there exists no undetectable (output) attacks for a dynamic monitor. It should be notice that this result relies on the fact that the rotor angle measurement is known to be correct, because, for instance, it is protected using sophisticated and costly security methods [1]. Since the state of the IEEE 14 bus system can be reconstructed by means of this measurement only (in a system theoretic sense, the system is observable by measuring one generator rotor angle), the output attack Du(t) is easily identiﬁed as Du(t) = y(t) −Cˆx(t), where ˆx(t) = x(t) is the reconstructed system state at time t. C. An example of state and output attack against a water supply network Consider the water supply network EPANET 3 linearized at a steady state with non-zero pressure drops [44]. The water 12 network model as well as a possible cyber-physical attack are illustrated in Fig. 7. The considered cyber-physical attack aims at stealing water from the reservoir R2 while remaining unde- tected from the installed pressure sensors S1, . . . , S7. In order to achieve its goal, the attacker corrupts the measurements of sensor S1 (output attack), it steals water from the reservoir R2 (state attack), and, ﬁnally, it modiﬁes the input of the control pump P2 to restore the pressure drop due to the loss of water in R2 (state attack). We now analyze this attack in more details. Following the modeling in Section II-B, an index-one de- scriptor model describing the evolution of the water network in Fig. 7 is computed. For notational convenience, let x1(t), x2(t), x3(t), and x4(t) denote, respectively, the pressure at time t at the reservoir R2, at the reservoir R1 and at the tanks T1, T2 and T3, at the junction P2, and at the remaining junctions. The index-one descriptor model reads as   ˙x1(t) M ˙x2(t) 0 0  =   0 0 0 0 0 A22 0 A24 A31 0 A33 A34 0 A42 A43 A44     x1(t) x2(t) x3(t) x4(t)  , where the pattern of zeros is due to the network interconnec- tion structure, and M = diag(1, A1, A2, A3) corresponds to the dynamics of the reservoir R1 and the tanks T1, T2, and T3. With the same partitioning, the attack signature reads as B = [B1 B2 0] and D = [0 0 D1], where B1 = 1 0 0 0T , B2 = 0 0 1 0T , and D1 = 1 0 . . . 0T . Let the attack u2(t) be chosen as u2(t) = −A31x1(t). Then, the state variables x2, x3, and x4 are decoupled from x1. Consequently, the attack mode u1 does not affect the dynamics of x2, x3, and x4. Let u1(t) = −1, and notice that the pressure x1(t) decreases with time (that is, water is being removed from R2). Finally, for the attack to be undetectable, since the state variable x1 is continuously monitored by S1, let u3(t) = −x1(t). It can be veriﬁed that the proposed attack strategy allows an attacker to steal water from the reservoir R2 while remaining undetected from the sensors measurements. In other words, the attack (Bu(t), Du(t)), with u(t) = [uT 1 (t) uT 2 (t) uT 3 (t)]T, excites only zero dynamics for the water network system in Fig. 7. We conclude this section with the following remarks. First, for the implementation of the proposed attack strategy, neither the network initial state, nor the network structure besides A31 need to be known to the attacker. Second, the effectiveness of the proposed attack strategy is independent of the sensors measuring the variables x3 and x4. On the other hand, if additional sensors are used to measure the ﬂow between the reservoir R2 and the pump P2, then an attacker would need to corrupt these measurements as well to remain undetected. Third and ﬁnally, due to the reliance on networks to control actuators in cyber-physical systems, the attack u2(t) on the pump P2 could be generated by a cyber attack [22]. VII. CONCLUSION For cyber-physical systems modeled by linear time-invariant descriptor systems, we have analyzed fundamental limitations of static, dynamic, and active attack detection and identiﬁ- cation monitors. We have rigorously shown that a dynamic detection and identiﬁcation monitor exploits the network dy- namics and outperforms the static counterpart, while requiring, possibly, fewer measurements. Additionally, we have shown that active monitors have the same limitations as passive dynamic monitors. Finally, we have described graph theoretic conditions for the existence of undetectable and unidentiﬁable attacks. These latter conditions exploit the system intercon- nection structure, and they hold for almost all compatible nu- merical realizations. In the companion paper [39] we develop centralized and distributed attack detection and identiﬁcation monitors. REFERENCES [1] A. R. Metke and R. L. Ekl, “Security technology for smart grid networks,” IEEE Transactions on Smart Grid, vol. 1, no. 1, pp. 99– 107, 2010. [2] S. Sridhar, A. Hahn, and M. Govindarasu, “Cyber–physical system security for the electric power grid,” Proceedings of the IEEE, vol. 99, no. 1, pp. 1–15, 2012. [3] J. Slay and M. Miller, “Lessons learned from the Maroochy water breach,” Critical Infrastructure Protection, vol. 253, pp. 73–82, 2007. [4] A. A. C´ardenas, S. Amin, and S. S. Sastry, “Research challenges for the security of control systems,” in Proceedings of the 3rd Conference on Hot Topics in Security, Berkeley, CA, USA, 2008, pp. 6:1–6:6. [5] G. E. Apostolakis and D. M. Lemon, “A screening methodology for the identiﬁcation and ranking of infrastructure vulnerabilities due to terrorism,” Risk Analysis, vol. 25, no. 2, pp. 361–376, 2005. [6] M. Basseville and I. V. Nikiforov, Detection of Abrupt Changes: Theory and Application. Prentice Hall, 1993. [7] S. X. Ding, Model-Based Fault Diagnosis Techniques: Design Schemes, Algorithms, and Tools. Springer, 2008. [8] A. A. C´ardenas, S. Amin, B. Sinopoli, A. Giani, A. A. Perrig, and S. S. Sastry, “Challenges for securing cyber physical systems,” in Workshop on Future Directions in Cyber-physical Systems Security, Newark, NJ, USA, Jul. 2009. [9] C. L. DeMarco, J. V. Sariashkar, and F. Alvarado, “The potential for malicious control in a competitive power systems environment,” in IEEE Int. Conf. on Control Applications, Dearborn, MI, USA, 1996, pp. 462– 467. [10] S. Amin, A. C´ardenas, and S. Sastry, “Safe and secure networked control systems under denial-of-service attacks,” in Hybrid Systems: Computation and Control, vol. 5469, Apr. 2009, pp. 31–45. [11] Y. Liu, M. K. Reiter, and P. Ning, “False data injection attacks against state estimation in electric power grids,” in ACM Conference on Com- puter and Communications Security, Chicago, IL, USA, Nov. 2009, pp. 21–32. [12] A. Teixeira, S. Amin, H. Sandberg, K. H. Johansson, and S. Sastry, “Cyber security analysis of state estimators in electric power systems,” in IEEE Conf. on Decision and Control, Atlanta, GA, USA, Dec. 2010, pp. 5991–5998. [13] S. Amin, X. Litrico, S. S. Sastry, and A. M. Bayen, “Stealthy deception attacks on water SCADA systems,” in Hybrid Systems: Computation and Control, Stockholm, Sweden, Apr. 2010, pp. 161–170. [14] Y. Mo and B. Sinopoli, “Secure control against replay attacks,” in Allerton Conf. on Communications, Control and Computing, Monticello, IL, USA, Sep. 2010, pp. 911–918. [15] R. Smith, “A decoupled feedback structure for covertly appropriating network control systems,” in IFAC World Congress, Milan, Italy, Aug. 2011, pp. 90–95. [16] M. Zhu and S. Mart´ınez, “Stackelberg-game analysis of correlated attacks in cyber-physical systems,” in American Control Conference, San Francisco, CA, USA, Jul. 2011, pp. 4063–4068. [17] F. Hamza, P. Tabuada, and S. Diggavi, “Secure state-estimation for dynamical systems under active adversaries,” in Allerton Conf. on Communications, Control and Computing, Sep. 2011. [18] G. Dan and H. Sandberg, “Stealth attacks and protection schemes for state estimators in power systems,” in IEEE Int. Conf. on Smart Grid Communications, Gaithersburg, MD, USA, Oct. 2010, pp. 214–219. 13 [19] E. Scholtz, “Observer-based monitors and distributed wave controllers for electromechanical disturbances in power systems,” Ph.D. disserta- tion, Massachusetts Institute of Technology, 2004. [20] F. Pasqualetti, A. Bicchi, and F. Bullo, “A graph-theoretical characteriza- tion of power network vulnerabilities,” in American Control Conference, San Francisco, CA, USA, Jun. 2011, pp. 3918–3923. [21] F. Pasqualetti, F. D¨orﬂer, and F. Bullo, “Cyber-physical attacks in power networks: Models, fundamental limitations and monitor design,” in IEEE Conf. on Decision and Control and European Control Conference, Orlando, FL, USA, Dec. 2011, pp. 2195–2201. [22] A.-H. Mohsenian-Rad and A. Leon-Garcia, “Distributed internet-based load altering attacks against smart power grids,” IEEE Transactions on Smart Grid, vol. 2, no. 4, pp. 667 –674, 2011. [23] S. Sundaram and C. Hadjicostis, “Distributed function calculation via linear iterative strategies in the presence of malicious agents,” IEEE Transactions on Automatic Control, vol. 56, no. 7, pp. 1495–1508, 2011. [24] F. Pasqualetti, A. Bicchi, and F. Bullo, “Consensus computation in unreliable networks: A system theoretic approach,” IEEE Transactions on Automatic Control, vol. 57, no. 1, pp. 90–104, 2012. [25] D. G. Eliades and M. M. Polycarpou, “A fault diagnosis and security framework for water systems,” IEEE Transactions on Control Systems Technology, vol. 18, no. 6, pp. 1254–1265, 2010. [26] W. M. Wonham, Linear Multivariable Control: A Geometric Approach, 3rd ed. Springer, 1985. [27] Y. Mo and B. Sinopoli, “False data injection attacks in control systems,” in First Workshop on Secure Control Systems, Stockholm, Sweden, Apr. 2010. [28] J. W. van der Woude, “A graph-theoretic characterization for the rank of the transfer matrix of a structured system,” Mathematics of Control, Signals and Systems, vol. 4, no. 1, pp. 33–40, 1991. [29] A. Osiadacz, Simulation and Analysis of Gas Networks. Houston, TX, USA: Gulf Publishing Company, 1987. [30] A. Kumar and P. Daoutidis, Control of Nonlinear Differential Algebraic Equation Systems. CRC Press, 1999. [31] X. Litrico and V. Fromion, Modeling and Control of Hydrosystems. Springer, 2009. [32] J. Burgschweiger, B. Gn¨adig, and M. C. Steinbach, “Optimization models for operative planning in drinking water networks,” Optimization and Engineering, vol. 10, no. 1, pp. 43–73, 2009. [33] P. F. Boulos, K. E. Lansey, and B. W. Karney, Comprehensive Water Distribution Systems Analysis Handbook for Engineers and Planners. American Water Works Association, 2006. [34] T. Geerts, “Invariant subspaces and invertibility properties for singular systems: The general case,” Linear Algebra and its Applications, vol. 183, pp. 61–88, 1993. [35] P. Kunkel and V. Mehrmann, Differential-Algebraic Equations: Analysis and Numerical Solution. European Mathematical Society, 2006. [36] A. Abur and A. G. Exposito, Power System State Estimation: Theory and Implementation. CRC Press, 2004. [37] F. L. Lewis, “A survey of linear singular systems,” Circuits, Systems, and Signal Processing, vol. 5, no. 1, pp. 3–36, 1986. [38] F. D¨orﬂer and F. Bullo, “Kron reduction of graphs with applications to electrical networks,” IEEE Transactions on Circuits and Systems, Nov. 2011, submitted. [39] F. Pasqualetti, F. D¨orﬂer, and F. Bullo, “Attack Detection and Identiﬁ- cation in Cyber-Physical Systems – Part II: Centralized and Distributed Monitor Design,” IEEE Transactions on Automatic Control, Feb. 2012, Submitted. Available at http://arxiv.org/pdf/1202.6049. [40] K. J. Reinschke, Multivariable Control: A Graph-Theoretic Approach. Springer, 1988. [41] J. M. Dion, C. Commault, and J. van der Woude, “Generic properties and control of linear structured systems: a survey,” Automatica, vol. 39, no. 7, pp. 1125–1144, 2003. [42] K. J. Reinschke, “Graph-theoretic approach to symbolic analysis of linear descriptor systems,” Linear Algebra and its Applications, vol. 197, pp. 217–244, 1994. [43] J. Tokarzewski, Finite Zeros in Discrete Time Control Systems, ser. Lecture notes in control and information sciences. Springer, 2006. [44] L. A. Rossman, “Epanet 2, water distribution system modeling soft- ware,” US Environmental Protection Agency, Water Supply and Water Resources Division, Tech. Rep., 2000.