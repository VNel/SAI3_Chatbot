Vulnerability Coordination Under the Cyber Resilience Act Jukka Ruohonen1[0000−0001−5147−3084] and Paul Timmers2 1 University of Southern Denmark, juk@mmmi.sdu.dk 2 KU Leuven & University of Oxford, paul.timmers@kuleuven.be Abstract. A new Cyber Resilience Act (CRA) was recently agreed upon in the European Union (EU). It imposes many new cyber security re- quirements practically to all information technology products, whether hardware or software. The paper examines and elaborates the CRA’s new requirements for vulnerability coordination, including vulnerability disclosure. Although these requirements are only a part of the CRA’s obligations for vendors, also some new vulnerability coordination man- dates are present, including particularly with respect to so-called actively exploited vulnerabilities. The CRA further alters the coordination prac- tices on the side of public administrations. With the examination, elab- oration, and associated discussion, the paper contributes to the study of cyber security regulations, providing also a few practical takeaways. Keywords: cyber security regulations, vulnerability disclosure, vulnerability databases, actively exploited vulnerabilities, near misses, EU, CRA, NIS2 1 Introduction The EU’s new Cyber Resilience Act, that is, Regulation (EU) 2024/2847, was agreed upon in October 2024. The paper presents an analysis of the CRA’s im- plications for vulnerability coordination, including vulnerability disclosure. Al- though the handling of vulnerabilities is a classical topic, the CRA imposes some new requirements. It also enlarges the scope of theoretical concepts involved. For these reasons, the paper carries both practical relevance and timeliness. In terms of explicitly related work, the paper continues the initial assessments [7] that were conducted based on the European Commission’s proposal for the CRA. The CRA is a part of a larger regulatory package for cyber security that was pursued by the von der Leyen’s first Commission, which was in office between 2019 and 2024. Although many of the other laws in the package are on the side of critical infrastructure, the overall goal of improved coordination, which can be understood broadly as a management of dependencies [17, 26], is strongly present throughout the package. Whether it is risk analysis or incident management, the EU context generally implies that some coordination is required at multiple lev- els; between cyber security professionals, companies, industry sectors, national public authorities, and EU-level institutions, among other abstraction levels. To arXiv:2412.06261v2 [cs.CR] 8 Mar 2025 make sense of the coordination involved, it is useful to analytically separate horizontal coordination (such as between the member states) and vertical co- ordination, which occurs between EU-level institutions and units at a national level [22, 23]. Then, as will be elaborated, the CRA involves both horizontal and vertical coordination. Coordination requires also technical infrastructures. Regarding the larger regulatory package for cyber security, relevant to men- tion is Directive (EU) 2022/2555, which is commonly known as the NIS2 di- rective. With respect to vulnerability coordination—a term soon elaborated in Section 2, the directive strengthens and harmonizes the role of national com- puter security incident response teams (CSIRTs) in Europe. In general, various networks between CSIRTs, both in Europe and globally, have been important for improving cyber security throughout the world, often overcoming obstacles that more politically oriented cyber security actors have had [28]. Importantly for the present purposes, the NIS2 directive, in its Article 12(2), specifies also an establishment of a new European vulnerability database operated by the European Union Agency for Cybersecurity (ENISA), which is the principal EU- level institution coordinating particularly with the national CSIRTs but also involved in international collaboration. While it is still too early to say with confidence, together the CRA and NIS2 may thus also affect the infrastructures for vulnerability archiving, which is currently strongly built upon institutions and companies in the United States, including particularly the not-for-profit MITRE corporation involved in the assignment of Common Vulnerabilities and Exposures (CVEs) and the National Vulnerability Database (NVD) maintained by the National Institute of Standards and Technology (NIST). With respect to the regulatory cyber security package, it can be further noted that the CRA is rather unique in a sense that its legal background and logic are motivated by the EU’s product safety laws and the general consumer protection jurisprudence [7]. Therefore, also the associated terminology is somewhat different compared to the other laws in the package. For instance, the CRA brings market surveillance authorities to the public administration of cyber security in the EU. In general, these authorities are responsible for ensuring that only compliant products enter into and circulate on the EU’s internal market; the examples include authorities ensuring the safety of food, drugs, aviation, chemicals, and so forth and so on. The CRA covers the whole information technology sector and beyond. Both hardware and software products with a networking functionality are in its scope. Among the notable exemptions not covered by the regulation, as specified in the CRA’s Article 2, are medical devices, motor vehicles, and ships and marine equip- ment. Furthermore, recital 12 clarifies that cloud computing is also excluded. The CRA categorizes products into three categories: “normal”, “important”, and “critical” products. While all products need to comply with the CRA’s es- sential requirements, more obligations are placed upon the important and critical products [24]. However, in what follows, the focus is only on the CRA’s implica- tions for vulnerability coordination, including vulnerability disclosure. With this focus in mind, the opening Section 2 introduces the vulnerability coordination and disclosure concepts. Then, the subsequent Section 3 discusses and elaborates the CRA’s new implications to vulnerability coordination and disclosure. The implications are not uniform across everyone; therefore, Section 4 continues by briefly elaborating the requirements for open source software products and their projects. To some extent, the CRA addresses also the pressing issues with sup- ply chain security. The important supply chain topic is discussed in Section 5. A conclusion and a discussion are presented in the final Section 6. 2 Vulnerability Disclosure and Coordination There are various ways to disclose and coordinate a vulnerability between the vulnerability’s discoverer and a software vendor affected by the vulnerability. Historically—and perhaps still so—a common practice was so-called direct dis- closure through which a discoverer and a vendor coordinate and negotiate pri- vately, possibly without notifying any further parties, including maintainers of vulnerability databases and public authorities [25]. Partially due to the prob- lems associated with direct disclosure, another historical—and sometimes still practiced—process was a so-called full disclosure via which a discoverer makes his or her vulnerability discovery public, possibly even without notifying a ven- dor affected or anyone else beforehand. One of the primary reasons for the full disclosure practice was—and sometimes still is—a deterrence against vendors who would not otherwise cooperate. However, this practice can be seen to in- crease security risks because sensitive information is publicly available but no one has had time to react; there are no patches available because a vendor may not even know about a vulnerability information being available in the public. For this reason and other associated reasons, a third vulnerability disclosure model emerged. It is called coordinated vulnerability disclosure; in essence, a discoverer contacts an intermediary party who helps with the coordination and collaboration with a vendor affected, often also providing advices to other par- ties and the general public through security advisories and security awareness campaigns. This coordinated disclosure model is the de facto vulnerability dis- closure practice today. Regarding the intermediaries involved, a national CSIRT is typically acting as a coordinator, but also commercial companies may act in a similar role, as is typical in the nowadays popular so-called bug bounties and their online platforms. In addition to security improvements, commercial bug bounty platforms may give vendors more control over disclosure processes [1], while for discoverers they offer monetary rewards, learning opportunities, and some legal safeguards [2]. It is also important to emphasize that today practi- cally all coordinated vulnerability disclosure models further follow a so-called responsible disclosure, meaning that vendors are given a fixed time period to develop and release patches before information is released to the public. With respect to Europe and the public sector, CSIRT-based coordinated vul- nerability disclosure model, the NIS2 directive specified in its Article 12(1) three primary tasks for the national CSIRTs in the member states: (1) they should identify and contact all entities concerned, including the vendors affected in par- ticular; (2) they should assist natural or legal persons who report vulnerabilities; and (3) they should negotiate disclosure timelines and arrange coordination for vulnerabilities that affect multiple entities. While simple, these legal mandates for public sector bodies are important because the legal landscape for vulnera- bility disclosure has been highly fragmented in Europe [5, 10]. The CRA relies partially upon these mandates in NIS2, but it also imposes new requirements for both national CSIRTs and vendors (or manufacturers, as they are called in the CRA). Before continuing, it should be clarified that a broader term of vul- nerability coordination has sometimes been preferred in the literature because vulnerability disclosure presents only a narrow perspective on the overall han- dling of vulnerabilities [26]. In addition to contacting, communicating, assisting, and negotiating, numerous other tasks are typically involved, including develop- ment of patches, testing these, and delivering these to customers, clients, and users in general, assignment of CVE identifiers, writing and releasing security advisories, archiving information to vulnerability databases, and so forth and so on. These additional tasks do not affect only vendors but also CSIRTs often need to carry out additional tasks beyond those specified in the NIS2 directive. For these reasons, also the present work uses a term vulnerability coordination. 3 The CRA’s New Requirements The CRA separates voluntary vulnerability disclosure from mandatory obliga- tions placed upon vendors. Regardless whether a disclosure of a vulnerability is done on voluntary or mandatory basis, it should be primarily done through a national CSIRT, although voluntary disclosure may be done also to ENISA directly according to the CRA’s Article 15(1). Then, according to Article 15(2), both vendors and others may also report not only vulnerabilities but also se- curity incidents and so-called near misses. These near misses are defined in the NIS2’s Article 6(5) as events that “could have compromised the availability, au- thenticity, integrity or confidentiality of stored, transmitted or processed data or of the services offered by, or accessible via, network and information systems” but which were successfully mitigated. These mitigated security events are one but not the only example of new terminology brought by the EU’s new laws. When a disclosure is done to a national CSIRT, the given CSIRT should then without undue delay carry out vertical coordination toward the EU-level. This important obligation placed upon national public sector authorities is specified in the CRA’s Article 16(1) according to which a common EU-level disclosure infras- tructure is established. It is maintained by ENISA. Through this infrastructure, according to Article 16(2), a given national CSIRT should notify other Euro- pean CSIRTs designed as public sector authorities on those territories on which a vendor’s vulnerable products have been made available. The territorial notion seems sensible enough when dealing with physical products, whether routers, mobile phones, or automobiles. However, many digital products, including soft- ware products in particular, are distributed online without any specific territorial scope. For such products, it seems a reasonable assumption that all European CSIRTs should be notified. This point applies particularly to large software ven- dors, such as, say, Microsoft or Google. Similar reasoning was behind a schism during the CRA’s political negotiations because some companies and member states feared that sensitive vulnerability information would unnecessarily spill over throughout Europe due to the EU-level reporting infrastructure [23]. The schism was resolved by relaxing the obligation placed upon CSIRTs. In partic- ular, according to Article 16(2), national CSIRTs may delay coordination and reporting toward the EU-level under exceptional circumstances requested by a vendor affected. The article specifies three clarifying conditions regarding these exceptional circumstances: (1) a given vulnerability is actively exploited by a malicious actor and no other member state is affected; (2) immediate reporting would affect the essential interests of a member state; and (3) imminent high cy- ber security risk is stemming from reporting. Although a national CSIRT should always still notify ENISA about its decision to delay reporting, it seems that the three conditions are so loose that most cases could be delayed in principle. Time will tell how the regulators interpret the exceptional circumstances in practice. When no exceptional circumstances are present and reporting is done nor- mally by a CSIRT, it should be clarified that both vertical and horizontal coor- dination is present. A CSIRT’s notification toward the EU-level is vertical in its nature, while distributing information to other CSIRTs is a horizontal activity. In addition, further horizontal coordination is present because the CRA’s Arti- cle 16(3) specifies that a CSIRT should also notify any or all market surveillance authorities involved. This obligation complicates the coordination substantially because it may be that numerous market surveillance authorities are present, including everything from product safety authorities to customs. Alternatively, it may be that a member state has specified its national CSIRT also as a market surveillance authority in the CRA’s context. Again, time will tell how the coordi- nation works in practice. Future evaluation work is required later in this regard. The exceptional circumstances noted contain the concept of actively exploited avulnerabilities. Such vulnerabilities are a core part of the CRA. An actively ex- ploited vulnerability is defined in Article 3(42) as “a vulnerability for which there is reliable evidence that a malicious actor has exploited it in a system without permission of the system owner”. Recital 68 clarifies that security breaches, including data breaches affecting natural persons, are a typical example. The recital also notes that the concept excludes good faith testing, investigation, correction, or disclosure insofar as no malicious motives have been involved. Then, according to Article 14(1), all vendors should notify about actively ex- ploited vulnerabilities in their products to both a given national CSIRT and ENISA. Article 14(2) continues by specifying that vendors should deliver an early notification within 24 hours, an update within 72 hours, and a final report within two weeks. Furthermore, the subsequent paragraphs 3 and 4 in Article 14 obligate vendors to report not only about actively exploited vulnerabilities but also about actual security incidents. These are defined in the NIS2’s Article 6(6) analogously to the near misses but without the successful mitigation condition. Furthermore, Article 14(8) specifies that both actively exploited vulnerabilities and security incidents should be communicated to the users impacted, possibly including the general public, either by a vendor affected or a given CSIRT. Other natural or legal persons Vendors National CSIRT ENISA Common reporting infrastructure Voluntary reporting of conventional vulnerabilities Vendors Voluntary reports (A) No exceptional circumstances (B) Delay due to exceptional circumstances Mandatory reporting of actively exploited vulnerabilities (B) Notification about a delay National CSIRT Market surveillance authority National level EU-level Reporters OR OR AND Users Fig. 1. Vulnerability Coordination Under the CRA in an Analytical Nutshell Regarding vulnerabilities, as can be seen also from Fig. 1, it should be un- derlined that the mandatory notifications only involve actively exploited vulner- abilities. Thus, among other things, so-called silent patching is excluded from the CRA’s scope; it refers to cases in which a vendor has found a vulnerabil- ity from its product and silently corrected it without making the information available to others [25]. A more important point is that the definition for ac- tively exploited vulnerabilities is rather loose. When considering a possibility of underreporting—a topic that has been discussed in the literature in somewhat similar settings [14], particularly the wording about reliable evidence raises a concern. A relevant question is: whose evidence? If vendors alone answer to the question, underreporting may occur. Though, other parties too, including public authorities, have threat intelligence platforms, security information and event management (SIEM) systems, and many related techniques deployed. Against this backdrop, a vendor deciding not to report an actively exploited vulnerability may later on find itself as having been non-compliant. In addition, Article 60 allows market surveillance authorities to conduct sweeps to check compliance. It is important to further note that the concept of actively exploited vulner- abilities is used also in the United States. In particular, the Cybersecurity & Infrastructure Agency (CISA) therein maintains a catalog of known exploited vulnerabilities [8]. Given the ENISA’s and CISA’s established cooperation [11], it remains to be seen whether the catalog will be used also for enforcing the CRA or otherwise helping its implementation. An analogous point applies to the in- ternational coordination between vulnerability databases, including particularly between the NVD and the EU’s upcoming vulnerability database enacted in the NIS2 directive. A related important point is that less strict vulnerability re- porting requirements are imposed upon open source software projects and their supporting foundations, which are known as stewards in the CRA’s parlance. Finally, it is important to emphasize that the CRA’s so-called essential cyber security requirements, which, like with the EU’s product safety laws [22], will be augmented in the nearby future with technical standards, contain also obli- gations explicitly related to vulnerabilities and their coordination. In general, as specified in Annex I, vendors should only make available products without known exploitable vulnerabilities, but they should also ensure that vulnerabilities can be addressed through security updates, including, where applicable, automated security updates separated from functional updates that bring new features. They must also establish and enforce a coordinated vulnerability disclosure pol- icy, and apply effective and regular security testing and reviews, among other things. As soon discussed in Section 5, the essential cyber security requirements imply also new requirements for supply chain management and coordination. 4 The CRA and Open Source Many open source software (OSS) projects and their foundations were critical about the CRA during its policy-making. Some notable OSS foundations even raised an argument that online distribution of OSS might be blocked in the EU due to the CRA (see [12], among many others during the CRA’s policy-making). While the argument might have merely been a part of an aggressive lobbying strategy, some have used a term “regulatory anger” to describe the situation during the political negotiations, concluding that the new regulatory obligations for OSS projects are modest at best and relatively easy to fulfill [16]. The rea- son for the only modest implications originates from the fact that the CRA essentially only applies to commercial OSS projects. This restriction is clarified in recitals 17, 18, and 19. These recitals clarify that natural or legal persons who merely contribute to OSS projects are not within the regulation’s scope. Nor is a mere distribution of OSS in the CRA’s scope. Instead, the keyword is monetization. To quote from recital 19, the CRA only applies to OSS projects that “are ultimately intended for commercial activities”, including “cases where manufacturers that integrate a component into their own products with digital elements either contribute to the development of that component in a regular manner or provide regular financial assistance to ensure the continuity of a soft- ware product”. This clarification essentially means that the main target is OSS foundations; the Linux Foundation would be the prime example. However, none of the keywords—including monetization, ultimate intentions, regular contribu- tions, and financial assistance—are actually defined in Article 3. This lack of definitions makes it unclear how the regulators and legal systems will interpret the situation. Regardless, even with vague definitions and potential disputes, the actual regulatory mandates placed upon OSS foundations are only light. Thus, Article 24 specifies three obligations for OSS foundations: (1) they are obliged to develop and publish cyber security policies that address particularly the coordination of vulnerabilities and foster the voluntary reporting of vulner- abilities; (2) they must cooperate with market surveillance authorities who may also request the cyber security policies; (3) and they too must report about ac- tively exploited vulnerabilities and severe security incidents. While the first two obligations are mostly about documentation, and most large OSS foundations likely already have such documented policies in place, the reporting obligation may perhaps be somewhat difficult to fulfill because the supporting OSS foun- dations are mostly involved in the development—and not deployment—of open source software. This point reiterates the earlier remark about reliable evidence. However, according to Article 64(10)(b), OSS foundations are excluded from the scope of administrative fines. This exclusion casts a small doubt over whether the supervising authorities have a sufficient deterrence against non-compliance. It can be mentioned that the initial legislative proposal for the CRA, identi- fied as COM/2022/454 final, was more stringent about OSS. Thus, perhaps the lobbying by OSS stakeholders was also successful. Having said that, there are two important points many OSS lobbyists missed during the negotiations. The first is that the CRA’s Article 25 entails a development of voluntary security at- testation programmes for OSS projects to ensure compliance with the essential cyber security requirements. Such programmes can be interpreted to boost the security of open source software [16]. The second point stems from Article 13(6), which mandates that a vendor who discovers a vulnerability from a third-party software component, including an OSS component, must report the vulnerability to the natural or legal persons responsible for the component’s development or maintenance. Also this reporting obligation can be seen to improve the security of open source software too. It is also directly related to supply chains. 5 The CRA and Supply Chains Both the CRA and NIS2 directive address supply chain security, either explicitly or implicitly. In fact, throughout the CRA’s motivating 130 recitals, supply chain security is frequently mentioned. Many of the new supply chain obligations are specified in Annex I. Accordingly, vendors should try to identify and document vulnerabilities in third-party software components they use; for this task, they are mandated to draw up a software bill of materials (SBOM) for their products. A SBOM is defined in Article 3(39) to mean “a formal record containing details and supply chain relationships of components included in the software elements of a product with digital elements”. In practice, SBOMs are primarily about software dependencies, whether managed through a package manager or bundled into a software product directly. These are also under active research particularly in software engineering [3, 18]. As motivated by the CRA’s recital 77, SBOMs are seen not only important for regulatory purposes but they are also perceived as relevant for those who purchase and operate software products. However, the same recital notes that vendors are not obliged to make SBOMs public, although they must supply these to market surveillance authorities upon request according to Article 13(25). Confidentiality must be honored in such cases. But SBOMs are not the only new obligation related to supply chains. Historically, there was a problem for many vulnerability discoverers to find appropriate contact details about organizations and their natural persons re- sponsible [25]. The problem and related obstacles likely still persist today, as hinted by experiences with large-scale coordinated vulnerability disclosure and the poor adoption rate of new initiatives such as the so-called security.txt for the world wide web [6, 15, 27]. To this end, paragraph 6 in Annex I mandates ven- dors to also provide contact details for reporting vulnerabilities. This obligation is important also for regulators; as was noted in Section 2, they should coor- dinate vulnerability handling, including disclosure, also in case multiple parties are involved. Without knowing whom to contact, let alone which components have been integrated, such multi-party coordination is practically impossible. The same point applies to the earlier note about obligations placed upon ven- dors who may discover vulnerabilities in third-party components they use. The obligation to provide contact details is recapitulated in paragraph 2 of Annex II. 6 Conclusion The paper examined, elaborated, and discussed the implications from the EU’s new CRA regulation upon vulnerability coordination. When keeping in mind the paper’s framing only to vulnerability coordination, the CRA’s new obligations cannot be argued to be substantial—in fact, it can be argued that many of these obligations have already long belonged to security toolboxes of responsible vendors prioritizing cyber and software security. Nevertheless, there are some new implications and associated research possibilities worth briefly pinpointing. Of the new regulatory obligations and points raised thereto, (1) further re- search is required about the concept of actively exploited vulnerabilities. Such research might also generally reveal whether the existing empirical vulnerability research has been biased in a sense that serious vulnerabilities affecting actual deployments have perhaps been downplayed; with some notable exceptions [4], the focus has often been on reported vulnerabilities affecting software products, components, and vendors, not on their actual deployments [19]. On a more theo- retical side of research, (2) further contributions are required also regarding the other fundamental concepts involved, including not only vulnerabilities but also security incidents and the so-called near misses. Then, regarding supply chains, (3) further research is required also on SBOMs. Although technical research is well underway in this regard, including with respect to a question of how to generate SBOMs automatically [20], many questions remain about applicability, usability, and related aspects, including for regulatory purposes. Although per- haps only partially related to the paper’s explicit theme, (4) a relevant research question would also be whether, how, and how well vendors can comply with the requirement to provide security patches, preferably in an automated manner. When recalling the CRA’s scope, the question is non-trivial. While providing au- tomated security updates for Internet of things devices sounds like a reasonable and well-justified goal, the situation may be quite different in industrial set- tings [24]. It also remains generally unclear whether the CRA applies to physical security, including patching of software operating in air-gapped and related de- ployments. As always, (5) further policy-oriented research is also needed. Among other things, a close eye is needed to monitor and evaluate the regulation’s future implementation, adoption, administration, and enforcement. Regarding the CRA’s future implementation, (6) a particularly relevant re- search topic involves examining the upcoming technical standards upon which the essential cyber security requirements are based. This topic is important al- ready because complying with these standards provides a presumption of confor- mity according to the CRA’s Article 27(1). The topic can be extended to other (7) conformity assessment procedures involved, including the mandatory third- party audits required for critical products and the CRA’s relation to the older cyber security certification schemes in the EU. Among other things, a good topic to examine would be the accreditation of conformity assessment bodies. It may be that the CRA will also entail a new labor market demand for cyber security professionals specialized into security testing, auditing, and related domains. At the same time, as also implicitly remarked in the CRA’s Article 10, there is al- legedly a cyber security skill gap in Europe and elsewhere [13]. As the gap may correlate with education [21, 29], (8) it may also be worthwhile to further study the CRA and its future implementation with education and curricula in mind. Regarding adoption, (9) it is relevant to know which conformity assessment pro- cedures vendors will prefer in the future; according to Article 32(1), there are four distinct procedures for conformity assessments under the CRA. Although it is too early to speculate what the CRA’s broader implications may be, three general points can be still raised. First, the larger regulatory cyber security package in the EU has expectedly raised some criticism that fragmen- tation and complexity have increased [9, 23]. The CRA has contributed to this increase. The CRA also interacts with the EU’s other(cyber security laws. In particular, as the NIS2 directive also imposes reporting obligations for vendors, synchronization between the CRA and NIS2 has been perceived as crucial [7]. Second, a notable limitation of the CRA is that it offers no legal guards against criminal or civil liability from disclosing vulnerabilities. Such guards have of- ten been seen important in the literature [2, 5]. Third, it remains to be seen whether the CRA actually improves the cyber security of products. Although all points require further research, including rigorous evaluations, particularly the last point is fundamental in terms of the CRA’s explicit goals. According to the Act’s first recital, cyber insecurity affects not only the EU’s economy but also its democracy as well as the safety and health of consumers. Already against this backdrop, it is important and relevant to evaluate in the future how well the CRA managed to remove or at least mitigate cyber insecurity in the EU. References [1] Ahmed, A., Deokar, A., Lee, H.C.B.: Vulnerability Disclosure Mechanisms: A Synthesis and Framework for Market-Based and Non-Market-Based Disclosures. Decision Support Systems 148, 113586 (2021) [2] Akgul, O., Eghtesad, T., Elazari, A., Gnawali, O., Grossklags, J., Mazurek, M.L., Votipka, D., Laszka, A.: Bug Hunters’ Perspectives on the Challenges and Benefits of the Bug Bounty Ecosystem. In: Proceedings of the 32nd USENIX Security Symposium. pp. 2275–2291. USENIX, Anaheim (2023) [3] Bi, T., Xia, B., Xing, Z., Lu, Q., Zhu, L.: On the Way to SBOMs: Investigating De- sign Issues and Solutions in Practice. ACM Transactions on Software Engineering and Methodology 33(6), 1–25 (2024) [4] Bilge, L., Dumitras, T.: Before We Knew It: An Empirical Study of Zero-Day Attacks in the Real World. In: Proceedings of the 2012 ACM Conference on Computer and Communications Security (CCS 2012). pp. 833–844. ACM, Raleigh (2012) [5] CEPS: Software Vulnerability Disclosure in Europe: Technology, Policies and Le- gal Challenges (2018), Report of a CEPS Task Force, the Centre for European Policy Studies (CEPS), available online in December 2024: https://www.ceps. eu/wp-content/uploads/2018/06/CEPS%20TFRonSVD%20with%20cover_0.pdf [6] Chen, T.H., Tagliaro, C., Lindorfer, M., Borgolte, K., Van Der Ham-De Vos, J.: Are You Sure You Want To Do Coordinated Vulnerability Disclosure? In: Pro- ceedings of the IEEE European Symposium on Security and Privacy Workshops (EuroS&PW). pp. 307–314. IEEE, Vienna (2024) [7] Chiara, P.G.: The Cyber Resilience Act: the EU Commission’s Proposal for a Horizontal Regulation on Cybersecurity for Products With Digital Elements: An Introduction. International Cybersecurity Law Review 3, 255–272 (2022) [8] CISA: Reducing the Significant Risk of Known Exploited Vulnerabilities (2024), Cybersecurity & Infrastructure Agency (CISA), available online in December 2024: https://www.cisa.gov/known-exploited-vulnerabilities [9] de Vasconcelos Casimiro, S.: Cyber Operations Threatening the European Union and its Member States: The Rise of the European Union as a Cyber Defence Actor. In: Vicente, D.M., de Vasconcelos Casimiro, S., Chen, C. (eds.) The Legal Challenges of the Fourth Industrial Revolution: The European Union’s Digital Strategy, pp. 211–232. Springer, Cham (2023) [10] ENISA: Coordinated Vulnerability Disclosure Policies in the EU (2022), European Union Agency for Cybersecurity (ENISA). Available on- line in December 2024: https://www.enisa.europa.eu/publications/ coordinated-vulnerability-disclosure-policies-in-the-eu [11] ENISA: CISA and ENISA Enhance Their Cooperation (2023), European Union Agency for Cybersecurity (ENISA). Available online in December 2024: https: //www.enisa.europa.eu/news/cisa-and-enisa-enhance-their-cooperation [12] The Linux Foundation: Open Source and the CRA: It Will Not Work (2023), Available online in December 2024: https://www.linuxfoundation.org/blog/ open-source-and-the-cra-will-not-work [13] Furnell, S., Fischer, P., Finch, A.: Can’t Get the Staff? The Growing Need for Cyber-Security Skills. Computer Fraud & Security (2), 5–10 (2017) [14] Gorton, D., Lagerstr¨om, R., Ekstedt, M.: Time Between Vulnerability Disclosures: A Measure of Software Product Vulnerability. Computers & Security 62, 278–295 (2016) [15] Hilbig, T., Geras, T., Kurpis, E., Schreck, T.: security.txt Revisited: Analysis of Prevalence and Conformity in 2022. Digital Threats: Research and Practice 4(3), 1–17 (2024) [16] Hubert, B.: EU CRA: What Does It Mean for Open Source? (2023), Available online in December 2024: https://berthub.eu/articles/posts/ eu-cra-what-does-it-mean-for-open-source/ [17] Malone, T.W., Crowston, K.: The Interdisciplinary Study of Coordination. ACM Computing Surveys 26(1), 87–119 (1994) [18] O’Donoghue, E., Reinhold, A.M., Izurieta, C.: Assessing Security Risks of Software Supply Chains Using Software Bill of Materials. In: Proceedings of the IEEE International Conference on Software Analysis, Evolution and Reengineering – Companion (SANER-C). pp. 134–140. IEEE, Rovaniemi (2024) [19] Pashchenko, I., Plate, H., Ponta, S.E., Sabetta, A., Massacci, F.: Vulnerable Open Source Dependencies: Counting Those That Matter. In: Proceedings of the 12th International Symposium on Empirical Software Engineering and Measurement (ESEM 2018). pp. 42:1 – 42:10. ACM, Oulu (2018) [20] Rabbi, M.F., Champa, A.I., Nachuma, C., Zibran, M.F.: SBOM Generation Tools Under Microscope: A Focus on The npm Ecosystem. In: Proceedings of the 39th ACM/SIGAPP Symposium on Applied Computing (SAC 2024). pp. 1233–1241. ACM, Avilla Spain (2024) [21] Ricci, S., Parker, S., Jerabek, J., Danidou, Y., Chatzopoulou, A., Badonnel, R.: Understanding Cybersecurity Education Gaps in Europe. IEEE Transactions on Education 67(2), 190–201 (2024) [22] Ruohonen, J.: A Review of Product Safety Regulations in the European Union. International Cybersecurity Law Review 3, 345–366 (2022) [23] Ruohonen, J.: The Incoherency Risk in the EU’s New Cyber Security Policies. In: van de Wetering, R., Roelens, R.H.B., Bagheri, S., Dwivedi, Y.K., Pappas, I.O., M¨antym¨aki, M. (eds.) Proceedings of the 23rd IFIP Conference on e-Business, e-Services, and e-Society (I3E 2024), Lecture Notes in Computer Science (Volume 14907). pp. 284–295. Springer, Heerlen (2024) [24] Ruohonen, J., Hjerppe, K., Kang, E.Y.: A Mapping Analysis of Requirements Between the CRA and the GDPR (2025), Archived manuscript, available online: https://arxiv.org/abs/2503.01816 [25] Ruohonen, J., Hyrynsalmi, S., Lepp¨anen, V.: A Mixed Methods Probe into the Direct Disclosure of Software Vulnerabilities. Computers in Human Behavior 103, 161–173 (2020) [26] Ruohonen, J., Rauti, S., Hyrynsalmi, S., Lepp¨anen, V.: A Case Study on Software Vulnerability Coordination. Information and Software Technology 103, 239–257 (2018) [27] Stock, B., Pellegrino, G., Rossow, C., Johns, M., Backes, M.: POSTER: Map- ping the Landscape of Large-Scale Vulnerability Notifications. In: Proceedings of the ACM SIGSAC Conference on Computer and Communications Security (CCS 2016). pp. 1787–1789. ACM, Vienna [28] Tanczer, L.M., Brass, I., Carr, M.: CSIRTs and Global Cybersecurity: How Tech- nical Experts Support Science Diplomacy. Global Policy 9(S3), 60–66 (2018) [29] Zivanovic, M., Lend´ak, I., Popovic, R.: Tackling the Cybersecurity Workforce Gap with Tailored Cybersecurity Study Programs in Central and Eastern Europe. In: Proceedings of the 19th International Conference on Availability, Reliability and Security (ARES 2024). pp. 1–8. ACM, Vienna (2024)