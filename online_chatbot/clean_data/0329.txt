Let‚Äôs Talk Through Physics! Covert Cyber-Physical Data ExÔ¨Åltration on Air-Gapped Edge Devices Matthew Chan Rutgers University matthew.chan@rutgers.edu Nathaniel Snyder University of California, Los Angeles natsnyder1@g.ucla.edu Marcus Lucas University of California, Los Angeles maluc@g.ucla.edu Luis Garcia University of California, Los Angeles lgarcia@isi.edu Oleg Sokolsky University of Pennsylvania sokolsky@cis.upenn.edu James Weimer Vanderbilt University weimerj@seas.upenn.edu Insup Lee University of Pennsylvania lee@cis.upenn.edu Paulo Tabuada University of California, Los Angeles tabuada@ee.ucla.edu Saman Zonouz Georgia Institute of Technology saman.zonouz@gatech.edu Mani Srivastava University of California, Los Angeles mbs@ucla.edu Abstract‚Äî Although organizations are continuously making concerted efforts to harden their systems against network attacks by air-gapping critical systems, attackers continuously adapt and uncover covert channels to exÔ¨Åltrate data from air-gapped systems. For instance, attackers have demonstrated the feasibility of exÔ¨Åltrating data from a computer sitting in a Faraday cage by exÔ¨Åltrating data using magnetic Ô¨Åelds. Although a large body of work has recently emerged highlighting various physical covert channels, these attacks have mostly targeted open-loop cyber- physical systems where the covert channels exist on physical channels that are not being monitored by the victim. Network architectures such as fog computing push sensitive data to cyber- physical edge devices‚Äìwhose physical side channels are typically monitored via state estimation. In this paper, we formalize covert data exÔ¨Åltration that uses existing cyber-physical models and infrastructure of individual devices to exÔ¨Åltrate data in a stealthy manner, i.e., we propose a method to circumvent cyber-physical state estimation intrusion detection techniques while exÔ¨Åltrating sensitive data from the network. We propose a generalized model for encoding and decoding sensitive data within cyber-physical control loops. We evaluate our approach on a distributed IoT network that includes com- putation nodes residing on physical drones as well as on an industrial control system for the control of a robotic arm. Unlike prior works, we formalize the constraints of covert cyber-physical channel exÔ¨Åltration in the presence of a defender performing state estimation. Keywords‚ÄîCyber-physical systems, covert channel, side chan- nel, data exÔ¨Åltration I. INTRODUCTION The practice of air-gapping critical systems‚Äìi.e., physically isolating a computer from an unsecured network‚Äìprovides assurances against standard network vulnerabilties and signif- icantly reduces the associated attack surface. These defenses typically only break down in the face of insider or physical attacks as in the Stuxnet malware [8]. However, recent attacks have overcome air-gap defenses to exÔ¨Åltrate data via covert channels that exploit device peripherals, including electro- magnetic emanations [20], [19], [21], magnetic Ô¨Åelds [27], [18], power consumption [26], acoustic noise [24], [23], [35], [25], observable characteristics [16], [28], [17], and thermal emissions [22]. The countermeasures proposed for such attacks typically discuss procedural countermeasures such as secure practices in the work environment or technological approaches that attempt to conceal or shield the physical covert channels. Mitigating the physical covert channels is feasible for static scenarios, e.g., data centers for a distributed cloud computing architecture. However, distributed computation architectures such as fog computation have evolved to perform computation on much more dynamic and adaptive edge network devices. Edge devices in the wild that are sensing and actuating in the physical environment with distributed state estimation introduce physical covert channels that exhibit much more complexities than the aforementioned channels. There have been several driving factors that have pushed the cloud computation paradigm to distributed computing on the edge. In particular, the explosion of the internet of things (IoT) has called for an increased emphasis on the collateral attributes of distributed edge networks, e.g., mobility, wide- spread geographical location, low-latency, and heterogene- ity [6]. In parallel, recent works [38], [7] have shown the feasibility of driving computation to edge devices in an attempt to facilitate advancements that target these attributes. Yet as applications are driven further from cloud computing towards the edge, there exists a tradeoff in utility versus physical security guarantees. In particular, emerging scenarios that rely on deployable and/or mobile infrastructures such as emergency response necessitate a means of distributed edge computation on devices that are cyber-physically insecure. As opposed to cloud data centers, these low-level devices are physically ex- posed and may not be able to deploy any of the aforementioned procedural countermeasures while providing cyber-physical runtime guarantees. However, unlike the aforementioned covert channels, these cyber-physical systems are typically monitored via supervisory controller state estimation to ensure the sys- tem is behaving correctly. Therefore, an attacker‚Äôs encoding mechanism for data exÔ¨Åltration would need to be designed so as not to have the state estimator raise any Ô¨Çags. Because arXiv:2210.07531v1 [cs.CR] 14 Oct 2022 fog architectures are running inferencing closer to or on the edge devices, an attacker may have access to higher-level information inferred from the data and, as such, has to encode less bits into an attack since more information can be encoded into each bit. For instance, a drone that is monitoring a group of soldiers may have an inference algorithm that detects how many soldiers are in its view. An attacker would only have to encode the number of soldiers into the data exÔ¨Åltration as opposed to sending the raw data. In this paper, we show how an edge device‚Äôs physical actuation can be used as a covert channel to exÔ¨Åltrate sensitive data. In particular, we introduce a cyber-physical encoding technique that maintains stealthiness against an entity who is monitoring the cyber-physical system via state estimation techniques. We begin by characterizing control system models for both an attacker and a defender in the same cyber- physical context. We empirically demonstrate how an attacker would maximize the rate of transmission while maintaining stealthiness with respect to the physical covert channel. This also implies that our approach maintains the utility of the cyber-physical application. For instance, to encode data into the actuation of a drone, our approach would encode data into the movement of the drone while ensuring that the drone completes its waypoint navigation correctly. This approach is analogous to prior attacks that focused on the semantic models of autonomous systems, e.g., cyber-physical attacks that target state-estimation techniques or adversarial machine learning techniques that target learned models. We evaluate our attack on two exemplary cyber-physical systems: a robotic arm in the context of an industrial control system as well as a drone surveilling an area of interest. For each system, we encode the data across a variety of applications and evaluate the efÔ¨Åcacy of each attack. We use computer vision techniques to observe the physical actuation and decode the encoded bits. We also evaluate each attack against defenders with varying levels of probabilistic certainty about the estimated system states, including a ‚Äúperfect" de- fender that has access to the precise attacker model. We optimize our attacks against state-of-the-art state estimation techniques and show how we would maximize transmission rate for each case with respect to the state estimation noise. We further enumerate countermeasures that can be embedded into state estimation techniques as well as the associated control mechanisms. Our contributions are summarized as follows: ‚Ä¢ We characterize the state-of-the-art of cyber-physical data exÔ¨Ålration techniques (Section II and introduce a generalized cyber-physical covert channel attack model for data exÔ¨Åltration that is optimized against state estimation techniques to maximize the transmis- sion rate while maintaining stealthiness (Sections III and IV). ‚Ä¢ We evaluate our approach on a variety of applica- tions across two exemplary cyber-physical systems and show the efÔ¨Åcacy of such an attack (Section V). ‚Ä¢ We discuss future directions of such attacks and enu- merate countermeasures (Sections VI and VIII). The source code and datasets of our system are available online at: [repository]1 II. BACKGROUND In this section we provide a background on air-gapped covert data exÔ¨Åltration. We then discuss the recent advance- ments in edge computation that have driven sensitive data and applications to the edge. to establish a preliminary foundation for generalizing a system model and its associated threat model. A. Air-Gapped Covert Data ExÔ¨Åltration Currently, covert data exÔ¨Åltration works have shown how physical side channels may be enabled across different modal- ities for air-gapped systems such as electromagnetic radi- ation [20], [19], [21], magnetic Ô¨Åelds [27], [18], power consumption [26], acoustic channel [9], [24], [25], optical Ô¨Åeld [16], [28], [17], as well as thermal emissions [22]. In all cases, these systems typically propose a cyber-physical air-gapped covert channel followed by an associated coun- termeasure to prevent such channels from being exploited. Subsequent works will then continue this attacker-defender game where a new covert channel is proposed to attack the hardened system. For instance, to provide a defense against the aforementioned attacks where data was exÔ¨Åltrated via electro- magnetic radiation [20], [19], [21], technical countermeasures are proposed such as physical insulation and software-based reductions of information-bearing emissions. Subsequent at- tacks then proposed a means of circumventing the physical insulation of electromagnetic radiation by exÔ¨Åltrating via the magnetic Ô¨Åeld emissions of the targeted device [27], [18]. The procedural and technical countermeasures presented the aforementioned attacks generally propose insulation of the physical channels in which data can be exÔ¨Åltrated that are subsequently exploited. For both attacks and defenses, these approaches fail to encapsulate the physical model of these channels that stem from the memory-mapped inputs and outputs of the system. Such physical models can be used to perform cyber-physical state estimation to understand what will be the physical impact of a particular action in the cyber space. Further, state estimation allows for providing an under- standing of the mutual dependency between physical channels, e.g., the correlation between a computer‚Äôs fan operation and the acoustic channel. From a defender‚Äôs perspective, state estima- tion not only enables the cyber-physical noise models that may need to be insulated, but also can perform intrusion detection if an attacker is explicitly encoding data into a particular channel that deviates from the estimated state of the channel. From an attacker‚Äôs perspective, state estimation techniques can be used to craft complex cyber-physical attacks on neglected physical channels. In both cases, the respective problems are exacerbated when moving from the static, immobile systems considered in these works‚Äìe.g., data center computers that are easier to physically insulate‚Äìto mobile and autonomous edge devices that are difÔ¨Åcult to physically insulate and expose even more cyber-physical channels. In this paper, we aim to formalize the notion of securing all physical covert channels, 1The source code and datasets will be available after the paper is published to respect the double-blind policy. 2 particularly in the context of mobile and autonomous edge devices. B. Computation on Autonomous Edge Devices Although edge and fog computation can be alluded to interchangeably [34], we refer to edge computation as the enabling technologies that perform data processing on devices that reside a single ‚Äúhop" away from sensors and actuators, i.e., directly interfacing with sensors and actuators. This implies that the edge devices will need to perform local processing of data in addition to maintaining any cyber-physical functions. The need for such edge computation stems from several factors, including the bottleneck and insecurity of networking, the inefÔ¨Åciency of cloud computation for real-time systems, as well as the fact that edge devices now produce data instead of just consuming data [34]. With the increasing demand for such frameworks, the industry has been quick to provide IoT edge services that excel in different domains. Platforms such as Microsoft Azure IoT Edge [15], AWS IoT Greegrass [32], and Watson IoT [2] have enabled previous cloud services to be migrated to the edge devices in collaboration with cloud services. Google IoT Edge [1] has similarly enabled and facilitated machine learning on the edge. GE Predix [3] has enabled distributed edge services for Industrial IoT (IIoT) applications. The increasing ubiquity of such technologies has spilled into privacy-sensitive edge applications that call for increased security and privacy measures. Privacy-sensitive edge applications. Prior works have shown that computation on the edge can signiÔ¨Åcantly reduce the latency for invasive applications such as facial recognition [39] or cognitive assistance [30]. Such local processing reduces security and privacy concerns for sensitive contexts such as emergency response scenarios where IoT devices may provide supportive services for humans [36], as shown in Figure 1. However, enabling such inference abstractions on the edge now exposes the higher level logic that can be inferred from the raw data that is being processed. In distributed cloud computation models, the raw data (e.g., an image) was sent over the network to be processed on the cloud. ExÔ¨Åltrating raw data through physical side channels is more challenging as each bit represents a very small fraction of the larger signal. However, raised abstractions and inference applications enable more information to be encoded into each bit that is exÔ¨Åltrated. We now characterize the models and assumptions for physical covert channels from both an attacker‚Äôs perspective as well as a defender of the system. III. MODELS AND ASSUMPTIONS In this section we will provide a precise system model considered in this paper for physical covert channels. We then deÔ¨Åne the threat model along with the adversarial assumptions. In particular, we categorize the different attack scenarios that arise in this context. A. System Model The system model we consider in this paper is depicted in Figure 2, where the visible IoT/CPS Edge device is monitoring a sensitive application in the context of an edge computation system model as depicted in Figure 1. A supervisory controller is monitoring the system state of the edge device and sending high-level control commands accordingly, e.g., an air trafÔ¨Åc controller sending a coordinate setpoint for a drone. The supervisory controller is also using the state information to ensure that the system state is consistent with previously sent control commands, e.g., a drone‚Äôs previous state has been updated according to the physical dynamics. We assume that the edge device has local control loops that convert the high-level commands from the supervisory controller to local actuation with respect to its internally maintained state estimation, e.g., a drone‚Äôs stability and waypoint navigation control loops. Finally, we assume that there may be one or more humans in the same vicinity that can observe the physical characteristics of the device from a distance. The notion of a human‚Äôs perception is an analog to a human‚Äôs perception with respect to distortion models in the context of adversarial machine learning [33]. We now discuss the threat model with respect to this system model. B. Threat model The threat model has two components: the compromised edge device that is encoding sensitive information into physical actuation, and an adversarial observer that is decoding the encoded actuation. Compromised software model. We assume that an attacker has compromised the edge device in such a way in which the attacker has full control of one or more physical actuators of the device. We also assume that the attacker has access to the physical dynamics of the edge device such that an attacker can model the state estimator along with an estimated noise model for the device. Such assumptions have been in used in prior cyber-physical state estimation attacks as these models can be practically obtained [11]. However, unlike previous cyber- physical system attacks, we do not assume that the attacker can report false system states to the supervisory controller as the mechanism that reports the sensed system state may be located on a different chip than the exploited software module, e.g., an attacker who has compromised the GPIO microcontroller may not be able to compromise the reported values of a separate GPS chip that is reporting the location. Enhanced adversarial observer model. For our enhanced adversarial observer, we simply assume that an adversary may be able to ‚Äúzoom" in on the edge device to observe Ô¨Åne- grained observable physical characteristics that would not be observable to a normal human observer. To formalize the adversary model, we place both the attacker and the defender in a control systems context. C. A Control Systems Summarization We formalize a control-theoretic, systems-oriented model of our proposed attacker and defender models. This systems- view summarizes the aforementioned attack vectors and elab- orates on how an attacker/defender would begin to model the physical variables and their cyber-physical dependencies. To start, we can choose to describe the cyber-physical system as a set of discrete-time, non-linear stochastic equations repre- senting the dynamics of the system as: x(t + 1) = f(x(t), u(t)) + g(w(t)) (1) 3 Privacy-Sensitive Applications Cloud Services IoT Edge Devices Distributed Logic Sensors/Actuators State Estimator Edge Application Big Data Figure 1: Edge computation system model. @ !" # + 1 CPS State Estimation Supervisory Control Visible IoT/CPS Edge Device Compromised Firmware System State Control Commands Fine-grained Observable Physical Characteristics Control + Stealthy Encoding X Decoding via State Estimation ‚Ä¶11011000100‚Ä¶ Enhanced Observer Normal Observer Figure 2: Data exÔ¨Åltration attack overview. With x(t) ‚ààRn as the state vector, u(t) ‚ààRp as the control input, f(x(t), u(t)) as a deterministic propagation function and g(w(t)) being a potentially non-linear function of the system‚Äôs process noise w(t) ‚ààRr, described by an underlying probability density function [29]. The CPS can also access information from its available set of sensing instruments. We can model a set of sensors using a stochastic transformation over the system state vector as: z(t) = h(x(t)) + v(t) (2) With z(t) ‚ààRq as the sensor measurement vector received from the sensing instruments and v(t) ‚ààRq representing a stochastic noise term, commonly regarded to be independent of the process noise w(t). Such a set of non-linear system equations can be linearized about a known system equilibrium-point (or the system‚Äôs current state ÀÜx(t)) as: Œ¥x(t) = x(t) ‚àíxeq(t), with Œ¥x(t) ‚ààRn and expressed linearly as: Œ¥x(t + 1) = A(t)Œ¥x(t) + B(t)Œ¥u(t) + G(t)w(t) (3) With A(t), B(t), G(t) possibly time varying (or time- invariant). We consider A ‚ààRn√ón to represent the state dynamics matrix, B ‚ààRn√óp, as the control input matrix, and G ‚ààRn√ór as a process-noise propagation matrix, respectively. Using the dynamics models and on board measurement equipment, we can develop control structures and state es- timators, possibly linear or non-linear in nature, to describe the attack or defense strategy of an adversary or defender. In constraining the system dynamics to a set of linearized propagation equations, when necessary, well-known estimators and controllers such as Kalman Filters and Linear Regulators can be applied to model simple and descriptive representations of the respective adversary and defender strategies in consid- eration. By subjecting the defender and attacker models to a control-theoretic perspective, we can provide provable mea- sures, when necessary, over the various ‚Äúblocks" of the system, i.e., the adversary, the defender, and the model dynamics which is referred to as the plant. Figure 3 depicts a general system structure in which the aforementioned blocks are connected into a system repre- sentation. The goal of an attacker is to encode data into a physical covert channel while maintaining stealthiness. To deÔ¨Åne stealthiness, we Ô¨Årst formalize the plant, adversary, and defender models as follows. Attacker systems model. An attacker is formalized to take the plant‚Äôs estimator output ÀÜx and the controller‚Äôs output uk as inputs to its system. In contrast, the defender attempts to monitor (and identify) deviations to the expected control inputs and state. To deviate a system‚Äôs response, an attacker will add an attack vector to the process noise, œâk to the actuators and/or sensor noise, vk to the measurement, respectively. In doing so, the attacker can break multiple independence assumptions the 4 Plant (System Model) ùíô ùíö ùùä Observer (Defender) ùíñ ref Controller (Defender) Attacker (Targets ùùék, ùùäk) ùùäattack &ùíô ùùé ùíñùíå ùùéùíÇùíïùíïùíÇùíÑùíå ref &ùíô ùíñ ùùä ùíñ Figure 3: Control system representation of the threat model. Add chi-squared detector to this model system state estimator may rely upon for its estimation model. Therefore, the system state, i.e., xk can now be correlated to the process or measurement noise by the attacker‚Äôs choosing. The choice and encoding scheme of the attacker will be domain speciÔ¨Åc and described in the subsequent section. But Ô¨Årst, we brieÔ¨Çy discuss the defender model in this context. Defender systems model. The defender differs from the system‚Äôs state estimator, in that the defender uses the output of the state estimate and its policy to detect whether a state deviates from its intended path. The goal of the defender will be to distinguish whether a perturbation is due to an attack or merely a random perturbation. This formalization allows us to model the encoding and decoding of data into covert channels, and subject them to systems-theory, when necessary. We now use our control-theoretic representation of attacker and defender in the context of covert data exÔ¨Åltration. We deÔ¨Åne what an attacker‚Äôs stealthiness and imperceptibility is with respect to this systems model. DeÔ¨Ånition III.1 (Stealthiness). We deÔ¨Åne stealthiness as the attacker‚Äôs ability to deviate the CPS‚Äôs state such that any threshold levels of the system are not crossed as a result of the attack, the attacked state(s) do not strongly correlate with non-attacked state variables, and the attack is conducted on a state which does not utilize a ‚Äôcolored-noise‚Äô state estimator, i.e., if the measurement noise is correlated, then computing an ensemble average for the auto-correlation of the measurement noise (empirically) would differ from the known correlation signal. This basic structure provides an outline for our domain- speciÔ¨Åc design of both an attack and defense strategy for cyber- physical data exÔ¨Åltration. IV. CYBER-PHYSICAL DATA EXFILTRATION In this section we formalize the design of a cyber-physical data exÔ¨Åltration attack over a physical covert channel given the aforementioned system models. The goal of the attacker is to encode data into a physical channel while maintaining stealthiness. The choice of the physical channel and all of the associated parameters will be domain-speciÔ¨Åc and dependent on the defender model. We will therefore categorize the different attacker-defender scenarios with varying levels of quality for the defender‚Äôs state estimator. In all cases, the attacker needs an enhanced sensing modality that can decode the bits at a sufÔ¨Åcient granularity. To illustrate each component of the attack design, we present a motivating example of a simpliÔ¨Åed robotic arm. A. Motivating Example: SimpliÔ¨Åed Industrial Control System Figure 4 shows an example of a simpliÔ¨Åed industrial control system (ICS) where a robotic arm is controlled by a programmable logic controller (PLC). The PLC receives higher-level setpoint commands from a supervisory control and data acquisition (SCADA) entity, which may consist of human- machine interfaces, PLC workstations, as well as historians for data logging. The robot arm is composed of two segments that are controlled by stepper motors. In this simpliÔ¨Åed example, each arm is equipped with an inertial measurement unit (IMU) that is used to close the loop for the arm‚Äôs controller. For simplicity, we restrict each arm to move along the X-Y plane. In this case, we assume that the PLC takes a an XY-coordinate setpoint from the SCADA entity and its internal control loop calculates the associated actuation commands necessary to arrive at the desired waypoint for both arm segments. For this simpliÔ¨Åed case, we will demonstrate how an attacker may choose a particular attack vector along with the associated parameters. We implemented this industrial control system with a Dobot robotic arm controlled by a Siemens S7 1200 PLC. The robotic arm has a swappable end attachment that can stand in for several example applications, such as 3D printing, laser etching, and a gripper for industrial automation. The PLC controls the arm in a closed feedback loop, reading in sensor data from the arm‚Äôs two accelerometers and actuating its stepper motors to control the arm‚Äôs movement. For simplicity, we limit the motion of the arm to a two-dimensional plane. We emulate the SCADA components through an API that sends motion commands to the PLC, which calculates the appropriate actuation commands for the arm‚Äôs stepper motors. Given this system, we now describe how a defender would model a state estimator to detect anomalies in the sensor data. ICS defender model design. The typical goal of a defender, e.g., the SCADA entity in this context, is to develop an appropriate state estimator that will detect any anomalies. Theoretically, a perfectly tuned state estimator model for all memory-mapped physical I/O and it‚Äôs associated physical covert channels of a CPS would detect any cyber-physical data exÔ¨Åltration attack[5]. In practice, it is difÔ¨Åcult to develop a perfectly robust state estimation model for real-world applications as the state dynamics and measurements can be far from ideal. Further, a defender can only develop a state estimation model for the observable set of physical variables‚Äìincluding the phys- ical channels and associated noise models that depend on a particular variable. This means that the state estimation model is heavily dependent on not only the availability and quality of sensors instrumentation, but also the associated level of process noise for the system model. For instance, if the robotic arm is making inferences about it‚Äôs own pose and reporting just the XY-coordinates of the robots end effector 5 y 1 x1 Start End ‚Äú0‚Äù ‚Äú0‚Äù ‚Äú1‚Äù ‚Äú0‚Äù ‚Äú1‚Äù ‚Äú0‚Äù ‚Äú1‚Äù Estimation-Free Trajectory x1 End ‚Äú0‚Äù ‚Äú0‚Äù ‚Äú1‚Äù ‚Äú0‚Äù ‚Äú1‚Äù ‚Äú0‚Äù ‚Äú1‚Äù With Trajectory Estimation Start y 1 Error Bounds Expected Trajectory y 1 x1 y2 x2 IMU Arm 1 Encoding Arm 1 Arm 2 SCADA Workstation Historian HMI PLC Attack Trajectory Figure 4: SimpliÔ¨Åed industrial control system to illustrate cyber-physical data exÔ¨Åltration. An attacker may encode data into the movement of the robotic arm that is not being estimated or into the noise model associated with movement that is being estimated. before and after a movement command, then a state estimator is only able to report the posterior ÀÜxt then prior ¬Øxt+1 state estimates and associated covariances of the end effector. An anomaly could be detected using a distance metric such as a Euclidean distance to see if the current XY-coordinates, {(x1, y1), (x2, y2)} are close enough to the ÀÜx and ÀÜy estimates within a certain error œµ, i.e., p ( ÀÜy1 ‚àíy1)2 + ( ÀÜx1 ‚àíx1)2 + ( ÀÜy2 ‚àíy2)2 + ( ÀÜx2 ‚àíx2)2 < œµ. (4) However, because our system model assumes it is a remote defender, augmenting a defender‚Äôs state estimator necessitates sending more sensor data over the network, which is contra- dictory to the edge computation paradigm. In any case, we will detail the design of an attacker‚Äôs encoding and decoding schemes for varying levels of state estimation. B. Encoding Data into Physical Channels As discussed, an attacker‚Äôs encoding scheme into a par- ticular physical channel will depend on the quality of the defender‚Äôs state estimation model‚Äìwhich is assumed to be known by the attacker. As such, we consider three different defender models: (1) an attacker encoding data into a physical channel that is independent from any of the defender‚Äôs state estimator models, i.e., the control process for that state variable is locally autonomous; (2) an attacker encoding data into the "noise" of a channel that is being directly estimated by the system‚Äôs state estimator; and (3) the "perfect" defender that is fully aware of an attacker‚Äôs encoding scheme and is as powerful as the attacker in terms of sensing capabilities. For the latter case, the roles are essentially reversed and the attacker‚Äôs stealthiness goals will be focused on maintaining conÔ¨Ådentiality of the data being encoded. We discuss each case in detail. Case 1: Local autonomy and estimation. If a state vari- able‚Äôs associated control loop is locally autonomous to the edge device, i.e., there is no feedback control or estimation mechanism from a higher Ô¨Ådelity external entity, then an attacker essentially has little to no inhibitions with respect to stealthiness and can manipulate any aspect of the system as long as the utility of the application is maintained. For instance, in Figure 4, the estimation-free trajectory scenario shows how an attacker may encode data into the path from a starting ("Start") XY-coordinate to an ending ("End") XY- coordinate. Such an attack would need to ensure that the utility of the function is maintained, e.g., that the encoding will have a mean noise of zero while ensuring that it reaches a distance within an error bound before the next sample. This also implies that the associated perturbations will not cause any collateral threshold violations for other states being estimated. And although this example shows the path trajectory between two sampled points as the physical channel of choice, any other cyber-physical channel that depends on the associated physical variables can also be utilized by an attacker, e.g., the acoustic noise of the stepper motors during the path trajectory. In any case, the attacker may engineer an encoding scheme that will transmit the data while ensuring the utility function‚Äôs integrity is maintained. However, encoding data becomes more difÔ¨Åcult for subsequent cases where the state variable is being estimated. Case 2: Remote external feedback control. If a state vari- able‚Äôs associated control loop relies on external state estimation and feedback control, the attacked state variable is being monitored with Ô¨Åne granularity ‚Äìwhich complicates the design of the attacker‚Äôs encoding scheme. However, it is infeasible for a defender to have a perfect state estimator model for real world systems due to environmental and systematic noise. Such an encoding mechanism requires an accurate noise model that is at least as granular as the noise model of the defender. The plot on the right of Figure 4 shows an attacker encoding bits into the trajectory of the end effector while staying within an error bounds. In this case, the attacker is much more restricted in terms of how much noise can be introduced in the encoding scheme due to the fact that the bits are being encoded into an estimated variable. However, up until now, we have assumed the attacker is more powerful than the defender. 6 Case 3: An omniscient perfect defender. The Ô¨Ånal defender model is an ideal "perfect" defender that not only has much more sensing capabilities than the attacker with perfect state estimation, but also knows the attacker model, i.e., the asso- ciated encoding and decoding schemes and modalities. In this case, the roles are reversed as an attacker has been exposed and needs to maintain conÔ¨Ådentiality of the exÔ¨Åltrated data. Obviously, a defender could simply take the system ofÔ¨Çine if the utility of the system is not critical and if it has a means to remotely control the device, i.e., only a subset of the device‚Äôs remotely controlled variables have been compromised. But in a honeypot scenario‚Äìi.e., where a defender is attempting to discover more information about the attack‚Äìthe exÔ¨Åltrated data can reveal the intent of the attacker along with other sensitive semantic information. From a cryptographic perspective, an attacker can leverage two "secrets": (1) standard cryptographic techniques embedded in the encoding software payload and (2) the location and sampling parameters of the decoding sensor. In this paper, we focus on the latter solution in which the location of a sensor can hide the semantic meaning of data being encoded. Although the design of a cryptographic mechanism within the software payload is outside of the scope of this paper, such an approach has several security and en- gineering challenges to ensure the semantic information being encoded into the physical actuation is sufÔ¨Åciently secured. If a defender can recover the device, static and dynamic analysis techniques can be used to reverse engineer some of the semantic information, e.g., combining static binary analysis with the dynamic behavioral analysis of the encoder when given certain inputs or environmental conditions [37]. We now present a generalized decoding mechanism for these encoding schemes. C. Decoding Cyber-physical Encoded Data Figure 5: System state tracking using colored markers. In order to decode data that has been encoded with any of these encoding schemes, the attacker simply needs to mirror Figure 6: Camera-tracked system state trace. Each segment encodes a single bit based on the change in angle. Bit Rate FPS Bit Error Rate 5 bit/sec 30 0% 10 bit/sec 30 0% 15 bit/sec 30 15.6% Table I: Bit error rates (BERs) for various encoding rates. the modality and granularity of the encoding scheme. For instance, in the estimation-free trajectory attack of the ICS example, an attacker would need access to the Ô¨Åner-grained path trajectory between movement commands. Having access to either a faster sampling rate or even the IMU data would be ideal, but it is not realistic for a remote attacker‚Äìespecially if we are assuming the defender does not have access to these results. A more realistic approach is that an attacker may infer the cyber-physical encoding utilizing an air-gapped physical channel such as a microphone monitoring the noise of the device or by visually monitoring the movements of each component from a distance with a camera. For instance, we im- plemented malicious motion command on the aforementioned PLC that encodes a bit string in the actuation of the arm‚Äôs motors during a benign motion command. An attacker may focus a camera on the arm to observe speciÔ¨Åc markers on the arm as shown in Figure 5. We applied color markers to the arm to simplify the tracking algorithm2. For tracking the markers we utilized OpenCV‚Äìan open-source computer vision library. The resulting output of an encoded movement is shown in Figure 6. We now discuss the design considerations for a communication protocol given an encoding and decoding scheme. D. Communication Protocol There are several domain-speciÔ¨Åc design parameters that need to be tuned for particular CPS. Regardless of whether an attacker is using cryptographic mechanisms or not, the goal should be to maximize both the rate of transmission as well as the signal-to-noise ratio (SNR). 2A more sophisticated algorithm could perform position tracking without external markers speciÔ¨Åc to the CPS 7 Channel Capacity and Bit Error Rate. There are several factors that determine the channel capacity of data exÔ¨Åltration. ‚Ä¢ Physical system constraints. The rate of encoding into a physical system is limited by the actuation speed of the system, which is determined by the system‚Äôs kinematics. Faster encoding speeds require greater forces which the system may not support. Addition- ally, physical systems may have a minimum precision with which motions can be made consistently (eg. a single motor step is 1.8 for the robotic arm¬∞). ‚Ä¢ The observer‚Äôs frame rate and resolution. The channel capacity is also limited by the capabilities of the observer. For a camera, the frame rate is analogous to the sampling rate, and we found that for the robotic arm, at least 3 frames were necessary to identify an encoded motion consistently. Additionally, the resolu- tion of the observer is correlated with the encoding: a higher resolution means that smaller motions can be detected reliably, allowing a greater encoding rate within the constraints of the physical system. ‚Ä¢ Maintaining stealth. In a scenario with a defender performing state estimation on the system, a faster encoding produces more noticeable actuations, in- creasing the likelihood of revealing the exÔ¨Åltration process to the defender. Table I shows the bit error rates for decoding in the robotic arm scenario. As we approached the limits of the encoding rate we found that the decoding accuracy decreases signiÔ¨Åcantly due to increased system vibration coupled with fewer frames per encoded bit. We now brieÔ¨Çy discuss design considerations for error checking. We now brieÔ¨Çy discuss mechanisms that can be utilized to maintain the integrity of the data. Error checking and redundancy. Since the transmission channel is a one-way communication link, re-transmission can not be requested in case of a transmission error. Forward error correction such as cyclic-redundancy checks (CRC) [10], can be used to correct errors at the receiver at the cost of reducing transmission bandwidth for redundancy. Alternatively, if the same variables are being transmitted repeatedly (data values), then the values have a short "lifetime" and we can forgo error correction altogether, Ô¨Åltering out outliers at the receiver. The Ô¨Ånal design piece focuses on an attacker‚Äôs means of maintaining imperceptibility from a defender. E. Maintaining Imperceptibility The Ô¨Ånal notion of the aforementioned attacks is main- taining imperceptibility in the face of a ‚Äúhuman observer"‚Äì or an observer that may be monitoring the CPS through a particular modality or set of modalities from sensors equivalent to a human‚Äôs ‚Äúsensors". This problem is analogous to the problem of adversarial machine learning where an attacker is introducing perturbations to a model‚Äôs input data while minimizing some loss function such that the system will misclassify the data sample while maintaining imperceptibility of the perturbations [33]. In this context, the perfect model of perceptibly is the associated decoding mechanism itself. In addition to maintaining stealthiness with respect to the state estimation model, an attacker will also minimize the encoded movements such that the decoding function will only work with a decoder that has a sufÔ¨Åcient sensing granularity, e.g., a camera equipped with an appropriate focal length to pickup tiny movements of the robotic arm. We propose the following simple scheme for maintaining imperceptibility. For a given attacker strength, it is desirable to encode information at the lowest SNR that the attacker can still decode reliably (eg. with an acceptable bit error rate). By deÔ¨Ånition, this minimizes the differentiation between signal and noise for any observer and results in the least conspicuous encoding. Additionally, the frequency and choice of encoding should be chosen carefully to closely mirror normal operating characteristics. That being said, determining these parameters may be impractical in certain situations. We now evaluate each of the aforementioned attacker-defender scenarios on a much more complex autonomous edge device. V. EVALUATION ON AN AUTONOMOUS EDGE DEVICE We now evaluate both the attacker and defender models presented from the previous section in the context of a more complex edge computation scenario: a surveillance drone. We are emulating the aforementioned scenario depicted in Figure 1 where a drone is part of an IoT coalition supporting a group of Ô¨Årst responders or soldiers. In particular, the drone is tasked to surveil an area, e.g., to search for particular objects of interest. Any inferences made by the drone will be reported by back to a supervisory entity that is interacting with the drone. We describe our experimental setup in detail. A. Experimental Setup To evaluate the drone surveillance application, we formal- ize our defense models on both position and orientation state estimates of a CrazyÔ¨Çie quadcopter [14]. For our scenario, we abstract the speciÔ¨Åc task and focus on the trajectory of the drone since the CrazyÔ¨Çie cannot support such a large computation load3. Throughout the trajectory, the ideal attacker can choose to deviate any physical degree of freedom of the system such as position, speed, or orientation. For simplicity, we show the effect a defender can have when an attacker is physically exÔ¨Åltrating data through the drone‚Äôs yaw variable. We use an Optitrack motion capture system to provide the drone with external location estimates of its 3D position and orientation in space. The CrazyÔ¨Çie was Ô¨Åtted with four Optitrack markers to precisely localize the drone during its Ô¨Çight. Our Optitrack setup utilizes 12 cameras to obtain sub- millimeter positioning accuracy. This state of the art level of accuracy allows us to provide the defender with a very precise and accurate state estimator for the drone‚Äìmore precise than outdoor localization schemes4. The drone with the markers as well as its representation in the Optitrack software can be seen in Figure 7. We use the Robotic Operating System (ROS) as the software package to communicate between the drone, motion capture system, and host computer in real time. 3Although the CrazyÔ¨Çie cannot support such large computation, neural accelerators have already shown such inferencing can be run on the edge. It is a safe assumption that this computation is already or will be soon enabled on larger outdoor drones. 4The CrazyÔ¨Çie quadcopter was chosen because it can be Ô¨Çown indoors and the motion capture system needs to be calibrated in a static indoor environment. 8 Cam. 1 Cam. 3 Cam. 5 Cam. 7 Figure 7: Drone evaluation setup using the Optitrack motion capture system. The system consists of 12 Optitrack motion capture cameras. The circled cameras were the four different perspectives selected in our evaluation. Figure 8: Optitrack replays used to simulate an enhanced observer: 1. Normal, 2. Enhanced, 3. Tracking example. We evaluate a defender model under the three aforemen- tioned attack cases for our experimental setup. For the Ô¨Årst case, the drone is tasked to execute a constant hover at 0.5 meters. The attacker encodes the data into the yaw variable about a Ô¨Åxed position. For the second case, we allow the defender to monitor both the position and yaw variable of the drone. Because the defender would be able to easily detect a change in yaw for a stationary hovering case, the drone is tasked to Ô¨Çy in a circle approximately 1 meter radius at 0.5 meters from ground level. In the third case, the drone is tasked to hover again, but now the attacker exÔ¨Åltrates data with an asynchronous and more challenging encoding scheme to highlight alternative means of stealthiness in the face of a perfect defender. The attacker generally uses two encoding schemes: The Ô¨Årst scheme is used in scenarios one and two. ‚Ä¢ Encoded Bit 1 Attacker yaws drone approximately 5 degrees counter-clockwise from start. Attacker yaws back to reference to complete the transmission. ‚Ä¢ Encoded Bit 0 Attacker yaws drone approximately 5 degrees clockwise. Attacker yaws back to reference to complete the transmission. To evaluate the feasibility of decoding the cyber-physical encoded data, we utilized video recordings of replays from the Optitrack system. The recordings were taken at 30 frames per second, and zoomed-in simulates an enhanced observer as shown in Figure 8. Similar to the ICS scenario, relative angles were established between the markers to track the system state for data exÔ¨Åltration. Baselines with no attacker perturbation were Ô¨Årst found for both the hover and circle scenarios. For the hover scenario, ambient noise levels were seen to be small. For the circle (surveillance) scenario, the drone conducted ten circles with no attacker perturbation for ground truth. Figure 10 depicts the surveillance loop of the drone, and Figure 9 shows the baseline position error and yaw of the drone as it completes 10 circles with no attacker perturbation. Furthermore, Figure 9 details Ô¨Åve segments per each subplot, depicting the respective amount of position error or yaw as the drone navigates two full circle paths, resets and starts again. We observe the XYZ position error variances are .00123, .00101, and .0001 m2, for the case of no attacker, respectively. B. Evaluating Across Different Defense Schemes We now provide an evaluation of different attacks across the aforementioned defender models. Case 1: Local autonomy and estimation. For case 1, the attacker is encoding into the yaw variable that is not being estimated by the defender. The attacker exÔ¨Åltrates using the Ô¨Årst bit encoding scheme. We repeat this process for encoding speeds of 1 bit/s, 2 bit/s and 5 bit/s. Figure 11 illustrates the hovering sequences of the drone. The data presented in Figure 11 furthermore shows the yaw of the drone does not undergo signiÔ¨Åcant drift as the attacker perturbs the system. Simple threshold values are sufÔ¨Åcient for the defender to detect an attacker in this experimental setup. Table II summarizes these results. From the attacker‚Äôs perspective, observing the drone‚Äôs motion from afar provides a reconstruction shown in Figure 12. Noisy artifacts are present due to Ô¨Çickering markers and temporary occlusions. Isolating a single channel in Figure 13 reveals a signal with acceptable signal-to-noise ratios (dB) 9 20 40 60 80 100 120 0.00 0.05 0.10 Error Pos X (m) Baseline Error for Drone Surveillance Path 20 40 60 80 100 120 0.00 0.05 0.10 Error Pos Y (m) 20 40 60 80 100 120 0.000 0.025 0.050 Error Pos Z (m) 20 40 60 80 100 120 Time (seconds) 0.2 0.0 Yaw (rad) Figure 9: Baseline errors for drone surveillance path. 1.0 0.5 0.0 0.5 1.0 1.0 0.5 0.0 0.5 1.0 0.1 0.2 0.3 0.4 0.5 Surveillance Path of Drone Figure 10: Baseline surveillance loop of drone. Freq Mean Thresh Low Thresh High Accuracy 1Hz 0 -.025 .025 100% 2Hz -.125 -.035 .035 93.75% 5Hz -0.14 -.030 0.30 93.75 % Table II: Defender Results for Case 1. Defender has knowl- edge of attacker encoding strategy. Defender uses threshold detection levels to detect attack 0 10 20 30 40 0.075 0.050 0.025 0.000 0.025 0.050 0.075 yaw (rad) Drone Hover Encoding 1hz 10 15 20 25 30 0.20 0.15 0.10 0.05 yaw (rad) Drone Hover Encoding 2hz 8 10 12 14 16 Time (sec) 0.200 0.175 0.150 0.125 0.100 yaw (rad) Drone Hover Encoding 5hz Figure 11: From Top: Drone yaw (radians) vs Ô¨Çight time (seconds) for exÔ¨Åltrating a 1 and 0 at about 1hz, 2hz and 5hz, respectively 0 5 10 15 20 25 30 Time (sec) -90 -60 -30 0 30 60 90 Relative Tracker Angles Hover Encoding 1 Hz - Camera 7 (Raw) 0 2 4 6 8 10 12 14 16 18 20 Time (sec) -90 -60 -30 0 30 60 90 Relative Tracker Angles Hover Encoding 2.5 Hz - Camera 7 (Raw) 0 2 4 6 8 10 12 14 16 Time (sec) -90 -60 -30 0 30 60 90 Relative Tracker Angles Hover Encoding 5 Hz - Camera 7 (Raw) Figure 12: Visually reconstructed drone encoding trace. 10 0 5 10 15 20 25 30 Time (sec) -90 -75 -60 -45 -30 Relative Tracker Angles Hover Encoding 1 Hz - Camera 7 (Isolated) SNR = 6.8 0 2 4 6 8 10 12 14 16 18 20 Time (sec) -90 -75 -60 -45 -30 Relative Tracker Angles Hover Encoding 2.5 Hz - Camera 7 (Isolated) SNR = 8.8 0 2 4 6 8 10 12 14 16 Time (sec) -90 -75 -60 -45 -30 Relative Tracker Angles Hover Encoding 5 Hz - Camera 7 (Isolated) SNR = 5.7 Figure 13: Isolated encoding trace for decoding. for decoding (with sufÔ¨Åcient signal processing). Of note in Figure 13, as the encoding frequency approaches the channel capacity, physical system constraints become apparent, as the drone must either endure greater accelerations or make smaller rotations (observed) to maintain the 5 Hz bitrate. Case 2: Remote external feedback control. For case two, the attacker is encoding into the yaw variable as the drone Ô¨Çies along its circular surveillance path. Figure 14 shows the 3D position error of the CPS under encoding scheme 1. The attacker‚Äôs encoding begins at each vertical red line, respectively. In this example, we Ô¨Årst give the defender the sub-task of monitoring the position of the drone. Figure 14 shows the position error traces as the drone follows the circular reference path. One key importance of Figure 14 is the fact that the start of the attacker‚Äôs encoding signal does not inÔ¨Çuence error in 3D position. This is further evident when comparing the associated xyz position error variance levels from the attacker case (.00116, .00098, .000118) m2, respectively. Thus, we observe the yaw-attack has no effect on the position error variance levels and the attack is unobservable. Figure 15 depicts the yaw error about the reference path of the drone as the attacker performs encoding scheme one again. In this case, the defender solely monitors the yaw variable, while the attacker perturbs this channel. The start of each attacker encoding is represented by a vertical red line. We see that maximums and minimums of yaw directly align with the attacker‚Äôs encoding frequency over this channel. As seen from Figure 15, the drone‚Äôs yaw slightly drifts as the attacker perturbs the drone‚Äôs heading during its circular Ô¨Çight. We see implementing a simple thresholding technique here will not be as robust when compared to the hover case, since the Ô¨Çight data is clearly non-stationary in this example. Given the defender is monitoring the yaw state variable, and 20 25 30 35 40 45 50 55 0.00 0.05 0.10 Error Pos X (m) Drone Circular Path, with Position Detector (XYZ) and Attacker 20 25 30 35 40 45 50 55 0.00 0.05 0.10 Error Pos Y (m) 20 25 30 35 40 45 50 55 Time (seconds) 0.00 0.02 0.04 Error Pos Z (m) Figure 14: Error in XYZ Position as attacker encodes bit sequence through yaw. Encoding is unobservable when moni- toring just position. Start of attacker‚Äôs bit encoding represented in red. knows the attacker‚Äôs bit encoding scheme, a simple local min/max extrema search would detect the attacker‚Äôs presence and encoded bit sequence. Table III displays the defender‚Äôs accuracy in correctly detecting the exÔ¨Åltrated data through thresholding and local extrema Ô¨Ånding. 20 25 30 35 40 45 50 55 Time (seconds) 0.00 0.05 0.10 0.15 0.20 0.25 0.30 0.35 Error Yaw (rad) Drone Circular Path, with Yaw-Detector & Attacker Figure 15: Error in yaw (radians) vs Ô¨Çight time (seconds). Error in yaw is in sync with the start of each attacker perturbation command (red lines) For the circular Ô¨Çight scenario, it is again possible for an attacker to reconstruct and decode encoded data as the yaw is independent of the XYZ position. In this situation the attacker faces challenges similar to the defender when decoding (such as non-stationary data), as both parties are estimating the yaw. However, an unencoded Ô¨Çight can help establish a baseline Technique Accuracy Local Extrema 90.6% Thresholding 53.1% Table III: Defender Results for Case 2: Defender has knowl- edge of attacker encoding strategy. Comparison of threshold detection and local extrema accuracy. 11 for decoding. Figure 16 shows the adversarial observer‚Äôs reconstruction of the circular motion. Although the defender in this case would also be able to read and decode encoded data, we discuss in following sections ways to protect an attacker and their communication. 0 2 4 6 8 10 12 14 16 18 20 Time (sec) -80 -60 -40 -20 0 20 40 60 80 Relative Tracker Angles Circular Motion (no encoding) 0 2 4 6 8 10 12 14 16 18 20 Time (sec) -80 -60 -40 -20 0 20 40 60 80 Relative Tracker Angles Circular Motion (with encoding) Figure 16: Visually reconstructed circular motion trace. Case 3: An omniscient perfect defender. In the case of a perfect defender, who knows both the attacker‚Äôs covert physical channel and encoding scheme, there are two main secrets for the attacker to protect: ‚Ä¢ The communication contents. In the case of an ideal defender, the roles effectively swap ‚Äì the defender wants to Ô¨Ånd out what information is being exÔ¨Åltrated, whilst the attacker must defend this secret. To prevent a defender with knowledge of the system from Ô¨Åguring out what data the attacker is exÔ¨Åltrating, encryption (based on some shared secret between the compro- mised device and the attacker) can be used, which is outside of the scope of the paper. ‚Ä¢ The location of the decoding sensor. Depending on the encoding channel and scheme, it is possible that data exÔ¨Åltration is only feasible from certain perspec- tives (eg. the 2D robotic arm scenario). When the defender has this information, it may compromise the stealth of the attacker by giving away their location. Given the rotational symmetry of the yaw in the drone case, we hypothesize that this encoding channel gives little information on where the attacker is observing the system from. Figure 17 shows that this is indeed true; the encoding is visible from multiple camera angles. It is important to note though that certain angles are still "better" than others, whether due to occlusion or a observation angle depth leading to a larger SNR. However, given a capable attacker all of these angles are sufÔ¨Åcient for data exÔ¨Åltration without giving information to a knowledgeable defender. 0 2 4 6 8 10 12 14 16 18 20 Time (sec) -90 -60 -30 0 30 60 90 Relative Tracker Angles Hover Encoding 2.5 Hz - Camera 1 0 2 4 6 8 10 12 14 16 18 20 Time (sec) -90 -60 -30 0 30 60 90 Relative Tracker Angles Hover Encoding 2.5 Hz - Camera 3 0 2 4 6 8 10 12 14 16 18 20 Time (sec) -90 -60 -30 0 30 60 90 Relative Tracker Angles Hover Encoding 2.5 Hz - Camera 5 0 2 4 6 8 10 12 14 16 18 20 Time (sec) -90 -60 -30 0 30 60 90 Relative Tracker Angles Hover Encoding 2.5 Hz - Camera 7 Figure 17: Decoding as seen from various angles (see Figure 7 for camera locations). Obfuscated Encodings: We now consider the case when the attacker exÔ¨Åltrates a meaningful byte of data from the drone. A second, more challenging encoding scheme is now used: ‚Ä¢ Encoded Bit 1 Attacker yaws drone approximately 5 degrees counter-clockwise. Attacker holds this orien- tation for 0.75 seconds to transmit another encoded bit 1. ‚Ä¢ Encoded Bit 0 Attacker yaws drone approximately 5 degrees clockwise. Attacker holds this orientation for 0.75 seconds to transmit another encoded bit 0. Figure 18 depicts a byte of data being physically exÔ¨Åltrated through the drone‚Äôs yaw using the encoding scheme above. The byte is transmitted twice, to show reproducibility of the transmission. In this case, the attacker‚Äôs exÔ¨Åltration strategy is dependent on both direction of physical perturbation and the duration of the perturbation. If the defender chooses to implement either of the two formerly proposed techniques (thresholding, local-extrema search), the attacker will have successfully fooled the defender in recovering the wrong bit- string. For example, the byte exÔ¨Åltrated from Ô¨Ågure 18 is 10110110, however, the defender would guess 101010 if they only had knowledge of the attacker‚Äôs perturbation rule and not 12 the time delay rule. This demonstrates the attacker can fool the defender by encoding bits over both the system‚Äôs degrees of freedom and time. This situation is further exacerbated by the fact the attacker may be using cryptographic mechanisms to communicate the exÔ¨Åltrated bit string to a third party observer. We hypothesize combining secure state estimation models to estimate the current attack vector and possibly time-series machine learning models to infer the exÔ¨Åltrated bits from the attack sequence could provide a solution for the asynchronous exÔ¨Åltration scenario described here, and will be part of future work. 12 14 16 18 20 22 24 0.10 0.05 0.00 0.05 0.10 yaw (rad) Encoded Bit Pattern during Drone Hover, Byte 1 Figure 18: Attacker exÔ¨Åltrates a byte of data by yawing the drone with precise timing to exÔ¨Åltrate bits covertly. Byte 1 is: 10110110 VI. RELATED WORK In this section we will discuss some of the related work on data exÔ¨Åltration via covert channels as well as the formalization of side channels. Air-gapped covert data exÔ¨Åltration. There is a large body of research on the topic of physical covert channel data exÔ¨Åltration across air-gapped systems. Multiple works have shown that electromagnetic signals emitted from devices, e.g., signals from video displays [20], GSM frequencies emitted from workstations [19], or USB generated electromagnetic emissions [21], can be picked up by mobile phones to establish a physical covert channel. It was shown that even if these channels were physically insulated to conceal any emissions via a Faraday cage, magnetic Ô¨Åelds emitted from a CPU can act as a transmitter of data to mobile phones [27], [18]. Power consumption has also been utilized as a transmitter of data by modulating the CPU utilization [26]. Similarly (but at a larger scale), it was shown that two PLCs in the context of industrial power grid can communicate covertly with each other by modulating their associated actuators in a stealthy manner [12]. However, these systems are not necessarily air- gapped as they have direct access to the cyber-physical sensors. Thermal emissions between two PCs have also been utilized to establish bi-directional communication [22]. Acoustic covert channels have been utilized to exÔ¨Åltrate data from physical hard drive noises [24], commodity desktop speakers [25], or desktop fans [23]. It has even been shown propietary information of 3D printed models can be divulged from the noise of the motors [9]. There has also been several works that have shown a similar approach to optically encode and decode information by utilizing LEDs [28], [16], [17]. In all of these cases, these attacks were presented informally and, to the best of our knowledge, our work is the Ô¨Årst to formalize a control- theoretic model of covert physical channel exÔ¨Åltration while maintaining stealthiness as well as the utility of the respective cyber-physical application. Amost all of these related works actually do not implement these attacks in the context of cyber- physical applications and the associated proposed countermea- sures discuss physical isolation or procedural security that are not applicable to cyber-physical edge devices in the wild. It is important to note that there have been attempts to formalize the notion of side-channels. Formalizing cyber-physical side channel attacks. The notion of an information-theoretic model for side-channels has been discussed to describe what an attacker may derive from other types of side channels. In these attacks, an attacker can query a system to observe its characteristics and infer characteristics about a secret key given a limited number of queries [31]. Note that the analysis of side-channels are subsumed by our physical covert channel analysis as side-channels are cyber- physical dependencies stemming from the memory-mapped I/O of the system. An attacker or a defender can utilize our approach to analyze the cyber-physical dependencies of memory-mapped I/O and uncover possible side-channels that may leak information. The major difference is that our model assumes an attacker can compromise the CPS binary to encode information and instrument side-channels as covert channels. VII. DISCUSSION We brieÔ¨Çy discuss the practicality of such attacks as well as the practical design of defensive countermeasures. Practicality and efÔ¨Åcacy of attacks. The attacks presented in this paper are signiÔ¨Åcantly more complicated than the previous air-gapped attacks, e.g., encoding data into LEDs is much easier than encoding into the movement of a drone while maintaining the utility of the application. However, such attacks are also easier to mitigate as one can simply physically disable such unnecessary actuators to harden the systems, e.g., by removing any LEDs from the system. It is much less feasible to constrain particular movements of a CPS. Further, the attacks presented in this paper were very simple movements. For more complex systems with more physical degrees of freedom, e.g., a swarm of drones or a factory automation Ô¨Çoor with several robotic arms, more sophisticated encoding and decoding mechanisms can be instrumented to both increase the rate of data transmission as well as to further obfuscate the encoding scheme. Practical defensive measures. The state estimators utilized by the defenders in this paper were idealistic as we used the Optitrack motion capture system that has sub-millimeter accuracy and typically requires signiÔ¨Åcant calibration for a small and limited space. In reality, localization and state estimation of drones in the wild is much more noisier and less predictable. In such cases, state estimation may not be reliable enough to detect an attacker and a defender may need to rely on a means of attesting the software that is running on 13 the CPS. Recent works have made strides towards attesting the behavioral integrity [4] as well as the integrity of controller software [13] in the context of industrial control systems. However, these have yet to be generalized to more complex CPS such as drones. VIII. CONCLUSION In this paper, we characterized covert data exÔ¨Åltration over air-gapped cyber-physical channels in the context of edge device applications. In particular, we formalized how an attacker may maintain the stealthiness and utility of a cyber- physical application while maximizing the rate of transmission. We detailed how to practically model attackers and defenders in this context using real-world examples of an industrial control system as well as an autonomous drone surveilling an area. We Ô¨Ånally discuss the limitation of current defensive measures and discuss appropriate countermeasures. REFERENCES [1] Cloud iot edge - extending google cloud‚Äôs ai & ml | iot edge | google cloud. [2] Explore the internet of things (iot). [3] Predix edge computing | edge computing platform | ge digital. [4] ADEPU, S., BRASSER, F., GARCIA, L., RODLER, M., DAVI, L., SADEGHI, A.-R., AND ZONOUZ, S. Control behavior integrity for distributed cyber-physical systems. arXiv preprint arXiv:1812.08310 (2018). [5] BERTSEKAS, D. P., BERTSEKAS, D. P., BERTSEKAS, D. P., AND BERTSEKAS, D. P. Dynamic programming and optimal control, vol. 1. Athena scientiÔ¨Åc Belmont, MA, 1995. [6] BONOMI, F., MILITO, R., ZHU, J., AND ADDEPALLI, S. Fog com- puting and its role in the internet of things. In Proceedings of the Ô¨Årst edition of the MCC workshop on Mobile cloud computing (2012), ACM, pp. 13‚Äì16. [7] ESMAEILZADEH, H., SAMPSON, A., CEZE, L., AND BURGER, D. Neural acceleration for general-purpose approximate programs. In Proceedings of the 2012 45th Annual IEEE/ACM International Symposium on Microarchitecture (2012), IEEE Computer Society, pp. 449‚Äì460. [8] FALLIERE, N., MURCHU, L. O., AND CHIEN, E. W32. stuxnet dossier. White paper, Symantec Corp., Security Response 5, 6 (2011), 29. [9] FARUQUE, A., ABDULLAH, M., CHHETRI, S. R., CANEDO, A., AND WAN, J. Acoustic side-channel attacks on additive manufacturing systems. In Proceedings of the 7th International Conference on Cyber-Physical Systems (2016), IEEE Press, p. 19. [10] FREIVALD, M. P., RICHARDS, M. S., AND NOBLE, A. C. Change- detection tool indicating degree and location of change of internet documents by comparison of cyclic-redundancy-check (crc) signatures, Apr. 27 1999. US Patent 5,898,836. [11] GARCIA, L., BRASSER, F., CINTUGLU, M. H., SADEGHI, A.-R., MOHAMMED, O. A., AND ZONOUZ, S. A. Hey, my malware knows physics! attacking plcs with physical model aware rootkit. In NDSS (2017). [12] GARCIA, L., SENYONDO, H., MCLAUGHLIN, S., AND ZONOUZ, S. Covert channel communication through physical interdependencies in cyber-physical infrastructures. In Smart Grid Communications (SmartGridComm), 2014 IEEE International Conference on (2014), IEEE, pp. 952‚Äì957. [13] GHAEINI, H. R., CHAN, M., BAHMANI, R., BRASSER, F., GARCIA, L., ZHOU, J., SADEGHI, A.-R., AND ZONOUZ, S. Patt: Physics-based attestation of control systems. In International Symposium on Research in Attacks, Intrusions, and Defenses (2019), Springer. [14] GIERNACKI, W., SKWIERCZY ¬¥NSKI, M., WITWICKI, W., WRO ¬¥NSKI, P., AND KOZIERSKI, P. CrazyÔ¨Çie 2.0 quadrotor as a platform for research and education in robotics and control engineering. In 2017 22nd International Conference on Methods and Models in Automation and Robotics (MMAR) (2017), IEEE, pp. 37‚Äì42. [15] GREMBAN, K. What is azure iot edge. [16] GUR, M., ZADOV, B., DAIDAKULOV, A., AND ELOVICI, Y. xled: Covert data exÔ¨Åltration from air-gapped networks via switch and router leds. In 2018 16th Annual Conference on Privacy, Security and Trust (PST) (2018), IEEE, pp. 1‚Äì12. [17] GURI, M., AND BYKHOVSKY, D. air-jumper: Covert air-gap exÔ¨Ål- tration/inÔ¨Åltration via security cameras & infrared (ir). Computers & Security 82 (2019), 15‚Äì29. [18] GURI, M., DAIDAKULOV, A., AND ELOVICI, Y. Magneto: Covert channel between air-gapped systems and nearby smartphones via cpu- generated magnetic Ô¨Åelds. arXiv preprint arXiv:1802.02317 (2018). [19] GURI, M., KACHLON, A., HASSON, O., KEDMA, G., MIRSKY, Y., AND ELOVICI, Y. Gsmem: Data exÔ¨Åltration from air-gapped computers over gsm frequencies. In USENIX Security Symposium (2015), pp. 849‚Äì864. [20] GURI, M., KEDMA, G., KACHLON, A., AND ELOVICI, Y. Airhopper: Bridging the air-gap between isolated networks and mobile phones using radio frequencies. In Malicious and Unwanted Software: The Americas (MALWARE), 2014 9th International Conference on (2014), IEEE, pp. 58‚Äì67. [21] GURI, M., MONITZ, M., AND ELOVICI, Y. Usbee: Air-gap covert- channel via electromagnetic emission from usb. In Privacy, Security and Trust (PST), 2016 14th Annual Conference on (2016), IEEE, pp. 264‚Äì 268. [22] GURI, M., MONITZ, M., MIRSKI, Y., AND ELOVICI, Y. Bitwhisper: Covert signaling channel between air-gapped computers using thermal manipulations. In Computer Security Foundations Symposium (CSF), 2015 IEEE 28th (2015), IEEE, pp. 276‚Äì289. [23] GURI, M., SOLEWICZ, Y., DAIDAKULOV, A., AND ELOVICI, Y. Fansmitter: Acoustic data exÔ¨Åltration from (speakerless) air-gapped computers. arXiv preprint arXiv:1606.05915 (2016). [24] GURI, M., SOLEWICZ, Y., DAIDAKULOV, A., AND ELOVICI, Y. Acoustic data exÔ¨Åltration from speakerless air-gapped computers via covert hard-drive noise (‚ÄòdiskÔ¨Åltration‚Äô). In European Symposium on Research in Computer Security (2017), Springer, pp. 98‚Äì115. [25] GURI, M., SOLWICZ, Y., DAIDAKULOV, A., AND ELOVICI, Y. Mosquito: Covert ultrasonic transmissions between two air-gapped computers using speaker-to-speaker communication. arXiv preprint arXiv:1803.03422 (2018). [26] GURI, M., ZADOV, B., BYKHOVSKY, D., AND ELOVICI, Y. Power- hammer: ExÔ¨Åltrating data from air-gapped computers through power lines. arXiv preprint arXiv:1804.04014 (2018). [27] GURI, M., ZADOV, B., DAIDAKULOV, A., AND ELOVICI, Y. Odini: Escaping sensitive data from faraday-caged, air-gapped computers via magnetic Ô¨Åelds. arXiv preprint arXiv:1802.02700 (2018). [28] GURI, M., ZADOV, B., AND ELOVICI, Y. Led-it-go: Leaking (a lot of) data from air-gapped computers via the (small) hard drive led. In International Conference on Detection of Intrusions and Malware, and Vulnerability Assessment (2017), Springer, pp. 161‚Äì184. [29] GUSTAFSON, D. E., AND SPEYER, J. L. Design of linear regulators for nonlinear stochastic systems. Journal of Spacecraft and Rockets 12, 6 (1975), 351‚Äì358. [30] HA, K., CHEN, Z., HU, W., RICHTER, W., PILLAI, P., AND SATYA- NARAYANAN, M. Towards wearable cognitive assistance. In Proceedings of the 12th annual international conference on Mobile systems, applications, and services (2014), ACM, pp. 68‚Äì81. [31] K√ñPF, B., AND BASIN, D. An information-theoretic model for adaptive side-channel attacks. In Proceedings of the 14th ACM conference on Computer and communications security (2007), ACM, pp. 286‚Äì296. [32] KURNIAWAN, A. Learning AWS IoT: Effectively manage connected devices on the AWS cloud using services such as AWS Greengrass, AWS button, predictive analytics and machine learning. Packt Publish- ing Ltd, 2018. [33] PAPERNOT, N., MCDANIEL, P., JHA, S., FREDRIKSON, M., CELIK, Z. B., AND SWAMI, A. The limitations of deep learning in adversarial settings. In 2016 IEEE European Symposium on Security and Privacy (EuroS&P) (2016), IEEE, pp. 372‚Äì387. [34] SHI, W., CAO, J., ZHANG, Q., LI, Y., AND XU, L. Edge computing: Vision and challenges. IEEE Internet of Things Journal 3, 5 (2016), 637‚Äì646. 14 [35] SONG, C., LIN, F., BA, Z., REN, K., ZHOU, C., AND XU, W. My smartphone knows what you print: Exploring smartphone-based side- channel attacks against 3d printers. In Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security (2016), ACM, pp. 895‚Äì907. [36] SRINIVASAN, R., MOHAN, A., AND SRINIVASAN, P. Privacy con- scious architecture for improving emergency response in smart cities. In 2016 Smart City Security and Privacy Workshop (SCSP-W) (2016), IEEE, pp. 1‚Äì5. [37] SUN, P., GARCIA, L., AND ZONOUZ, S. Tell me more than just assembly! reversing cyber-physical execution semantics of embedded iot controller software binaries. In 2019 49th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN) (2019), IEEE. [38] YAO, S., ZHAO, Y., SHAO, H., LIU, S., LIU, D., SU, L., AND ABDELZAHER, T. Fastdeepiot: Towards understanding and optimizing neural network execution time on mobile and embedded devices. In Proceedings of the 16th ACM Conference on Embedded Networked Sensor Systems (2018), ACM, pp. 278‚Äì291. [39] YI, S., HAO, Z., QIN, Z., AND LI, Q. Fog computing: Platform and applications. In 2015 Third IEEE Workshop on Hot Topics in Web Systems and Technologies (HotWeb) (2015), IEEE, pp. 73‚Äì78. 15