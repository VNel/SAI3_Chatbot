arXiv:1603.08312v1 [cs.CR] 28 Mar 2016 Optimizing Active Cyber Defense Wenlian Lu1,2, Shouhuai Xu3, and Xinlei Yi1 1 School of Mathematical Sciences, Fudan University Shanghai, P. R. China, 200433 Emails: {wenlian,11210180008}@fudan.edu.cn 2 Department of Computer Science, University of Warwick Coventry CV4 7AL, UK 3 Department of Computer Science, University of Texas at San Antonio San Antonio, Texas 78249, USA Email: shxu@cs.utsa.edu Abstract. Active cyber defense is one important defensive method for combating cyber attacks. Unlike traditional defensive methods such as ï¬rewall-based ï¬ltering and anti-malware tools, active cyber defense is based on spreading â€œwhiteâ€ or â€œbenignâ€ worms to combat against the attackersâ€™ malwares (i.e., malicious worms) that also spread over the network. In this paper, we initiate the study of optimal active cyber defense in the setting of strategic attackers and/or strategic defenders. Speciï¬cally, we investigate inï¬nite-time horizon optimal control and fast optimal control for strategic defenders (who want to minimize their cost) against non-strategic attackers (who do not consider the issue of cost). We also investigate the Nash equilibria for strategic defenders and attack- ers. We discuss the cyber security meanings/implications of the theoretic results. Our study brings interesting open problems for future research. Keywords: cyber security model, active cyber defense, optimization, epidemic model 1 Introduction The importance of cyber security is well recognized now. However, our under- standing of cyber security is still at its infant stage. In general, the attackers are constantly escalating their attack power and sophistication, while the defenders largely lag behind. To be speciï¬c, we mention the following asymmetry between cyber attack and cyber defense: The eï¬€ect of malware-like attacks is automati- cally ampliï¬ed by the network connectivity, while the defense eï¬€ect is not. This phenomenon had been implied by many previous results (e.g., [28, 9, 6, 26,34]), but was not explicitly pointed out until very recently [35]. The asymmetry is fun- damentally caused by that the defense is reactive, including intrusion detection systems, ï¬rewalls and anti-malware tools. The asymmetry can be eliminated by the idea of active cyber defense [35], where the defender also aims to take ad- vantage of the network connectivity. The concept of active cyber defense is not completely new because researchers have proposed for years the idea of using the defenderâ€™s â€œwhiteâ€ or â€œbenignâ€ worms to combat against the attackersâ€™ malwares [5, 1, 29, 23, 16, 18, 13, 30]. In a sense, active cyber defense already happened in practice; for example, the Welchia worm attempted to â€œkillâ€ the Blaster worm in compromised computers [23, 20]. It appears that full-ï¬‚edged active cyber defense is perhaps inevitable in the near future according to some recent reports [18, 24, 31]. It is therefore more imperative than ever to systematically characterize the eï¬€ectiveness of active cyber defense. This motivates the present study. 1.1 Our Contributions This paper is inspired by the recent mathematical model of active cyber de- fense dynamics [35], which characterizes the eï¬€ect of various model parameters (including the underlying complex network structures) in the setting where nei- ther the attacker nor the defender is strategic (i.e., both the attacker and the defender do not consider the issue of cost). Here we study a new perspective of active cyber defense, namely the strategic interaction between the attacker and the defender. On one hand, our study moves a step beyond [35] because we in- corporate control-theoretic and game-theoretic models to accommodate strategic interactions. On the other hand, our study assumes away the underlying complex network structures that are explicitly investigated in [35]. This means that our study is essentially based on the homogeneous (or well-mixed) assumption that each compromised computer can attack the same portion of computers. Tackling the problem of strategic attack-defense interactions with explicit complex net- work structures is left for future research. Therefore, we deem the present paper as a signiï¬cant ï¬rst step toward ultimately understanding the eï¬€ectiveness of strategic active cyber defense. Speciï¬cally, we make the following contributions. First, we investigate two ï¬‚avors of optimal control for strategic defenders against non-strategic attackers: inï¬nite-time horizon optimal control and fast optimal control. In the setting of inï¬nite-time horizon optimal control for the defender, we characterize the conditions under which the defender should adjust its active cyber defense power in a certain quantitative fashion. For example, we identify a condition under which the defender should give up using active cyber defense alone, and instead should resort to other defense methods as well (e.g., proactive defense). In the setting of fast optimal control, where the defender wants to occupy a certain portion of the network as soon as possible and at the minimal cost, there is a signiï¬cant diï¬€erence between the case that the active defense cost is linear and the case that the active defense cost is quadratic. Second, we identify the Nash equilibrium strategies when both the defender and the attacker are strategic. The ï¬ndings are interesting. For example, when the defender (or attacker) is reluctant to use/expose its advanced active cyber defense tools (or zero-day exploits), it will give up escalating its active defense (or attack) power; otherwise, there are three scenarios: (i) If the defender (or attacker) initially occupies only a certain small portion of the network, it will give up escalating its active defense (or attack). (ii) If the defender (or attacker) initially occupies a certain signiï¬cant portion of the network, it will escalate its active defense (or attack) as much as possible. (iii) If the defender (or attacker) initially occupies a certain large portion of the network, it will not escalate its active defense (or attack) â€” a sort of diminishing returns. The rest of the paper is structured as follows. Section 2 brieï¬‚y reviews the related prior work. Section 3 describes the basic active cyber defense model under the homogeneous assumption. Section 4 investigates optimal control for strategic defenders against non-strategic attackers. Section 5 studies Nash equilibria for strategic defenders and attackers. Section 6 concludes the paper with some open problems. Lengthy proofs are deferred to the Appendix. The main notations used in the paper are listed below: Î±B, Î±R defender Bâ€™s defense power Î±B and attacker Râ€™s attack power Î±R iB(t), iR(t) portions of the nodes occupied respectively by the defender and the attacker at time t, where iB(t) + iR(t) = 1 Ï€B, Ï€B(t) Ï€B is control variable and Ï€B(t) is control function Ë†Ï€B solution in the inï¬nite-time horizon optimal control case Ï€âˆ— B, Ï€âˆ—âˆ— B solutions in the case of fast optimal control with linear and quadratic cost functions, respectively z discount rate kB normalization ratio between the defenderâ€™s detection cost and re- covery cost Î» normalization ratio between the unit of time and the defenderâ€™s active defense cost kR normalization ratio between the attackerâ€™s maintenance cost and penetration cost 2 Related Work Our investigation is built on recent studies in mathematical computer malware models. These models originated in the mathematical biological epidemic models introduced in the 1920â€™s [19, 12], which were ï¬rst adapted to study the spread- ing of computer virus in the 1990â€™s [10, 11]. All these models made the homo- geneous assumption that each individual (e.g., computer) in the population has equally infection eï¬€ect on the other individuals in the population, and the as- sumption that the infected individuals recover because of reactive defense (e.g., anti-malware tools). In the past decade, there were many studies that aim to eliminate the aforementioned homogeneous assumption, by explicitly incorporat- ing the heterogeneous network structures [28,9, 6, 26, 34, 32]. The mathematical tools used for these studies are Dynamical Systems in nature. These studies demonstrated that the attack eï¬€ect of malware spreading against reactive de- fense is automatically ampliï¬ed by the largest eigenvalue of the adjacency ma- trix, which represents the underlying complex network structure. This is the attack-defense asymmetry phenomenon mentioned above. The attack-defense asymmetry phenomenon motivated the study of mathe- matical models of active cyber defense [35], which is a relatively new sub-ï¬eld in cyber security [18, 24, 31] as previous explorations were mainly geared toward legal and policy issues [5, 1, 29, 23, 16, 18, 13, 30]. One real-life incident of the ï¬‚a- vor of active cyber defense is that the Welchia worm attempted to â€œkick outâ€ another kind of worms (e.g., the Blaster worm) [23, 20]. In the ï¬rst mathemat- ical characterization of active cyber defense [35], neither the attacker nor the defender is strategic (i.e., they do not consider the issue of cost), albeit the model accommodates the underlying complex network structure. In the present paper, we move a step toward ultimately understanding optimal active cyber defense, where the attacker and/or the defender are/is strategic (i.e., they want to minimize their cost). Finally, we note that automatic patching [27] is not ac- tive cyber defense because automatic patching aims to prevent attacks, whereas active cyber defense aims to identify and possibly clean up infected computers. There have been many studies (e.g., [33, 21, 8, 4, 14, 22, 15, 25]) on applying Control Theory and Game Theory to understand various issues related to com- puter malware spreading. Our study is somewhat inspired by the botnet-defense model investigated in [4]. All the studies mentioned above only considered reac- tive defense; whereas we investigate how to optimize active cyber defense. For general information about the applications of Control Theory and Game Theory to cyber security, we refer to [2, 17] and the references therein. 3 The Basic Active Cyber Defense Model Consider a population of nodes, which can abstract computers in a cyber system. At any point in time, a node is either occupied by defender B (i.e., the node is secure), or occupied by attacker R (i.e., the node is compromised). Denote by iB(t) the portion of nodes that are occupied by the defender at time t, and by iR(t) the portion of nodes that are occupied by the attacker at time t, where iB(t)+iR(t) = 1 for any t â‰¥0. In the interaction between cyber attack and active cyber defense, the defender and the attacker can â€œgrabâ€ nodes from each other in the same fashion. Let Î±B abstract defender Bâ€™s power in grabbing attacker- occupied nodes using active cyber defense, and Î±R abstract attacker Râ€™s power in compromising defender-occupied nodes using malware-like cyber attacks. Under the homogeneous assumption that (i) each secure node has the same power in â€œgrabbingâ€ the attacker-occupied nodes and (ii) each compromised node has the same power in compromising the defender-occupied nodes, we obtain the following Dynamical System model: ( diB(t) dt = Î±BiB(t)iR(t) âˆ’Î±RiR(t)iB(t) diR(t) dt = Î±RiR(t)iB(t) âˆ’Î±BiB(t)iR(t), where iB(t) + iR(t) = 1, iB(t) â‰¥0, and iR(t) â‰¥0 for all t â‰¥0. Due to the symmetry, we only need to consider diB(t) dt = Î±BiB(t)(1 âˆ’iB(t)) âˆ’Î±RiB(t)(1 âˆ’iB(t)). (1) If neither the attacker nor the defender is strategic (i.e., they do not consider the issue of cost), the dynamics of system (1) can be characterized as follows. â€“ If the attacker is more powerful than the defender, namely Î±R > Î±B, the attacker will occupy the entire network in the fashion of the Logistic equation (i.e., when iR is small, iR increases slowly; when iR is around a threshold value, iR increases exponentially; when iR is large, iR increases slowly). â€“ If the defender is more powerful than the attacker, namely Î±B > Î±R, the defender will occupy the network in the same fashion as in the above case. â€“ If the attacker and the defender are equally powerful, namely Î±R = Î±B, the system state is in equilibrium. In other words, iB(t) = iB(0) and iR(t) = iR(0) = 1 âˆ’iB(0) for any t > 0. The above model accommodates non-strategic attackers and non-strategic de- fenders, and is the starting point for our study of optimal active cyber defense. 4 Optimal Control for Strategic Defender Against Non-Strategic Attacker 4.1 Inï¬nite-time Horizon Optimal Control In this setting, the non-strategic attacker R maintains a ï¬xed degree of attack power Î±R, while the defender B is strategic. That is, the strategic defender aims to minimize its cost (speciï¬ed below) by adjusting its defense power Î±B via Î±B = b + Ï€B(a âˆ’b), while obeying the dynamics of (1), where Ï€B âˆˆ[0, 1] is the control variable and Î±B âˆˆ[b, a] is the defenderâ€™s defense power with 1 â‰¥a > b â‰¥0. The cost to the defender consists of two parts. â€“ The recovery cost for recovering the compromised nodes to secure states (e.g., re-installing the operating systems and updating the backup data ï¬les, interference with the computersâ€™ routine functions). We represent this cost by fB(iB(t)) for some real-valued function fB(Â·). We assume f â€² B(Â·) < 0 because the more nodes the defender occupies, the lower the cost for the defender to recover the compromised nodes. â€“ The detection cost for detecting (or recognizing) compromised nodes via active cyber defense, which partly depends on the attackâ€™s evasiveness. We represent this cost by kB Â·Ï€B(Â·), where kB is the normalization ratio between the detection cost and the recovery cost, and Ï€B(Â·) is the control function that speciï¬es the adjustable degree of active cyber defense power. This is plausible because using more powerful active defense mechanisms (e.g., more sophisticated/advanced â€œwhiteâ€ worms) causes a higher cost but allows the defender to ï¬ght against the attacks more eï¬€ectively. The above deï¬nition of cost accommodates at least the following family of ac- tive cyber defense: The defender uses â€œwhiteâ€ worms to detect the compromised nodes, then possibly manually recovers the compromised nodes. This is perhaps the most probable scenario because for example, the attackerâ€™s malware may have corrupted or deleted some data ï¬les in the compromised computers. Note that the detection cost highlights the diï¬€erence between (i) active-cyber-defense based detection, where the defenderâ€™s detection tools (i.e., â€œwhiteâ€ worms) do not reside on the compromised computers, and (ii) reactive-cyber-defense based detection such as the current generation of anti-virus software, where the detec- tion tools do not spread over the network. Assuming that the attacker maintains a ï¬xed degree of attack power Î±R, the defenderâ€™s optimization goal is to minimize the total cost with a constant discount rate z over an inï¬nite-time horizon, namely inf 0â‰¤Ï€B(Â·)â‰¤1  JB(Ï€B(Â·)) = Z âˆ 0 eâˆ’zt(fB(iB(t)) + kB Â· Ï€B(t))dt  , (2) where f â€² B(Â·) < 0, Ï€B(Â·) âˆˆ[0, 1], and the attackerâ€™s ï¬xed degree of attack power Î±R is treated as a constant. Now the optimization problem reduces to identifying the optimal defense strategy Ë†Ï€B. To solve the minimization problem, we use Pontryaginâ€™s Minimum Principle to ï¬nd the Hamiltonian associated to (2): HB(iB, Ï€B, p) = fB(iB) + kBÏ€B + p[Î±BiB(1 âˆ’iB) âˆ’Î±RiB(1 âˆ’iB)] = (kB + piB(1 âˆ’iB)(a âˆ’b))Ï€B + fB(iB) + pbiB(1 âˆ’iB) âˆ’pÎ±RiB(1 âˆ’iB),(3) where p is the adjoint equation  Ë™p = âˆ’âˆ‚HB âˆ‚iB + zp = âˆ’f â€² B(iB) + p[z âˆ’(Î±B âˆ’Î±R)(1 âˆ’2iB)] p1(âˆ) = 0. (4) The optimal strategy Ë†Ï€B is obtained by minimizing the Hamiltonian HB(iB, Ï€B, p). Since HB(iB, Ï€B, p) is linear in Ï€B, the optimal control strategy Ë†Ï€B takes the following bang-bang control form: Ë†Ï€B = ï£± ï£´ ï£´ ï£² ï£´ ï£´ ï£³ 1 if âˆ‚HB âˆ‚Ï€B < 0 uB (0 < uB < 1, to be determined) if âˆ‚HB âˆ‚Ï€B = 0 0 if âˆ‚HB âˆ‚Ï€B > 0 (5) where âˆ‚HB âˆ‚Ï€B = kB + piB(1 âˆ’iB)(a âˆ’b). In the singular form âˆ‚HB âˆ‚Ï€B = 0 and for a period of time, we have p = âˆ’kB iB(1 âˆ’iB)(a âˆ’b). (6) Further diï¬€erentiating âˆ‚HB âˆ‚Ï€B with respect to t, we have d dt âˆ‚HB âˆ‚Ï€B  = Ë™piB(1 âˆ’iB)(a âˆ’b) + p(1 âˆ’2iB)Ë™iB(a âˆ’b) = iB(1 âˆ’iB)(a âˆ’b)  âˆ’f â€² B(iB) + p[z âˆ’(Î±B âˆ’Î±R)(1 âˆ’2iB)]  +p(1 âˆ’2iB)(a âˆ’b)  Î±BiB(1 âˆ’iB) âˆ’Î±RiB(1 âˆ’iB)  = âˆ’iB(1 âˆ’iB)(a âˆ’b)f â€² B(iB) âˆ’kBz Deï¬ne FB(iB) = âˆ’iB(1 âˆ’iB)(a âˆ’b)f â€² B(iB) âˆ’kBz. Then we need to study the roots of FB(Â·) = 0. 0 0.2 0.4 0.6 0.8 1 0 0.05 0.1 0.15 0.2 0.25 iB y=iB(1âˆ’iB)(aâˆ’b) y=kBz i1 i2 Fig. 1. Illustration of the roots of FB(iB) = 0 with fB(iB) = 1âˆ’iB, aâˆ’b = 1 and kBz = 1/8, where the x-axis represents iB and the y-axis represents y(iB) = iB(1âˆ’iB)(aâˆ’b). The arrows indicate the directions the outcome under optimal control will head for. Before presenting the results, we discuss the ideas behind them. In this paper, we focus on case fB(iB) = 1 âˆ’iB, which can be easily extended to any linear recovery-cost function. If kBz < 1 4(a âˆ’b), then FB(iB) = 0 has two roots: i1 = 1 âˆ’ q 1 âˆ’4 kBz aâˆ’b 2 and i2 = 1 + q 1 âˆ’4 kBz aâˆ’b 2 with 0 < i1 < i2 < 1. As illustrated in Figure 1, this implies ï£± ï£² ï£³ FB(iB) < 0 if iB < i1 FB(iB) > 0 if i1 < iB < i2 FB(iB) < 0 if iB > i2. Then, the optimal strategy Ë†Ï€B of the singular form can be obtained by solving Ë™iB |iB=i1 or iB=i2= 0. Theorem 1. Suppose the non-strategic attacker maintains a ï¬xed degree of at- tack power Î±R, fB(iB) = 1 âˆ’iB and kBz < 1 4(a âˆ’b). Let i1 < i2 be the roots of FB(iB) = 0. Let uB = Î±Râˆ’b aâˆ’b . The optimal control strategy for defender B is: Ë†Ï€B = ï£± ï£´ ï£´ ï£´ ï£´ ï£² ï£´ ï£´ ï£´ ï£´ ï£³ 0 if iB < i1 uB if iB = i1 1 if i1 < iB < i2 uB if iB = i2 0 if iB > i2 . (7) Proof of Theorem 1 is deferred to Appendix A. In practice, i1 and i2 can be obtained numerically. Theorem 1 (also as illustrated in Figure 1) shows that the outcome of the inï¬nite-time horizon optimal control, namely limtâ†’âˆiB(t), depends on the initial system state iB(0) as follows: â€“ If 1 > iB(0) > i2, the defender should use the least powerful/costly active defense mechanisms (i.e., Î±B = b) because Ë†Ï€B = 0. Moreover, the outcome of the optimal defense is that the defender will occupy i2 portion of the network, namely limtâ†’âˆiB(t) = i2. This suggests a sort of diminishing returns in active cyber defense: It is more cost-eï¬€ective to pursue â€œgood enoughâ€ security (i.e., limtâ†’âˆiB(t) = i2 < 1) than to pursue â€œperfectâ€ security (i.e., limtâ†’âˆiB(t) = 1) even if it is possible. â€“ If 0 = iB(0) < i1, the defender should use the least powerful/costly active defense mechanisms (i.e., Î±B = b) because Ë†Ï€B = 0. Moreover, the outcome of the optimal defense is that the defender should give up (using active cyber defense as the only defense methods), as the attacker will occupy the entire network, namely limtâ†’âˆiB(t) = 0. In other words, the defender should resort to other defense methods as well (e.g., proactive defense). â€“ If iB(0) âˆˆ(i1, i2), the defender should use the most powerful/costly active defense mechanisms (i.e., Î±B = a) because Ë†Ï€B = 1. Moreover, the outcome of the optimal defense is that the defender will occupy i2 portion of the network, namely limtâ†’âˆiB(t) = i2. This also suggests a sort of diminishing returns mentioned above. â€“ If iB(0) = i1 or iB(0) = i2, the defender should adjust its deployment of active cyber defense mechanisms according to uB = Î±Râˆ’b aâˆ’b , which means Î±B = Î±R. Moreover, the outcome of the optimal defense is that iB(t) = iB(0) for all t > 0. Now we consider the degenerated scenarios of kBz â‰¥1/4(a âˆ’b). The proof is similar to, but much simpler than, the proof of Theorem 1, and thus omitted. Theorem 2. Suppose the non-strategic attacker maintains a ï¬xed degree of at- tack power Î±R and fB(iB) = 1 âˆ’iB. â€“ If kBz = 1/4(a âˆ’b), then FB(iB) = 0 has only one root, i1 = i2 = 1 2. The optimal control strategy is Ë†Ï€B = ï£± ï£² ï£³ 0 if iB < i1 uB = Î±Râˆ’b aâˆ’b if iB = i1 0 if iB > i1. (8) â€“ If kBz > 1/4(a âˆ’b), then FB(iB) = 0 has no root. The optimal control strategy is Ë†Ï€B = 0. The cyber security implications of Theorem 2 are the following. In the case kBz = 1 4(a âˆ’b), the outcome under the optimal control depends on the initial system state as follows: â€“ If 1 > iB(0) > i1, the defender should use the least powerful/costly active cyber defense mechanisms because Ë†Ï€B = 0. The outcome is that the defender will occupy i1 portion of the network, namely limtâ†’âˆiB(t) = i1. â€“ If 0 = iB(0) < i1, the defender should use the least powerful/costly active cyber defense mechanisms because Ë†Ï€B = 0. The outcome is that the defender will give up using active cyber defense alone, as the attacker will occupy the entire the network, namely limtâ†’âˆiB(t) = 0. In other words, the defender should resort to other defense methods as well (e.g., proactive defense). â€“ If iB(0) = i1, the defender will adjust its degree of active cyber defense power according to Ë†Ï€B = uB = Î±Râˆ’b aâˆ’b , which means Î±B = Î±R. The outcome is that iB(t) = iB(0) for all t > 0. In the case kBz > 1/4(aâˆ’b), the defender should use the least powerful/costly ac- tive cyber defense mechanisms because Ë†Ï€B = 0. The outcome is that limtâ†’âˆiB(t) = 0, meaning that the defender should give up using active cyber defense alone and resort to other defense methods as well (e.g., proactive defense). By considering Theorems 1 and 2 together, we draw some deeper insights. Speciï¬cally, for a given z, diï¬€erent kBâ€™s suggest diï¬€erent optimal active defense strategies. More speciï¬cally, if kB > 1 4z(a âˆ’b), meaning that the cost of optimal control is dominating, then defender B should use the least powerful/costly active cyber defense mechanisms because Ë†Ï€B(t) = 0 for all t and the outcome is limtâ†’âˆiB = 0. In other words, the defender should give up using active cyber defense alone, and resort to other kinds of defense methods as well (e.g., proactive defense). If kB < 1 4z(a âˆ’b), meaning that the cost of control is not dominating, the defender should enforce optimal control according to the initial state iB(0). In particular, if kB = 0, meaning that the special case that the cost of control is not counted, defender B should use the most powerful/costly active defense mechanisms as Ë†Ï€B(t) = 1 for all t, and the outcome is that limtâ†’âˆiB = 1, namely that the defender will occupy the entire network. 4.2 Fast Optimal Control for Strategic Defenders against Non-Strategic Attackers Now we consider fast optimal control for strategic defenders against non-strategic attackers, as motivated by the following question: Suppose the attacker maintains a ï¬xed degree of attack power Î±R and the defender initially occupies iB(0) = i0 < ie portions of the nodes, how can the defender use optimal control to occupy the desired ie portions of the nodes as soon as possible? More precisely, the optimization is to minimize the sum of active defense cost and time (after appropriate normalization), which can be described by the following functional: JF (Ï€B(Â·)) = T + Î» Z T 0 h(Ï€B(t))dt where h(Â·) is the cost function with respect to the control function Ï€B(Â·). We consider two scenarios of cost functions: linear and quadratic. In both scenarios, we need to identify defender Bâ€™s optimal strategy with respect to the dynamics of (1) and a given objective ie > i0 for some hitting time T that is to be identiï¬ed. Scenario I: Fast optimal control with linear cost functions. In this sce- nario, we have h(Ï€B) = Ï€B. The optimization task is to minimize the active defense cost plus the time T : inf 0â‰¤Ï€B(Â·)â‰¤1 ( JF (Ï€B(Â·)) = T + Î» Z T 0 Ï€B(t)dt ) (9) subject to ï£± ï£² ï£³ diB(t) dt = Î±BiB(t)(1 âˆ’iB(t)) âˆ’Î±RiB(t)(1 âˆ’iB(t)) iB(0) = i0 iB(T ) = ie where Î» > 0 is the normalization ratio between the unit of time and the active defense cost R T 0 Ï€B(t)dt, and i0 < ie. That is, Î», i0 and ie are given, but T is free. Note that the active defense cost R T 0 Ï€B(t)dt includes both detection and recovery cost, where Ï€B(t) is the control function. Theorem 3. The solution to the fast optimal control problem (9) is (Ï€âˆ— B, T âˆ—) = (1, T1), (10) where T1 = 1 aâˆ’Î±R ln  ie 1âˆ’ie 1âˆ’i0 i0  . Proof of Theorem 3 is deferred to Appendix B. The cyber security implication of Theorem 3 is the following. In order to achieve fast optimal control, the defender should use the most powerful/costly active cyber defense mechanisms, namely Ï€B(t) = 1 for t < T âˆ—, until the system state becomes iB(T âˆ—) = ie at time T âˆ—. After time T âˆ—, if the defender continues enforcing Ï€B(t) = 1 for t > T âˆ—, then limtâ†’âˆiB(t) = 1, meaning that the defender will occupy the entire network. Scenario II: Fast optimal control with quadratic cost functions. In this scenario, we have h(Ï€B) = Ï€2 B. The optimization task is to minimize the following sum of active defense cost and time, which diï¬€ers from the linear cost (9) in that the cost function Ï€B is replaced with cost function Ï€2 B: inf 0â‰¤Ï€B(Â·)â‰¤1 ( JF (Ï€B(Â·)) = T + Î» Z T 0 Ï€2 B(t)dt ) (11) subject to ï£± ï£² ï£³ diB(t) dt = Î±BiB(t)(1 âˆ’iB(t)) âˆ’Î±RiB(t)(1 âˆ’iB(t)) iB(0) = i0 iB(T ) = ie where Î» > 0 is the ratio between the unit of time and the active defense cost R T 0 Ï€2 B(t)dt (including both recovery cost and detection cost), and i0 < ie. That is, Î», i0 and ie are given, but T is free. Theorem 4. The solution to the fast optimal control problem (11) is (Ï€âˆ—âˆ— B , T âˆ—âˆ—) = ( (uâˆ—, T2), if Î» â‰¥ aâˆ’b a+bâˆ’2Î±R and a âˆ’b > 2(Î±R âˆ’b), (1, T3), otherwise (12) where uâˆ—= Î±R âˆ’b a âˆ’b + rb âˆ’Î±R a âˆ’b 2 + 1 Î», T2 = 1 b + (a âˆ’b)uâˆ—âˆ’Î±R ln  ie 1 âˆ’ie 1 âˆ’i0 i0  , T3 = 1 a âˆ’Î±R ln  ie 1 âˆ’ie 1 âˆ’i0 i0  . Proof of Theorem 4 is deferred to Appendix C. It cyber security implication is: Unlike in the setting of linear cost function (Theorem 3), the defender should not necessarily enforce the most powerful/costly active cyber defense mechanisms as Ï€âˆ—âˆ— B is not always equal to 1. If the defender continues enforcing Ï€B(t) = 1 for t > T âˆ—âˆ—after the system reaches state iB(T âˆ—âˆ—) = ie at time T âˆ—âˆ—, the defender will occupy the entire network, namely limtâ†’âˆiB(t) = 1. 5 Nash Equilibria for Strategic Attacker and Defender Now we ask the question: What if the attacker is also strategic? Analogous to the way of modeling strategic defenders, we assume Î±R âˆˆ[b, a]. (It is straightforward to extend the current setting Î±B, Î±R âˆˆ[b, a] to the setting Î±B âˆˆ[bB, aB] and Î±R âˆˆ[bR, aR].) A strategic attacker can adjust its attack power Î±R = b + Ï€R(a âˆ’b), via control variable Ï€R(Â·) âˆˆ[0, 1]. That is, the attacker can launch more sophis- ticated attacks (i.e., greater Ï€R leading to greater Î±R), which however incurs higher cost (e.g., the investment for obtaining more powerful attack tools). Since both the defender and the attacker are strategic, we naturally consider a game-theoretic model. Speciï¬cally, the defender Bâ€™s optimization task is Ï†B(iB) = inf 0â‰¤Ï€B(Â·)â‰¤1  JB(Ï€B(Â·), Ï€R(Â·)) = Z âˆ 0 eâˆ’zt(fB(iB(t)) + kB Â· Ï€B(iB(t)))dt  , and the attacker Râ€™s optimization task is Ï†R(iB) = inf 0â‰¤Ï€R(Â·)â‰¤1  JR(Ï€B(Â·), Ï€R(Â·)) = Z âˆ 0 eâˆ’zt(fR(iB(t)) + kR Â· Ï€R(iB(t)))dt  , where Ï€B(Â·), Ï€R(Â·) âˆˆ[0, 1], f â€² B(Â·) < 0 (as in the inï¬nite-time horizon optimal control case investigated above), f â€² R(Â·) > 0 because fR(iB(t)) represents the maintenance cost to the attacker, kR is the normalization ratio between the at- tackerâ€™s maintenance cost and penetration cost (which depends on the capability of the attack tools), and kR Â· Ï€R(Â·) is the penetration cost. Note that f â€² R(Â·) > 0 is relevant because the attacker may need to conduct some costly (or risky) activities after â€œgrabbingâ€ a node from the defender (e.g., downloading attack payloads from some remote server, while this downloading operation may in- crease the chance that the compromised node is detected by active defense). Since f â€² R(Â·) > 0 implies dfR/diR < 0, the attackerâ€™s optimization task for Ï€R is in parallel to the optimization for Ï€B. The Hamiltonians associated to defender Bâ€™s and attacker Râ€™s optimization problems are: HB(iB, Ï€B(iB), Ï€R(iB), p1) = fB(iB) + kBÏ€B + p1[Î±BiB(1 âˆ’iB) âˆ’Î±RiB(1 âˆ’iB)] = (kB + p1iB(1 âˆ’iB)(a âˆ’b))Ï€B + fB(iB) + p1biB(1 âˆ’iB) âˆ’p1Î±RiB(1 âˆ’iB); HR(iB, Ï€B(iB), Ï€R(iB), p2) = fR(iB) + kRÏ€R + p2[Î±BiB(1 âˆ’iB) âˆ’Î±RiB(1 âˆ’iB)] = (kR âˆ’p2iB(1 âˆ’iB)(a âˆ’b))Ï€R + fR(iB) + p2Î±BiB(1 âˆ’iB) âˆ’p2biB(1 âˆ’iB). The adjoint equation is ï£± ï£´ ï£´ ï£² ï£´ ï£´ ï£³ Ë™p1 = âˆ’âˆ‚HB âˆ‚iB + zp1 = âˆ’f â€² B(iB) + p1[z âˆ’(Î±B âˆ’Î±R)(1 âˆ’2iB)] p1(âˆ) = 0 Ë™p2 = âˆ’âˆ‚HR âˆ‚iB + zp2 = âˆ’f â€² R(iB) + p2[z âˆ’(Î±B âˆ’Î±R)(1 âˆ’2iB)] p2(âˆ) = 0. Theorem 5. Suppose fB(iB) = 1 âˆ’iB, fR(iB) = iB. Then, the Nash equilibria under various scenarios are listed in Table 1, where FB(iB) = âˆ’iB(1 âˆ’iB)(a âˆ’ b)f â€² B(iB) âˆ’kBz and FR(iB) = iB(1 âˆ’iB)(a âˆ’b)f â€² R(iB) âˆ’kRz. Proof of Theorem 5 is similar to the proof of Theorem 1 and omitted due to space limitation. Its cyber security implication is: The outcome of playing the Nash equilibrium strategies also depends on the initial system state and the relationship between kB and kR. As illustrated in Figure 2, if kB < kR with kRz < 1 4(aâˆ’b), meaning that the attacker is more concerned with its control cost (e.g., reluctant to use/expose its advanced attack tools such as zero-day exploits) than the defender, then FB(iB) = 0 has two roots i1, i2 and FR(iB) = 0 has two roots i3, i4. Then, we have i1 < i3 < i4 < i2 (the only possibility under the given conditions). Therefore, the outcomes under the Nash equilibrium strategies are summarized as follows: â€“ If iB(0) < i1, then iB(t) = iB(0) and iR(t) = iR(0) for all t > 0 because Ë†Ï€B = Ë†Ï€R = 0 are the Nash equilibrium strategies. â€“ If i3 > iB(0) > i1, then Ë†Ï€B = 1 and Ë†Ï€R = 0 until iB = i3, which implies that iB(t) strictly increases until iB = i3. When iB(t) = i3 at some point in time t = t1, Ë†Ï€B = Ë†Ï€R = 1 implies iB(t) = i3 for t > t1. Table 1. Nash equilibrium strategies for defender and attacker in various cases. kB kR Roots of FB(iB) = 0 Roots of FR(iB) = 0 Nash equilibria kBz < 1 4 (a âˆ’b) kRz < 1 4 (a âˆ’b) 0 < i1 < i2 < 1 0 < i3 < i4 < 1 Ë†Ï€B = ï£± ï£² ï£³ 0 if iB(0) â‰¤i1 1 if i1 < iB(0) < i2 0 if iB(0) â‰¥i2 Ë†Ï€R = ï£± ï£² ï£³ 0 if iB(0) < i3 1 if i3 â‰¤iB(0) â‰¤i4 0 if iB(0) > i4 kBz < 1 4 (a âˆ’b) kRz = 1 4 (a âˆ’b) 0 < i1 < i2 < 1 i3 = i4 = 1 2 Ë†Ï€B = ï£± ï£² ï£³ 0 if iB(0) â‰¤i1 1 if i1 < iB(0) < i2 0 if iB(0) â‰¥i2 Ë†Ï€R = ï£± ï£² ï£³ 0 if iB(0) < i3 1 if iB(0) = i3 0 if iB(0) > i3 kBz < 1 4 (a âˆ’b) kRz > 1 4 (a âˆ’b) 0 < i1 < i2 < 1 No real-valued roots Ë†Ï€B = ï£± ï£² ï£³ 0 if iB(0) â‰¤i1 1 if i1 < iB(0) < i2 0 if iB(0) â‰¥i2 Ë†Ï€R = 0 kBz = 1 4 (a âˆ’b) kRz < 1 4 (a âˆ’b) 0 < i1 = i2 = 1 2 0 < i3 < i4 < 1 Ë†Ï€B = ï£± ï£² ï£³ 0 if iB(0) < i1 1 if iB(0) = i1 0 if iB(0) > i2 Ë†Ï€R = ï£± ï£² ï£³ 0 if iB(0) â‰¤i3 1 if i3 < iB(0) < i4 0 if iB(0) â‰¥i4 kBz = 1 4 (a âˆ’b) kRz = 1 4 (a âˆ’b) 0 < i1 = i2 = 1 2 i3 = i4 = 1 2 Ë†Ï€B = ï£± ï£² ï£³ 0 if iB(0) < i1 Ï€R if iB(0) = i1 0 if iB(0) > i2 Ë†Ï€R = ï£± ï£² ï£³ 0 if iB(0) < i3 Ï€B if iB(0) = i3 0 if iB(0) > i3 kBz = 1 4 (a âˆ’b) kRz > 1 4 (a âˆ’b) 0 < i1 = i2 = 1 2 No real-valued roots Ë†Ï€B = 0, Ë†Ï€R = 0 kBz > 1 4 (a âˆ’b) kRz < 1 4 (a âˆ’b) No real-valued roots 0 < i3 < i4 < 1 Ë†Ï€B = 0 Ë†Ï€R = ï£± ï£² ï£³ 0 if iB(0) â‰¤i3 1 if i3 < iB(0) < i4 0 if iB(0) â‰¥i4 kBz > 1 4 (a âˆ’b) kRz = 1 4 (a âˆ’b) No real-valued roots i3 = i4 = 1 2 Ë†Ï€B = 0, Ë†Ï€R = 0 kBz > 1 4 (a âˆ’b) kRz > 1 4 (a âˆ’b) No real-valued roots No real-valued roots Ë†Ï€B = 0, Ë†Ï€R = 0 0 0.2 0.4 0.6 0.8 1 0 0.05 0.1 0.15 0.2 0.25 iB y=iB(1âˆ’iB)(aâˆ’b) y=kBz i1 i2 i3 i4 y=kRz Fig. 2. Illustration of the roots of FB(iB) = 0 with fB(iB) = 1 âˆ’iB, and the roots of FR(iB) = 0 with fR(iB) = iB, where a âˆ’b = 1, kBz = 1/8 and kRz = 1/6. The x-axis represents iB and the y-axis represents y(iB) = iB(1 âˆ’iB)(a âˆ’b). Arrows indicate the directions the outcome under the Nash equilibrium heads for. Black-colored bars indicate that the trajectory under the Nash equilibrium stays static. â€“ If i4 > iB(0) > i3, then iB(t) = iB(0) and iR(t) = iR(0) for all t > 0 because Ë†Ï€B = Ë†Ï€R = 1. â€“ If i2 > iB(0) > i4, then Ë†Ï€B = 1 and Ë†Ï€R = 0 until iB = i2, which implies that iB(t) strictly increases until iB = i2. When iB(t) = i2 at some point in time t = t2, Ë†Ï€B = Ë†Ï€R = 1 implies iB(t) = i3 for t > t2. â€“ If iB(0) > i2, then iB(t) = iB(0) and iR(t) = iR(0) for all t > 0 because Ë†Ï€B = Ë†Ï€R = 1. If kR > 1 4(a âˆ’b) > kB, meaning that the attacker is extremely concerned with its control cost (e.g., not willing to easily use/expose its advanced attack tools such as zero-day exploits) but the defender is not, then it always holds that Ë†Ï€R = 0 because FR(iB) = 0 has no root but FB(iB) = 0 has two roots i1 < i2. From Table 1, we see that limtâ†’âˆiB(t) = 1 always holds, namely that the attacker gives up using its advanced attack tools. If both kB > 1 4(aâˆ’b) and kR > 1 4(aâˆ’b), meaning that both the defender and the attacker are extremely concerned with their control costs (i.e., neither the defender wants to easily use/expose its advanced active defense tools, nor the attacker wants to use/expose its advanced attack tools such as zero-day exploits), then it always holds that Ë†Ï€B = Ë†Ï€R = 0 because FB(iB) = 0 and FR(iB) = 0 have no real-valued roots. As a result, iB(t) = iB(0) for any t > 0. The scenarios that one or both FB(iB) = 0 and FR(iB) = 0 have one root can be regarded as degenerated cases of the above. Moreover, the cases of kB > kR (i.e., the defender is more concerned about its control cost, such as not willing to easily use/expose its advanced active defense tools), the outcomes under the Nash equilibria can be derived analogously. 6 Conclusion We have investigated how to optimize active cyber defense, by presenting opti- mal control solutions for strategic defenders against non-strategic attackers, and identifying Nash equilibrium strategies for strategic defenders and attackers. We have discussed the cyber security implications of the theoretic results. This paper brings interesting problems for future research. First, it is inter- esting to extend the models to accommodate nonlinear fB(Â·) and fR(Â·). Second, the models are geared toward active cyber defense. A comprehensive defense solution, as hinted in our analysis, should require the optimal integration of re- active, active, and proactive cyber defense. Therefore, we need to extend the models to accommodate reactive defense and proactive cyber defense. Moreover, it is interesting to investigate how to extend the models to accommodate moving target defense, which has not be systematically evaluated yet [7]. Third, how to extend the models to accommodate the underlying network structures? Acknowledgement. Wenlian Lu was jointly supported by the Marie Curie International Incoming Fellowship from the European Commission (no. FP7- PEOPLE-2011-IIF-302421), the National Natural Sciences Foundation of China (no. 61273309), the Shanghai Guidance of Science and Technology (SGST) (no. 09DZ2272900) and the Laboratory of Mathematics for Nonlinear Science, Fudan University. Shouhuai Xu was supported in part by ARO Grant #W911NF-12-1- 0286 and AFOSR Grant FA9550-09-1-0165. Any opinions, ï¬ndings, and conclu- sions or recommendations expressed in this material are those of the author(s) and do not necessarily reï¬‚ect the views of any of the funding agencies. References 1. D. Aitel. Nematodes â€“ beneï¬cial worms. http://www.immunityinc.com/ downloads/nematodes.pdf, Sept. 2005. 2. T. Alpcan and T. BaÂ¸sar. Network Security: A Decision and Game Theoretic Ap- proach. Cambridge University Press, 2011. 3. M. Bardi and I. Capuzzo-Dolcetta. Optimal control and viscosity solutions of Hamilton-Jacobi-Bellman equations. Birkhauser, 2008. 4. Alain Bensoussan, Murat Kantarcioglu, and SingRu Hoe. A game-theoretical approach for ï¬nding optimal strategies in a botnet defense model. In Proc. GameSecâ€™10, pages 135â€“148, 2010. 5. F. Castaneda, E. Sezer, and J. Xu. Worm vs. worm: preliminary study of an active counter-attack mechanism. In Proc. ACM WORMâ€™04, pages 83â€“93, 2004. 6. D. Chakrabarti, Y. Wang, C. Wang, J. Leskovec, and C. Faloutsos. Epidemic thresholds in real networks. ACM Trans. Inf. Syst. Secur., 10(4):1â€“26, 2008. 7. M. Collins. A cost-based mechanism for evaluating the eï¬€ectiveness of moving target defenses. In Proc. GameSecâ€™12, pages 221â€“233, 2012. 8. Neal Fultz and Jens Grossklags. Blue versus Red: Towards a Model of Distributed Security Attacks. In Proc. Financial cryptography and data security (FCâ€™99), pages 167â€“183. 2009. 9. A. Ganesh, L. Massoulie, and D. Towsley. The eï¬€ect of network topology on the spread of epidemics. In Proc. of IEEE Infocom 2005, 2005. 10. J. Kephart and S. White. Directed-graph epidemiological models of computer viruses. In Proc. IEEE Symposium on Security and Privacy, pages 343â€“361, 1991. 11. J. Kephart and S. White. Measuring and modeling computer virus prevalence. In Proc. IEEE Symposium on Security and Privacy, pages 2â€“15, 1993. 12. W. Kermack and A. McKendrick. A contribution to the mathematical theory of epidemics. Proc. of Roy. Soc. Lond. A, 115:700â€“721, 1927. 13. J. Kesan and C. Hayes. Mitigative counterstriking: Self-defense and deterrence in cyberspace. Harvard Journal of Law and Technology (forthcoming, available at SSRN: http: // ssrn. com/ abstract= 1805163 ). 14. M. Khouzani, S. Sarkar, and E. Altman. A dynamic game solution to malware attack. In Proc. IEEE INFOCOM, pages 2138â€“2146, 2011. 15. M. Khouzani, S. Sarkar, and E. Altman. Saddle-point strategies in malware attack. IEEE Journal on Selected Areas in Communications, 30(1):31â€“43, 2012. 16. H. Lin. Lifting the veil on cyber oï¬€ense. IEEE Security & Privacy, 7(4):15â€“21, 2009. 17. M. Manshaei, Q. Zhu, T. Alpcan, T. Basar, and J. Hubaux. Game theory meets network security and privacy. ACM Computing Survey, to appear. 18. W. Matthews. U.s. said to need stronger, active cyber defenses. http://www. defensenews.com/story.php?i=4824730, 1 Oct 2010. 19. A. McKendrick. Applications of mathematics to medical problems. Proc. of Edin. Math. Soceity, 14:98â€“130, 1926. 20. R. Naraine. â€™friendlyâ€™ welchia worm wreaking havoc. http://www.internetnews.com/ent-news/article.php/3065761/ Friendly-Welchia-Worm-Wreaking-Havoc.htm, August 19, 2003. 21. J. Omic, A. Orda, and P. Van Mieghem. Protecting against network infections: A game theoretic perspective. In Infocomâ€™09, pages 1485â€“1493, 2009. 22. R. PÂ´Ä±bil, V. LisÂ´y, C. Kiekintveld, B. BosanskÂ´y, and M. Pechoucek. Game theoretic model of strategic honeypot selection in computer networks. In Proc. GameSecâ€™12, pages 201â€“220, 2012. 23. B. Schneier. Benevolent worms. http://www.schneier.com/blog/archives/ 2008/02/benevolent_worm_1.html, February 19, 2008. 24. L. Shaughnessy. The internet: Frontline of the next war? http://www.cnn.com/ 2011/11/07/us/darpa/, November 7, 2011. 25. George Theodorakopoulos, Jean-Yves Le Boudec, and John S. Baras. Selï¬sh re- sponse to epidemic propagation. IEEE Trans. Aut. Contr., 58(2):363â€“376, 2013. 26. Piet Van Mieghem, Jasmina Omic, and Robert Kooij. Virus spread in networks. IEEE/ACM Trans. Netw., 17(1):1â€“14, February 2009. 27. M. Vojnovic and A. Ganesh. On the race of worms, alerts, and patches. IEEE/ACM Trans. Netw., 16:1066â€“1079, October 2008. 28. Y. Wang, D. Chakrabarti, C. Wang, and C. Faloutsos. Epidemic spreading in real networks: An eigenvalue viewpoint. In Proc. IEEE SRDSâ€™03, pages 25â€“34, 2003. 29. N. Weaver and D. Ellis. White worms donâ€™t work. ;login: The USENIX Magazine, 31(6):33â€“38, 2006. 30. Homeland Security News Wire. Active cyber-defense strategy best de- terrent against cyber-attacks. http://www.homelandsecuritynewswire.com/ active-cyber-defense-strategy-best-deterrent-against-cyber-attacks, 28 June 2011. 31. J. Wolf. Update 2-u.s. says will boost its cyber arsenal. http://www.reuters.com/ article/2011/11/07/cyber-usa-offensive-idUSN1E7A61YQ20111107, November 7, 2011. 32. S. Xu, W. Lu, and L. Xu. Push- and pull-based epidemic spreading in arbitrary networks: Thresholds and deeper insights. ACM Transactions on Autonomous and Adaptive Systems (ACM TAAS), 7(3):32:1â€“32:26, 2012. 33. S. Xu, W. Lu, L. Xu, and Z. Zhan. Adaptive epidemic dynamics in networks: Thresholds and control. ACM Transactions on Autonomous and Adaptive Systems (ACM TAAS), to appear. 34. S. Xu, W. Lu, and Z. Zhan. A stochastic model of multivirus dynamics. IEEE Trans. Dependable Sec. Comput., 9(1):30â€“45, 2012. 35. Shouhuai Xu, Wenlian Lu, and Hualun Li. A stochastic model of active cyber defense dynamics. Internet Mathematics, to appear. A Proof of Theorem 1 Proof. By the Dynamic Programming (DP) argument [3], we know that defender Bâ€™s value function of the optimal solution can be deï¬ned as: Ï†(iB) = inf 0â‰¤Ï€B(Â·)â‰¤1  JB(Ï€B(Â·)) = Z âˆ 0 eâˆ’zt(fB(iB(t)) + kB Â· Ï€B(t))dt  . (13) This leads to the following Bellman equation: zÏ†(iB) = inf 0â‰¤Ï€B(Â·)â‰¤1  fB(iB) + kBÏ€B(t) + Ï†â€²(iB)[Î±BiB(1 âˆ’iB) âˆ’Î±RiB(1 âˆ’iB)]  = inf 0â‰¤Ï€B(Â·)â‰¤1 HB(iB, Ï€B(t), Ï†â€²(iB)) = inf 0â‰¤Ï€B(Â·)â‰¤1 HB(iB, Ï€B(t), p), where p = Ï†â€²(iB). (14) From (5), we know that the optimal strategy Ë†Ï€B takes the form: Ë†Ï€B = 1kB+piB(1âˆ’iB)(aâˆ’b)<0 + uB1kB+piB(1âˆ’iB)(aâˆ’b)=0, (15) where 1 is the indicator function. The inï¬mum of Hamiltonian (3) is: inf 0â‰¤Ï€B(Â·)â‰¤1 HB(iB, Ï€B, p) = fB(iB) + [kB + piB(1 âˆ’iB)(a âˆ’b)]1kB+piB(1âˆ’iB)(aâˆ’b)<0 + p(b âˆ’Î±R)iB(1 âˆ’iB). Hence, we have zÏ†(iB) = fB(iB) + [kB + piB(1 âˆ’iB)(a âˆ’b)]1kB+piB(1âˆ’iB)(aâˆ’b)<0 + p(b âˆ’Î±R)iB(1 âˆ’iB) = fB(iB) + [kB + Ï†â€²(iB)iB(1 âˆ’iB)(a âˆ’b)]1kB+Ï†â€²(iB)iB(1âˆ’iB)(aâˆ’b)<0 + Ï†â€²(iB)(b âˆ’Î±R)iB(1 âˆ’iB). (16) Let y(iB) = kB + Ï†â€²(iB)iB(1 âˆ’iB)(a âˆ’b). In what follows, we are to verify that (7) satisï¬es (15) with Ï†(iB) deï¬ned by (16), which means that (7) minimizes the Hamiltonian in the term of (13). This completes the proof. In order to verify that (7) satisï¬es (15) with Ï†(iB) deï¬ned by (16), we dif- ferentiate (16) with respect to iB to obtain [(b âˆ’Î±R) + (a âˆ’b)1y<0]iB(1 âˆ’iB)yâ€² âˆ’zy âˆ’FB(iB) = 0, (17) which can be rewritten as yâ€² âˆ’ z [(b âˆ’Î±R) + (a âˆ’b)1y<0]iB(1 âˆ’iB)y âˆ’ FB(iB) [(b âˆ’Î±R) + (a âˆ’b)1y<0]iB(1 âˆ’iB) = 0. (18) If kB + Ï†â€²(iB)iB(1 âˆ’iB)(a âˆ’b) < 0 namely y(iB) < 0, (18) should be d dx  y(x)eâˆ’ R x 0 z (aâˆ’Î±R)Î¾(1âˆ’Î¾) dÎ¾  âˆ’ FB(x) (a âˆ’Î±R)x(1 âˆ’x)eâˆ’ R x 0 z (aâˆ’Î±R)Î¾(1âˆ’Î¾) dÎ¾ = 0. (19) If kB + Ï†â€²(iB)iB(1 âˆ’iB)(a âˆ’b) > 0 namely y(iB) > 0, (18) should be: d dx  y(x)e R 1 x z (bâˆ’Î±R)Î¾(1âˆ’Î¾) dÎ¾  âˆ’ FB(x) (b âˆ’Î±R)x(1 âˆ’x)e R 1 x z (bâˆ’Î±R)Î¾(1âˆ’Î¾) dÎ¾ = 0. (20) Therefore, we only need to prove that the optimal defense strategy (7) satisï¬es (17), namely (19) or (20). The proof is split into cases, depending on x residing in interval (i2, 1) or (0, i1) or (i1, i2), or x = i1, or x = i2. Case 1: i2 < x < 1. By (20), we have y(x)e R 1 x z (bâˆ’Î±R)Î¾(1âˆ’Î¾) dÎ¾ âˆ’ Z x i2 FB(Î¶) (b âˆ’Î±R)Î¶(1 âˆ’Î¶)e R 1 Î¶ z (bâˆ’Î±R)Î¾(1âˆ’Î¾) dÎ¾dÎ¶ = 0. Hence, we have y(x) = Z x i2 FB(Î¶) (b âˆ’Î±R)Î¶(1 âˆ’Î¶)e R x Î¶ z (bâˆ’Î±R)Î¾(1âˆ’Î¾) dÎ¾dÎ¶. (21) Since iB > i2, we have y(x) > 0. Therefore, we have Ë†Ï€B = 0 for iB âˆˆ(i2, 1). Case 2: 0 < x < i1. By (20), we have y(x)eâˆ’ R x 0 z (bâˆ’Î±R)Î¾(1âˆ’Î¾) dÎ¾ âˆ’ Z x i1 FB(Î¶) (b âˆ’Î±R)Î¶(1 âˆ’Î¶)eâˆ’ R Î¶ 0 z (bâˆ’Î±R)Î¾(1âˆ’Î¾) dÎ¾dÎ¶ = 0. Hence, y(x) = Z x 0 FB(Î¶) (b âˆ’Î±R)Î¶(1 âˆ’Î¶)e R x Î¶ z (bâˆ’Î±R)Î¾(1âˆ’Î¾) dÎ¾dÎ¶ + kBe R x 0 z (bâˆ’Î±R)Î¾(1âˆ’Î¾) dÎ¾ =kB âˆ’ Z x 0 a âˆ’b b âˆ’Î±R f â€² B(Î¶)e R x Î¶ z (bâˆ’Î±R)Î¾(1âˆ’Î¾) dÎ¾dÎ¶ (22) Since iB < i1, we have y(x) > 0. Therefore we have Ë†Ï€B = 0 for iB âˆˆ(0, i1). Case 3: i1 < x < i2. By (19), we have y(x)e R 1 x z (aâˆ’Î±R)Î¾(1âˆ’Î¾) dÎ¾ âˆ’ Z x i2 FB(Î¶) (a âˆ’Î±R)Î¶(1 âˆ’Î¶)e R 1 Î¶ z (aâˆ’Î±R)Î¾(1âˆ’Î¾) dÎ¾dÎ¶ = 0. Hence y(x) = Z x i2 FB(Î¶) (a âˆ’Î±R)Î¶(1 âˆ’Î¶)e R x Î¶ z (aâˆ’Î±R)Î¾(1âˆ’Î¾) dÎ¾dÎ¶. (23) Since iB âˆˆ(i1, i2), we have y(x) < 0. This implies Ë†Ï€B = 1. Cases 4 & 5: x = i1 or x = i2. By (21,22,23), we have y(x) = 0. If x = i1 or x = i2, we can derive Ï†â€²(iB) = âˆ’kB iâˆ—(1âˆ’iâˆ—)(aâˆ’b) from the deï¬nition of y(Â·). According to (16), we have: zÏ†(iâˆ—) = fB(iâˆ—) + kB Î±Râˆ’b aâˆ’b . Diï¬€erentiating with respect to iâˆ—, we have âˆ’iâˆ—(1 âˆ’iâˆ—)(a âˆ’b)f â€² B(iâˆ—) âˆ’kBz = FB(iâˆ—) = 0. Consider the singular form iB(t) = iâˆ—for a period of time. We obtain that Ë™iB |iB=iâˆ—= 0 and thus Ë†Ï€B = uB = Î±Râˆ’b aâˆ’b , where iâˆ—= i1 or iâˆ—= i2. âŠ“âŠ” B Proof of Theorem 3 Proof. To solve the minimization problem, we formulate the current value Hamil- tonian associated with (9): HF (iB, Ï€B, q) = Î»Ï€B + q(Î±B âˆ’Î±R)iB(1 âˆ’iB) = [Î» + q(a âˆ’b)iB(1 âˆ’iB)]Ï€B + q(b âˆ’Î±R)iB(1 âˆ’iB). The adjoint equation is Ë™q = âˆ’âˆ‚HF âˆ‚iB = âˆ’q(Î±B âˆ’Î±R)(1 âˆ’2iB), with the boundary condition HF (iâˆ— B(T âˆ—), Ï€âˆ— B(T âˆ—), q(T âˆ—)) + 1 = 0, (24) where T âˆ—denotes the optimal hitting time that iB(T âˆ—) = ie, Ï€âˆ— B(Â·) denotes the optimal feedback control, and iâˆ— B(Â·) denotes the corresponding trajectory. The optimal control Ï€âˆ— B is obtained by minimizing Hamiltonian HF (iB, Ï€B, q). Since HF (iB, Ï€B, q) is linear in Ï€B, the optimal control Ï€âˆ— B takes the following bang-bang form: Ï€âˆ— B = ï£± ï£´ ï£´ ï£² ï£´ ï£´ ï£³ 1 if âˆ‚HF âˆ‚Ï€B < 0 uâˆ— B (0 < uâˆ— B < 1, to be determined) if âˆ‚HF âˆ‚Ï€F = 0 0 if âˆ‚HF âˆ‚Ï€B > 0 where âˆ‚HF âˆ‚Ï€B = Î» + q(a âˆ’b)iB(1 âˆ’iB). From (24), there are two possibilities: (i). If âˆ‚HF âˆ‚Ï€B â‰¥0, then 0 = bâˆ’Î±R aâˆ’b ( âˆ‚HF âˆ‚Ï€B âˆ’Î») + 1, which implies âˆ‚HF âˆ‚Ï€B = aâˆ’b Î±Râˆ’b + Î» is a positive constant. (ii). If âˆ‚HF âˆ‚Ï€B < 0, then 0 = âˆ‚HF âˆ‚Ï€B + bâˆ’Î±R aâˆ’b ( âˆ‚HF âˆ‚Ï€B âˆ’Î») + 1, which implies âˆ‚HF âˆ‚Ï€B = aâˆ’b aâˆ’Î±R h bâˆ’Î±R aâˆ’b Î» âˆ’1 i is a negative constant. It can be seen that only under the above (ii), the constraint iB(T ) = ie can be obtained for some T . Then, the solution to the optimal fast control should be Ï€B(t) = 1 for all time. So (Ï€âˆ— B, T âˆ—) = (1, T1), where T1 satisï¬es iB(T1) = i0 1âˆ’i0 e(aâˆ’Î±R)T1 1 + i0 1âˆ’i0 e(aâˆ’Î±R)T1 = ie, that is, T1 = 1 aâˆ’Î±R ln  ie 1âˆ’ie 1âˆ’i0 i0  . This completes the proof. âŠ“âŠ” C Proof of Theorem 4 Proof. To solve the optimization problem, we formulate the current value Hamil- tonian associated with (11): HF (iB, Ï€B, q) = Î»Ï€2 B + q(Î±B âˆ’Î±R)iB(1 âˆ’iB) = Î»Ï€2 B + q(a âˆ’b)iB(1 âˆ’iB)Ï€B + q(b âˆ’Î±R)iB(1 âˆ’iB). The adjoint equation is Ë™q = âˆ’âˆ‚HF âˆ‚iB = âˆ’q(Î±B âˆ’Î±R)(1 âˆ’2iB), and the boundary condition is HF (iB(T âˆ—âˆ—), Ï€âˆ—âˆ— B (T âˆ—âˆ—), q(T âˆ—âˆ—)) + 1 = 0, (25) where T âˆ—âˆ—denotes the optimal ï¬nal time, Ï€âˆ—âˆ— B (Â·) denotes the optimal feedback control, iB(Â·) denotes the corresponding trajectory, and iB(T âˆ—âˆ—) = ie. Let D = q(a âˆ’b)iB(T âˆ—âˆ—)(1 âˆ’iB(T âˆ—âˆ—)). From (25) we have HF (iB(T âˆ—âˆ—), Ï€âˆ—âˆ— B (T âˆ—âˆ—), q(T âˆ—âˆ—)) + 1 = Î»(Ï€âˆ—âˆ— B )2 + DÏ€âˆ—âˆ— B + b âˆ’Î±R a âˆ’b D + 1 = 0. (26) The optimal control, Ï€âˆ—âˆ— B , is obtained by minimizing the Hamiltonian HF (iB, Ï€B, q). Because the Hamiltonian HF (iB, Ï€B, q) is quadratic in Ï€B, the optimal control, Ï€âˆ—âˆ— B , takes the following form: Ï€âˆ—âˆ— B = ï£± ï£´ ï£´ ï£² ï£´ ï£´ ï£³ 1 if âˆ’D 2Î» > 1 âˆ’D 2Î» (0 < uâˆ— B < 1, to be determined) if 0 â‰¤âˆ’D 2Î» â‰¤1 0 if âˆ’D 2Î» < 0. From (26), we know there are three possibilities. (i). If âˆ’D 2Î» < 0, then 0 = bâˆ’Î±R aâˆ’b D + 1, namely that D = aâˆ’b Î±Râˆ’b is a positive constant. (ii) If âˆ’D 2Î» > 1, then 0 = bâˆ’Î±R aâˆ’b D + 1, namely that D = âˆ’aâˆ’b aâˆ’Î±R (Î» + 1) is also a constant. Note that D < âˆ’2Î» if and only if a âˆ’b â‰¤2(Î±R âˆ’b), or if and only if Î» < aâˆ’b a+bâˆ’2Î±R and a âˆ’b > 2(Î±R âˆ’b). (iii). If 0 â‰¤âˆ’D 2Î» â‰¤1, then 0 = Î»  âˆ’D 2Î» 2 âˆ’2Î»  âˆ’D 2Î» 2 âˆ’b âˆ’Î±R a âˆ’b 2Î»  âˆ’D 2Î»  + 1, namely that D = 2b âˆ’Î±R a âˆ’b Î» âˆ’ r 4 b âˆ’Î±R a âˆ’b Î» 2 + 4Î» is a constant. Note that âˆ’D 2Î» âˆˆ(0, 1) if and only if Î» â‰¥ aâˆ’b a+bâˆ’2Î±R and a âˆ’b > 2(Î±R âˆ’b). In term of minimizing the Hamiltonian HF under the above case (i), we have Ï€âˆ—âˆ— B = 0 for all time, which is impossible to obtain iB(T ) = ie; under the above case (ii), we have Ï€âˆ—âˆ— B = 1 for all time; under the above case (iii), we have Ï€âˆ—âˆ— B = D âˆ’2Î» for all time. To sum up, we have (Ï€âˆ—âˆ— B , T âˆ—âˆ—) = (uâˆ—, T2) if Î» â‰¥ aâˆ’b a+bâˆ’2Î±R and a âˆ’b > 2(Î±R âˆ’b) (1, T3) otherwise (27) where uâˆ—= D âˆ’2Î» = Î±Râˆ’b aâˆ’b + r bâˆ’Î±R aâˆ’b 2 + 1 Î», and T2 and T3 satisfy iB(T2) = i0 1âˆ’i0 e(b+(aâˆ’b)uâˆ—âˆ’Î±R)T2 1 + i0 1âˆ’i0 e(b+(aâˆ’b)uâˆ—âˆ’Î±R)T2 = ie, iB(T3) = i0 1âˆ’i0 e(aâˆ’Î±R)T3 1 + i0 1âˆ’i0 e(aâˆ’Î±R)T3 = ie, respectively. This completes the proof. âŠ“âŠ”