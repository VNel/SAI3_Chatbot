1 Optimal Cyber-Insurance Contract Design for Dynamic Risk Management and Mitigation Rui Zhang, Quanyan Zhu Abstract With the recent growing number of cyberattacks and the constant lack of effective defense methods, cyber risks become ubiquitous in enterprise networks, manufacturing plants, and government computer systems. Cyber-insurance provides a valuable approach to transfer the cyber risks to insurance companies and further improve the security status of the insured. The designation of effective cyber-insurance contracts requires the considerations from both the insurance market and the dynamic properties of the cyber risks. To capture the interactions between the users and the insurers, we present a dynamic moral- hazard type of principal-agent model incorporated with Markov decision processes, which are used to capture the dynamics and correlations of the cyber risks as well as the userâ€™s decisions on the protections. We study and fully analyze a case with a two-state two-action user under linear coverage insurance, and we further show the risk compensation, Peltzman effect, linear insurance contract principle, and zero-operating proï¬t principle in this case. Numerical experiments are provided to verify our conclusions and further extend to cases of a four-state three-action user under linear coverage insurance and threshold coverage insurance. Index Terms Cyber-Insurance, Markov Decision Processes, Principal-Agent Problem, Moral Hazard, Information Asymmetry, Mechanism Design I. INTRODUCTION Cyber risks created by malicious attackers such as ransomware [1], data breaches [2], and denial- of-service [3], have become severe threats to the security of important devices and private data in Internet of things (IoT) and cyber-physical systems (CPS) [4]. For example, the CryptoLocker R. Zhang and Q. Zhu are with the Department of Electrical and Computer Engineering, New York University, Brooklyn, NY, 11201 E-mail:{rz885,qz494}@nyu.edu. arXiv:1804.00998v3 [cs.CR] 7 May 2019 2 ransomware attack has caused an estimated loss of $3 million [5]. The 2016 Dyn cyberattack has resulted in the disruption of major Internet platforms and services to large swathes of users in Europe and North America [6]. Although various defense methods such as ï¬rewalls [7], intrusion detection systems [8], and moving-target defenses [9], have been deployed to detect the intrusion attempts and protect the networked devices, they cannot eliminate the cyber risks due to the complexities of cyber- environments [10]. Moreover, cyber threats are becoming stealthier, more strategic and purposeful as exempliï¬ed by the advanced persistent threats such as Stuxnet attacks on Iranian nuclear power plant in 2009 and the Ukrainian power plant attack in 2015 [11], [12]. Recently emerged cyber-insurance provides an economically viable solution to further mitigate the cyber risks and improve network resiliency [13]â€“[17]. The insured network users could quickly recover from severe cyber-incidents since part of the losses have been covered by the insurers. However, like the classic insurance, the insurers may suffer from offering coverage to reckless users due to the information asymmetry that the insurers cannot directly observe the usersâ€™ protections [18]â€“[20]. Moreover, as suggested by the theory of risk compensation in traditional insurance scenarios [21], the users may become less careful against cyberattacks knowing that insurers will cover their losses, for example, users may click more phishing emails, ignore the warnings of upgrading ï¬rewalls or systems, and reduce the frequency of scanning viruses or worms. As a result, the users may encounter more severe cyber-incidents and the insurers may bear extra cyber risks. Thus, it is imperative to study cyber-insurance contracts and its impacts on the usersâ€™ cyber-risk statuses. However, classic risk analysis and insurance frameworks cannot be directly applied to cyber risks and cyber-insurance as cyber risks are dynamically evolving and strongly correlated [22]â€“[25]. For example, an adversary can ï¬rst launch a node capture attack to compromise the system [26], [27], and then gain the administration to the devices [28], steal private information [29], or inject Ransomware worms or viruses [30]. In this paper, we capture the correlations and dynamics of the cyber risks as well as the usersâ€™ decisions on the protections with the Markov decision processes (MDP) [31], [32]. Different states of the MDP are used to capture the different cyber risks from various sources, such as service failures, attackers, or network connections. The transitions of states capture the connections of different cyber risks, and they are affected by the userâ€™s actions of protections at different times. To further mitigate the cyber risks, the user has a choice of purchasing cyber-insurance. After 3 paying a premium, the user could receive ï¬nancial coverages from the insurer to reimburse his losses caused by various cyber risks as shown in Fig. 1. The objective of the user is to ï¬nd an optimal deployment of protections and cyber-insurance that minimizes his cyber-losses. Fig. 1. Cyber-insurance example. The blue, red, and green icons represent user, attacker, and insurer, respectively. A user pays a premium to an insurer to purchase the cyber-insurance. Then, the user could receive ï¬nancial coverages from the insurer to cover part of his losses caused by cyberattacks. A rational user selects a cyber-insurance from which he could beneï¬t more, i.e., contracts with a low premium and a high coverage. However, an insurer tends to offer an insurance contract that has a high premium and a low coverage, as the insurer aims to maximize his operating proï¬t. Moreover, similar to the traditional insurance scenarios, the insurer is not aware of the local protections of the user, and an inappropriate insurance contract could largely damage the insurerâ€™s proï¬t. We address such conï¬‚icting interests and the information asymmetry between the user and the insurer with a moral hazard type of principal-agent problem [19], [20], [33], [34]. The analysis, as well as the solution of the problem, is important to study the impacts of cyber-insurance to the user and design effective insurance contracts. The major contributions of this work are summarized as follows: â€¢ We integrate Markov Decision Processes (MDP) into a moral hazard type of principal-agent model to investigate the impacts of cyber-insurance on the userâ€™s cyber risks and design effective cyber-insurance contracts for the insurer. â€¢ We fully characterize a case between a two-state two-action user and a linear coverage insurer. The results of this case indicate that the optimal insurance contracts follow linear insurance 4 contract principle and zero-operating proï¬t principle. The analysis also demonstrates the existence of risk compensation and Peltzman effect in cyber-insurance. â€¢ We develop computational tools to solve problems involving multiple cyber-risk states, various protection choices, and complex insurance contracts. Our numerical experiments illustrate risk compensation, Peltzman effect, and zero-operating proï¬t principle in cases of a four-state three-action user under linear coverage insurance and threshold coverage insurance. A. Organization of the Paper The rest of this paper is organized as follows. Section II presents the related works. Section III and Section IV discuss the userâ€™s problem and the insurerâ€™s problem, respectively. Section V presents a case study of a linear coverage insurance contract on a two-state two-action user. Section VI and Section VII present numerical results and concluding remarks, respectively. Appendices A, B, and C provide the proofs of the Proposition 2, and Theorem 1, and Proposition 4, respectively. We provide a summary of notations in the following table for convenience. II. RELATED WORKS Recently, with fast-growing types and amounts of the networked devices and shortages of effective and state-of-art defense methods, cyber-insurance has drawn huge attention as it can transfer the unexpected cyber risks to the insurance companies [13]â€“[17], [25], [35]â€“[39]. The existing insurance framework could bring useful insights on modeling the cyber-insurance [13], [40]. The moral hazard models in the economics literature are good tools to capture the information asymmetry between the insured and the insurers [18]â€“[20]. Various frameworks and methodologies have been brought up to investigate cyber-insurance contracts and their impacts to cyber risks. Several works have studied cyber-insurance through market-based approaches by analyzing the supply and demand relations between insurers and insureds [14], [16], [25], [35]. In [16], Pal et al., have analyzed regulated monopolistic and competitive cyber-insurance markets, and showed that cyber-insurance can improve the network security but the insurer can make zero expected proï¬ts in monopoly markets. In [14], [25], [35], BÂ¨ohme et al., have presented several market models of cyber-insurance with the consideration of interdependency between cyber risks and information asymmetries between insurers and insureds, and showed analytical results on the impacts of cyber-insurance to cyber-security and the vialibity of a market for cyber-insurance. 5 Summary of Notations t Time t S , N Set and Number of All Possible States Sn State n (1 â‰¤n â‰¤N) s, st State, State at Time t (s,st âˆˆS ) X Set of Direct Losses at All Possible States Xn Direct Loss at State Sn x, xt Direct Loss, Direct Loss at Time t p(st,st+1) Transition Probability from st to st+1 A , M Set and Number of All Possible Protections Am Protection m (1 â‰¤m â‰¤M) a, at Protection, Protection at Time t (a,at âˆˆA ) p(st,at,st+1) Transition Probability from st to st+1 under at c(a) Cost Function Î±s Stationary State Protection at State s (Î±s âˆˆA ) â„¦ Set of All Possible Stationary Protection Policies Ï€ Stationary Protection Policy (Ï€(s) = Î±s,âˆ€s âˆˆS ) Ï Value of Transition Probabilities R Set of All Possible Coverage Functions r(x), K Coverage Function (r âˆˆR), Premium (K âˆˆRâ‰¥0) r0(x) Zero Coverage Function (r0(x) = 0,âˆ€x âˆˆRâ‰¥0) R Coverage Level (r(x) = Rx) l(s,a,r) Effective Loss Function V(s,Ï€,r) Expected Cumulative Effective Loss Function Ï€âˆ— r Optimal Stationary Protection Policy Under Coverage r SGB Set of Two States (SGB = {SG,SB}) SG, SB Good State, Bad State s, sc One State, The Other State (s,sc âˆˆSGB;sc Ì¸= s) XG, XB Direct Losses at Good State, Bad State AHL Set of Two Actions (AHL = {AH,AL}) AH, AL Strong Protection, Weak Protection Î±G, Î±B Stationary State Protections at Good State, Bad State Î±s, Î±sc Stationary State Protections RG, RB Threshold Coverage Levels at Good State, Bad State 6 Game theory has been used to capture the interactions between insurers and insureds of cyber-insurance [17], [36], [39]. In [39], Laszka et al., have used a two-player signaling game to capture the information asymmetry between a potential client and an insurer, and further studied incentives for auditing potential clients before cyber-insurance premium calculations. In [36], Grossklags et al., have presented several security games to capture the decision-making of network users on protections and insurance. The equilibrium analysis shows that users may seek to self-protect themselves at just slightly above the lowest protection level in the weakest-target game. In [17], Zhang et al. have studied the interactions between insureds, attackers, and insurers with a bi-level game-theoretic framework in a networked environment and demonstrated the impacts of network connections to the three types of players. Most previous works have focused on the information asymmetry and interdependencies of cyber risks, however, their models have not captured the dynamics and correlations of the cyber risks, which have been studied with different methodologies and models [41]â€“[45]. In [44], Poolsappasit et al. have used a bayesian attack graphs model to analyze the network security risk assessment and mitigation. In [45], the authors have used a differential epidemic model to capture the spreading of viruses and worms in computer networks. These works aim to reduce the impacts of cyber risks through local protections, such as ï¬rewalls [7], intrusion detection [28], or moving target defenses [9], which cannot fully mitigate the risks of cyberattacks. In this work, we focus on studying the dynamics and correlations of the cyber risks and analyzing the impacts of the cyber-insurance to both the insureds and the insurers. We ï¬rst capture the cyber risks as well as the userâ€™s deployments of local protections with Markov decision processes, which have been used variously to analyze cybersecurity [46], [47]. We then use the existing moral hazard type of principal-agent model to capture the interactions between the user and the insurer with incomplete information. The analysis of both the optimal insurance contract and the userâ€™s response to it provides useful insights on the designation of the cyber-insurance contracts in the real world. III. USERâ€™S OPTIMAL PROTECTION POLICIES We use discrete Markov decision processes (MDP) to capture the evolvements of the userâ€™s cyber risks with time, and an illustration is provided in Fig. 2. Let st âˆˆS denote the userâ€™s cyber-risk state at time t âˆˆZâ‰¥0, where S â‰¡{Sn|1 â‰¤n â‰¤N} is the set of all possible cyber-risk states. Different cyber-risk states may incur various types of losses, e.g., data breaches, physical 7 device damages, and compromised ï¬nancial accounts. In this paper, we consider that all types of losses are measurable and can be quantiï¬ed by monetary direct losses. We assume that each cyber-risk state Sn âˆˆS is associated with a ï¬xed direct loss Xn âˆˆRâ‰¥0, and the userâ€™s direct loss at time t can be denoted by xt âˆˆX , where X â‰¡{Xn|1 â‰¤n â‰¤N}. Fig. 2. Illustration of cyber-insurance. The dynamics of the userâ€™s cyber risks are captured by MDP with st denoting the cyber-risk state at time t, which is associated with a direct loss xt. The user can choose various protections at to reduce the future losses. The objective of the user is to ï¬nd the optimal protection sequence {at}tâ‰¥0 which minimizes his cumulative losses. The user can also purchase cyber-insurance to mitigate his losses. The insurer ï¬rst announces the insurance contract {K,r}, where K and r indicate the premium and the coverage function, respectively. The user can decide whether to purchase the insurance or not. If the user chooses to purchase the insurance, he must pay a premium K, and when he faces a loss of x, the insurer should provide a coverage of r(x) to him. The objective of the insurer is to maximize his proï¬t. Note that the insurer has no information of the userâ€™s protection sequences. The user can adopt different protections, such as ï¬rewalls, intrusion detection systems, and moving-target defenses, to reduce the possibilities of entering cyber-risk states that can incur severe losses. Let at âˆˆA denote the protections at time t, where A â‰¡{Am|1 â‰¤m â‰¤M} is the set of all available protections. The transition probability p(st,at,st+1) denotes the probability that the user goes to state st+1 at time t +1 when he is currently in state st and adopts protection at, which naturally captures the correlations among different cyber-risk states under different protections. Note that âˆ‘N n=1 p(st,at,Sn) = 1 as the user can only enter states within S at time t +1. 8 We further provide two examples to illustrate the states S and protections A of the user. Example 1. Suppose a customer whose computer faces threats of Ransomware. In this example, the customer has S = {S1,S2} and A = {A1,A2}. States S1 and S2 denote that the computer is secure and compromised, respectively. The customer can choose to do nothing A1 or add ï¬rewalls A2. The computer has a lower probability of facing Ransomware, i.e., entering state S2, if the customer deploys ï¬rewalls. When the computer is compromised, the customer needs to either pay the money or replace the computer, which can be covered if he has purchased cyber-insurance. Example 2. Consider a cloud center who aims to protect itself from the damages caused by po- tential attackers. In this example, the cloud center has S = {S1,S2,S3} and A = {A1,A2,A3,A4}. State S1 denotes the situation when it is safe and faces no cyberattacks. However, the cloud center may encounter data breaches and denial-of-services, which are represented by states S2 and S3, respectively. Each state Sn âˆˆS is associated with a direct loss Xn. For example, at time t, st = S2 indicates that the cloud center faces data breaches which inï¬‚ict X2 direct losses to it. Specially, the direct loss X1 = 0 at state S1, which indicates that the cloud center has no loss when it faces no cyberattacks. To defend against these cyberattacks, the cloud center may deploy ï¬rewalls, intrusion detection systems, and moving-target defense, which are represented by protections A2, A3, and A4, respectively. Specially, the cloud center can also choose to do nothing, which is denoted as A1. The cloud center has smaller probabilities of entering states with high losses if he deploys protections, however, these protections are also costly. The cloud center can also purchase cyber-insurance to cover part of its losses and help it recover from cyber-incidents. The objective of the cloud center is to ï¬nd an optimal deployment of protections and cyber-insurance such that its future cumulative losses are minimized. Cases involve other cyber risks or protections can be extended through increasing the size of S and A . Besides the protections, the user can also mitigate his losses through purchasing cyber-insurance. After paying a premium to an insurer, the user could receive a coverage of r(xt) from the insurer when he faces a direct loss of xt, where r : Râ‰¥0 â†’Râ‰¥0 is the coverage function of the insurance. The objective of the user is to ï¬nd an optimal sequence of protections {at}tâˆˆZâ‰¥0 that minimizes the expected cumulative effective losses given the initial state s0 âˆˆS , which can be captured as min {at} E ( âˆ âˆ‘ t=0 Î´t (xt âˆ’r(xt)+c(at)) s0 ) , (1) 9 where function c(at) returns the cost of protection at, and Î´ âˆˆ(0,1) is the discount factor which indicates that future losses are valued less at time 0. In this paper, we consider that the user decides his protections contingent on his current states. Such feedback strategy allows the user to maintain his security level by adopting the necessary protections that can reduce the losses from cyberattacks and save the costs of protections at the same time. The strategy is usually denoted by a stationary protection policy Ï€ : S â†’A , e.g., Ï€(Sn) = Am indicates that the user always takes protection Am at state Sn. As a result, the expected cumulative effective losses of the user under a stationary protection policy can be captured as V(s0,Ï€,r) = E  âˆ âˆ‘ t=0 Î´t (xt âˆ’r(xt)+c(Ï€ (st))) s0  . (2) The user aims to ï¬nd an optimal stationary protection policy Ï€âˆ— r âˆˆâ„¦that minimizes his expected cumulative effective losses given the coverage function r, and such objective can be captured as Ï€âˆ— r âˆˆargmin Ï€âˆˆâ„¦V(s0,Ï€,r), (3) where â„¦denotes the set of all possible stationary policies. A rational user purchases the insurance only when the expected cumulative effective losses plus the premium under the insurance is lower than the losses without insurance, which can be captured as V(s0,Ï€âˆ— r ,r)+K â‰¤V(s0,Ï€âˆ— r0,r0), (4) where K âˆˆRâ‰¥0 is the premium of the insurance and r0 indicates a zero coverage function, i.e., r0(X) = 0 for all X âˆˆRâ‰¥0, which corresponds to the case when there is no insurance. The fact that the user purchases the insurance only when inequality (4) is satisï¬ed must be considered by the insurer while designing effective insurance contracts. The optimal protection policy Ï€âˆ— r could be obtained by solving (3) with either dynamic programming or linear programming [48], and we summarize both approaches in the following subsections. A. Dynamic Programming Approach Recall equation (2), let us deï¬ne the loss function l(st,at,r) = xt âˆ’r(xt)+c(at) which indicates the effective loss at time t under the coverage function r. Note that l(st,at,r) does not take xt as 10 variable since the direct loss xt is uniquely determined by the userâ€™s cyber-risk state st. Thus, we can express the expected cumulative effective losses as V(s0,Ï€,r) = E  âˆ âˆ‘ t=0 Î´tl(st,Ï€(st),r)|s0  = l(s0,Ï€(s0),r)+Î´ âˆ‘ sâ€²âˆˆS p(s0,Ï€(s0),sâ€²)V(sâ€²,Ï€,r), (5) where l(s0,Ï€(s0),r) and Î´ âˆ‘ sâˆˆS p(s0,Ï€(s0),s)V(s,Ï€,r) capture the effective loss at time 0 and the future expected cumulative effective losses, respectively. As a result, given a coverage function r, the optimal protection policy Ï€âˆ— r can be found by the following dynamic programming operators [48]. Ï€âˆ— r (s) âˆˆarg min aâˆˆA  l(s,a,r)+Î´ âˆ‘ sâ€²âˆˆS p(s,a,sâ€²)V(sâ€²,Ï€âˆ— r ,r)  , (6) V(s,Ï€âˆ— r ,r) = l(s,Ï€âˆ— r (s),r)+Î´ âˆ‘ sâ€²âˆˆS p(s,Ï€âˆ— r (s),sâ€²)V(sâ€²,Ï€âˆ— r ,r). (7) By iterating (6) and (7) for all states s âˆˆS until no further changes take place, we can achieve Ï€âˆ— r and V(s,Ï€âˆ— r ,r), and the convergence to the optimum is guaranteed [48]. B. Linear Programming Approach Besides the dynamic programming, we can also use linear programming to solve the userâ€™s problem (3). Problem (3) can be reformulated into a linear programming problem in the standard form as [48] min Î· dTÎ· s.t. OÎ· = b,Î· â‰¥0, with its dual problem max Î¸ bTÎ¸ s.t. dâˆ’OTÎ¸ â‰¥0, where Î· âˆˆRNMÃ—1 and Î¸ âˆˆRNÃ—1 are denoted as the prime variable and the dual variable, respectively. Note that N and M are the sizes of S and A , respectively. Vector b âˆˆRNÃ—1 is a column vector of size N with all the elements equal to 1. Vector d âˆˆRNMÃ—1 is a column vector of size NM which captures the per-state and per-action losses, and the (N(nâˆ’1)+m)-th element of it equals l(Sn,Am,r), where 1 â‰¤n â‰¤N and 1 â‰¤m â‰¤M. Matrix O = E âˆ’Î´P, where matrix E âˆˆRNÃ—NM has that En,N(nâˆ’1)+m = 1 for 1 â‰¤n â‰¤N and 1 â‰¤m â‰¤M and all the other elements are 0, and matrix P âˆˆRNÃ—NM is the transition probability matrix where Pnâ€²,N(nâˆ’1)+m = p(n,am,nâ€²), 1 â‰¤n â‰¤N, 1 â‰¤nâ€² â‰¤N, and 1 â‰¤m â‰¤M. 11 The optimal primal variable Î·âˆ—represents the optimal state-action frequencies; the optimal dual variable Î¸ âˆ—represents the expected cost-to-go values of the states for the given coverage function r, i.e., Î¸ âˆ— n = V(Sn,Ï€âˆ— r ,r) for 1 â‰¤n â‰¤N. After solving the dual problem, we can ï¬nd the optimal protection policy Ï€âˆ— r by plugging V(Sn,Ï€âˆ— r ,r) into (6). IV. INSURERâ€™S OPTIMAL INSURANCE CONTRACTS In this section, we present and analyze the insurerâ€™s problem of designing cyber-insurance contracts. An illustration of the interactions between the user and the insurer has been provided in Fig. 2. Note that the insurer ï¬rst announces the insurance contract {K,r}, and the user then makes the decision of purchasing the insurance based on the expected cumulative effective losses under that insurance contract. If the user chooses to purchase the insurance, the insurer instantly earns a proï¬t of K at time 0, but the insurer is required to pay the coverage of r(xt) when the user faces a loss of xt at time t. As a result, the insurerâ€™s operating proï¬t can be captured as K âˆ’E  âˆ‘âˆ t=0 Î´tr(xt) s0 , where E{âˆ‘âˆ t=0 Î´tr(xt) s0} denotes the expected cumulative coverage provided by the insurer to the user. The objective of the insurer is to ï¬nd an optimal insurance contract {Kâˆ—,râˆ—} that maximizes his operating proï¬t. As a result, the insurerâ€™s problem can be captured as max {K,r}K âˆ’E  âˆ âˆ‘ t=0 Î´tr(xt) s0  s.t. K âˆ’E  âˆ âˆ‘ t=0 Î´tr(xt) s0  â‰¥0; (8a) V(s0,Ï€âˆ— r ,r)+K â‰¤V(s0,Ï€âˆ— r0,r0). (8b) (8) Constraint (8a) captures the insurerâ€™s individual rationality that he chooses not to provide the insurance if he has a negative proï¬t. Constraint (8b) captures the userâ€™s individual rationality on purchasing the insurance and it comes from inequality (4). By solving problem (8), the insurer can ï¬nd an optimal insurance contract which maximizes his operating proï¬t and is acceptable by the user. After combing the userâ€™s problem and the insurerâ€™s problem, the interactions of the user and the insurer can be captured by the following principal-agent problem. max {K,r}K âˆ’E  âˆ âˆ‘ t=0 Î´tr(xt) s0  s.t. K âˆ’E  âˆ âˆ‘ t=0 Î´tr(xt) s0  â‰¥0; (9a) V(s0,Ï€âˆ— r ,r)+K â‰¤V(s0,Ï€âˆ— r0,r0); (9b) Ï€âˆ— r âˆˆargmin Ï€âˆˆâ„¦V(s0,Ï€,r). (9c) (9) 12 Problem (9) is an optimization problem nested with various sub-optimization problems. The solution of Problem (9) captures both the userâ€™s objective of minimizing his expected cumulative effective losses and the insurerâ€™s objective of maximizing his own proï¬t with the consideration of the userâ€™s rational choice of purchasing the insurance. To ï¬nd the solution of problem (9), we can ï¬rst solve the userâ€™s problem (3) and obtain the optimal protection policies Ï€âˆ— r and the corresponding losses V(s0,Ï€âˆ— r ,r) to the coverage function r, and then achieve {Kâˆ—,râˆ—} by solving the insurerâ€™s problem (8). We can simplify the insurerâ€™s problem (8) by exploring the expected cumulative effective losses and the optimal protection policies as discussed in the following subsection. A. Insurerâ€™s Problem: Simpliï¬cations and Direct Conclusions We ï¬rst notice that the expected cumulative coverage is equal to the expected cumulative direct losses minus the expected cumulative effective losses, i.e., E  âˆ âˆ‘ t=0 Î´tr(xt)|s0  = E  âˆ âˆ‘ t=0 Î´t (xt +c(Ï€âˆ— r (st)))|s0  âˆ’E  âˆ âˆ‘ t=0 Î´t (xt âˆ’r(xt)+c(Ï€âˆ— r (st)))|s0  = V(s0,Ï€âˆ— r ,r0)âˆ’V(s0,Ï€âˆ— r ,r), where V(s0,Ï€âˆ— r ,r0) can be interpreted as the expected cumulative effective losses given the optimal protection policy Ï€âˆ— r and the zero coverage function r0. Thus, Problem (8) can be rewritten as follows. max {K,r}K âˆ’(V(s0,Ï€âˆ— r ,r0)âˆ’V(s0,Ï€âˆ— r ,r)) s.t. K âˆ’(V(s0,Ï€âˆ— r ,r0)âˆ’V(s0,Ï€âˆ— r ,r)) â‰¥0; (10a) V(s0,Ï€âˆ— r ,r)+K â‰¤V(s0,Ï€âˆ— r0,r0). (10b) (10) Constraint (10b) indicates that the maximum premium that can be charged by the insurer for a coverage function r is Kmax = V(s0,Ï€âˆ— r0,r0)âˆ’V(s0,Ï€âˆ— r ,r). (11) The user chooses not to purchase the insurance with a premium K > Kmax because the losses and the premium under the insurance are higher than the losses without insurance. As a result, problem (8) is equivalent to the following problem after letting K be equal to Kmax and plugging (11) into its objective function and constraint. max râˆˆR V(s0,Ï€âˆ— r0,r0)âˆ’V(s0,Ï€âˆ— r ,r0) s.t. V(s0,Ï€âˆ— r0,r0)âˆ’V(s0,Ï€âˆ— r ,r0) â‰¥0, (12) 13 where R denotes the set of all possible coverage functions, and the constraint indicates that the proï¬t of the insurer cannot be negative. After solving (12), we can ï¬nd the optimal coverage function râˆ—, and then the optimal premium can be computed through (11). Similarly, the principal- agent problem (9) can also be rewritten as max râˆˆR V(s0,Ï€âˆ— r0,r0)âˆ’V(s0,Ï€âˆ— r ,r0) s.t. V(s0,Ï€âˆ— r0,r0)âˆ’V(s0,Ï€âˆ— r ,r0) â‰¥0; (13a) Ï€âˆ— r âˆˆargmin Ï€âˆˆâ„¦V(s0,Ï€,r). (13b) (13) Comparing to (8) and (9), we only need to ï¬nd the optimal protection policies Ï€âˆ— r to obtain the optimal insurance contract {Kâˆ—,râˆ—} through (12) and (13). One useful insight regarding the operating proï¬t could be obtained without solving (12) or (13), which is summarized in the following remark and proposition. Remark 1. Any coverage function r that yields Ï€âˆ— r = Ï€âˆ— r0, i.e., the user has the same optimal protec- tion policy between the case under the coverage function r and the case under no insurance, is a feasible solution with the corresponding premium K =V(s0,Ï€âˆ— r0,r0)âˆ’V(s0,Ï€âˆ— r ,r) =V(s0,Ï€âˆ— r0,r0)âˆ’ V(s0,Ï€âˆ— r0,r) â‰¥0 as V(s0,Ï€âˆ— r0,r) â‰¤V(s0,Ï€âˆ— r0,r0), and the insurer has a zero operating proï¬t under that insurance contract as V(s0,Ï€âˆ— r0,r0)âˆ’V(s0,Ï€âˆ— r ,r0) = V(s0,Ï€âˆ— r0,r0)âˆ’V(s0,Ï€âˆ— r0,r0) = 0. Proposition 1. Any insurance contract {K,r} that yields Ï€âˆ— r = Ï€âˆ— r0 and meets (11) is optimal for the insurer, and the insurer has a zero operating proï¬t under that contract. Proof. The operating proï¬t of the insurer has that V(s,Ï€âˆ— r0,r0)âˆ’V(s,Ï€âˆ— r ,r0) â‰¤0 from (13b), i.e., Ï€âˆ— r0 âˆˆargmin Ï€âˆˆâ„¦V(s,Ï€,r0). Thus, the maximum proï¬t that the insurer can achieve is 0. As a result, if the user has Ï€âˆ— r = Ï€âˆ— r0 under an insurance contract {K,r}, that contract is feasible from Remark 1 and it is also optimal. Remark 1 indicates that the insurer has a zero operating proï¬t when the user has the same protection policies with or without insurance, which explains market neutrality. Proposition 1 indicates that the insurance contract in Remark 1 is optimal for the insurer. We denote this conclusion as the zero operating proï¬t principle. V. CASE STUDY: TWO-STATE TWO-ACTION USER AND LINEAR COVERAGE INSURER In this section, we present a representative case where the user has two states and two actions and the insurer provides the linear coverage. Analysis of this case provides structural insights of the 14 insurance contracts. Recall Section III, the user in this case has the set of states SGB â‰¡{SG,SB}, where SG and SB indicate good state and bad state, respectively. The losses that associated with the states can be further identiï¬ed as XG and XB. The difference between the good state and the bad state is that the user has lower losses at the good state than that at the bad state, i.e., 0 â‰¤XG < XB. To reduce the losses, the user can choose to take a strong protection AH or a weak protection AL, in other words, the user has the action set AHL = {AH,AL}. We further use shorthand notations CH and CL to represent the costs of protections AH and AL, respectively, i.e, c(AH) = CH and c(AL) = CL. The differences between a strong protection and a weak protection can be identiï¬ed in detail as follows: â€¢ p(s,AH,SB) < p(s,AL,SB),âˆ€s âˆˆSGB, which indicates that the user has a higher probability of going to the bad state when he has a weak protection. â€¢ p(s,AL,SG) < p(s,AH,SG),âˆ€s âˆˆSGB, which indicates that the user has a higher probability of going to the good state when he has a strong protection. â€¢ 0 â‰¤CL < CH, which indicates that the cost of a strong protection is higher than the cost of a weak protection. These differences capture the fact that a strong protection can make the user more secure but its cost is also higher. With two states and two actions, the user has only four possible stationary protection policies, i.e., â„¦= {Î HH,Î HL,Î LH,Î LL}, where â€¢ Î HH(SG) = AH and Î HH(SB) = AH; â€¢ Î HL(SG) = AH and Î HL(SB) = AL; â€¢ Î LH(SG) = AL and Î LH(SB) = AH; â€¢ Î LL(SG) = AL and Î LL(SB) = AL. An optimal protection policy Ï€âˆ—âˆˆâ„¦can be achieved by solving Problem (3) which minimizes the userâ€™s expected cumulative effective losses. Besides protections, the user can also purchase the insurance to further mitigate his losses. We consider that the insurer offers a linear coverage with R âˆˆ[0,1] denoting the coverage level of the insurance, i.e., r(x) = Rx. Specially, R = 0 and R = 1 indicate no coverage and full coverage, respectively. Methods in Sections III and IV can be used to ï¬nd the optimal protection policy of the user and the optimal insurance contract for the insurer. Since there are only two states and two actions 15 for the user, we can ï¬nd them analytically. A. Userâ€™s Optimal Protection Policy We ï¬rst introduce several notations to simplify representations. Since the user has only two states SG and SB, we use sc Ì¸= s to denote the other state for a given state s âˆˆSGB. Since the user adopts a stationary protection policy, i.e., he has ï¬xed protections at each state, we identify his state protections as Î±G and Î±B for the good state and the bad state, respectively. We further deï¬ne the action dependent expected cumulative effective loss function as follows V(s,Î±s;Î±sc,R) = l(s,Î±s,R)+Î´ p(s,Î±s,SG)V(SG,Î±G;Î±B,R)+Î´ p(s,Î±s,SB)V(SB,Î±B;Î±G,R). (14) Remark 2. For a protection policy Ï€ that has Ï€(SG) = Î±G and Ï€(SB) = Î±B, the expected cumulative effective loss function (5) is equivalent to the action dependent expected cumulative effective loss function (14), i.e., V(SG,Ï€,R) = V(SG,Ï€(SG);Ï€(SB),R) = V(SG,Î±G;Î±B,R); V(SB,Ï€,R) = V(SB,Ï€(SB);Ï€(SG),R) = V(SB,Î±B;Î±G,R). As a result, the dynamic programming operators (6) and (7) can be written as Ï€âˆ— R(SG) âˆˆarg min Î±GâˆˆAHL V(SG,Î±G;Ï€âˆ— R(SB),R); (15) Ï€âˆ— R(SB) âˆˆarg min Î±BâˆˆAHL V(SB,Î±B;Ï€âˆ— R(SG),R), (16) where V(SG,Î±G;Î±B,R) = l(SG,Î±G,R) +Î´ p(SG,Î±G,SG)V(SG,Î±G;Î±B,R)+Î´ p(SG,Î±G,SB)V(SB,Î±B;Î±G,R); (17) V(SB,Î±B;Î±G,R) = l(SB,Î±B,R) +Î´ p(SB,Î±B,SG)V(SG,Î±G;Î±B,R)+Î´ p(SB,Î±B,SB)V(SB,Î±B;Î±G,R). (18) Both (17) and (18) are linear equations on V(SG,Î±G;Î±B,R) and V(SB,Î±B;Î±G,R), thus, we can solve them together and achieve V(SG,Î±G;Î±B,R) = (1âˆ’Î´ p(SB,Î±B,SB))l(SG,Î±G,R)+Î´ p(SG,Î±G,SB)l(SB,Î±B,R) Ip(Î±G,Î±B) ; (19) V(SB,Î±B;Î±G,R) = Î´ p(SB,Î±B,SG)l(SG,Î±G,R)+(1âˆ’Î´ p(SG,Î±G,SG))l(SB,Î±B,R) Ip(Î±G,Î±B) , (20) 16 where Ip(Î±G,Î±B) =  1âˆ’Î´ p(SG,Î±G,SG)  1âˆ’Î´ p(SB,Î±B,SB)  âˆ’Î´ 2p(SG,Î±G,SB)p(SB,Î±B,SG). (21) As a result, we can ï¬nd Ï€âˆ— R by solving (15) and (16) with (19) and (20), respectively. Since there are only two protection choices AH and AL, we can ï¬nd the optimal protection policy by comparing the action dependent expected cumulative effective losses under AH and AL. Lemma 1. The optimal protection policy Ï€âˆ— R given the coverage level R can be summarized as follows: â€¢ Ï€âˆ— R = Î LL if and only if V(SG,AH;AL,R) â‰¥V(SG,AL;AL,R) and V(SB,AH;AL,R) â‰¥V(SB,AL;AL,R); â€¢ Ï€âˆ— R = Î LH if and only if V(SG,AH;AH,R) â‰¥V(SG,AL;AH,R) and V(SB,AH;AL,R) < V(SB,AL;AL,R); â€¢ Ï€âˆ— R = Î HL if and only if V(SG,AH;AL,R) < V(SG,AL;AL,R) and V(SB,AH;AH,R) â‰¥V(SB,AL;AH,R); â€¢ Ï€âˆ— R = Î HH if and only if V(SG,AH;AH,R) < V(SG,AL;AH,R) and V(SB,AH;AH,R) < V(SB,AL;AH,R). Proof. The user chooses a protection policy with lower expected cumulative effective losses in both good state and bad state. We consider that the user always takes AL when V(s,AH;Î±sc,R) = V(s,AL;Î±sc,R). We can further simplify the comparisons in Lemma 1 as shown in the following proposition. Proposition 2. Let us deï¬ne function h : S Ã—A Ã—R â†’R as h(s,Î±sc,R) = (1âˆ’R)Î´ (p(s,AH,sc)âˆ’p(s,AL,sc))(Xsc âˆ’Xs) +(1âˆ’Î´ +Î´ p(SB,Î±sc,SG)+Î´ p(SG,Î±sc,SB))(CH âˆ’CL), the optimal protection policy Ï€âˆ— R can be summarized as follows: â€¢ Ï€âˆ—= Î LL if and only if h(SG,AL,R) â‰¥0 and h(SB,AL,R) â‰¥0; â€¢ Ï€âˆ—= Î LH if and only if h(SG,AH,R) â‰¥0 and h(SB,AL,R) < 0; â€¢ Ï€âˆ—= Î HL if and only if h(SG,AL,R) < 0 and h(SB,AH,R) â‰¥0; â€¢ Ï€âˆ—= Î HH if and only if h(SG,AH,R) < 0 and h(SB,AH,R) < 0. Proof. See Appendix A. Thus, we could obtain the optimal protection policy of the user by analyzing h(s,Î±sc,R), and we further have the following observation on it. Proposition 3. Function h(s,Î±sc,R) is linearly increasing on the coverage level R. 17 Proof. We can see that h(s,Î±sc,R) is linear on R with a slope of âˆ’Î´(p(s,AH,sc) âˆ’p(s,AL,sc))(Xsc âˆ’Xs). From the properties of protections and direct losses, we have p(SG,AH,SB)âˆ’p(SG,AL,SB) < 0, XB âˆ’XG > 0, p(SB,AH,SG)âˆ’p(SB,AL,SG) > 0, and XG âˆ’XB < 0. As a result, âˆ’Î´(p(s,AH,sc)âˆ’p(s,AL,sc))(Xsc âˆ’Xs) > 0 and h(s,Î±sc,R) is linearly increasing on R. Before we obtain the optimal protection policy Ï€âˆ— R, we note the following proposition regarding the uniqueness of Ï€âˆ— R. Theorem 1. The optimal protection policy Ï€âˆ— R is unique. Proof. See Appendix B. With Lemma 1, Proposition 3, and Theorem 1, we can obtain the optimal protection policies of the user with respect to the coverage level as stated in the following proposition. Proposition 4. Let us deï¬ne the value of transition probabilities as Ï = p(SB,AH,SG)+ p(SG,AH,SB)âˆ’p(SB,AL,SG)âˆ’p(SG,AL,SB). (22) The userâ€™s optimal protection policies with respect to the insurerâ€™s coverage level can be summarized with the following cases as also shown in Fig. 3. Case 1: If h(SG,AL,0) â‰¥0 and h(SB,AL,0) â‰¥0, the optimal protection policies Ï€âˆ— R = Î LL for R âˆˆ[0,1]. Case 2: If h(SG,AL,0) < 0 and h(SB,AH,0) â‰¥0, we have Ï < 0 in this case. The optimal protection policies Ï€âˆ— R = Î HL for R âˆˆ[0,RG) and Ï€âˆ— R = Î LL for R âˆˆ[RG,1], where RG = 1âˆ’(1âˆ’Î´+Î´ p(SB,AL,SG)+Î´ p(SG,AL,SB))(CHâˆ’CL) Î´(p(SG,AL,SB)âˆ’p(SG,AH,SB))(XBâˆ’XG) . Case 3: If h(SG,AH,0) â‰¥0 and h(SB,AL,0) < 0, we have Ï > 0 in this case. The optimal protection policies Ï€âˆ— R = Î LH for R âˆˆ[0,RB) and Ï€âˆ— R = Î LL for R âˆˆ[RB,1], where RB = 1âˆ’(1âˆ’Î´+Î´ p(SG,AL,SB)+Î´ p(SB,AL,SG))(CHâˆ’CL) Î´(p(SB,AH,SG)âˆ’p(SB,AL,SG))(XBâˆ’XG) . Case 4: If h(SG,AH,0) < 0 and h(SB,AH,0) < 0, â€¢ Case 4(a): If Ï < 0, Ï€âˆ— R = Î HH for R âˆˆ[0,RB), Ï€âˆ— R = Î HL for R âˆˆ[RB,RG), and Ï€âˆ— R = Î LL for R âˆˆ[RG,1], where RG = 1âˆ’(1âˆ’Î´+Î´ p(SB,AL,SG)+Î´ p(SG,AL,SB))(CHâˆ’CL) Î´(p(SG,AL,SB)âˆ’p(SG,AH,SB))(XBâˆ’XG) , 18 RB = 1âˆ’(1âˆ’Î´+Î´ p(SG,AH,SB)+Î´ p(SB,AH,SG))(CHâˆ’CL) Î´(p(SB,AH,SG)âˆ’p(SB,AL,SG))(XBâˆ’XG) . â€¢ Case 4(b): If Ï > 0, Ï€âˆ— R = Î HH for R âˆˆ[0,RG), Ï€âˆ— R = Î LH for R âˆˆ[RG,RB), and Ï€âˆ— R = Î LL for R âˆˆ[RB,1], where RG = 1âˆ’(1âˆ’Î´+Î´ p(SB,AH,SG)+Î´ p(SG,AH,SB))(CHâˆ’CL) Î´(p(SG,AL,SB)âˆ’p(SG,AH,SB))(XBâˆ’XG) , RB = 1âˆ’(1âˆ’Î´+Î´ p(SG,AL,SB)+Î´ p(SB,AL,SG))(CHâˆ’CL) Î´(p(SB,AH,SG)âˆ’p(SB,AL,SG))(XBâˆ’XG) . â€¢ Case 4(c): If Ï = 0, Ï€âˆ— R = Î HH for R âˆˆ[0,Rs) and Ï€âˆ— R = Î LL for R âˆˆ[Rs,1], where Rs = RG = 1âˆ’(1âˆ’Î´+Î´ p(SB,AH,SG)+Î´ p(SG,AH,SB))(CHâˆ’CL) Î´(p(SG,AL,SB)âˆ’p(SG,AH,SB))(XBâˆ’XG) = RB = 1âˆ’(1âˆ’Î´+Î´ p(SG,AH,SB)+Î´ p(SB,AH,SG))(CHâˆ’CL) Î´(p(SB,AH,SG)âˆ’p(SB,AL,SG))(XBâˆ’XG) Proof. See Appendix C. (a) Case 1 (b) Case 2 (c) Case 3 (d) Case 4(a) (e) Case 4(b) (f) Case 4(c) Fig. 3. All possible cases of the userâ€™s optimal protection policies with respect to the insurerâ€™s coverage level. A detailed discussion is provided in Proposition 4. We can see from Proposition 4 that the user tends to take weak protections with the increase of the coverage level in all cases, and this reckless behavior is often referred as the risk compensation 19 [21]. One critical impact of the risk compensation is the Peltzman effect as shown in the following theorem. Theorem 2. Peltzman effect: The user faces higher cyber risks under cyber-insurance. Such phenomena exists in the following cases: â€¢ R âˆˆ[RG,1] in Case 2 and Case 4(b); â€¢ R âˆˆ[RB,1] in Case 3 and Case 4(a); â€¢ R âˆˆ[Rs,1] in Case 4(c). Proof. We only need to prove that the user has higher expected cumulative direct losses in these cases. Let Vd(s,Ï€) and Vc(Ï€) denote the expected cumulative direct losses and the expected cumulative costs given the initial state s and the protection policy Ï€. We have that Vd(s,Ï€)+ Vc(Ï€) =V(s,Ï€,0). Recall that the optimal protection policy Ï€âˆ— 0 without insurance has V(s,Ï€âˆ— 0,0) â‰¤ V(s,Ï€,0) for Ï€ âˆˆâ„¦, thus, when the user has a different optimal protection policy Ï€âˆ— R Ì¸= Ï€âˆ— 0 given the coverage level R, we have V(s,Ï€âˆ— 0,0) â‰¤V(s,Ï€âˆ— R,0). As a result, we can achieve Vd(s,Ï€âˆ— 0)+Vc(Ï€âˆ— 0) â‰¤Vd(s,Ï€âˆ— R)+Vc(Ï€âˆ— R). Note that Vc(Ï€âˆ— 0) > Vc(Ï€âˆ— R) in these cases as Vc(Î HH) > Vc(Î HL) >Vc(Î LL) and Vc(Î HH) >Vc(Î LH) >Vc(Î LL) from CH >CL. Thus, we have Vd(s,Ï€âˆ— 0) < Vd(s,Ï€âˆ— R) and the user faces higher cyber risks. B. Optimal Insurance Contract Recall Section IV, the insurerâ€™s problem (12) in this case can be written as follows: max Râˆˆ[0,1]Ï„(R) = V(SG,Ï€âˆ— 0,0)âˆ’V(SG,Ï€âˆ— R,0) s.t. Ï„(R) â‰¥0, (23) where Ï„(R) denotes the operating proï¬t of the insurer if he provides a coverage level of R. Note that SG in Ï„(R) indicates that the initial state of the user is the good state. Proposition 5. The optimal insurance contract {Kâˆ—,Râˆ—} for each case in Proposition 4 can be summarized as follows: â€¢ Case 1: Râˆ—âˆˆ[0,1] and Kâˆ—= Râˆ—k(SG,AL;AL), â€¢ Case 2: Râˆ—âˆˆ[0,RG] and Kâˆ—= Râˆ—k(SG,AH;AL), â€¢ Case 3: Râˆ—âˆˆ[0,RB] and Kâˆ—= Râˆ—k(SG,AL;AH), â€¢ Case 4(a): Râˆ—âˆˆ[0,RB] and Kâˆ—= Râˆ—k(SG,AH;AH), â€¢ Case 4(b): Râˆ—âˆˆ[0,RG] and Kâˆ—= Râˆ—k(SG,AH;AH), 20 â€¢ Case 4(c): Râˆ—âˆˆ[0,Rs] and Kâˆ—= Râˆ—k(SG,AH;AH), where k(SG,Î±G;Î±B) = (1âˆ’Î´ p(SB,Î±B,SB))XG+Î´ p(SG,Î±G,SB)XB Ip(Î±G,Î±B) . (24) For all the cases, the operating proï¬t under the optimal insurance contract is 0, i.e., Ï„(Râˆ—) = 0. Proof. We can obtain the optimal insurance contract for all cases using the results from Proposition 1. In Case 1, any coverage level Râˆ—âˆˆ[0,1] is optimal, and the associated pre- mium Kâˆ—=V(SG,Î LL,0)âˆ’V(SG,Î LL,R) =V(SG,AL;AL,0)âˆ’V(SG,AL;AL,R) = Râˆ—k(SG,AL;AL), where k(SG,AL;AL) comes from (27) in Appendix A. Similarly, we can obtain the optimal insurance contracts in Cases 2, 3, and 4. We can see from the optimal insurance contracts that the premium is linear on the coverage level, which can be summarized as the linear insurance contract principle. Moreover, all the optimal insurance contracts lead to a zero operating proï¬t for the insurer, which indicates a zero-operating proï¬t principle. The optimal insurance contracts usually provide limited coverage levels. When the coverage level is high, the user tends to act recklessly, which induces high risks and high direct losses of the user as shown in Theorem 2, and the insurer is required to cover the extra losses caused by that, which induces a negative proï¬t of him. As a result, the insurer chooses not to provide the insurance to the user in that case. VI. NUMERICAL EXAMPLES In this section, we ï¬rst present numerical experiments on a two-state two-action user and a linear coverage insurer to verify our previous analytical results. We then present numerical experiments on a four-state three-action user with a linear coverage insurer and a threshold coverage insurer. A. Two-State Two-Action User and Linear Coverage Insurer In this subsection, we aim to verify our analysis on the two-state two-action user and the linear coverage insurer with numerical experiments. We assume that the user has Î´ = 0.9, XG = 0, XB = 10, CL = 0, CH = 1, p(SG,AL,SB) = p(SG,AL,SG) = 0.5, p(SB,AL,SG) = p(SB,AL,SB) = 0.5, p(SG,AH,SB) = 1 âˆ’p(SG,AH,SG) = 0.2, and p(SB,AH,SG) = 1 âˆ’p(SB,AH,SB) = 0.6. We can achieve that Ï = âˆ’0.20, h(SG,AH,0) = âˆ’1.88, h(SG,AL,0) = âˆ’1.70, h(SB,AH,0) = âˆ’0.08, and h(SB,AL,0) = 0.10. Thus, the userâ€™s optimal protection policies can be described as the Case 4(a) in 21 Proposition 4. The optimal insurance contract {Kâˆ—,Râˆ—} has Râˆ—âˆˆ[0,RB] and Kâˆ—= Râˆ—k(SG,AH;AH), where RB = 0.0889 and k(SG,AH;AH) = 21.9512 from Proposition 5. With the dynamic programming approach or linear programming approach in Section III, we can compute the optimal protection policies and the expected cumulative effective losses of the user as shown in Figs.4(a,b). We can further calculate the premium and the operating proï¬t of the insurer as shown in Figs.4(c,d). We can see that the numerical results coincide with our analytical results. (a) (b) (c) (d) Fig. 4. Two-State Two-Action User and Threshold Coverage Insurer. The horizontal axis in Figs. (a), (b), (c), (d) represents the coverage level R. The green area denotes the region of optimal insurance contracts. B. Four-State Three-Action User and Linear Coverage Insurer In this subsection, we consider a more complicated example where the user has four states and three actions, and the insurer provides linear coverage. We show that our model can be used to analyze the interactions between the user and the insurer in a numerical way. 22 We assume that the userâ€™s states can be identiï¬ed as SG, SB,1, SB,2, and SB,3 with the state losses XG = 0, XB,1 = 4, XB,2 = 8, and XB,3 = 16, respectively. SG indicates the good state, while SB,i indicates the bad states with i capturing the level of the damage. The user can take no protection A0, weak protection AL, or strong protection AH, and the costs of them can be identiï¬ed as c(A0) = 0, c(AL) = 0.3, and c(AH) = 0.6, respectively. Different actions have different impacts on the transition probabilities. For convenience, we summarize the transition probabilities by the following matrix: Pa = ï£® ï£¯ï£¯ï£¯ï£¯ï£¯ï£° p(SG,a,SG) p(SG,a,SB,1) p(SG,a,SB,2) p(SG,a,SB,3) p(SB,1,a,SG) p(SB,1,a,SB,1) p(SB,1,a,SB,2) p(SB,1,a,SB,3) p(SB,2,a,SG) p(SB,2,a,SB,1) p(SB,2,a,SB,2) p(SB,2,a,SB,3) p(SB,3,a,SG) p(SB,3,a,SB,1) p(SB,3,a,SB,2) p(SB,3,a,SB,3) ï£¹ ï£ºï£ºï£ºï£ºï£ºï£» (25) The user has a larger probability of going to the good state and a smaller probability of going to the bad state with better protections. We then take the following transition probabilities in this example: PA0 = ï£® ï£¯ï£¯ï£¯ï£¯ï£¯ï£° 0.25 0.25 0.25 0.25 0.25 0.25 0.25 0.25 0.25 0.25 0.25 0.25 0.25 0.25 0.25 0.25 ï£¹ ï£ºï£ºï£ºï£ºï£ºï£» ; PAL = ï£® ï£¯ï£¯ï£¯ï£¯ï£¯ï£° 0.4 0.3 0.2 0.1 0.4 0.3 0.2 0.1 0.4 0.3 0.2 0.1 0.4 0.3 0.2 0.1 ï£¹ ï£ºï£ºï£ºï£ºï£ºï£» ; PAH = ï£® ï£¯ï£¯ï£¯ï£¯ï£¯ï£° 0.8 0.2 0.0 0.0 0.7 0.2 0.1 0.0 0.6 0.2 0.1 0.1 0.5 0.2 0.2 0.1 ï£¹ ï£ºï£ºï£ºï£ºï£ºï£» . Let Î´ = 0.9, the optimal protection policies and the expected cumulative effective losses of the user are shown in Figs.5(a,b). We can see from (a,b) that the user decreases his protections with the increase of the coverage level, and the user also has lower expected cumulative effective losses with higher coverage levels. The premium and the operating proï¬t of the insurer are shown in Figs.5(c,d). We can see that with the increase of the coverage level, the premium is linearly 23 increasing. Moreover, the maximum operating proï¬t that can be achieved by the insurer is 0. We can also observe that the optimal insurance contract tends to provide limited coverage levels, and higher coverage levels can lead to negative operating proï¬ts of the insurer. Thus, the risk compensation, the zero-operating proï¬t principle, and the linear insurance contract principle still hold in this example. (a) (b) (c) (d) Fig. 5. Four-State Three-Action User and Linear Coverage Insurer. The horizontal axis in Figs. (a), (b), (c), (d) represents the coverage level R. The green area denotes the region of optimal insurance contracts. C. Four-State Three-Action User and Threshold Coverage Insurer In this subsection, we consider a threshold coverage insurance and show its impact on the four-state three-action user and the insurer. We use the same settings for the user as in the previous subsection. The threshold insurance contract has two coverage levels R0 = 0 and R1 = 0.9, which are distinguished by a threshold XR âˆˆ[0,20]. When the loss of the user x â‰¤XR, the insurer provides no coverage R0x, otherwise, 24 the insurer provides a coverage R1x. A lower XR indicates that the insurance has a higher coverage for smaller losses. The objective of the insurer is to maximize his operating proï¬t by ï¬nding the optimal threshold Xâˆ— R and the associated premium Kâˆ—. The optimal protection policies and the expected cumulative effective losses of the user are shown in Fig.6(a,b), and we can see from them that the user decreases his protections with the decrease of the threshold XR, which indicates that the user tends to act recklessly knowing that the insurer provides a high coverage even he has a small loss from cyber risks. Moreover, we can see that the premium is a staircase function on the threshold XR, and it decreases with the increase of XR, which shows that the insurer charges a higher premium to provide a higher coverage level. The maximum operating proï¬t that can be achieved by the insurer is 0. As a result, this example shows the similar risk compensation and zero-operating proï¬t principle as in the previous examples. Note that the gray area has XR > XB,3, i.e., the insurer provides no coverage for the user at any states, which is equivalent to the case when there is no insurance. VII. CONCLUSION In this paper, we have presented a dynamic moral-hazard type of principal-agent model to study the cyber-insurance and its impacts on the cyber-security. The dynamics and correlations of the cyber risks have been modeled by Markov decision processes where the user aims to ï¬nd the optimal protection policy to mitigate the impacts of cyberattacks. Both the computational and analytical tools have been presented to design the optimal cyber-insurance contracts. We have studied and fully analyzed a case where the user has two states and two actions, and the insurer provides linear coverage insurance. We have further demonstrated the Peltzman effect that the user has higher cyber risks under insurance due to risk compensation, i.e., the user tends to act more recklessly knowing he is protected. We have presented the linear insurance contract principle and the zero-operating proï¬t principle of the optimal cyber-insurance contract. Numerical experiments have been used to corroborate our results and further demonstrate the case study with a four-state three-action user and his interactions with linear coverage insurance and threshold coverage insurance. The risk compensation and the zero-operating proï¬t principle have been shown to hold in these cases. One direction of future research is the investigation of cyber-insurance contracts over complex networks such as scale-free and small-world networks with dynamic cyber risks. 25 (a) (b) (c) (d) Fig. 6. Four-State Three-Action User and Threshold Coverage Insurer. The horizontal axis in Figs. (a), (b), (c), (d) represents the threshold XR. The green area denotes the region of optimal insurance contracts. APPENDIX A. PROOF OF PROPOSITION 2 To simplify the notation in this proof, we deï¬ne the discounted transition probabilities as bp(s,Î±s,s) = 1âˆ’Î´ p(s,Î±s,s), bp(s,Î±s,sc) = Î´ p(s,Î±s,sc). Remark 3. The following facts hold for bp: (i) bp(SG,Î±G,SG)âˆ’bp(SG,Î±G,SB) = bp(SB,Î±B,SB)âˆ’bp(SB,Î±B,SG) = 1âˆ’Î´; (ii) If Î´ = 1, we have bp(SG,Î±G,SG) = bp(SG,Î±G,SB) and bp(SB,Î±B,SB) = bp(SB,Î±B,SG). Thus, (21) can be written as Ip(Î±G,Î±B) = bp(SG,Î±G,SG)bp(SB,Î±B,SB)âˆ’bp(SG,Î±G,SB)bp(SB,Î±B,SG). 26 Remark 4. The following facts hold for Ip: (i) Ip(Î±G,Î±B) = (1âˆ’Î´ + bp(SG,Î±G,SB))(1âˆ’Î´ + bp(SB,Î±B,SG))âˆ’bp(SG,Î±G,SB)bp(SB,Î±B,SG) = (1âˆ’Î´)2 +(1âˆ’Î´)(bp(SG,Î±G,SB)+ bp(SB,Î±B,SG)) > 0 when 0 â‰¤Î´ < 1; (ii) Ip(AH,Î±B)âˆ’Ip(AL,Î±B) = (1âˆ’Î´)(bp(SG,AH,SB)âˆ’bp(SG,AL,SB)); (iii) Ip(Î±G,AH)âˆ’Ip(Î±G,AL) = (1âˆ’Î´)(bp(SB,AH,SG)âˆ’bp(SB,AL,SG)). The action dependent expected cumulative effective losses (19) and (20) can be rewritten as follows: V(s,Î±s;Î±sc,R) = (1âˆ’R)k(s,Î±s;Î±sc)+b(s,Î±s;Î±sc), (26) where k(s,Î±s;Î±sc) = bp(SB,Î±B,sc)XG+bp(SG,Î±G,sc)XB Ip(Î±G,Î±B) ; (27) b(s,Î±G;Î±sc) = bp(SB,Î±B,sc)c(Î±G)+bp(SG,Î±G,sc)c(Î±B) Ip(Î±G,Î±B) . (28) Note that k(SG,AH;Î±B)âˆ’k(SG,AL;Î±B) = bp(SB,Î±B,SB)XG+bp(SG,AH,SB)XB Ip(AH,Î±B) âˆ’bp(SB,Î±B,SB)XG+bp(SG,AL,SB)XB Ip(AL,Î±B) = bp(SB,Î±B,SB)Ip(AL,Î±B)XG+bp(SG,AH,SB)Ip(AL,Î±B)XB Ip(AH,Î±B)Ip(AL,Î±B) âˆ’bp(SB,Î±B,SB)Ip(AH,Î±B)XG+bp(SG,AL,SB)Ip(AH,Î±B)XB Ip(AH,Î±B)Ip(AL,Î±B) = bp(SB,Î±B,SB)(Ip(AL,Î±B)âˆ’Ip(AH,Î±B))XG Ip(AH,Î±B)Ip(AL,Î±B) + bp(SG,AH,SB)Ip(AL,Î±B)XBâˆ’bp(SG,AL,SB)Ip(AH,Î±B)XB Ip(AH,Î±B)Ip(AL,Î±B) = (1âˆ’Î´)bp(SB,Î±B,SB)(bp(SG,AL,SB)âˆ’bp(SG,AH,SB))XG Ip(AH,Î±B)Ip(AL,Î±B) + (1âˆ’Î´)bp(SB,Î±B,SB)(bp(SG,AH,SB)âˆ’bp(SG,AL,SB))XB Ip(AH,Î±B)Ip(AL,Î±B) = (1âˆ’Î´)bp(SB,Î±B,SB)(bp(SG,AL,SB)âˆ’bp(SG,AH,SB))(XGâˆ’XB) Ip(AH,Î±B)Ip(AL,Î±B) , (29) where the fourth equality is achieved by plugging Remark 4(i)(ii). Similarly, we can achieve that k(SB,AH;Î±G)âˆ’k(SB,AL;Î±G) = (1âˆ’Î´)bp(SG,Î±G,SG)(bp(SB,AH,SG)âˆ’bp(SB,AL,SG))(XGâˆ’XB) Ip(Î±G,AH)Ip(Î±G,AL) ; (30) b(SG,AH;Î±B)âˆ’b(SG,AL;Î±B) = (1âˆ’Î´)bp(SB,Î±B,SB)(bp(SB,Î±B,SB)+bp(SG,Î±B,SB))(CHâˆ’CL) Ip(AH,Î±B)Ip(AL,Î±B) ; (31) b(SB,AH;Î±G)âˆ’b(SB,AL;Î±G) = (1âˆ’Î´)bp(SG,Î±G,SG)(bp(SG,Î±G,SG)+bp(SB,Î±G,SG))(CHâˆ’CL) Ip(Î±G,AH)Ip(Î±G,AL) . (32) As a result, we have V(SG,AH;Î±B,R)âˆ’V(SG,AL;Î±B,R) = (1âˆ’R)(k(SG,AH;Î±B)âˆ’k(SG,AL;Î±B))+b(SG,AH;Î±B)âˆ’b(SG,AL;Î±B) = (1âˆ’Î´)bp(SB,Î±B,SB) Ip(AH,Î±B)Ip(AL,Î±B)h(SG,Î±B,R); (33) V(SB,AH;Î±G,R)âˆ’V(SB,AL;Î±G,R) = (1âˆ’Î´)bp(SG,Î±G,SG) Ip(Î±G,AH)Ip(Î±G,AL)h(SB,Î±G,R), (34) 27 where h(s,Î±sc,R) has been deï¬ned in Proposition 2. Since 1 âˆ’Î´ > 0, bp(s,Î±s,s) > 0, and Ip(Î±s,Î±sc) > 0, we have that V(s,AH;Î±sc,R) <V(s,AL;Î±sc,R) if h(s,Î±sc,R) < 0 and V(s,AH;Î±sc,R) â‰¥ V(s,AL;Î±sc,R) if h(s,Î±sc,R) â‰¥0. Proposition 2 holds. APPENDIX B. PROOF OF THEOREM 1 Recall the value of transition probabilities Ï from (22) in Proposition 4. Besides Proposition 3, we note that h(s,Î±sc,R) has the following extra facts. h(SG,AH,R)âˆ’h(SG,AL,R) = h(SB,AH,R)âˆ’h(SB,AL,R) = ÏÎ´(CH âˆ’CL); (35) h(SG,AH,R)âˆ’h(SB,AH,R) = h(SG,AL,R)âˆ’h(SB,AL,R) = ÏÎ´(1âˆ’R)(XB âˆ’XG); (36) h(SG,AH,R)âˆ’h(SB,AL,R) = ÏÎ´ ((CH âˆ’CL)+(1âˆ’R)(XB âˆ’XG)); (37) h(SB,AH,R)âˆ’h(SG,AL,R) = ÏÎ´ ((CH âˆ’CL)âˆ’(1âˆ’R)(XB âˆ’XG)). (38) If Ï€âˆ— R = Î HL, we have h(SG,AL,R) < 0 and h(SB,AH,R) â‰¥0 from Proposition 2. Thus, Ï€âˆ— R Ì¸= Î LL and Ï€âˆ— R Ì¸= Î HH. Similarly, if Ï€âˆ— R = Î LH, we have Ï€âˆ— R Ì¸= Î LL and Ï€âˆ— R Ì¸= Î HH; if Ï€âˆ— R = Î LL, we have Ï€âˆ— R Ì¸= Î LH and Ï€âˆ— R Ì¸= Î HL; if Ï€âˆ— R = Î HH, we have Ï€âˆ— R Ì¸= Î LH and Ï€âˆ— R Ì¸= Î HL. Thus, to prove the uniqueness of Ï€âˆ— R, we only need to prove that (i). Ï€âˆ— R = Î LH and Ï€âˆ— R = Î HL cannot exist at the same time and (ii). Ï€âˆ— R = Î LL and Ï€âˆ— R = Î HH cannot exist at the same time. If Ï€âˆ— R = Î LH and Ï€âˆ— R = Î HL at the same time, we have h(SG,AH,R) â‰¥0, h(SB,AL,R) < 0, h(SG,AL,R) < 0, and h(SB,AH,R) â‰¥0 from Proposition 2, which indicates that Ï > 0 from (37) as h(SG,AH,R) > h(SB,AL,R) and ÏÎ´ ((CH âˆ’CL)âˆ’(1âˆ’R)(XB âˆ’XG)) > 0 from (38) as h(SG,AL,R) < h(SB,AH,R). Thus, we can achieve that (CH âˆ’CL) > (1âˆ’R)(XB âˆ’XG). However, h(SG,AL,R) = (1âˆ’R)Î´(p(SG,AH,SB)âˆ’p(SG,AL,SB))(XB âˆ’XG) +(1âˆ’Î´ +Î´ p(SB,AL,SG)+Î´ p(SG,AL,SB))(CH âˆ’CL) > (1âˆ’R)Î´(p(SG,AH,SB)âˆ’p(SG,AL,SB))(XB âˆ’XG) +(1âˆ’Î´ +Î´ p(SB,AL,SG)+Î´ p(SG,AL,SB))(1âˆ’R)(XB âˆ’XG) = (1âˆ’R)(XB âˆ’XG)(1âˆ’Î´ +Î´ p(SG,AH,SB)+Î´ p(SB,AL,SG)) > 0, (39) which violates h(SG,AL,R) < 0. As a result, Ï€âˆ— R = Î LH and Ï€âˆ— R = Î HL cannot exist at the same time. 28 If Ï€âˆ— R = Î LL and Ï€âˆ— R = Î HH at the same time, we have h(SG,AL,R) â‰¥0, h(SB,AL,R) â‰¥0, h(SG,AH,R) < 0, and h(SB,AH,R) < 0, which indicates that Ï < 0 from (35) and ÏÎ´ ((CH âˆ’CL)âˆ’(1âˆ’R)(XB âˆ’XG 0 from (38). Thus, we can achieve that (CH âˆ’CL)âˆ’(1âˆ’R)(XB âˆ’XG) > 0. However, h(SB,AH,R) = (1âˆ’R)Î´(p(SB,AH,SG)âˆ’p(SB,AL,SG))(XG âˆ’XB) +(1âˆ’Î´ +Î´ p(SB,AH,SG)+Î´ p(SG,AH,SB))(CH âˆ’CL) > (1âˆ’R)Î´(p(SB,AH,SG)âˆ’p(SB,AL,SG))(XG âˆ’XB) +(1âˆ’Î´ +Î´ p(SB,AH,SG)+Î´ p(SG,AH,SB))(1âˆ’R)(XB âˆ’XG) = (1âˆ’R)(XB âˆ’XG)(1âˆ’Î´ +Î´ p(SG,AH,SB)+Î´ p(SB,AL,SG)) > 0, which violates h(SB,AH,R) < 0. As a result, Ï€âˆ— R = Î LL and Ï€âˆ— R = Î HH cannot exist at the same time. Thus, Theorem 1 holds. APPENDIX C. PROOF OF PROPOSITION 4 There are only four possible protection policies Î LL, Î HL, Î LH, and Î HH. Thus, the optimal protection policy Ï€âˆ— 0 without insurance has only four cases: Case 1, Case 2, Case 3, and Case 4 as presented in Proposition 4, which are determined by h(s,Î±sc,0) in Proposition 2. As a result, we only need to prove the trends of Ï€âˆ— R with respect to R in different cases. We ï¬rst note that when R = 1, we have h(SG,Î±B,1) > 0 and h(SB,Î±G,1) > 0, which indicates that Ï€âˆ— R=1 = Î LL. Moreover, if the user has Ï€âˆ— bR = Î LL for a coverage level of bR âˆˆ[0,1], we have h(SG,AL, bR) â‰¥0 and h(SB,AL, bR) â‰¥0 from Proposition 2. Since h(s,Î±sc,R) is linearly increasing on R as shown in Proposition 3, we have h(SG,AL,R) â‰¥0 and h(SB,AL,R) â‰¥0 for R â‰¥bR, which indicates that Ï€âˆ— R = Î LL for R â‰¥bR. Thus, we can conclude that Ï€âˆ— R = Î LL when R is sufï¬ciently large and the user chooses not to change his policy with the increase of R once he achieves Ï€âˆ— R = Î LL for all cases. To prove Cases 2, 3, and 4, recall the value of transition probabilities Ï from (22). If Ï < 0, we have h(SG,AH,R) < h(SB,AL,R) from (37). However, when Ï€âˆ— R = Î LH, we have h(SG,AH,R) â‰¥0 and h(SB,AL,R) < 0 from Proposition 2, which violates h(SG,AH,R) < h(SB,AL,R). Thus, we have Ï€âˆ— R Ì¸= Î LH if Ï < 0. As a result, Case 2 and Case 4(a) has Ï < 0 and the user have Ï€âˆ— R Ì¸= Î LH in these cases. Since h(SB,AH,0) â‰¥0 when Ï€âˆ— 0 = Î HL in Case 2 and h(SB,AH,R) is linearly increasing on R, h(SB,AH,R) â‰¥0 for R âˆˆ[0,1]. Thus, the user has Ï€âˆ— R Ì¸= Ï€HH in Case 2 and Case 2 holds. The threshold RG is achieved by solving h(SG,AL,R) = 0. Case 4(a) holds from Case 29 2, and the thresholds RG and RB are achieved by solving h(SG,AL,R) = 0 and h(SB,AH,R) = 0, respectively. If Ï > 0 and Ï€âˆ— R = Î HL, we have h(SG,AL,R) < 0 and h(SB,AH,R) â‰¥0 from Proposition 2 and thus h(SB,AH,R)âˆ’h(SG,AL,R) = ÏÎ´ ((CH âˆ’CL)âˆ’(1âˆ’R)(XB âˆ’XG)) > 0 from (38), which indicates that (CH âˆ’CL)âˆ’(1âˆ’R)(XB âˆ’XG) > 0. However, we could obtain that h(SG,AL,R) > 0 following similar arguments as in (39), which violates h(SG,AL,R) < 0. Thus, we have Ï€âˆ— R Ì¸= Î HL if Ï > 0. As a result, Case 3 and Case 4(b) have Ï > 0 and the user has Ï€âˆ— R Ì¸= Î HL in these cases. Since h(SG,AH,R) â‰¥0 when Ï€âˆ— 0 = Î LH in Case 3 and h(SG,AH,R) is linearly increasing on R, h(SG,AH,R) â‰¥0 for R âˆˆ[0,1]. Thus, the user has Ï€âˆ— R Ì¸= Ï€HH in Case 3 and Case 3 holds. The threshold RB is achieved by solving h(SB,AL,R) = 0. Case 4(b) holds from Case 3, and the thresholds RB and RG are achieved by solving h(SB,AL,R) = 0 and h(SG,AH,R) = 0, respectively. If Ï = 0, we have h(SG,AH,R) = h(SG,AL,R) = h(SB,AH,R) = h(SB,AL,R) from (35)-(38). However, Î LH and Î HL indicate that h(SG,AH,R) â‰¥0 > h(SB,AL,R) and h(SG,AL,R) < 0 â‰¤ h(SB,AH,R), respectively. Thus, we have Ï€âˆ— R Ì¸= Î HH and Ï€âˆ— R Ì¸= Î LL if Ï = 0. As a result, Case 4(c) has Ï = 0 and the user has Ï€âˆ— R Ì¸= Î HL and Ï€âˆ— R Ì¸= Î LH. Thus, Case 4(c) holds, and the thresholds RG and RB are achieved by solving h(SG,AH,R) = 0 and h(SB,AH,R) = 0, respectively. REFERENCES [1] G. Oâ€™Gorman and G. McDonald, Ransomware: A growing menace. Symantec Corporation, 2012. [2] S. Romanosky, D. Hoffman, and A. Acquisti, â€œEmpirical analysis of data breach litigation,â€ Journal of Empirical Legal Studies, vol. 11, no. 1, pp. 74â€“104, 2014. [3] Å. Apiecionek, J. M. Czerniak, and H. Zarzycki, â€œProtection tool for distributed denial of services attack,â€ in International Conference: Beyond Databases, Architectures and Structures, pp. 405â€“414, Springer, 2014. [4] M. H. Manshaei, Q. Zhu, T. Alpcan, T. BacsÂ¸ar, and J.-P. Hubaux, â€œGame theory meets network security and privacy,â€ ACM Computing Surveys (CSUR), vol. 45, no. 3, p. 25, 2013. [5] L. Kelion, â€œCryptolocker ransomware hasâ€™ infected about 250,000 pcsâ€™,â€ BBC News techology, 2013. [6] S. Hilton, â€œDyn analysis summary of friday october 21 attack,â€ Dyn Blog. Dyn News, vol. 26, 2016. [7] W. R. Cheswick, S. M. Bellovin, and A. D. Rubin, Firewalls and Internet security: repelling the wily hacker. Addison-Wesley Longman Publishing Co., Inc., 2003. [8] C. H. Rowland, â€œIntrusion detection system,â€ June 11 2002. US Patent 6,405,318. [9] S. Jajodia, A. K. Ghosh, V. Subrahmanian, V. Swarup, C. Wang, and X. S. Wang, Moving Target Defense II: Application of Game Theory and Adversarial Modeling, vol. 100. Springer, 2012. [10] V. Kumar, J. Srivastava, and A. Lazarevic, Managing cyber threats: issues, approaches, and challenges, vol. 5. Springer Science & Business Media, 2006. [11] J. P. Farwell and R. Rohozinski, â€œStuxnet and the future of cyber war,â€ Survival, vol. 53, no. 1, pp. 23â€“40, 2011. 30 [12] A. Beelitz and D. M. Merkl-Davies, â€œUsing discourse to restore organisational legitimacy:â€˜ceo-speakâ€™after an incident in a german nuclear power plant,â€ Journal of Business Ethics, vol. 108, no. 1, pp. 101â€“120, 2012. [13] J. Kesan, R. Majuca, and W. Yurcik, â€œCyberinsurance as a market-based solution to the problem of cybersecurity: a case study,â€ in Proc. WEIS, pp. 1â€“46, 2005. [14] R. BÂ¨ohme, G. Schwartz, et al., â€œModeling cyber-insurance: Towards a unifying framework.,â€ in WEIS, 2010. [15] N. Shetty, G. Schwartz, M. Felegyhazi, and J. Walrand, â€œCompetitive cyber-insurance and internet security,â€ Economics of Information Security and Privacy, pp. 229â€“247, 2010. [16] R. Pal, L. Golubchik, K. Psounis, and P. Hui, â€œWill cyber-insurance improve network security? a market analysis,â€ in INFOCOM, 2014 Proceedings IEEE, pp. 235â€“243, IEEE, 2014. [17] R. Zhang, Q. Zhu, and Y. Hayel, â€œA bi-level game approach to attack-aware cyber insurance of computer networks,â€ IEEE Journal on Selected Areas in Communications, vol. 35, no. 3, pp. 779â€“794, 2017. [18] M. Rothschild and J. Stiglitz, â€œEquilibrium in competitive insurance markets: An essay on the economics of imperfect information,â€ in Uncertainty in economics, pp. 257â€“280, Elsevier, 1978. [19] B. Holmstrom et al., â€œMoral hazard and observability,â€ Bell journal of Economics, vol. 10, no. 1, pp. 74â€“91, 1979. [20] B. Holmstrom, â€œMoral hazard in teams,â€ The Bell Journal of Economics, pp. 324â€“340, 1982. [21] F. Ewold, â€œInsurance and risk,â€ The Foucault effect: Studies in governmentality, pp. 197â€“210, 1991. [22] S. Xu, â€œCybersecurity dynamics,â€ in Proceedings of the 2014 Symposium and Bootcamp on the Science of Security, p. 14, ACM, 2014. [23] D. Fava, J. Holsopple, S. J. Yang, and B. Argauer, â€œTerrain and behavior modeling for projecting multistage cyber attacks,â€ in Information Fusion, 2007 10th International Conference on, pp. 1â€“7, IEEE, 2007. [24] S. Cheung, U. Lindqvist, and M. W. Fong, â€œModeling multistep cyber attacks for scenario recognition,â€ in DARPA information survivability conference and exposition, 2003. Proceedings, vol. 1, pp. 284â€“292, IEEE, 2003. [25] R. BÂ¨ohme and G. Kataria, â€œModels and measures for correlation in cyber-insurance.,â€ in WEIS, 2006. [26] P. Tague and R. Poovendran, â€œModeling node capture attacks in wireless sensor networks,â€ in Communication, Control, and Computing, 2008 46th Annual Allerton Conference on, pp. 1221â€“1224, IEEE, 2008. [27] P. Tague, M. Li, and R. Poovendran, â€œMitigation of control channel jamming under node capture attacks,â€ IEEE Transactions on Mobile Computing, vol. 8, no. 9, pp. 1221â€“1234, 2009. [28] A. K. Jones and R. S. Sielken, â€œComputer system intrusion detection: A survey,â€ Computer Science Technical Report, pp. 1â€“25, 2000. [29] S. Romanosky, R. Telang, and A. Acquisti, â€œDo data breach disclosure laws reduce identity theft?,â€ Journal of Policy Analysis and Management, vol. 30, no. 2, pp. 256â€“286, 2011. [30] A. Gazet, â€œComparative analysis of various ransomware virii,â€ Journal in computer virology, vol. 6, no. 1, pp. 77â€“90, 2010. [31] M. L. Puterman, Markov decision processes: discrete stochastic dynamic programming. John Wiley & Sons, 2014. [32] S. Roy, C. Ellis, S. Shiva, D. Dasgupta, V. Shandilya, and Q. Wu, â€œA survey of game theory as applied to network security,â€ in System Sciences (HICSS), 2010 43rd Hawaii International Conference on, pp. 1â€“10, IEEE, 2010. [33] S. J. Grossman and O. D. Hart, â€œAn analysis of the principal-agent problem,â€ Econometrica: Journal of the Econometric Society, pp. 7â€“45, 1983. [34] J.-J. Laffont and D. Martimort, The theory of incentives: the principal-agent model. Princeton university press, 2009. [35] R. BÂ¨ohme, â€œCyber-insurance revisited.,â€ in WEIS, 2005. [36] J. Grossklags, N. Christin, and J. Chuang, â€œSecure or insure?: a game-theoretic analysis of information security games,â€ in Proceedings of the 17th international conference on World Wide Web, pp. 209â€“218, ACM, 2008. 31 [37] D. K. Tosh, S. Shetty, S. Sengupta, J. P. Kesan, and C. A. Kamhoua, â€œRisk management using cyber-threat information sharing and cyber-insurance,â€ in International Conference on Game Theory for Networks, pp. 154â€“164, Springer, 2017. [38] J. P. Kesan and C. M. Hayes, â€œStrengthening cybersecurity with cyberinsurance markets and better risk assessment,â€ Minn. L. Rev., vol. 102, p. 191, 2017. [39] A. Laszka, E. Panaousis, and J. Grossklags, â€œCyber-insurance as a signaling game: Self-reporting and external security audits,â€ in Proceedings of the 9th Conference on Decision and Game Theory for Security (GameSec 2018), Springer, 2018. [40] I. Ehrlich and G. S. Becker, â€œMarket insurance, self-insurance, and self-protection,â€ Journal of political Economy, vol. 80, no. 4, pp. 623â€“648, 1972. [41] W. Stallings, Network and internetwork security: principles and practice, vol. 1. Prentice Hall Englewood Cliffs, New Jersey, 1995. [42] A. Perrig, J. Stankovic, and D. Wagner, â€œSecurity in wireless sensor networks,â€ Communications of the ACM, vol. 47, no. 6, pp. 53â€“57, 2004. [43] Q. Zhu, C. Fung, R. Boutaba, and T. Basar, â€œGuidex: A game-theoretic incentive-based mechanism for intrusion detection networks,â€ IEEE Journal on Selected Areas in Communications, vol. 30, no. 11, pp. 2220â€“2230, 2012. [44] N. Poolsappasit, R. Dewri, and I. Ray, â€œDynamic security risk management using bayesian attack graphs,â€ IEEE Transactions on Dependable and Secure Computing, vol. 9, no. 1, pp. 61â€“74, 2012. [45] J. Kim, S. Radhakrishnan, and S. K. Dhall, â€œMeasurement and analysis of worm propagation on internet network topology,â€ in Computer Communications and Networks, 2004. ICCCN 2004. Proceedings. 13th International Conference on, pp. 495â€“500, IEEE, 2004. [46] Y. Wu, B. Wang, and K. R. Liu, â€œOptimal defense against jamming attacks in cognitive radio networks using the markov decision process approach,â€ in Global Telecommunications Conference (GLOBECOM 2010), 2010 IEEE, pp. 1â€“5, IEEE, 2010. [47] D. Shen, G. Chen, E. Blasch, and G. Tadda, â€œAdaptive markov game theoretic data fusion approach for cyber network defense,â€ in Military Communications Conference, 2007. MILCOM 2007. IEEE, pp. 1â€“7, IEEE, 2007. [48] J. Filar and K. Vrieze, Competitive Markov decision processes. Springer Science & Business Media, 2012.