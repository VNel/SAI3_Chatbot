Network Risk Estimation: A Risk Estimation Paradigm for Cyber Networks Arda Bayera,∗, David Malufb, Behnaam Aazhanga aRice University, 6100 Main St, 77005 TX, Houston, U.S. bCisco, 170 West Tasman Drive, 95134 CA, San Jose, U.S. Abstract Cyber networks are fundamental to many organization’s infrastructure, and the size of cyber networks is increasing rapidly. Risk measurement of the enti- ties/endpoints that make up the network via available knowledge about possible threats has been the primary tool in cyber network security. However, the dy- namic behavior of the entities and the sparsity of risk-measurable points are limiting factors for risk measurement strategies, which results in poor network visibility considering the volatility of cyber networks. This work proposes a new probabilistic risk estimation approach to network security, NRE, which operates on top of existing risk measurements. The proposed method NRE extracts rela- tionships among system components from the network connection data, models risk propagation based on the learned relationships and refines the estimates whenever risk measurements are provided. In this work, (i) the risk estima- tion scheme is proposed, (ii) an application of quantitative risk estimates is devised, (iii) descriptiveness of the risk estimates are compared to a pure risk measurement alternative and (iv) low computational complexity of the proposed method is illustrated capable of real-time deployment. The proposed method, NRE, is ultimately a quantitative data-driven risk assessment tool that can be used to add security aspects to existing network functions, such as routing, and it provides a robust description of the network state in the presence of threats, capable of running in real-time. Keywords: Cyber Network Security, Quantitative Risk Assessment, Risk Measurement, Functional Connectivity, Kalman Filter ∗Corresponding author Email addresses: Arda.Bayer@rice.edu (Arda Bayer), dmaluf@cisco.com (David Maluf), aaz@rice.edu (Behnaam Aazhang) Preprint submitted to Elsevier January 2025 arXiv:2501.16487v1 [eess.SY] 27 Jan 2025 1. Introduction Cyber networks play a crucial role in the functioning of many organizations. A cyber network, or network as short, is essentially any interconnection of indi- vidual devices referred to as “entities” or “endpoints” that communicate with each other or make their communication possible. Typical examples of networks are (i) domestic networks (smartphones, TVs, lighting systems, etc.), (ii) enter- prise networks (consisting of users, servers, and routers, as depicted in Figure 1), (iii) industrial networks (e.g., sensors that gauge machine performance and communicate it to a Command and Control Center), and also (iv) networks of devices at hubs such as airports and malls. Recent advancements in technolo- gies such as wireless, the Internet of Things (IoT), and increased adoption of cloud computing have rapidly increased the effective size of the ultimate cyber network, where previously mentioned networks are frequently brought together. Accordingly, studies indicate that the size of the ultimate cyber network, cou- pled with the cloud, is increasing rapidly and poses a challenge when assessing the network regarding security [8]. Figure 1: An enterprise network [6] consisting of users, servers and routers. The intercon- nection of these entities makes up the network topology, which indicates existing direct com- munication channels. The network topology of a cyber network is the starting point of Risk Estimation. Risk assessment is the primary tool of cyber network security against count- less threats [1, 2, 21, 24]. Cyber networks make up the infrastructure of many organizations and institutions, making them attractive targets for malicious attacks. A typical attack targeted at a cyber network works from the most vulnerable endpoint to its target. Attackers strive to exploit any weaknesses, and defenders try to patch the inherent vulnerabilities of their system compo- nents [19]. Against a wide variety of vulnerabilities, the status quo of cyber network security has been “risk measurements”, with a unifying notion of risk for a selection of vulnerabilities. 2 The term risk, sometimes called vulnerability score [21, 25], is used to quan- tify the expected loss if a security breach were to occur while considering the likelihood of that breach [19, 24, 26]. The current defenses for cyber networks measure the risks in a principled way by prioritizing vulnerabilities based on their associated costs and leveraging existing knowledge about the threat to estimate the likelihood of that threat [21]. Accordingly, a cyber security system that gathers information about entities and quantifies network vulnerability is a risk measurement system that gauges the cyber network’s risk through avail- able entities. Some examples of risk measurement tools are antivirus software, intrusion detection systems (IDSs), and network endpoint analytics tools [8]. Since entities are ultimately responsible for the risk at the network level, the risk measurement practice can be viewed as a way to probe the vulnerability of the cyber network through available entities. However, even with the ideal risk measurements, in practice, the risk-measurable entities are generally a small portion of the network, and the growing size of the network, along with changing entity behavior, are currently limiting factors of risk measurement practice in cyber network security [1, 21]. In this work, a scalable and data-driven risk estimation paradigm, referred to as “Network Risk Estimation (NRE)”, is designed to address these challenges. The proposed system works within a probabilistic framework where a risk dis- tribution on entities is estimated using (1) the connection data and (2) the risk measurements whenever and wherever provided. To our knowledge, this is the first work to model risk propagation based on entity relationships. The premise of the NRE is that the threat will propagate from the entity that is the threat’s source to the entities associated with it. This premise lays out the spatial -across entities- and temporal -across time- dynamics of the risk propagation model of NRE. The result is an estimated probability distribution of risks among entities over time. The probabilistic risk estimates given by the proposed system can be used to (a) assess the network security quantitatively and (b) add security aspect to network-related functions. For instance, entities with high risks can be identified as weak points in the network. Alternatively, as a more elaborate network man- agement action, the safety aspect can be added to packet routing as illustrated in Figure 2, which is briefly discussed in Section 5.2. Our contributions are (i) entity relationship modeling from available connection data, (ii) partitioning of the network via discovered entity relationships, (iii) explicit probabilistic es- timation of entity risks, (iv) and an application of these estimates in network management. The rest of the paper is organized as follows. Section 2 briefly summarizes the related work in risk analysis, risk measurement approach to vulnerability assessment, and network modeling for intrusion detection. Section 3 formally states the problem of interest. In Section 4, the details of the proposed method are provided. Finally, Section 5 presents (1) the overall risk estimation process and the results on a public dataset, (2) a direct application of the produced risk 3 Figure 2: An application of risk estimation on a cyber network. The graph gives the network topology where each node is an entity, and an edge indicates an allowed communication channel. Red entities are measured to have relatively higher risks, green entities have low measured risks, and blue entities desire to communicate. Two possible routes are depicted via green and red dashed arrows. For safe routing, the green path is chosen over the red one since measured entities in the vicinity have less risk. estimates, (3) a particular proof of concept experiment designed for comparison with the alternative method, and (4) the running time complexity analysis. In addition, the implementation of the work that is described in this paper is open source and can be accessed at https://github.com/ab126/NRE. 2. Related Work The subject of risk assessment is well-established, and it is common to many engineering designs [3]. There exist standards for risk assessment regarding net- work security that have been set from an organizational standpoint. ISO 31000 [15] lays out general guidelines for organizations of any kind for the purpose of assessing the risks that may hinder the organization’s normal operation. These guidelines set the standard for risk management and give general instructions to deal with organizational risks where risk is essentially defined the same as in this work; the likelihood of a threat times the impact. However, it lacks the speci- ficity to be directly applied to a cyber network. For example, cloud computing is a substantial cyber network instance that is extremely dynamic and volatile. For the cloud, these standards were criticized for being unable to cover the cloud environment’s dynamic nature, and a proactive method was suggested [1]. In accordance with this shortcoming, some qualitative and quantitative risk assess- ment work has been dedicated to cloud computing risk assessment [1, 2, 26, 27]. Among these studies, “Quantitative Impact and Risk Assessment Framework ” [26] presents a risk assessment framework that relies on the consensus of an 4 expert team on the impacts of various risks and security reports in estimating the likelihood which is used to get a measurement of risks. Its main drawback is that it fails to be adaptive due to the reliance on expert discussion and lack of use of real-time network data. Another work that was aimed to quantify risks in a cloud environment is “Cyber Supply Chain Cloud Risk Assessment” [1], which similarly follows the ISO 31000 guidelines and outlines a quantita- tive risk assessment framework with an emphasis on the supply chain side of the cloud. This work puts forth the idea of making use of the topological in- formation in supply-side components of the cloud service and uses probability distributions to model the uncertainty inherent in calculating the risks. How- ever, this risk measurement approach is also not fully data-driven in the sense that it still requires cloud service provider stakeholders’ knowledge and inter- vention to produce quantitative risks for the whole network. The authors also point out the need for a “dynamic & adaptive” risk assessment technology for the cloud environment as future needs [1]. The studies mentioned so far can be treated as direct risk measurement practices on cyber networks where the outcome is the risk values. However, there are also works done on indirect risk measurements that deduce the likelihood part of the risk for a particular threat. The most common studies of this category are Intrusion Detection Systems (IDSs) that are developed for various cyber- physical networks against certain threats. For the intrusion detection problem, there exist labeled network data, called herein as connection data, which consists of the collection of communication sessions between pairs of entities called flows. A collection of descriptors called flow features can be extracted from raw bits making up the flows [29], after which the intrusion detection problem becomes a classification problem on the flows. An example of such an IDS is given by Wu et. al. where the flows are converted into doc-matrix format based on the presence of particular intervals of flow features, which are then used in the classification of flows [33]. Another approach for modeling intrusion detection has been the incorpora- tion of network topology into the detection task via graph structure. Entity relationships gathered from connection data have previously been summarized in a “Communication Graph” [20] where nodes are the entities and edges are present if two respective nodes have participated in a flow. In their work, after obtaining the communication graph, the intrusion detection problem boils down to an edge partitioning problem on the communication graph, which has been solved by transforming it to a canonical node partitioning problem on the dual graph [20]. Variants of the communication graph have been studied in intrusion detection with the same idea of explicitly using entity relationships (see [9] for a survey). For instance, different graph neural network architectures were de- signed by Chang et. al. to make the best use of both structural information in the graph, the entity relationships, and the information in the flow descriptors [7]. Despite the vast modeling perspectives, these studies from the intrusion de- 5 tection literature are essentially risk measurements for particular threats, such as “Distributed Denial of Service” or “Brute Force” attacks [29], from risk as- sessment [3] point of view. Consequently, as mentioned in Section 1, this ap- proach to cyber network security suffers from limited risk-measurable entities, the dynamic nature of the network in terms of changing entity behavior, and the addition of new entities. 3. Problem Statement In the security setting, network assessment is done in terms of risk mea- sures [10, 19, 26]. Once the risks of individual threats are identified, defensive measures can be taken [26, 27]. As an example, if the greatest risk against the network is an exploit due to an older version of the software, a software update can be administered to the respective entities in the network. Following the same idea about the network-level risks, the risk of an entity for a particular threat is proposed in this work as the likelihood of the entity being compromised times the impact of the same entity being compromised. Here, the impact is the quantification of the cost if the unwanted scenario were to happen. An example the cost in dollar amounts if the respective entity was compromised to a virus. Ultimately, this definition of entity risk is along the same line as the conven- tional definition of risk used for the whole network [15, 19, 24, 26] but at the entity level. Accordingly, the goal of this work is to estimate the risks of each entity in the network, given (1) some risk measurements on a set of entities and (2) the connection data, the flows, that capture the activity in the network. Phrased in the framework of probability theory, the problem tackled here is to find the probability distribution of entity risks given sparse risk measurements on some entities, red and green entities in Figure 2, and connection data. It is implied that the risk measurements, whatever the source be, are mapped to the same “risk units” or scale according to the same standard. When risks are forged for every entity, network management becomes clear. For instance, given two entities that want to communicate, e.g., blue entities in Figure 2, one can find the “most trusted path” to route the packets in between, which is referred to as safe routing (Section 5.2). One way to do this is to minimize the expected maximum risk along the path over all possible paths between two entities, intuitively picking the green path instead of the red one in Figure 2. This application of the proposed risk estimation method is illustrated in Section 5.2. Another use case is that the “high risk” entities in the network can be immediately identified and can be used in devising new measurement strategies or in implementing safety rules such as quarantining. 4. Method This section outlines the details of the proposed risk estimation method. The underlying premise assumed in this work is that the risk of entities will 6 propagate through the network by the way entities influence each other. This is based on the fact that organized cyber-attacks target system vulnerabilities to gain privilege over entities [16, 21]. It is assumed herein that during this process, the exploiter leaves a footprint in the connection data/flows, referred to as the influence relationship between involved entities. With this reasoning, the first part of the proposed work is dedicated to uncovering the way enti- ties influence each other in the network, which is the basis for the functional connectivity graph (Section 4.1). This step summarizes the discovered entity behavioral relationships as a weighted directed graph F. In the second part, the calculated graph is used as a linear model for predicting risks, in which the risk estimates are refined with incoming measurements using a probabilistic frame- work (Section 4.2). Finally, in Section 4.3, real-time deployment is discussed. Although the proposed method is used in the context of cyber networks, it is generalizable to other dynamic networks for obtaining low dimensional latent variables regarding system state. 4.1. Inference of Relationships For the cyber networks considered in this work, it is assumed that the con- nection data comprises distinct flows just like NetFlow, sFlow formats [13] where a flow is defined as any communication between two endpoints in one session [13, 31]. These flows have multiple flow attributes that give additional informa- tion about flows such as timestamp, flow duration, and number of packets in each direction and more [17]. Previously in the field of cyber-security, similar entity relationship graphs have been constructed as “communication graphs” [9, 20] where two entities have an edge if there has been at least one flow observed between them. Although the communication graph is a valid way to model the entity relationships, we here present a more general way to devise the relationship graph, referred as the functional connectivity graph, encompassing the communication graph but also capable of capturing more abstract dependencies among entities. Given the collection of flows referred as the connection data, the relationship among entities is analyzed in this work with respect to a single connection parameter derived from flow attributes. Each connection parameter captures a distinct aspect of the flows. For instance, “Number of Packets Received” is a connection parameter derived from “Number of Packets in the Forward Direction” and “Number of Packets in the Backward Direction” flow attributes. It represents the inward volume of flows for an entity. Ultimately, the connection parameter models the aspect of entity behavior for the risk prediction process. In this work, a few straightforward choices of connection parameters have been put forth. A summary of relevant connection parameters is given in Table 1. Once a connection parameter is chosen, discrete-time signals are formed for each entity. This process requires a synchronization step described in Section 4.1.1. Then, in Section 4.1.2, the method used for obtaining the functional connectivity graph is presented. Section 4.1.3 and Section 4.1.4 discuss some of 7 Table 1: A Summary of Connection Parameters that are used. Each connection parameter captures an aspect of flows involving an entity, and it is derived from flow attributes in connec- tion data. Aggregation Method refers to the way flows are aggregated in the synchronization step (Section 4.1.1). The flow attributes are based on Lashkari et al. citecicflowmeter. Connection Parameter Description Aggregation Method Activation A binary indicator denoting if an entity is sending or receiving any packets N/A Active Time Mean time an entity was active before becoming idle Average Flow Duration Total duration of the flows Total Flow Speed Average bytes per second Average Header Length Average bytes used in packet header in forward direction Average Idle Time Mean time the flows were idle before becoming active Average Number of Active Packets Total number of packets with at least 1 byte of packet payload in forward direction Total Number of Packets Received Total number of packets in the backward direction Total Number of Packets Sent Total number of packets in the forward direction Total Packet Delay Average of packet Inter Arrival Time (IAT) in forward directions Average Packet Length Average size of packets in forward direction Average Port Number The port number used by the entity for the flow Last Protocol Flow’s Internet Protocol Number (e.g. TCP:6, UDP:17, etc.) Last Response Time Average of packet Inter Arrival Time (IAT) in backward direction Average the optional but recommended steps taken to optimize the graph, which will be used as the essential model for risk prediction. 4.1.1. Synchronization A flow can start and end anytime in the network. Consequently, the ob- servations about entities in connection data are asynchronous naturally. For modeling entity behaviors, working with synchronous discrete-time signals is 8 easier. Accordingly, all the flows in a given time interval are aggregated with a custom choice of window size, yielding synchronous signals for entities. For a chosen synchronization window size denoted by δ (e.g., 2 s), flow attributes for each flow in a time window are aggregated by either summing, averaging, or taking the last value depending on the connection parameter that is being used (see Table 1). As an example, if it is desired to build the entity- relationship model by the number of packets an entity receives, the “Number of Packets Received” (NPR) signal for each entity can be formed by counting the total number of packets each entity received per time-window. Similarly, if the objective is to model the flow speed, the “Flow Speed” signal can be computed as the mean flow speed of the flows created by each entity. This process is summarized in Figure 3, where flows of two entities are depicted on the top row, and the constructed synchronous signals for two distinct connection parameters are given below. Here, the “Activation” is another connection parameter that can be used to deduce if two entities have sent packets coincidentally or not. Synchronous samples of these signals are then used to quantify influences among entities. Figure 3: An illustration of the synchronization process involving two entities. Shaded and unshaded regions denote consecutive synchronization time windows. Flows: Flow history of two arbitrary entities. Each tick corresponds to a flow in connection data. Activation: The connection parameters that lead to a signal that depicts the activities of respective entities. Number of Packets Received (NPR): Another connection parameter that grants a signal indi- cating the number of packets an entity receives. Ultimately, the obtained signals are defined per entity and are synchronous. 4.1.2. Functional Connectivity Graph from Connection Data After constructing synchronous signals per entity for a given connection parameter, the next step is to infer the underlying relationships among pairs of entities. The extent of entity A influencing entity B is quantified solely 9 from the constructed signals of entity A and B with a choice of an influence measure. The end goal of this step is the functional connectivity graph which is a weighted directed graph G = (V, E, W) where V is the set of entities, E is the set of edges where an edge e = (vi, vj) represent the influence of entity vi on vj and the respective non-negative weight wij ≥0 quantify how strong the influence is for respective edge. Once the entities are indexed, the graph G = (V, E, W) is completely de- scribed by the respective weight matrix denoted by F where the entries are the weights when the edge is present, and 0 otherwise; Fij = ( wij , (vi, vj) ∈E 0 , (vi, vj) /∈E , as depicted in Figure 4. The superscript (t) is used to denote that the calcula- tion of the graph was done for the time window [t, t + τ) where τ is the fixed graph window size. Throughout this work, the weight matrix notation, F, will be used to refer to the functional connectivity graph instead of the conventional set notation G = (V, E, W). Obtaining the underlying functional connectivity graph out of observational data falls in the field of “Causal Discovery”, which comes with a few caveats for cyber networks. First, even if there was a unique underlying causal struc- ture among entities in generating the connection data, the precise recovery of this structure is only possible up to a set of functional connectivity graphs that are indistinguishable without additional information [11]. Secondly and more critically, conventional causal discovery algorithms such as the Peter-Clark al- gorithm [11] and their variants scale terribly with the number of nodes/entities. The “Causal Discovery” is typically employed for problems having no more than 15 nodes, whereas in this case, the number of devices/entities can easily be thousands. For these reasons, inferring the functional connectivity graph from signals obtained according to Section 4.1.1 is simplified greatly for the cy- ber network to what is called simple association network inference [14], which results in an undirected graph F. In doing so, each pair of nodes is studied in- dependently, and the objective weights of this graph, wij, are computed using a simple similarity metric for signals on the entities. However, the risk estimation approach proposed here is suited for any functional connectivity graph inference method that might be more appealing for different scenarios. The similarity metric that has been used for weight calculation is the “Mag- nitude of the Pearson Correlation Coefficient”. In quantifying the relationship, each sample of the preprocessed signal is assumed to be independent with an appropriate choice of window size in Section 4.1.1, and thus, sample-based esti- mation of the correlation coefficient is justified as a metric for the association. The resulting graph is undirected or equivalently graph weight matrix F is sym- metric. Let Y (t) i = {y(t) i,1, y(t) i,2, ..., y(t) i,N} denote the N samples of the synchronous sig- nal obtained as in Section 4.1.1 for the entity i in the time window [t, t+τ). Then the functional connectivity graph for this time window obtained via the “Magni- 10 (a) F(t) (b) F(t+τ) Figure 4: A Functional Connectivity Graph F that manifests the relationships among entities at two different timestamps. (a) F(t) and (b) F(t+τ). For each pair of entities (i, j), the strength of influence F (.) ij is calculated, which results in a weighted directed graph in general. The graph evolves with time as the connections happen. tude of the Pearson Correlation Coefficient” estimator is a symmetric weighted graph whose weight matrix’s entries are given by (1) where Cov(Y (t) i , Y (t) j ) is the sample covariance, s(Y (t) i ) is the sample standard deviation and yi(t) is the sample mean. The edge weights are normalized such that F (t) ij ∈[0, 1] and F (t) ii = 1, for the functional connectivity graphs in the proposed risk estimation scheme. The consequence of this normalization is that an entity will maintain its risk, and the entities that influence it will add to its previous risk (see Section 4.2). The scaling of the absolute values of the risks are handled later in Section 4.2.2. F (t) ij = |rij| = |Cov(Y (t) i , Y (t) j )| s(Y (t) i ) s(Y (t) j ) (1) Cov(Y (t) i , Y (t) j ) = 1 N −1 N X k=1 (y(t) i,k −yi (t))(y(t) j,k −yj (t)) s(Y (t) i ) = v u u t 1 N −1 N X k=1 (y(t) i,k −yi(t))2 yi (t) = 1 N N X k=1 y(t) i,k The calculated functional connectivity graph is per time-window that has been chosen, and the resulting graph F(t) is dynamic, and it most likely will change over time as illustrated in Figure 4. Although the inferred functional connectivity graph might resemble the network topology, i.e. the allowed com- munication channels between entities such as the one in Figure 2, there is a 11 crucial difference. Distant entities in the network topology might influence each other, resulting in a significant edge in the functional connectivity graph; how- ever, there might be no direct edge in the network topology. For this reason, it is better to work with the functional connectivity graph from risk estimation point of view. In forming the functional connectivity graph, different metrics such as Con- ditional Shannon Entropy, Mutual Information [32], Directed Information [23], or Graphical Directed Information [34] can be chosen. This preference would, in general, result in a weighted directed graph F(t). However, the experiments presented in Section 5 are confined to the metric given by (1), which leads to a symmetric graph weight matrix F(t). One thing that must be considered as a result of using different similarity metrics is the scaling of risks. Having un- bounded values in the entries will greatly affect the risk estimation step, Section 4.2, thus we highly recommend normalizing the functional connectivity graph in one way or another. On top of the normalized functional connectivity graph F(t), an additional mechanism to control the scaling of risks is designed in this work which is discussed in Section 4.2.2. 4.1.3. Forget Factor In practice, it is desired for calculated functional connectivity graph F(t) to have a “memory” such that the current connectivity graph carries over some of the relationships captured in previous time windows. This memory mechanism is modeled in the proposed work by (2) as: F(t) s = (1 −ρf)F(t−τ) s + ρfF(t) (2) Here, ρf is referred to as the forget factor, and it controls the contribution of the past edge weight on the current functional connectivity graph. The value of ρf is experimentally determined by validation on the training part of the dataset. The graph F(t) s is referred to as the smoothed graph since it will change less dramatically with time and, it can be used in place of F(t) from Section 4.1.4 and onwards. 4.1.4. Node Partitioning Occasionally, the calculated functional connectivity graph having thousands of entities will be sparse due to the local activity of entities. In those cases, it is much more desirable to break the problem into smaller subproblems by isolating functionally independent groups of entities via node partitioning and treating them independently for risk calculation (Figure 5). In practice, the separated entities will have small but non-zero edge weights between them. The node partitioning approximation essentially discards these inter-group edges, which are lost information. In order to reduce the approximation error, the node partitioning objective has been set to minimize the sum of the weights of the discarded edges, known as the “Ratio Cut” problem [12]. 12 Figure 5: Entity groups detected via spectral partitioning algorithm. Left: The matrix repre- sentation of the Functional connectivity graph F(t) for the whole network where entities are enumerated on both axes. The (i, j)th entry, or F (.) ij , is the weight quantifying how much entity i influences entity j. Right: A sub-network of interest. Risk estimation is solved inde- pendently on the detected entity groups. For the proposed method, the spectral partitioning algorithm has been used as the preferred partitioning method, which solves the relaxed ratio cut problem where the sum of inter-group edges is minimized with a penalty against smaller groups [12]. The partitioning can be applied until the entity groups are of the desired size, e.g., small enough to be processed in real-time. However, it must be noted that this is still an approximation, and each additional partitioning will increase the approximation error. Ultimately, spectral partitioning suggests a set of entities that can be studied independently with minimal error, which means that the risk prediction problem can be broken down into smaller, much more manageable problems in which the entities are well-connected. 4.2. Risk Propagation Model The underlying assumption for the proposed risk propagation model is a lin- ear model concerning how the risks propagate throughout the network. Suppose we have the risk estimates for each entity in the network at time t represented by a column vector xt ∈Rn where n is the number of entities. The risk propa- gation model assumed here can be stated as “the increase in the risk of a given entity A, is proportional to the risks of the entities that influence A and to the extent they influence A”. In other words, if A is clearly associated with a high-risk entity, we expect A’s risk to increase accordingly. This idea is summarized precisely as the set of linear equations given by (3), and it is illustrated in Figure 6. xt+τ = F(t)xt (3) 13 Figure 6: Risk Propagation Illustration for the Network Risk Estimation system. Entity A’s risk, which is an entry in risk vector xt, at the next time step is its previous risk plus the weighted sum of its neighbors’ risks weighted by the edge weights given by functional connec- tivity graph F(t). This risk propagation idea specifies the temporal and spatial dynamics of the risk. Here xt is the current risk estimates for the whole network at time t, F(t) is the graph calculated from connections in time interval [t, t + τ) and xt+τ is predicted risks at time t + τ. Another interpretation of (3) is a diffusion process on the weighted graph F(t) where the risks are diffused through the edges in accordance with the edge weights. Ultimately, the risk propagation idea summarized by (3) states the temporal dynamics and spatial relationships of the entity risks, i.e., how the risks evolve in the network over time. To give an example of the risk propagation model and the notion of entity risks, consider the threat of malicious-software/virus for a cyber network. The entity risks, in this case, can be the expected cost of a given entity being com- promised by the virus in dollar amounts. Antivirus countermeasures are able to tell us about the likelihood of certain entities being compromised, and con- sequently the associated risk, but this is not the case for the whole network. Our intuition about how the virus advances among entities is essentially sum- marized by the saying “Tell me who your friends are, and I’ll tell you who you are”, which constitutes the risk propagation model. Accordingly, if we have an estimate of the risk distribution for every entity in the network at some point in time, then we can have an educated guess about the risk distribution for the very next time step. This insight about the risks is not covered by the antivirus countermeasures, and it has to do with the observed behavior of entities. 4.2.1. Optimal Linear Risk Estimator Using the risk propagation model given in (3), one can keep predicting the risks given the connections and initial estimate. Even though this estimate carries the intuitive idea that entities influenced by risky entities should become riskier, the risk estimates are prone to errors. As an example, a small error 14 in the initial risk estimate and an error in the estimation of the relationship graph will lead to increasing discrepancies between the actual risks and the risk estimates over time. For this reason, the risk estimates obtained by (3) are refined with the incoming risk measurements in minimum mean squared error sense, where the measurements are referred to collectively as zt. The resulting estimation process is also known as the discrete Kalman Filter [30]. Integration of this probabilistic framework into the risk estimation problem is crucial since it not only gives the optimal risk estimates according to the assumed model but the uncertainties of those estimates as well, in the form of error covariance matrix Pt|t. Based on (3), a linear probabilistic model is assumed for the entity risks xt. A portion of the entities are risk-measured at time instance t, represented by zt. System and Measurement Model: xt+τ = F(t)xt + wt zt = Htxt + vt (4) Here, xt ∈Rn is the actual risks at the beginning of time t, wt ∼N(0, Qt) is the system process noise which is independently normal distributed with 0 mean and diagonal covariance matrix Qt, vt ∼N(0, Rt) is the independently normal distributed measurement noise, zt ∈Rm is the risk measurements and Ht ∈{0, 1}m×n is the matrix that selects entities that are measured at time t. Essentially, each row of Ht and zt corresponds to a risk measurement in the network. zt contains the measured risk value, the respective row of Ht has a 1 in the position of the measured entity, and the rest of the entries are 0. xt represents risk values of all entities in the network, which is the value desired to be estimated, whereas zt are the noisy risk measurements from a usually small number of entities. In Figure 2, zt corresponds to risk measurements of red and green entities, and xt represent the risks of every entity; red, green, gray and blue combined. The estimate risk distribution is described by the mean of the estimate ˆxt|t = E[xt|zt 0] and the error covariance matrix Pt|t = E  xt −ˆxt|t  xt −ˆxt|t T |zt 0  where E[.] is the expected value operator and zt 0 = {z0, ..., zt} are all the risk measurements up to time t. Assuming the model in (4) and an initial guess about the risk distribution, the linear optimal risk estimator is given recursively by (5) and (6), which is derived in Appendix A. Predict: ˆxt+τ|t = F(t)ˆxt|t Pt+τ|t = F(t)Pt|tF(t)T + Qt (5) 15 Update: St+τ = Ht+τPt+τ|tHT t+τ + Rt+τ K∗ t+τ = Pt+τ|tHT t+τS−1 t+τ ˆxt+τ|t+τ = ˆxt+τ|t + K∗ t+τ(zt+τ −Ht+τˆxt+τ|t) Pt+τ|t+τ = Pt+τ|t −K∗ t+τSt+τK∗ t+τ T (6) Risk distribution described by ˆxt|t and Pt|t is the best linear risk estimate, in minimum mean squared error (MMSE) sense, in the presence of risk mea- surements [5]. Initial risk estimate need not be exact and can be guessed, such as uninformative uniform mean ˆx0|0 = 1 and process noise for error covariance P0|0 = Q0. The Kalman Filter given by (5) & (6) guarantees that the estima- tion error will converge to zero in the case of fixed system parameters F, H, Q and R as long as they are accurate. If no measurement is made at a time step, then only the predict step is applied and a posteriori estimate becomes the same as a priori estimate, ˆxt+τ|t+τ = ˆxt+τ|t and Pt+τ|t+τ = Pt+τ|t. 4.2.2. Relief Factor The risk estimates given by (6) tell us about the risk distribution in the net- work as a result of (i) the risk propagation model and (ii) risk measurements. Although the relative risks of entities are the more interesting aspect, without proper scaling, the risk estimates ˆxt|t are unbounded. This happens when the functional connectivity graph F(t) has eigenvalues greater than 1. From risk es- timation point of view, this is an undesired effect since an entity left alone should not have unbounded risks when no additional measurements are provided. Con- sequently, this desired property is added to the estimation scheme by scaling the posterior estimates ˆxt+τ|t+τ and Pt+τ|t+τ with what’s here referred as the relief factor ρr which acts as a design parameter of the risk estimation system. ˆx′ t+τ|t+τ = (1 −ρr)ˆxt+τ|t+τ P′ t+τ|t+τ = (1 −ρr)2Pt+τ|t+τ (7) The relief factor essentially controls the rate at which the risks of entities degrade when left unobserved. The estimates ˆx′ t+τ|t+τ and P′ t+τ|t+τ give the risk estimates accounted for the scaling effect of functional connectivity graph, and they can now be readily used for decision making concerning risks. As a rule of thumb, the value ρ∗ r = 1 −1/λmax will theoretically ascertain that risks stay bounded where λmax is the largest eigenvalue of F(t). The larger the value of ρr, the faster the risk estimates will diminish. The value of the relief factor can be adjusted just like any other hyper-parameter to meet the desired risk levels prior to testing. If no observations, zt, are provided, relative values of entity risks are conserved regardless of the value of the relief factor ρr. 16 4.3. Real Time Operation A profound advantage of risk estimation over risk measurement is that es- timation can be done as the network is observed, whereas measurements are much less frequent. In this section, the flowchart of the real-time operation of the proposed risk estimation system is outlined. First, in order to reduce the possible computational overhead due to the size of the network, past representative flow data of the network is processed for the identification of related entity groups. The entity signals are formed as in Section 4.1.1, and then the functional connectivity graph for the whole network of interest is calculated as in Section 4.1.2. Then, the functional connectiv- ity graph for the whole network is partitioned into non-overlapping groups of entities as described in Section 4.1.4, which defines the entity groups for the upcoming steps. This whole process is done offline as denoted by the top row of Figure 7. Once entity groups of desirable size are obtained, their flows are then pro- cessed similarly and current functional connectivity graphs for each cluster are calculated. Finally, for each entity cluster risk prediction and update according to the provided risk measurements are employed as in Section 4.2.1 indepen- dently and this latter process is illustrated as the bottom row of Figure 7. Figure 7: Flow chart for Real-Time Operation of NRE. The top row is done offline on a large set of past flows to infer entity communities. The bottom row computes the functional connectivity graph for the current time window and estimates the risks as flows occur. Related section numbers are given above each block. 5. Results and Discussion The proposed risk estimation system has been experimented on a public dataset and is presented in this section. Most public datasets contain flow information and, occasionally, part of the network topology. However, risk measurements are problem-specific, and they are not commonly measured in gathering a dataset. The dataset used for testing is the CIC-IDS-2017 dataset [28, 29], which emulates a real-life network with benign network traffic and multiple attacks over 5 days. The benign traffic of this dataset was generated by realistic user profiles, and the attacks included common intrusions that aim to exploit system vulnerabilities in order to gain leverage over the network for 17 malicious purposes [29]. This dataset has been used as the benchmark for testing new risk measurement methods [7, 9, 33] . Section 5.1 demonstrates the resulting risk estimates over time with synthetic risk measurements. In Section 5.2, an example of possible network management action with the proposed risk estimates is illustrated. In Section 5.3, the ef- fectiveness of the proposed risk estimates is compared to a risk measurement alternative, and finally, in Section 5.4, a running time analysis of the proposed system is presented. 5.1. Risk Estimates Over Time Monday Session of the CIC-IDS-2017 dataset contains benign flows produced by the inner network that consists of servers, firewall, routers, switches, and users [29]. This session is used for illustrating the risk estimation procedure since it resembles common network connection data, and artificial measurements based on the provided network topology were added to analyze the results of the proposed risk estimation method. In this part, the risk estimates for the inner network [29] are calculated for a brief time interval under normal operation of this network. In this illustra- tion, the functional connectivity graph F(t) is computed from the flows that are comprised of benign emulated user activity, and it is held fixed during the risk estimation process for simplicity. Low uncertainty risk measurement of high-risk value is defined on the web server 192.168.10.50, indexed as entity 1, at time instance t0 = 90s, and the relief factor is set slightly below the rule of thumb defined in Section 4.2.2. Snapshots of the calculated mean of relative risk es- timates ˆxt|t and their respective covariance matrices Pt|t are given in Figure 8b. Initially, the relative risk estimates were set to independent identically nor- mal distribution N(c1, σ2I) with low risk mean c for each entity due to the lack of prior information about entity risks σ2 being their variance. Single risk measurement was done at time instance t0 = 90s on entity 1 whose effect can be seen from 8b as high relative mean risk value for entity 1 and low variance, the (1,1) entry of risk the covariance matrix Pt|t. After some time, the relative risk distribution converged to a stationary state given by the dominant eigen- vector of the functional connectivity graph F(t) since risk estimation without measurements simplifies to consecutive multiplication by the functional con- nectivity graph F(t) that is also fixed. In this state, entity 0 with IP address 192.168.10.3, which turns out to be the DNS server in this network topology [29], ends up having the highest risk due to its higher connectivity with other entities as seen from the functional connectivity graph F(t) on Figure 8a. It is fair to say entity 0 has become the risk sink in this sub-network, which is along with our risk propagation intuition (3) since it is influenced by many entities and risk estimation is dominated by the prediction step (5) as opposed to the measurements. The variances of risk estimates, the diagonal values of the 18 Figure 8: Risk Estimates over time for the Network Risk Estimation system. (a) Functional Connectivity Graph F(t) that is calculated from the flows of usual activity for this network and is held fixed during risk estimation. (b) Mean of risk estimates ˆxt|t and covariance matrix Pt|t at the start of each synchronization time window. Low variance risk measurement is provided on entity one at time t0 = 90s, which appears as the small value in the diagonal of the risk estimate covariance matrix Pt|t. Over time, the mean of the risk estimate ˆxt|t converges to a state dictated by the functional connectivity graph F(t). covariance matrix Pt|t, in general increase over time due to successive prediction, and the only mechanisms that reduce these variances are the introduction of risk measurements or the risk relief controlled by the relief factor where both were present in this example. All in all, probabilistic risk distributions described by ˆxt|t and Pt|t carry all the information necessary to make decisions in this example since the prior risk distribution was specified as a Gaussian distribution. In the most general case, only the mean and covariance matrix of the prior risk distribution still needs to be provided to the proposed system, which can be chosen as a uniform mean with some variance as in this example if no information is available regarding the prior risk distribution. Either way, the risk estimates are optimal among all linear estimators given the risk propagation model (4). As an example of utilization of these risk estimates in network management, ˆxt|t can be used to spot the highest risk entity with the respective confidence given by Pt|t. Alternatively, as illustrated in Section 5.2, routing on this network can be designed to minimize over estimated risks. 5.2. Simple Safe Routing Another benefit of the proposed work NRE is that since it is a quantitative risk assessment method, decision-making and management of the network is straightforward after obtaining the risk estimates. One example is the “safe routing” design, which is to pick the route for packets to traverse in the network when any two entities are set to communicate. This section provides a simple safe-routing application by finding the best route for a pair of entities based on 19 Figure 9: A solved case of simple safe routing for the insider network of CIC-IDS-2017 [29]. Entities, with unique identifiers beneath, are sorted horizontally according to their min-max path’s distance, called path risk. Node colors color-code the mean entity risks, and edges indicate the network topology or available paths. The green path is the min-max risk path between the source entity and the destination, and the red path is not since 192.168.10.50’s risk is higher than every other entity in the green path. a security measure of paths in the network topology and the proposed entity risk estimates. It is assumed that the underlying network topology is known; that is, for each entity, the entities that can be reached are given. Let the mean risk estimates at the current time be estimated. Then, intuitively, a user in the network will desire to avoid high-risk entities and prefer low-risk entities to route the desired packets over, as illustrated in Figure 2. Given the risk estimates, this objective can be formalized as minimizing a security loss over the available paths in the network topology, referred to as the path risk. Different security losses such as the average mean risk of entities along the path are reasonable, and the one that is chosen in this example is maximum mean risk of entities along the path. For this choice, the packets will be routed with the set of entities in the network for which all the mean risks are below a certain level, which is made as small as possible by the path choice. This path will be referred to as the min-max path. For the sub-network in Section 5.1, excluding the DNS server, the min-max path between a source and every other entity is computed, and the result is depicted in Figure 9. Here, the leftmost entity 192.168.10.14 is the source from which all min-max paths are calculated. Every other entity is arranged according to their min-max path’s distance from the source, the path risks and their identifier IP addresses beneath them. If the packets are desired to be sent to the entity 192.168.10.5, 20 then the green path in Figure 9 is the path with the least maximum risk, which is the choice for simple safe routing problem. In the identification of safe paths, only the mean of the risk estimates ˆxt|t was used, and thus it was called the “simple safe routing”. In a more general setting, the risk distribution described by the error covariance matrix Pt|t can be utilized, and also, the objective loss that is to be minimized can be designed as a combination of path risk and round trip time signifying a trade-off between security and packet delay. Ultimately, this example illustrates a network management application of the proposed risk estimates, highlighting a way to add “security” aspect to a network function. With this addition, network decisions can be judged by previously unknown risks, and utility vs. security allotment can be quantitatively assessed. In the case of routing, in some cases, it might be desirable to sacrifice slightly from the round trip delay to keep a path’s risk level lower. Having risk estimates described by ˆxt|t and Pt|t enables this design. 5.3. Proof of Concept The method outlined in Section 4 can be used to estimate the risks of in- dividual entities that are not necessarily risk-measurable but are observable in terms of the connection data. A fair question is whether these risk estimates convey substantial information about the network state when the risk measure- ments are limited. In this section, the utility of these estimates is assessed by an experiment designed on the same labeled dataset CIC-IDS-2017 [28]. In par- ticular, Tuesday session has been selected for this experiment since it contained the most different variety of threats. The experiment is a binary classification problem of identifying the state of the network, whether malicious activity is present or not, labeled as “ATTACK” or “BENIGN” accordingly. The risk estimates obtained by the proposed method on the identified relevant part of the network have been compared to the limited risk measurements from a trained model on the flows of the insider network [29] for this binary classification problem. 5.3.1. Experimental Setup For this experiment, the dataset is divided into chunks of flows consisting of consecutive flows in designated time windows for calculating the functional connectivity graph, F(t), and the state of the network is assigned either as “ATTACK” if any of the flows are part of an attack or as “BENIGN” otherwise. The proposed risk estimation method is then employed to estimate the risks in the network without any measurements provided. The network is partitioned according to the entity behaviors in the attack-free Monday session flows of the dataset. Specifically, the node partitioning, as described in Section 4.1.4, is performed on these flows, which led to the discovery of 141 entities relevant to the insider network. These entities are then set as the sub-network for the risk estimation process on the Tuesday session. 21 The chunks of Tuesday session are split into training, validation, and test sets for which the mean of entity-level risks are calculated for a particular connec- tion parameter, as detailed in Section 4, without any measurements provided. Then the risk estimate vector ˆxt|t ∈R141 is used as a sample in 141-dimensional feature space to train binary classifiers using three different generic machine learning models of various complexity: Naive Bayes, Decision Trees, and Ran- dom Forest [22]. The experimental “Receiver Operating Characteristics” (ROC) curves of these classifiers are then obtained on the validation set, and the hyper- parameters (i) synchronization window size δ, (ii) the window size τ for graph calculation, and (iii) the forget factor ρf are tuned via maximizing the “area under the curve (AUC)” performance metric, for the best classifier among the aforementioned models, on the validation set. The relief factor is not considered in tuning for this experiment since it has no effect on classification performance but rather is just a scaling factor of the features due to the absence of risk measurements. After a grid search on the space of potential hyper-parameters, the combination (δ, τ, ρf) = (1.2s, 90s, 0.5) is picked. For these hyperparame- ters, an instance of ROC curves obtained for the proposed method (NRE) with “Number of Packets Received” connection parameter is given in Figure 11a. The tuned hyper-parameters are then used on the previously separated test ses- sion for the goodness assessment of the proposed risk estimates in network state inference. The proposed method is compared to a representative of previous works in risk measurement, which was restricted to measurable entities. The previous work on network state inference considers various flow attributes and builds a model from these attributes for estimating the risk of the network as a whole [18, 33, 35]. In this experiment, this method is referred to as the “Flow-Based Network State Inference” method (FBNSI ) due to its similarity with the flow- based risk measurement methods in Intrusion Detection literature [31]. To cap- ture the limitations of the sole risk measurement methods in practice, flows of the FBNSI are constrained to the flows of the insider network in this experiment. This sub-network contained only 13 entities, including the DNS server [29]. The insider network is the local network that was the target of the emulated attacks in forming this dataset [29]. Previous work in risk measurement would extract information such as av- erage round trip delay, transmission rate, and response time [18] from flows to predict the risk of the whole network via predicting the likelihood of an attack. In contrast, the proposed system is designed to make use of per-entity attributes to estimate entity-level risks, which then tell about the network state. Conse- quently, in this experiment, the risk measurement method FBNSI is designed to make inferences, BENIGN or ATTACK, about the state of the network using the same time windows as the proposed method. In order to keep the informa- tion used about the flows same, the flow attributes are restricted to the same connection parameter used by the proposed method, e.g., the number of packets in forward and backward direction flow attributes are selected for the “Number of Packets Received” connection parameter. As a result, the feature space for 22 the risk measurement method FBNSI is either one or two-dimensional, whose features correspond to the flow attribute used to generate the risk estimates by the proposed method. Figure 10: Flowchart of the Flow-Based Network State Inference (FBNSI ) method. Chunks of flows for the time window [t, t+τ) are fed into a Machine Learning model trained on individual flows. The decisions on the individual flows are aggregated by counting the percentage of flows labeled as attack flow, which determines the network state for the time window. Decisions are made about the network state with FBNSI method by first training the same classifiers on individual flows, which classify the individual flows themselves as either benign flow or attack flow. For the time window of flows over which the network state is sought, the flow-level decisions are aggregated by simply counting the attack flow percentage in the chunk. This percentage is assigned as the likelihood of the network state being ATTACK, which is used in inferring the state of the network. The whole network state inference process is summarized in Figure 10. The only hyperparameter of this method is the time window size τ for net- work state estimation, which is picked as τ = 180s for testing after a simi- lar tuning process on the training and validation set. The experimental ROC curves for the FBNSI method are obtained via thresholding the likelihood of network state on the validation set, which is shown in Figure 11b for “Number of Packets Received” connection parameter. For testing, the operating points for both methods are picked from the inferred curves as the points maximizing balanced accuracy classification metric, which corresponds to the 45◦tangent to the ROC curves. Balanced accuracy has been chosen as the main classification performance metric since it accounts for the uneven distribution of classes, i.e., network states. Finally, both methods are tested on the unseen test set from the Thursday session of the dataset, and only the peak balanced accuracy among the three classifiers used is reported for clarity. The threats for this day consisted of web attacks such as Brute Force, XSS, and Sql Injection [29]. The testing was done using all available connection parameters except “Activation” since it is not available for FBNSI. The window size τ was picked as τ = 180s in order to compare two methods which was the optimal window size for FBNSI but sub- optimal for NRE. Figure 12 shows these peak balanced accuracy across different connection parameters, which reflect how the model would do if both methods 23 Figure 11: Comparison of ROC curves on validation set for the “Number of Packets Received” connection parameter. (a) Proposed Method NRE: Network state can be inferred with as good as 0.95 AUC (Area Under the Curve) when risks are estimated for the related part of the network. (b) Risk Measurement Method FBNSI, based on [18, 33, 35]: Network state inference is possible for the measurable part of the network but with lower performance with the best AUC being 0.77. modeled different aspects of flows. 5.3.2. Analysis The scatter points in Figure 11 are the experimental operating points yielded by thresholding the likelihood of the positive class given by the two methods described. For visual interpretation, smooth non-linear curves have been fitted to the operating points obtained on the validation set by fitting a line to the logit transform of both coordinates. Inferred ROC curves show how these models will perform if more data from the same distribution were tested. For the test results, it is concluded from Figure 12 that not all aspects of connection data had substantial information about the network state for the risk measurement method FBNSI. As evident from the nature of the threats present in this session, some connection parameters, such as “Flow Duration” and “Port Number”, were sufficient in distinguishing the network state. However, connec- tion parameters such as “Active Time” were not informative. In other words, different connection parameters in this experiment represent varying degrees of risk measurement expressiveness, and the performance of the risk measurement paradigm depends on the amount of information the measurements have about the network state. In the case of limited risk measurements, the model does not provide valuable information about the network state. However, with the addition of entity identity and the propagation of the risk estimates to the rest of the network based on entity association, even the poor aspects of connection data were sufficient in inferring the network state, which is indicated as the consistently high peak balanced accuracy for NRE in Figure 12. In other words, judging the network state by its entity’s state and modeling their interactions as risk propagation have enhanced the visibility of the network in the case of poor risk measurements. 24 Figure 12: Comparison of purely risk measurement approach FBNSI and proposed risk estima- tion method NRE across different connection parameters in terms of peak balanced accuracy. When risk measurements are descriptive of the network (connection parameters towards the left), the risk measurement approach is viable. However, when risk measurements are limited, FBNSI is not descriptive of the network. The proposed risk estimation approach NRE is de- scriptive of network state regardless of the modeled aspect of flows with comparable network state inference performance. The experiment conducted on the CIC-IDS-2017 dataset indicated that the proposed entity risk estimation method is able to provide sufficient information needed for network state inference. Estimating the entity risks has made detect- ing abnormal network states easier, even if the available risk measurements were not substantial. The proposed risk estimates maintain the crucial information needed to make judgments about the network, such as intrusion detection, while carrying all the benefits of being a quantitative risk assessment tool so that it can readily be used in network management and decision-making. 5.4. Running Time Tests One of the main advantages of risk estimation over risk measurement is operating in time scales that the device network might change. For this reason, it is desirable for the risk estimation system to have low running time complexity. Accordingly, the running time of the proposed risk estimation method has been analyzed over various design parameters on the same Tuesday session of the CIC-IDS-2017 dataset [28]. In this analysis, only the running time of calculation of the functional connectivity graph F(t) using connection data is examined since the predict and update steps given by the Section 4.2.1 are just matrix multiplications that can be computed much faster than the aforementioned step. The experiments were conducted on Google Colaboratory environment [4] with CPU specifications being dual-core Intel(R) Xeon(R) CPU @ 2.20GHz. 25 (a) (b) Figure 13: (a) Simulation Time vs. Graph Window Size with 1s Synchronization Windows. Running is proportional to the window size that is used to calculate the functional connectivity graph. (b) Simulation time vs. Synchronization Window size with 500s Graph Time Windows. Running time is inversely proportional to the window size that is used to aggregate flows to form the synchronous signals. For both cases, the simulation time ∆ts ∝N where N = ⌊τ/δ⌋ and the dotted line highlights this trend of the mean. First, the running time per connection window was tested with respect to both time windows, the signal synchronization window size δ, and graph window size τ as defined in Section 4.1. If the number of samples used to calculate a sin- gle edge weight in this graph is denoted as N, then it follows that N = ⌊τ/δ⌋. A simple analysis of (1) shows that the running time complexity of the calculation of a single edge in the connectivity graph is O(N) for the Pearson correlation coefficient estimator, although it might be different for others estimators used to calculate the functional connectivity graph F(t). Figure 13 shows the sim- ulation time it took to calculate a single connectivity graph F(t) for different time window sizes where the simulated running times are the box-plot, and the expected run-time is the dashed line. The other parameter that crucially affects running time is the size of the network or the number of entities in the connectivity graph n. In calculating the graph F(t), each edge weight calculation is done separately, so the theoretical asymptotic behavior of the running time with respect to the size of the network is O(n2) where the experiment showed even a tighter bound of O(n1.81) given by Figure 14a. Finally, for a particular parameter collection (τ, δ, n) = (500s, 5s, 17) collec- tion of timestamps at the start of the graph window in the dataset td and the simulation times ts has been collected and is given in Figure 14b. This plot has an average slope of about 1/255, which indicates that 1 second of simulation time covers 255 seconds of flows in the dataset. The gain of 255 implies that real-time operation is possible for this parameter set. For the real-time operation, it should be noted that parameter selection will be the deterministic factor for this gain. For instance, O(n2) behavior in entity size implies that there will be a critical entity size n∗, with a simulation time to 26 (a) (b) Figure 14: (a) log Average running time vs. log Number of Entities in the network of interest. A dashed line with slope 1.81 is the line fitted to the tail of the running times obtained, which implies an experimental bound on running time of O(n1.81). (b) Collection of time instances that mark the start of functional connectivity graph estimation in the dataset, td, and the respective recorded simulation times, ts. The average slope of 1/255 indicates that 1 seconds of simulation time is able to cover 255 seconds of connection data, which is an indicator of real-time operability. recording time gain of 1, beyond which no real-time operation will be possible. This scaling issue can be controlled by limiting the sub-network sizes in the node partitioning step in Section 4.1.4. 6. Conclusion The risk measurement approach in cyber-network security is subject to loss in efficacy when the measurements are limited to a small subset of entities in the network and are coarse in time, both of which are common in practice. In this work, a risk estimation paradigm for cyber network security, NRE, is proposed as an alternative to existing risk measurement strategies. The proposed system NRE estimates the risks of entities based on their observed relationships in the connection data. For the case where risk measurements are available on some entities, the estimated risks are refined by the probabilistic framework using the optimal linear estimator. The end result of this system is the estimated risk distribution of the entities in terms of the mean estimate ˆxt|t and the respective error covariance matrix Pt|t which carry all the information needed for active network management. The proposed system is fully data-driven as it does not need continuous human intervention, and it is adaptive to dynamic network environments where entity behavior might change over time. The risk estimation process has been carried out on a public dataset. A direct network security management application of the proposed risk estimates called “simple safe routing” is illustrated on the same network topology. The proof of concept has been established on the same dataset, where it has been shown that, if needed, abnormal network states can be better inferred with the proposed method when the available risk measurements are limited. Finally, the 27 real-time applicability of the proposed method was tested, which suggested that the online operation is possible with an appropriate choice of design parameters. Appendix A. Derivation of Optimal Linear Risk Estimator In this section, a derivation of the optimal risk estimator is presented, assum- ing the risk propagation model given in (3). The result is the discrete Kalman Filter applied for the risk estimation problem. The system and measurement model is given in (4), which is based on (3) with the process and measurement noise modeled. The goal is to find the unbiased linear estimator with minimum mean square error (MMSE) for the model in (4) given the risk measurements up to the current time t. This is also the optimal estimator when risks xt are Gaussian. Let ˆxt|t be the best-unbiased estimate of the risks at time t in the MMSE sense. It can be easily shown that this best estimate, in the MMSE sense, is the conditional expectation of the risks conditioned on the measurements up to time t [5]: ˆxt|t = E[xt|zt 0]. (A.1) Here, zt 0 = {z0, ..., zt} is the collection of discrete risk measurements starting from time 0, which is the reference point in time when the first measurement was made. The risk estimate ˆxt|t then has the error covariance matrix Pt|t: Pt|t = E  xt −ˆxt|t  xt −ˆxt|t T |zt 0  (A.2) Let ˆxt+τ|t be the best estimator after a time window of length τ, given the measurements up to time t. Then similarly using system model in (4) it can be shown that [30], ˆxt+τ|t = F(t)ˆxt|t. (A.3) This estimator in (A.3) is also known as the a priori estimate since the current measurement zt+τ has not been accounted for yet. Similarly, the prior estimate covariance matrix can be calculated as [30]: Pt+τ|t = F(t)Pt|tF(t)T + Qt. (A.4) Equations (A.3) and (A.4) are known as the predict steps. In accounting for the effect of new observations about current risks, an unbiased linear estimator is sought, which can be shown to have the following form [5]: ˆxt+τ|t+τ = ˆxt+τ|t + Kt+τνt+τ νt+τ = zt+τ −Ht+τ ˆxt+τ|t (A.5) 28 Here, the variable νt+τ is referred to as innovation since it represents the difference between actual measurement zt+τ and the predicted measurement Ht+τ ˆxt+τ|t based on the knowledge up to time step t. Kt+τ is the gain matrix for innovation which controls the contribution of measurements versus the pre- vious estimate. (A.5) describes a set of linear estimators. As the final step, the value of the gain matrix is specified by the MMSE criteria: K∗ t+τ = arg min Kt+τ E[(xt+τ −xt+τ|t+τ)T (xt+τ −xt+τ|t+τ)|zt+τ 0 ] (A.6) Minimization has a closed-form solution which is known as the Kalman Gain [30]: K∗ t+τ = Pt+τ|tHT t+τS−1 t+τ St+τ = Ht+τPt+τ|tHT t+τ + Rt+τ (A.7) The matrix St+τ in (A.7) is the innovation variance and it can be shown that St+τ = E[νt+τνT t+τ]. Combining with (A.5) the error covariance matrix Pt+τ|t+τ of the a posteriori estimate ˆxt+τ|t+τ can be obtained [30]: Pt+τ|t+τ = Pt+τ|t −K∗ t+τSt+τK∗ t+τ T (A.8) Together (A.5), (A.7) and (A.8) are the update equations for the risk esti- mates. The derivation done here yields the best risk estimate, in the MMSE sense, among all linear estimators, and it can be shown that if xt is Gaussian distributed, this estimator is the best among all estimators, linear and non-linear included [5]. References [1] Olusola Akinrolabu, Jason RC Nurse, Andrew Martin, and Steve New. 2019. Cyber risk assessment in cloud provider environments: Current models and future needs. Computers & Security 87 (2019), 101600. https://doi.org/10.1016/j.cose.2019.101600 [2] Sameer Hasan Albakri, Bharanidharan Shanmugam, Ganthan Narayana Samy, Norbik Bashah Idris, and Azuan Ahmed. 2014. Security risk assess- ment framework for cloud computing environments. Security and Commu- nication Networks 7, 11 (2014), 2114–2124. [3] Terje Aven. 2016. Risk assessment and risk management: Review of recent advances on their foundation. European Journal of Operational Research 253, 1 (2016), 1–13. 29 [4] Ekaba Bisong. 2019. Building machine learning and deep learning models on google cloud platform: A comprehensive guide for beginners. Apress Berkeley, CA, Berkeley, CA. 59–64 pages. https://doi.org/10.1007/ 978-1-4842-4470-8 [5] Robert G. Brown and Patrickyc Hwang. 1992. Introduction to random signals and applied Kalman filtering. New York, John Wiley & Sons, Inc., 1992. 512, New York, NY. [6] S Sreenivasa Chakravarthia and Sakkaravarthi Ramanathanb. 2016. Moni- toring Cloud Services Exploitation using Heterogeneous Network Flowdata Analysis. International Journal of Control Theory and Applications 9, 51 (2016), 299–309. [7] Liyan Chang and Paula Branco. 2021. Graph-based Solutions with Resid- uals for Intrusion Detection: the Modified E-GraphSAGE and E-ResGAT Algorithms. arXiv:2111.13597 [cs.CR] https://arxiv.org/abs/2111. 13597 [8] Cisco. 2023. Cisco Secure Network Analytics (Stealth- watch) - Cisco Security Analytics [White paper]. https://www.cisco.com/c/en/us/products/collateral/ security/stealthwatch/white-paper-c11-740605.html https://www.cisco.com/c/en/us/products/collateral/security/stealthwatch/white- paper-c11-740605.html. [9] Luis Filipe Dias and Miguel Correia. 2020. Big data analytics for intru- sion detection: an overview. Handbook of Research on Machine and Deep Learning Applications for Cyber Security (2020), 292–316. [10] Daji Ergu, Gang Kou, Yong Shi, and Yu Shi. 2014. Analytic network process in risk assessment and decision analysis. Computers & Operations Research 42 (2014), 58–74. [11] Clark Glymour, Kun Zhang, and Peter Spirtes. 2019. Review of causal discovery methods based on graphical models. Frontiers in genetics 10 (2019), 524. [12] Lars Hagen and Andrew B Kahng. 1992. New spectral methods for ratio cut partitioning and clustering. IEEE transactions on computer-aided design of integrated circuits and systems 11, 9 (1992), 1074–1085. [13] Rick Hofstede, Pavel ˇCeleda, Brian Trammell, Idilio Drago, Ramin Sadre, Anna Sperotto, and Aiko Pras. 2014. Flow monitoring explained: From packet capture to data analysis with netflow and ipfix. IEEE Communica- tions Surveys & Tutorials 16, 4 (2014), 2037–2064. [14] Steve Horvath. 2011. Weighted network analysis: applications in genomics and systems biology. Springer Science & Business Media, Los Angeles, CA. 30 [15] International Organization for Standardization. 2018. ISO 31000: Risk Management - Guidelines. https://www.iso.org/obp/ui#iso:std:iso:31000:ed-2:v1:en. [16] Harjinder Singh Lallie, Kurt Debattista, and Jay Bal. 2020. A review of attack graph and attack tree visual syntax in cyber security. Computer Science Review 35 (2020), 100219. [17] Arash Habibi Lashkari, Gerard Draper Gil, Mohammad Saiful Islam Ma- mun, and Ali A. Ghorbani. 2017. Characterization of Tor Traffic using Time based Features. In Proceedings of the 3rd International Conference on Information Systems Security and Privacy - Volume 1: ICISSP,. IN- STICC, SciTePress, Porto, Portugal, 253–262. https://doi.org/10. 5220/0006105602530262 [18] Qianmu Li, Youhui Tian, Qiang Wu, Qi Cao, Haiyuan Shen, and Huaqiu Long. 2020. A cloud-fog-edge closed-loop feedback security risk prediction method. IEEE Access 8 (2020), 29004–29020. [19] David A Maluf, Raghuram S Sudhaakar, and Kim-Kwang Raymond Choo. 2018. Trust Erosion: Dealing with Unknown-Unknowns in Cloud Security. IEEE Cloud Computing 5, 4 (2018), 24–32. [20] Shishir Nagaraja. 2014. Botyacc: Unified p2p botnet detection using be- havioural analysis and graph analysis. In European Symposium on Research in Computer Security. Springer, Cham, 439–456. [21] Xinming Ou and Anoop Singhal. 2011. Quantitative security risk assess- ment of enterprise networks. Springer, New York, NY. [22] F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Passos, D. Cournapeau, M. Brucher, M. Perrot, and E. Duchesnay. 2011. Scikit-learn: Machine Learning in Python. Journal of Machine Learning Research 12 (2011), 2825–2830. [23] Christopher J Quinn, Todd P Coleman, Negar Kiyavash, and Nicholas G Hatsopoulos. 2011. Estimating the directed information to infer causal relationships in ensemble neural spike train recordings. Journal of compu- tational neuroscience 30, 1 (2011), 17–44. [24] Patricia AS Ralston, James H Graham, and Jefferey L Hieb. 2007. Cyber security risk assessment for SCADA and DCS networks. ISA transactions 46, 4 (2007), 583–594. [25] Alex Ramos, Marcella Lazar, Raimir Holanda Filho, and Joel JPC Ro- drigues. 2017. Model-based quantitative network security metrics: A sur- vey. IEEE Communications Surveys & Tutorials 19, 4 (2017), 2704–2734. 31 [26] Prasad Saripalli and Ben Walters. 2010. Quirc: A quantitative impact and risk assessment framework for cloud security. In 2010 IEEE 3rd interna- tional conference on cloud computing. IEEE, Miami, FL, 280–288. [27] Alireza Shameli Sendi and Mohamed Cheriet. 2014. Cloud Computing: A Risk Assessment Model. In 2014 IEEE International Conference on Cloud Engineering. IEEE, Boston, MA, 147–152. https://doi.org/10.1109/ IC2E.2014.17 [28] Iman Sharafaldin, Arash Habibi Lashkari, and Ali Ghorbani. 2018. Intrusion detection evaluation dataset (CIC-IDS2017) [Dataset]. http://www.unb.ca/cic/datasets/IDS2017.html. [29] Iman Sharafaldin, Arash Habibi Lashkari, and Ali Ghorbani. 2018. To- ward Generating a New Intrusion Detection Dataset and Intrusion Traffic Characterization. In 4th International Conference on Information Systems Security and Privacy (ICISSP 2018). ICISSP, Madeira, Portugal, 108–116. https://doi.org/10.5220/0006639801080116 [30] Dan Simon. 2006. Optimal state estimation: Kalman, H infinity, and non- linear approaches. John Wiley & Sons, Hoboken, NJ. [31] Anna Sperotto, Gregor Schaffrath, Ramin Sadre, Cristian Morariu, Aiko Pras, and Burkhard Stiller. 2010. An overview of IP flow-based intrusion detection. IEEE communications surveys & tutorials 12, 3 (2010), 343– 356. [32] Zhe Wang, Ahmed Alahmadi, David Zhu, and Tongtong Li. 2015. Brain functional connectivity analysis using mutual information. In 2015 IEEE Global Conference on Signal and Information Processing (GlobalSIP). IEEE, Orlando, FL, 542–546. [33] Junrui Wu, Wenyong Wang, Lisheng Huang, and Fengjun Zhang. 2022. Intrusion detection technique based on flow aggregation and latent semantic analysis. Applied Soft Computing 127 (2022), 109375. [34] Joseph Young, Curtis L Neveu, John H Byrne, and Behnaam Aazhang. 2021. Inferring functional connectivity through graphical directed informa- tion. Journal of Neural Engineering 18, 4 (2021), 046019. [35] Chao Zhou, Yajuan Guo, Wei Huang, Jing Guo, and Daohua Zhu. 2016. Network Security Risk Prediction Based on Time-Varying Markov Model. In Proceedings of the 2016 4th International Conference on Mechanical Materials and Manufacturing Engineering. Atlantis Press, Wuhan, China, 212–215. https://doi.org/10.2991/mmme-16.2016.49 32