DARKMENTION: A Deployed System to Predict Enterprise-Targeted External Cyberattacks Mohammed Almukaynizi1, Ericsson Marin1, Eric Nunes1, Paulo Shakarian1,2 Gerardo I. Simari3,1, Dipsy Kapoor4, Timothy Siedlecki5 1Arizona State University 2Cyber Reconnaissance, Inc. 3Department of Computer Science and Engineering, Universidad Nacional del Sur (UNS) Institute for C.S. and Eng. (CONICET–UNS) 4University of Southern California 5Lockheed Martin Advanced Technology Laboratories {malmukay, esmarin, enunes1, shak}@asu.edu gis@cs.uns.edu.ar, dipsy@isi.edu, timothy.siedlecki@lmco.com Abstract—Recent incidents of data breaches call for organi- zations to proactively identify cyber attacks on their systems. Darkweb/Deepweb (D2web) forums and marketplaces provide environments where hackers anonymously discuss existing vul- nerabilities and commercialize malicious software to exploit those vulnerabilities. These platforms offer security practitioners a threat intelligence environment that allows to mine for patterns related to organization-targeted cyber attacks. In this paper, we describe a system (called DARKMENTION) that learns associa- tion rules correlating indicators of attacks from D2web to real- world cyber incidents. Using the learned rules, DARKMENTION generates and submits warnings to a Security Operations Center (SOC) prior to attacks. Our goal was to design a system that automatically generates enterprise-targeted warnings that are timely, actionable, accurate, and transparent. We show that DARKMENTION meets our goal. In particular, we show that it outperforms baseline systems that attempt to generate warnings of cyber attacks related to two enterprises with an average increase in F1 score of about 45% and 57%. Additionally, DARKMENTION was deployed as part of a larger system that is built under a contract with the IARPA Cyber-attack Automated Unconventional Sensor Environment (CAUSE) program. It is actively producing warnings that precede attacks by an average of 3 days. I. INTRODUCTION With the widespread use of technology, cyber-security has become a concern for both commercial organizations and governments. With the recent incidents of data breaches at Equifax, Verizon, Gmail and others1, organizations are looking at methods to proactively identify if they will be target of future attacks. A 2017 Verizon investigation report stated that 75% of breaches were perpetrated by outsiders exploiting known vulnerabilities [1]. Monitoring the vulnerabilities that are of interest to malicious threat actors from the discussions on Darkweb/Deepweb (D2web) hacking sites is a key aspect of predicting cyber-attacks [2]. In this paper, we describe DARKMENTION, a system that identiﬁes indicators of risks from unconventional sources of 1https://www.identityforce.com/blog/2017-data-breaches threat intelligence (D2web), monitors those sources in real- time to reason about the likelihood of future threats, generates warnings, and submits them to the Security Operations Center. We use concepts from causal reasoning [3], [4] and logic programming (in particular, the concepts of Point Frequent Function (pfr) from APT-logic [5], [6], [7]) to learn asso- ciation rules. An example of the rules we sought to learn is “if certain D2web activity is observed in a given time- point, then there will be an x number of attacks of type y, targeting organization o in exactly ∆t time-points, with probability p”. Our data is obtained from a commercially available API, maintained by a cyber-threat intelligence ﬁrm (called CYR3CON2), and from over 500 historical records of real-world targeted cyber incidents. Those incidents are recorded from the logs of two large enterprises participating to the IARPA Cyber-attack Automated Unconventional Sensor Environment (CAUSE) program3. Throughout the paper, we illustrate the viability of DARK- MENTION as a tool that addresses problems directly related to situational awareness, resource allocation, and countermeasure prioritization. In particular, we show that DARKMENTION produces warnings that are, ●timely: indicates the exact time-point in which a predicted attack will occur, ●actionable: provides metadata/warning details, i.e., the target enterprise, type of attack, volume, and the software vulnerabilities/threat actor identiﬁed from the D2web discussions, ●accurate: predicted unseen real-world attacks with an average increase in F1 of over 45% for one enterprise and 57% for the other, and ●transparent: allows analysts to easily trace the warnings back to the rules that were triggered, discussions that ﬁred the rules, etc. 2https://cyr3con.ai 3https://www.iarpa.gov/index.php/research-programs/cause 1 arXiv:1810.12492v1 [cs.CR] 30 Oct 2018 II. DATASET DESCRIPTION A. D2web Crawling Infrastructure Darkweb refers to the portion of the internet that is not indexed by search engines and cannot be accessed by standard browsers. Specialized browsers like Tor4 are required to access darkweb sites. We retrieve information from both market- places: where users advertise to sell information regarding vulnerabilities or exploits, and forums: that provide discussions on discovered vulnerabilities among others. We summarize the D2web crawling infrastructure that CYR3CON maintains—originally introduced in [8]. Cus- tomized lightweight crawlers and parsers were built for each site to collect and extract data. At the time of writing this paper, data is collected from more than 400 platforms (fo- rums and marketplaces). To ensure collection of cybersecurity relevant data, machine learning models are used to ﬁlter data related to drugs, weapons and other discussions irrelevant to cybersecurity. B. Data Pre-processing CVE-CPE mapping: Common Vulnerability Enumeration (CVE) is a unique identiﬁer assigned to each software vul- nerability reported in the National Vulnerability Database (NVD [9]). Common Platform Enumeration (CPE) is a list of software/hardware products that are vulnerable to a given CVE. CPE data can be obtained from the NVD. We query the database using API calls to look for postings with software vulnerability mentions (in terms of CVE number). Regular expressions5 are used to identify CVE mentions. We map each CVE to pre-identiﬁed groups of CPEs6 and nation-state threat actors who are known to leverage that CVE as part of their attack tactics7. Perhaps among the well-known threat actors is the North Korean group HIDDEN COBRA, which was recently identiﬁed to account for an increasing number of cyberattacks to US targets8. These CPE and nation-state actor mappings are used as pre-conditions during the rule-learning phase that is discussed in Sectiona III and IV. C. Enterprise-Relevant External Threats To construct rules and evaluate the performance of the learned model, we use data from historical records of attack attempts that are recorded from the logs of two enterprises participating in the IARPA CAUSE program9. One of the two enterprises is a defense industrial base (referred to Armstrong) while the other is a ﬁnancial services organization (referred to 4See the Tor Project’s ofﬁcial website (https://www.torproject.org/). 5https://cve.mitre.org/cve/identiﬁers/syntaxchange.html 6We cluster CPEs together based on common vendors/products. We iden- tiﬁed over 100 groups of CPEs, e.g., Microsoft-Ofﬁce, Apache-Tomcat, and Intel. However, only 33 were used as preconditions in the rules. 7We have encoded a list of threat actors along with vulnerabilities they favor by manually analyzing cyberthreat reports that were recently published by cy- bersecurity companies, e.g., https://media.kaspersky.com/en/business-security/ enterprise/KL Report Exploits in 2016 ﬁnal.pdf. 8https://www.us-cert.gov/ncas/alerts/TA17-164A 9https://www.iarpa.gov/index.php/research-programs/cause. Dexter). The database is distributed to the performers partic- ipating in a contest led by IARPA in increments, once every few months. Each data point is a record of a detected deliberate malicious attempt to gain unauthorized access, alter or destroy data, or interrupt services or resources in the environment of the participating organizations. Those malicious attempts were detected in uncontrolled environment, and by different security defense commercial products such as anti-virus, intrusion detection systems, and hardware controls. Each ground truth (GT) record includes: ID, Format Version, Reported Time, Occurrence Time, Event Type, and Target Industry10. The types of attacks included in the GT dataset are: ●Malicious Email (M-E). A malicious attempt is identi- ﬁed as a Malicious Email event if an email is received by the organization, and it either contains a malicious email attachment, or a link (embedded URL or IP address) to a known malicious destination. ●Malicious Destination (M-D). A malicious attempt is identiﬁed as a visit to a Malicious Destination if the visited URL or IP address hosts malicious content. ●Endpoint Malware (E-M). A Malware on Endpoint event is identiﬁed if malware is discovered on an endpoint device. This includes, but not limited to, ransomware, spyware, and adware. Other events related to insider threats are out of the scope of the current phase of the deployed system. A summary of the time periods and the number of records for each attack type is provided in Section V-C. III. DEPLOYED SYSTEM In this section we provide an overview of DARKMEN- TION. Figure 1 provides a graphical illustration of the sys- tem’s workﬂow. Our system comprises three main compo- nents, each was designed to serve a set of tasks. There are three reasons for having this particular design: (1) there are other base models that were implemented using the same GT data, (2) this design would result in minimal changes in the roles of the subteams/members, and (3) model ensembles can improve the overall predictions of the model generated warnings [10]. Rule Learning APT Rules CYR3CON API (D2web) Ground Truth (Armstrong, Dexter) Generate Warnings D2web streaming data Consolidation Warnings Base Models Warning Submission if if then then Security Operations Center Figure 1: The Deployed System. 10We intentionally skip some details about other ﬁelds of the GT records due to the limitation in space and irrelevance to the scope of this paper. 2 Rule learning: The ﬁrst component is responsible for learning rules, i.e., APT rules with pfr function [5], [6], [7]. The inputs to the rule learner are: (1) the CPE-groups/actors that were identiﬁed from the D2web discussions and the time-point in which they are mentioned, and (2) the GT events with their types and time-points in which they were observed. The learner follows the technical approach discussed in Section IV to generate APT rules. The output of this component is a set of APT rules that are determined to be useful, i.e., exceeding some thresholds on probability of occurrence and some support count (frequency with which a rule is satisﬁed in the historical data). Such capability aids in producing accurate and timely warnings. Figure 2 shows the percentage increase in the likelihood of occurrence of attack events per days following D2web discussions for the rules that were identiﬁed as useful. We note that the reported records of Malicious Destination for Dexter only cover a time period that ends before the testing time period starts. Therefore, no rules were produced for Malicious Destination. Additionally, the system did not learn useful rules relating to Armstrong’s Malicious Destination events when ∆t is 1, 2, or 5. 0 1 2 3 4 5 6 7 t malicious-email malicious-destination endpoint-malware Event type 0 150 300 450 600 750 % increase in likelihood of occurrence (a) Armstrong 0 1 2 3 4 5 6 7 t malicious-email endpoint-malware Event type 0 150 300 450 600 750 % increase in likelihood of occurrence (b) Dexter Figure 2: The percentage increase in likelihood of occurrence for the rules that are identiﬁed to be useful. Generating warnings: The second component is responsible for generating warnings using the APT rules. This component is executed daily by ﬁrst acquiring all CVEs mentioned in the last 24 hours within the D2web streaming data. The CPE groups/nation-state actors for these mentioned CVEs are then obtained. Next, based on the APT-rules, the model tries to match the CPE/nation-state actor mappings to a particular rule. If a match exists, the model predicts if and when an attack exploiting the vulnerabilities will occur by generating warn- ings. The warning ﬁelds are populated using the information contained in the rule, such as the probability, event type, and target organization. Such details help in producing actionable warnings, i.e., warnings that provide metadata/details includ- ing the CVEs/tactics, industry, volume of discussions, etc. Section IV-C provides further details about the way warnings are generated from rules. Model fusion: The ﬁnal component deals with consolida- tion. It fuses warnings from various heterogeneous models (including DARKMENTION), populates any missing warning ﬁelds according to the program requirement, and generates the ﬁnal version of each warning. This completed warning is submitted to the Security Operations Center. Each warning submitted is available to view and drill down into using a Web UI and Audit Trail analysis capability. This audit trail goes from the submitted warning all the way through model fusion, the individual models, and each individual model’s raw data used to generate a warning. In the case of DARKMENTION, this would include the D2web postings/items with the CVEs mentioned highlighted. This capability makes the warnings that DARKMENTION produces transparent warnings, i.e., allows analysts to easily trace the warnings back to the rules that were triggered, discussions that ﬁred the rules, etc. Figure 3 shows two screenshots taken from the system. Figure 3: Two screenshots from DARKMENTION. IV. ANNOTATED PROBABILISTIC TEMPORAL LOGIC (APT-LOGIC) We will deﬁne here the syntax and semantics of APT-logic programs (set of APT-logic rules) applied to our domain, which is built upon the work of Shakarian et al. in [6]. A. Syntax Herbrand base. We use BL to denote the Herbrand base (ﬁnite set of ground atoms) of a ﬁrst order logical lan- guage L. Then, we divide BL into two disjoint sets: BL{conditions} and BL{actions}, so that BL ≡BL{conditions}∪ BL{actions}. BL{conditions} comprehends the atoms allowed only in the premise of APT rules, representing condi- tions or users’ actions performed on D2web websites, e.g., mention on(forum 1,debian). On the other hand, BL{actions} comprehends the atoms allowed only in the con- clusion of APT rules, representing actions or malicious activ- ities reported by Armstrong or Dexter organizations in their own facilities, e.g., attack(armstrong,malicious −email,x). 3 Formulas. Complex sentences (formulas) are constructed re- cursively from atoms, using parentheses and the logical con- nectives: (¬ negation, ∨disjunction, ∧conjunction). However, we note that all formulas in this paper are single atoms. Time formulas. If F is a formula, t is a time point, then Ft is a time formula which states that F is true at time t. Probabilistic time formulas. If φ is a time formula and [l,u] is a probability interval ⊆[0,1], then φ ∶[l,u] is a probabilistic time formula (ptf). Intuitively, φ ∶[l,u] says φ is true with a probability in [l,u], or using the complete notation, Ft ∶[l,u] says F is true at time t with a probability in [l,u]. APT rules. Suppose condition F and action G are formulas, t is a natural number, [l,u] is a probability interval and fr ∈F is a frequency function symbol that we will deﬁne later. Then F fr ↝G ∶[t,l,u] is an APT (Annotated Probabilistic Temporal) rule, which informally saying, computes the probability that G is true in exactly ∆t time units after F becomes true. For instance, the APT rule below informs that the probability of Armstrong company being attacked by a malicious-email, in exactly 3 time units after users mention “debian” on forums 1, is between 40% and 50%. mention on(set forum 1,debian) pfr ↝ attack(armstrong, malicious-email) ∶[3,0.4,0.5] B. Semantics World. In general, a world is any set of ground atoms that belong to BL. However, due to our constraint that separates atoms into BL{conditions} and BL{actions}, not all possible worlds are allowed in our APT rules. Strictly, one atom belong- ing to BL{conditions} and one atom belonging to BL{actions} must be present in an allowable world for our pfr rules. Thread. A thread is a series of worlds that model the domain over time, where each world corresponds to a discrete time- point in T = {1,...,tmax}. Th(i) speciﬁes that according to the thread Th, the world at time i will be Th(i). Given a thread Th and a time formula φ, we say Th satisﬁes φ (denoted Th ⊧φ) iff: ●If φ ≡Ft for some ground time formula Ft, then Th(t) satisﬁes F; ●If φ ≡¬ρ for some ground time formula ρ, then Th does not satisfy ρ; ●If φ ≡ρ1 ∧ρ2 for some ground time formulas ρ1 and ρ2, then Th satisﬁes ρ1 and Th satisﬁes ρ2; ●If φ ≡ρ1 ∨ρ2 for some ground time formulas ρ1 and ρ2, then Th satisﬁes ρ1 or Th satisﬁes ρ2; Frequency functions. A frequency function represents tempo- ral relationships within a thread, checking how often a world satisfying formula F is followed by a world satisfying formula G. Formally, a frequency function fr belonging to F maps quadruples of the form (Th,F,G,t) to [0,1] of real numbers. Among the possible ones proposed in [5], we investigate here alternative deﬁnitions for Point Frequency Function (pfr), which speciﬁes how frequently the action G follows the condition F in “exactly” ∆t time points. To support ongoing security operations we need to relax the original assumption of a ﬁnite time horizon tmax in [5], [6]. We introduce here a different but equivalent formulation for pfr that does not rely on a ﬁnite time horizon. To accomplish that, we ﬁrst need to deﬁne how a ptf can be satisﬁed in our model. If we consider the ptf Ft ∶[l,u], and some A′ ∈A, where A is the set of all ptf’s satisﬁed by our thread Th, we say Th ⊧Ft ∶[l,u] iff: ●If F = a for some ground a, then ∃at ∶[l′,u′] ∈ A s.t. [l′,u′] ⊒[l,u]; ●If Ft ∶[l,u] = ¬F ′ t ∶[l,u] for some ground formula F ′, then Th ⊧F ′ t ∶[1 −u,1 −l]; ●If Ft ∶[l,u] = F ′ t ∶[l,u] ∧F ′′ t ∶[l,u] for some ground formulas F ′ and F ′′, then Th ⊧F ′ t ∶[l,u] and Th ⊧F ′′ t ∶ [l,u]; ●If Ft ∶[l,u] = F ′ t ∶[l,u] ∨F ′′ t ∶[l,u] for some ground formulas F ′ and F ′′, then Th ⊧F ′ t ∶[l,u] or Th ⊧F ′′ t ∶ [l,u]; We are ready to show the new formulation of pfr in Equation 1, which is equivalent to the original one proposed in [5] when tmax comprises the whole thread Th (all time points): pfr(Th,F,G,∆t) = (1) ⎡⎢⎢⎢⎢⎢⎢⎣ ∑ t∣T h⊧Ft∶[l,u]∧T h⊧Gt+∆t∶[l′,u′] l′ ∑ t∣T h⊧Ft∶[l,u] u , ∑ t∣T h⊧Ft∶[l,u]∧T h⊧Gt+∆t∶[l′,u′] u′ ∑ t∶T h⊧Ft∶[l,u] l ⎤⎥⎥⎥⎥⎥⎥⎦ Satisfaction of APT rules and programs. We say Th satisﬁes an APT Rule F pfr ↝G ∶[∆t,l,u] (denoted Th ⊧F pfr ↝G ∶ [∆t,l,u]) iff: pfr(Th,F,G,∆t) ⊆[l,u] (2) C. Rules and warnings Probability intervals. We derive the probability intervals related to all pairs [l,u] speciﬁed in this paper using the standard deviation of the corresponding point probability in a binomial distribution, i.e., std(p) = n∗p∗(1−p) n [11], where n is the number of events that produced the probability p. APT programs. Our algorithms only adds to the logic pro- grams the pfr rules with lower bounds exceeding the prior probability of the rule’s head happening at any random time point. Warnings generation. The problem is to identify whether a triggered rule should generate warnings, and the number of warnings to generate. When there is no triggered rules on a given day, no warnings are generated. When two rules are triggered on the same day, both predict the same attack type is going to happen on the same day (i.e., same ∆t), and one predicts x number of attacks while the other predicts y number of attacks, then they will generate x + y warnings if both are qualiﬁed to generate warnings. A pfr r ∈R is qualiﬁed to generate x number of warnings if (1) the rule is triggered, and (2) there is no other triggered rule r′ ∈R on the same 4 day and same rule head and ∆t as r’s but has higher point probability than r’s. V. EXPERIMENTAL RESULTS In this section, we provide evidence of the viability of our approach through a series of experiments. The warnings that are submitted by our system are evaluated by the Security Operations Centers (SOCs) on a monthly basis. However, we internally evaluated DARKMENTION since the external eval- uations are aggregated for all models, and DARKMENTION was operationally deployed only after the time periods those reports cover. A. Experimental Settings We perform evaluations on the warnings targeting Arm- strong that were submitted during July, August, and September of 2017. The results are aggregated per months for the experiments on Armstrong data while aggregated on periods of 7 days for Dexter. The latter starts from July 1 to July 28, 2016. These time windows differ because the Armstrong dataset covers a longer period of time as compared to the period covered by Dexter, and there is no more GT data about Dexter that is going to be provided or evaluated by the program. The reported records of Malicious Destination for Dexter only cover a time period that ends before the testing time period starts, hence they are not evaluated. B. Evaluation Metrics To evaluate the accuracy of our system, we use three metrics: recall, which corresponds to the fraction of GT events that have matching warnings from the total number of GT events; precision, which is the fraction of warnings that have matching GT events from the total number of the generated warnings; and F1, which is the harmonic mean of recall and precision. Matching warnings and GT events. DARKMENTION pre- dicts the exact number of attacks on each day. Therefore, the matching problem is to ﬁnd whether a warning w earns credit for predicting a GT attack event g. If w predicts an attack with different type than g's, or w predicts an attack on a different day than the occurrence day of g, then they do not match. Otherwise, they may or may not match based on whether or not w or g have already been paired up with another GT event or a warning, respectively. To join together warnings with GT events in parings while ensuring that resulting pairings are mutually exclusive, we use the Hungarian assignment algorithm [12]. Intuitively, the algorithm takes as input an n∗n matrix representation of (−1∗ lead-time). Lead-time is the time between warnings and GT events that are qualiﬁed to match. Then, the algorithm returns a solution S that maximizes the total lead-time11. Here, S is a set of pairs, each maps a warnings to a GT event such that 11Lead-time is a metric set by the program to evaluate the performers, but we ignore it in this evaluation. the pairs are guaranteed to be mutually exclusive12. We store in the database the pairs that are returned by the algorithm. C. Results We found that our system outperforms a baseline system that randomly generates x number of warnings on each day such that each value of x has a chance proportional to its frequency of occurrence in the historical data. We repeat the baseline for 100 runs and take the average of each metric. In the real-time deployment of DARKMENTION, human experts can evaluate the warnings by leveraging the other capabilities of the system, i.e., transparency and actionable through a Web UI dashboard. However, in those experiments any triggered rule is counted, which is not necessarily important given other details. That said, our system scored signiﬁcantly higher than the baseline system as shown in Table I. VI. RELATED WORK. To the best of our knowledge, this paper is the ﬁrst to present a deployed system that applies causal reasoning to predict enterprise-related external cyber threats. However, there exists a large body of related research with studies about malicious hacking community in D2web, and studies related to rule- learning methods for security applications. Hacking community on D2web.. While the hacking commu- nity in D2web sites has been widely investigated in the existing literature for applications such as analyzing the economics of D2web forums/markets [13], [14] and identifying future cyber- threats to mitigate risks [2], [15], none of these studies identify threats related to speciﬁc corporations or identify when in the future the predicted events may occur. DARKMENTION speciﬁcally predicts enterprise-targeted attacks and the periods in which those threats are predicted. Rule-learning methods for security applications. A large body of work on understanding and modeling the behavior of threat actors and reasoning future risk levels to assist in the implementation of strategic defense has been proposed. While a growing number of studies along these lines have focused on applications related to understanding the behavior of terrorist and insurgent groups [16], [7], the cyber-security applications have not received much attention, except in the line of graph-based and attacker/defender game theoretical modeling [17], [18]. Our work differs from such theoretical approaches since we focus on practical details related to deployment, and evaluate our system with real-world data. VII. CONCLUSION We present DARKMENTION, a deployed system that pro- duces warnings about cyber incidents that will likely occur in the future. Although the problem is difﬁcult, our system proves to be useful as a tool that helps SOC teams to identify risks, potential sources of risk (vulnerabilities or threat actors) and context on which it builds its reasoning in a timely, actionable, 12We add dummy rows (warnings) or columns (GT events) with lead-times of 1 to make the matrix square, then remove from the solution the pairs where the lead-time is 1. 5 Table I: Evaluation results. * A simple baseline model that generates x number of warnings on each day based on the prior probability of each possible value of x that was seen in the training data. Dataset type Testing starts #GT-events DARKMENTION Baseline* (average of 100 runs) %increase in F1 #warnings Precision Recall F1 #warnings Precision Recall F1 Armstrong M-E Jul-17 24 32 0.313 0.417 0.357 11.759 0.417 0.205 0.271 32% Aug-17 11 3 1.000 0.273 0.429 11.966 0.289 0.315 0.299 43% Sep-17 13 18 0.167 0.231 0.194 12.793 0.249 0.249 0.247 -21% M-D Jul-17 4 12 0.167 0.500 0.250 3.534 0.099 0.091 0.090 178% Aug-17 9 23 0.174 0.444 0.250 3.121 0.232 0.086 0.120 108% Sep-17 3 10 0.100 0.333 0.154 2.948 0.071 0.075 0.068 126% E-M Jul-17 14 10 0.300 0.214 0.250 8.552 0.326 0.200 0.242 3% Aug-17 18 45 0.200 0.500 0.286 9.155 0.324 0.168 0.217 32% Sep-17 17 21 0.286 0.353 0.316 8.879 0.247 0.127 0.164 93% Dexter M-E 1-Jul-16 2 13 0.150 1.000 0.267 2.720 0.157 0.205 0.169 58% 8-Jul-16 7 10 0.500 0.714 0.588 2.610 0.655 0.253 0.348 69% 15-Jul-16 9 6 0.333 0.222 0.267 2.770 0.619 0.188 0.276 -3% 22-Jul-16 4 2 0.500 0.250 0.333 3.050 0.469 0.355 0.385 -14% E-M 1-Jul-16 1 2 0.500 1.000 0.667 1.790 0.189 0.330 0.226 195% 8-Jul-16 3 4 0.250 0.333 0.286 1.750 0.245 0.167 0.186 54% 15-Jul-16 3 1 1.000 0.333 0.500 1.740 0.281 0.190 0.217 130% 22-Jul-16 4 2 0.500 0.250 0.333 1.780 0.383 0.208 0.257 30% accurate, and transparent manner. Our team was selected to progress to the second phase of the CAUSE program. ACKNOWLEDGMENT Some of the authors were supported by the Ofﬁce of Naval Research (ONR) Neptune program, the ASU Global Security Initiative (GSI), and the National Council for Scientiﬁc and Technological Development (CNPq-Brazil). Paulo Shakarian, Dipsy Kapoor, and Timothy Siedlecki are supported by the Ofﬁce of the Director of National Intelligence (ODNI) and the Intelligence Advanced Research Projects Activity (IARPA) via the Air Force Research Laboratory (AFRL) contract number FA8750-16-C-0112. Gerardo Simari is also partially supported by Universidad Nacional del Sur (UNS) and CONICET, Ar- gentina. The U.S. Government is authorized to reproduce and distribute reprints for Governmental purposes notwithstanding any copyright annotation thereon. Disclaimer: The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the ofﬁ- cial policies or endorsements, either expressed or implied, of ODNI, IARPA, AFRL, or the U.S. Government. REFERENCES [1] Verizon, “2017 data breach investigations report,” 2017. [Online]. Available: https://www.ictsecuritymagazine.com/wp-content/ uploads/2017-Data-Breach-Investigations-Report.pdf [2] M. Almukaynizi, E. Nunes, K. Dharaiya, M. Senguttuvan, J. Shakarian, and P. Shakarian, “Proactive identiﬁcation of exploits in the wild through vulnerability mentions online,” in 2017 International Conference on Cyber Conﬂict (CyCon U.S.), Nov 2017, pp. 82–88. [3] P. Suppes, A probabilistic theory of causality. North-Holland Publishing Company Amsterdam, 1970. [4] S. Kleinberg and B. Mishra, “The temporal logic of causal structures,” in Proceedings of the Twenty-Fifth Conference on Uncertainty in Artiﬁcial Intelligence. AUAI Press, 2009, pp. 303–312. [5] P. Shakarian, A. Parker, G. I. Simari, and V. S. Subrahmanian, “Anno- tated probabilistic temporal logic,” ACM Trans. Comput. Logic, vol. 12, no. 2, pp. 14:1–14:44, Jan. 2011. [6] P. Shakarian, G. I. Simari, and V. S. Subrahmanian, “Annotated prob- abilistic temporal logic: Approximate ﬁxpoint implementation,” ACM Trans. Comput. Logic, vol. 13, no. 2, pp. 13:1–13:33, Apr. 2012. [7] A. Stanton, A. Thart, A. Jain, P. Vyas, A. Chatterjee, and P. Shakarian, “Mining for causal relationships: A data-driven study of the islamic state,” in Proceedings of the 21th ACM SIGKDD International Con- ference on Knowledge Discovery and Data Mining. ACM, 2015, pp. 2137–2146. [8] E. Nunes, A. Diab, A. Gunn, E. Marin, V. Mishra, V. Paliath, J. Robert- son, J. Shakarian, A. Thart, and P. Shakarian, “Darknet and deepnet mining for proactive cybersecurity threat intelligence,” in Proceeding of ISI 2016. IEEE, 2016, pp. 7–12. [9] NIST, “National vulnerability database,” https://nvd.nist.gov/, Last Ac- cessed: Jan 2018. [10] J. M. Montgomery, F. M. Hollenbach, and M. D. Ward, “Improving pre- dictions using ensemble bayesian model averaging,” Political Analysis, vol. 20, no. 3, pp. 271–291, 2012. [11] G. Wadsworth and J. Bryan, Introduction to Probability and Random Variables, ser. A Wiley publication in mathematical statistics. McGraw-Hill, 1960. [Online]. Available: https://books.google.com/ books?id=NNtQAAAAMAAJ [12] J. Munkres, “Algorithms for the assignment and transportation prob- lems,” Journal of the society for industrial and applied mathematics, vol. 5, no. 1, pp. 32–38, 1957. [13] M. Motoyama, D. McCoy, K. Levchenko, S. Savage, and G. M. Voelker, “An analysis of underground forums,” in Proceedings of the 2011 ACM SIGCOMM conference on Internet measurement conference. ACM, 2011, pp. 71–80. [14] L. Allodi, “Economic factors of vulnerability trade and exploitation,” in Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security. ACM, 2017, pp. 1483–1499. [15] N. Tavabi, P. Goyal, M. Almukaynizi, P. Shakarian, and K. Ler- man, “Darkembed: Exploit prediction with neural language models,” in Proceedings of AAAI Conference on Innovative Applications of AI (IAAI2018), 2018. [16] V. S. Subrahmanian, A. Mannes, A. Roul, and R. Raghavan, Indian Mujahideen: Computational Analysis and Public Policy. Springer Science & Business Media, 2013. [17] J. Robertson, V. Paliath, J. Shakarian, A. Thart, and P. Shakarian, “Data driven game theoretic cyber threat mitigation.” 2016. [18] M. Brown, W. B. Haskell, and M. Tambe, “Addressing scalability and robustness in security games with multiple boundedly rational adversaries,” in International Conference on Decision and Game Theory for Security. Springer, 2014, pp. 23–42. 6