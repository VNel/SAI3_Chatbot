arXiv:1603.08307v1 [cs.CR] 28 Mar 2016 Cyber Epidemic Models with Dependences Maochao Xu1, Gaofeng Da2 and Shouhuai Xu3 1 Department of Mathematics, Illinois State University mxu2@ilstu.edu 2 Institute for Cyber Security, University of Texas at San Antonio dagfvc@gmail.com 3 Department of Computer Science, University of Texas at San Antonio shxu@cs.utsa.edu (corresponding author) Abstract Studying models of cyber epidemics over arbitrary complex networks can deepen our understanding of cyber security from a whole-system perspective. In this paper, we initiate the investigation of cyber epidemic models that accommodate the dependences between the cyber attack events. Due to the notorious difﬁculty in dealing with such dependences, essentially all existing cyber epidemic models have assumed them away. Speciﬁcally, we introduce the idea of Copulas into cyber epidemic models for accommodating the dependences between the cyber attack events. We investigate the epidemic equilibrium thresholds as well as the bounds for both equilibrium and non- equilibrium infection probabilities. We further characterize the side-effects of assuming away the due dependences between the cyber attack events, by showing that the results thereof are unnecessarily restrictive or even incorrect. Keywords: Copula, Cyber epidemics, dependence, epidemic threshold, spectral radius, infection probability 1 Introduction Cyberspace (or Internet) is perhaps the most complex man-made system. While cyberspace has become an indispens- able part of the society, economy and national security, cyber attacks also have become an increasingly devastating problem. Despite studies and progresses in the past decades, our understanding of cyber security from a whole-system perspective, rather than from a component or building-block perspective, is still at its infant stage. This is caused by many factors, including the dearth of powerful mathematical models that can capture and reason the interactions between the cyber attacks and the cyber defenses. Recently, researchers have started pursuing the cyber-security value of “biological epidemics”-like mathematical models. While conceptually attractive, biological epidemic models cannot be directly used to describe cyber security because there are many cyber-speciﬁc issues. One particular issue, which we initiate its study in the present paper, is the dependences between the cyber attack events. To the best of our knowledge, these dependences have been explic- itly assumed away in essentially all existing cyber epidemic models, perhaps because they are notoriously difﬁcult to cope with. Indeed, accommodating the dependences introduces yet another dimension of difﬁculty to cyber epidemic models that incorporate arbitrary complex network structures. However, the dependences are inherent because, for example, the events that computers get infected are not independent of each other, and a malware may ﬁrst infect some computers because the users visit some malicious websites and then spread over the network. Moreover, cyber attacks may be well coordinated by intelligent malwares, and the coordination causes positive dependences between the attack events. 1.1 Our contributions In this paper, we initiate the systematic study of a new sub-ﬁeld in cyber epidemic models, namely understanding and characterizing the importance of the dependences between the attack events in cyber epidemic models that ac- commodate arbitrary complex network structures. This is demonstrated through a non-trivial generalization of the 1 powerful push- and pull-based cyber epidemic model that was recently investigated in [19]. Speciﬁcally, we capture the dependences between the cyber attack events by incorporating the idea of Copulas into cyber epidemic models. To the best of our knowledge, this is the ﬁrst systematic study of cyber epidemic models that accommodate dependences, rather than assuming them away. Speciﬁcally, we make two contributions. First, we derive epidemic equilibrium thresholds, namely sufﬁcient conditions under which the epidemic spread- ing enters a non-negative equilibrium (the spreading never dies out when there are pull-based attacks, meaning that only positive equilibrium is relevant under this circumstance). Some of the sufﬁcient conditions are less restrictive but require hard-to-obtain information (i.e., these conditions are theoretically more interesting), and the others are more restrictive but require easy-to-obtain information (i.e., these conditions are practically more useful). We also derive bounds for the equilibrium infection probabilities and discuss their tightness. The bounds are easy to obtain/compute, and are useful especially when it is infeasible to obtain the equilibrium infection probabilities numerically (let alone analytically). For example, the upper bounds can be treated as the worst-case scenarios when provisioning defense resources. For Erd˝os-R´enyi (ER) and power-law networks, we further propose to approximate the equilibrium infec- tion probabilities by taking advantage of the bounds. The approximation results are smaller than the upper bounds and would not underestimate the number of infected nodes, meaning that the approximation results can lead to more cost-effective defense. We further present bounds for non-equilibrium infection probabilities, no matter whether the spreading converges to equilibrium or not. All the results are obtained by explicitly accommodating the dependence structures between the cyber attack events. Second, we characterize the side-effects of assuming away the due dependences on the bounds for equilibrium infection probabilities, on the epidemic equilibrium thresholds, and on the non-equilibrium infection probabilities. We show that assuming away the due dependences can make the results thereof unnecessarily restrictive or even incorrect. We further discuss the cyber security implications of the side-effects. It is worth mentioning that as a ﬁrst step towards ultimately tackling the dependence problem in cyber epidemic models, the Copulas technique, which we use in the present paper, is appealing because of the following. On one hand, it leads to tractable models, while capable of coping with high-dimensional dependence (i.e., dependence between a large vector of random variables). On the other hand, there are families of copula structures that have been extensively investigated in the literature of Applied Probability Theory and Risk Management, and various methods have been developed for estimating the types and parameters of copula structures in practice. Of course, much research remains to be done before we can answer questions such as: What approach is the most appropriate for accommodating dependence in cyber epidemic models, under what circumstances? 1.2 Related work Biological epidemic models can be traced back to McKendrick and Kermack [13, 10]. Such homogeneous biological epidemic models were introduced to computer science for characterizing the spreading of computer viruses in [9]. Heterogeneous epidemic models, especially the ones that accommodate arbitrary network structures, were not studied until recently [17, 6, 1]. These studies led to the full-ﬂedged push- and pull-based cyber epidemic model [19], which is the starting point of the present paper. To the best of our knowledge, all existing cyber epidemic models, which aim to accommodate arbitrary network structures (including other recent studies such as [16, 11, 20] and the references therein), assumed that the attacks are independent of each other. This is plausible because accommodating arbitrary network structures in cyber epidemic models already make the resulting models difﬁcult to analyze, and accommodating dependences introduces, as we show in the present paper, another dimension of difﬁculty to the models. The only exception is due to our recent study [18], which is based on a different approach to modeling cyber epi- demics [11]. The main contribution of [18] is to get rid of the exponential distribution assumptions for certain random variables. Moreover, the model in [18] can only accommodate the speciﬁc Marshall-Olkin dependence structure be- tween the attack events. In contrast, we here accommodate arbitrary dependence structures between the attack events, while investigating the epidemic equilibrium thresholds, the equilibrium and non-equilibrium infection probabilities, and the side-effects of assuming away the due dependences. Many of these issues are not studied in the context of [18] because its focus is different. This explains why the present paper is the ﬁrst systematic treatment of dependences in 2 cyber epidemic models. The dependence modeled in the present paper is static (i.e., time-invariant). This study inspired [5], which makes a further step towards modeling dynamic dependence between cyber attacks, but using a different modeling approach. The rest of the paper is organized as follows. In Section 2 we brieﬂy review some facts about Copulas. In Section 3 we investigate the generalized cyber epidemic model that accommodates the dependences between the cyber attack events. In Section 4 we characterize the side-effects as caused by assuming away the due dependences. In Section 5, we conclude the paper with future research problems. The following table summarizes the main notations used in the paper. G = (V, E) the graph/network in which cyber epidemics occurs, where V is the node set and E is the edge set deg(v) the degree of node v in graph G = (V, E), which can be represented by adjacency matrix A Iv(t), Iv,j(t) the state of node v at time t: Iv(t) = 1 means infected and 0 means secure; Iv,j(t) is the state of the jth neighbor of node v (1 means infected and 0 means secure), where 1 ≤j ≤deg(v) iv(t) the probability that node v ∈V is infected at time t iv,j(t) the condition probability that at time t node v ∈V is secure but the jth neighbor of node v is infected i− v , i+ v lower and upper bounds for the non-equilibrium infection probability limt→∞iv(t), where the sys- tem does not converge to any equilibrium i∗ v, i∗ v,j the equilibrium infection probabilities that node v and its jth neighbor are infected, respectively i∗−, i∗+ v i∗−is the lower bound for the equilibrium infection probability i∗ v for every v, i∗+ v is the upper bound for the equilibrium infection probability i∗ v of node v i∗, i∗ v i∗= (i∗ 1, . . . , i∗ N) where N = |V|, i∗ v = (i∗ v,1, . . . , i∗ v,deg(v)) α the probability that a secure node v ∈V is infected by pull-based cyber attacks at a time step β the probability that an infected node v ∈V becomes secure at a time step γ the probability that an infected node u successfully attacks node v over (u, v) ∈E at a time step ρ(M) spectral radius of matrix M Cv deg(v)-copula describing the dependence between the push-based cyber attacks against node v C 2-copula describing the dependence between the pull-based attacks and the push-based attacks against a node δC the diagonal section of copula C, i.e., δC(u) = C(u, . . . , u) 2 Preliminaries Copulas can model dependences by relating the individual marginal distributions to their multivariate joint distribu- tion. In this paper we will use the n-copulas [8, 15]. Speciﬁcally, a function C : [0, 1]n 7→[0, 1] is called n-copula if: • C(u1, . . . , un) is increasing in each component uz, z ∈{1, . . . , n}. • C(u1, . . . , uz−1, 0, uz+1, . . . , un) = 0 for all uj ∈[0, 1], j = 1, . . . , n, j ̸= z. • C(1, . . . , 1, uz, 1, . . . , 1) = uz for all uz ∈[0, 1], z = 1, . . . , n. • C is n-increasing, i.e., for all (u1,1, . . . , u1,n) and (u2,1, . . . , u2,n) in [0, 1]n with u1,j ≤u2,j and for all j = 1, . . . , n, it holds that 2 X z1=1 . . . 2 X zn=1 (−1) Pn j=1 zjC(uz1,1, . . . , uzn,n) ≥0. Let R1, . . . , Rn be random variables with distribution functions F1, . . . , Fn, respectively. The joint distribution function is F(r1, . . . , rn) = P (R1 ≤r1, . . . , Rn ≤rn). The well-known Sklar’s theorem states that there exists an n-copula C such that F(r1, . . . , rn) = C (F1(r1), . . . , Fn(rn)) . 3 There are many families of copulas [8, 15]. One example is the Gaussian copula with C(u1, . . . , un) = ΦP  Φ−1(u1), . . . , Φ−1(un)  , where Φ−1 is the inverse cumulative distribution function of the standard normal distribution and ΦP is the joint cumulative distribution function of a multivariate normal distribution with mean vector zero and covariance matrix equal to the correlation matrix P. For simplicity, we assume that the correlation matrix has the form X =     1 σ . . . σ σ 1 σ σ . . . σ σ . . . 1    , where σ measures the correlation between two random variables. Therefore, the Gaussian copula can be rewritten as C(u1, . . . , un) = Φσ  Φ−1(u1), . . . , Φ−1(un)  . Another example is the Archimedean family with C(u1, . . . , un) = φ−1 (φ(u1) + . . . + φ(un)) , where function φ is called a generator of C and satisﬁes certain properties (see [14] for details). The Archimedean family contains many well-known copula functions such as the Clayton and Frank copulas [15, 3]. The generator of the Clayton copula is φθ(u) = u−θ −1, and we have C(u1, . . . , un) =   n X j=1 u−θ j −n + 1   −1/θ , θ > 0. The generator of the Frank copula is ψξ(u) = log  e−ξu−1 e−ξ−1  , and we have C(u1, . . . , un) = −1 ξ log ( 1 + Qn j=1(e−ξuj −1) (e−ξ −1)n−1 ) , ξ > 0. For illustration purpose, we will use the Gaussian, Clayton and Frank copulas as examples. In order to compare the effects of dependences, we need to compare the degrees of dependences. For this purpose, we use the concordance order [15, 8]. Let C1 and C2 be two copulas, we say C1 is less than C2 in concordance order if C1(u1, . . . , un) ≤C2(u1, . . . , un) for all 0 ≤ui ≤1, i = 1, . . . , n. In particular, Gaussian copulas and Clayton copulas are increasing in σ and θ in concordance order, respectively. The following lemmas will be used in the paper. Lemma 1 ([15]) Let C be any n-copula, then max    n X j=1 uj −n + 1, 0   ≤C(u1, . . . , un) ≤min{u1, . . . , un}. Lemma 2 ([15]) Let C be an n-copula, then |C(u1, . . . , un) −C(v1, . . . , vn)| ≤ n X j=1 |uj −vj|. 4 3 Cyber Epidemic Model With Arbitrary Dependences Now we present and investigate the cyber epidemic model that accommodates the dependences between the cyber attack events. This is the ﬁrst systematic treatment of dependences in cyber epidemic models. 3.1 The Model As in [19], we consider an undirected ﬁnite network graph G = (V, E), where V = {1, 2, . . . , N} is the set of N = |V| nodes (vertices) that can abstract computers (or software components at an appropriate resolution), and E = {(u, v) : u, v ∈V} is the set of edges. Note that G abstracts the network structure according to which the push-based cyber attacks take place (e.g., malware spreading), where (u, v) ∈E abstracts that node u can attack node v. In both principle and practice, G can range from a complete graph (i.e., any u ∈V can directly attack any v ∈V) to any speciﬁc graph structure (i.e., node u may not be able to attack node v directly because, for example, the trafﬁc from node u is ﬁltered or u is blacklisted by v), which explains why we should pursue general results without restricting the network/graph structures. Denote by A = (avu) the adjacency matrix of G, where avu = 1 if and only if (u, v) ∈E, and avu = 0 otherwise. Note that the problem setting naturally implies avv = 0. Denote by deg(v) the degree of node v. In a discrete-time model, node v ∈V is either secure (but vulnerable to attacks) or infected (and can attack other nodes) at any time t = 0, 1, . . .. At each time step, an infected node v becomes secure with probability β, which abstracts the defense power. The model accommodates two large classes of cyber attacks: a secure node v can become infected because of (i) pull-based cyber attacks with probability α, which include drive-by-download attacks (i.e., node v getting infected because its user visits a malicious website) and insider attacks (i.e., the user intentionally runs a malware on node v), or (ii) push-based cyber attacks launched by v’s infected neighbor u over edge (u, v) ∈E with probability γ. Our extension to the above model is to accommodate the dependences between the push-based attacks as well as the dependences between the push-based attacks and the pull-based attacks. These attacks are not independent because the events that the nodes get infected are not independent of each other, and because the push-based attacks are not independent of the pull-based attacks (e.g., a malware could ﬁrst infect some nodes via the pull-based cyber attacks and then launch the push-based cyber attacks from the infected nodes). Moreover, the dependences between the push-based attacks can model that intelligent malwares launch coordinated attacks against the secure nodes. Speciﬁcally, let Iv(t) denote the state of node v at time t, where Iv(t) = 1 means v is infected and 0 means v is secure. Let  Iv,1(t), . . . , Iv,deg(v)(t)  denote the state vector of node v’s neighbors at time t, where Iv,j(t) =  1, the jth neighbor of node v is infected at time t, 0, otherwise. Deﬁne iv(t) = P(Iv(t) = 1) and iv,j(t) = P(Iv,j(t) = 1|Iv(t) = 0) where j = 1, . . . , deg(v). Let Xv(t) = 1 denote the event that node v is infected at time t + 1 because of the push-based cyber attacks, and Xv(t) = 0 otherwise. Let Xv,j(t + 1) = 1 denote the event that node v is infected at time t + 1 by its jth neighbor, and Xv,j(t + 1) = 0 otherwise. Note that P(Xv,j(t + 1) = 1|Iv(t) = 0) = γ · iv,j(t). Since any dependence structure between Xv,1(t + 1), . . . , Xv,deg(v)(t + 1) always can be accommodated by some copula function Cv, we have P(Xv(t + 1) = 0|Iv(t) = 0) = Cv  1 −P(Xv,1(t + 1) = 1|Iv(t) = 0), . . . , 1 −P(Xv,deg(v)(t + 1) = 1|Iv(t) = 0)  = Cv  1 −γiv,1(t), . . . , 1 −γiv,deg(v)(t)  . (1) Similarly, let Yv(t + 1) = 1 denote the event that node v is infected at time t + 1 because of the pull-based cyber attacks. Then, we have P(Yv(t + 1) = 1|Iv(t) = 0) = α. By further accommodating the dependence structure between the push-based attacks and the pull-based attacks via some copula function C, we have P(Iv(t + 1) = 1|Iv(t) = 0) = 1 −P (Xv(t + 1) = 0, Yv(t + 1) = 0|Iv(t) = 0) = 1 −C  Cv  1 −γiv,1(t), . . . , 1 −γiv,deg(v)(t)  , 1 −α  . (2) 5 Note that P(Iv(t + 1) = 1|Iv(t) = 1) = (1 −β)iv(t). (3) From Eqs. (1), (2) and (3), we obtain the probability that node v ∈V is infected at time t + 1 as: iv(t + 1) = P(Iv(t + 1) = 1) = P(Iv(t + 1) = 1|Iv(t) = 1)P(Iv(t) = 1) + P(Iv(t + 1) = 1|Iv(t) = 0)P(Iv(t) = 0) = (1 −β) · iv(t) + P(Iv(t + 1) = 1|Iv(t) = 0) · (1 −iv(t)) = (1 −β)iv(t) +  1 −C  Cv  1 −γiv,1(t), . . . , 1 −γiv,deg(v)(t)  , 1 −α  (1 −iv(t)). (4) We will analyze Eq. (4) for v ∈V to characterize the effects of the dependence structures C and Cv and the side-effects of assuming them away. Note that for the special case that the Xv,j’s are independent of each other and the push-based attacks and the pull-based attacks are also independent of each other, Eq. (4) degenerates to the model in [19]. Note also that in order to characterize the side-effects of assuming away the dependences, we need to accommodate the dependences at a higher-level of abstraction than the model parameters α and γ. This is because the parameters are indeed relatively easier to obtain in experiments/practice (e.g., considering a single compromised neighbor that is launching the push-based attacks, and considering the pull-based attacks in the absence of the push- based attacks). 3.2 Epidemic Equilibrium Threshold and Bounds for Equilibrium Infection Probabilities The concept of epidemic equilibrium threshold [19] naturally extends the well-known concept of epidemic threshold in that the former describes the condition under which the epidemic spreading converges to a non-negative equilibrium, whereas the latter traditionally describes the condition under which the epidemic spreading converges to 0 (i.e., the spreading dies out). Note that α > 0 implies that the spreading will never die out and that α = 0 is necessary for the spreading to die out. Denote by i∗ v the equilibrium infection probability for node v ∈V. In the equilibrium, Eq. (4) becomes: i∗ v = (1 −β)i∗ v + h 1 −C  Cv  1 −γi∗ v,1, . . . , 1 −γi∗ v,deg(v)  , 1 −α i (1 −i∗ v), v ∈V. (5) In what follows, Theorem 1 gives a general epidemic equilibrium threshold (i.e., sufﬁcient condition under which the spreading enters the equilibrium), and Theorem 2 gives a more succinct but more restrictive sufﬁcient condition. Lemma 3 Let A be the adjacency matrix of G. If ρ(A) < (β + α)2 γβ , (6) then system (4) has a unique equilibrium (i∗ 1, . . . , i∗ N) ∈[0, 1]N. Proof For any v ∈V, deﬁne fv(x) : [0, 1]N →[0, 1] as fv(x) = 1 −C  Cv  1 −γxv,1, . . . , 1 −γxv,deg(v)  , 1 −α  β + 1 −C  Cv  1 −γxv,1, . . . , 1 −γxv,deg(v)  , 1 −α , v = 1, . . . , N, where x = (x1, . . . , xN) ∈[0, 1]N. Deﬁne f(·) : [0, 1]N →[0, 1]N, where f(x) = (f1(x), . . . , fN(x)). According to the Banach ﬁxed-point theorem [7], it is sufﬁcient to show that f(x) = x has a unique solution i∗; that is, we need to prove that f(·) is a contraction mapping. Let x, y ∈[0, 1]N. Consider the distance between them in the Euclidean norm, ||f(x) −f(y)|| = v u u t N X v=1 (fv(x) −fv(y))2 = v u u t N X v=1 βΓv ∆v 2 , 6 where Γv = C  Cv  1 −γxv,1, . . . , 1 −γxv,deg(v)  , 1 −α  −C  Cv  1 −γyv,1, . . . , 1 −γyv,deg(v)  , 1 −α  , ∆v =  β + 1 −C  Cv  1 −γxv,1, . . . , 1 −γxv,deg(v)  , 1 −α  ·  β + 1 −C  Cv  1 −γyv,1, . . . , 1 −γyv,deg(v)  , 1 −α  . By Lemmas 1 and 2, it follows that |Γv| ≤γ deg(v) X k=1 |xv,k −yv,k| and ∆v ≥(β + α)2. Therefore, we have ||f(x) −f(y)|| ≤ βγ (β + α)2 v u u u t N X v=1   deg(v) X k=1 |xv,k −yv,k|   2 . Moreover, N X v=1   deg(v) X k=1 |xv,k −yv,k|   2 = (|x1 −y1|, . . . , |xN −yN|)A2(|x1 −y1|, . . . , |xN −yN|)T ≤ ||(|x1 −y1|, . . . , |xN −yN|)||2||A||2 = ||x −y||2||A||2, where ||A|| denotes the operator norm of A. Since A is symmetric matrix, we have ||A|| = ρ(A). From condition (6), it follows that ||f(x) −f(y)|| ≤ βγρ(A) (β + α)2 ||x −y|| < ||x −y||, which means that f(·) is a contraction mapping. Theorem 1 (general epidemic equilibrium threshold) Let A be the adjacency matrix of G and D be the diagonal matrix with the vth (1 ≤v ≤N) diagonal element equal to h(α, β, γ, i∗ v) = C  Cv  1 −γi∗ v,1, . . . , 1 −γi∗ v,deg(v)  , 1 −α  −β , where i∗ v is the equilibrium infection probability that satisﬁes Eq. (5). Let W = D+γA. If condition (6) holds, namely that system (4) has a unique equilibrium, and the spectral radius ρ(W) < 1, then limt→∞iv(t) = i∗ v exponentially for all v ∈V. Proof According to Lemma 3, there is a unique solution for i∗ v under condition (6). Denote by rv(t) = iv(t) −i∗ v. We want to identify a sufﬁcient condition under which limt→∞|rv(t)| = 0 for all v ∈V . Note that rv(t + 1) = rv(t) h C  Cv  1 −γi∗ v,1, . . . , 1 −γi∗ v,deg(v)  , 1 −α  −β i + (1 −iv(t)) × h C  Cv  1 −γi∗ v,1, . . . , 1 −γi∗ v,deg(v)  , 1 −α  −C  Cv  1 −γiv,1(t), . . . , 1 −γiv,deg(v)(t)  , 1 −α i . 7 By Lemma 2, we have |rv(t + 1)| ≤ |rv(t)|h(α, β, γ, i∗ v) + (1 −iv(t)) × Cv  1 −γi∗ v,1, . . . , 1 −γi∗ v,deg(v)  −Cv  1 −γiv,1(t), . . . , 1 −γiv,deg(v)(t)  ≤ |rv(t)|h(α, β, γ, i∗ v) + γ (1 −iv(t)) deg(v) X j=1 |i∗ v,j −iv,j(t)| ≤ |rv(t)|h(α, β, γ, i∗ v) + γ deg(v) X j=1 |rv,j(t)|, where h(α, β, γ, i∗ v) = C  Cv  1 −γi∗ v,1, . . . , 1 −γi∗ v,deg(v)  , 1 −α  −β . Deﬁne zv(t + 1) = zv(t)h(α, β, γ, i∗ v) + γ deg(v) X j=1 zv,j(t), with zv(0) ≡|rv(0)| and zv,j(0) ≡|rv,j(0)| for j = 1, . . . , deg(v). We see |rv(t)| ≤zv(t) for any t. Let z(t) = (z1(t), . . . , zn(t))T . Then, we have the following matrix form z(t + 1) = Wz(t) = W t+1z(0), (7) where W = D + γA, D is the diagonal matrix with diagonal element h(α, β, γ, i∗ v), and A is the adjacency matrix of G. Since matrix W is nonnegative and symmetric, the Spectral Theorem [12] says that ρ(W) is real. By using the well-known Gelfand formula, if ρ(W) < 1, then limt→∞W t = 0 and therefore limt→∞z(t) = 0. Since ρ(W) = lim t→∞∥W t ∥1/t and ∥W t ∥∼[ρ(W)]t , t →∞, where ∥· ∥is the norm in real space Rn, we conclude that ∥W t ∥converges to 0 exponentially when ρ(W) < 1. This means that the convergence rate of limt→∞i(t) = i∗is at least exponential. Use of the sufﬁcient condition given by Theorem 1 requires to know i∗(i.e., i∗ v for all v), which is difﬁcult to obtain analytically. It is therefore important to weaken this requirement. Now we present a sufﬁcient condition that only requires the equilibrium infection probability i∗ v for some v (rather than for all v ∈V). According to [4], we have ρ(W) ≤max v∈V h(α, β, γ, i∗ v) + γρ(A). Therefore, a more restrictive (than the one given by Theorem 1) sufﬁcient condition is to require max v∈V h(α, β, γ, i∗ v) + γρ(A) < 1, namely ρ(A) < 1 −maxv∈V h(α, β, γ, i∗ v) γ . According to Eq. (5), we have h(α, β, γ, i∗ v) = 1 − β 1 −i∗v . Therefore, we obtain the following more restrictive, but more succinct, sufﬁcient condition: Corollary 1 limt→∞iv(t) = i∗ v exponentially for all v ∈V, if ρ(A) ≤min 1 −maxv∈V |1 −β/(1 −i∗ v)| γ , (β + α)2 γβ  . (8) 8 Applying the above sufﬁcient condition still requires to know the minimal and maximal i∗ v’s, which is hard to obtain analytically. Although it is always possible to obtain them numerically, we would want to have some more general results without relying on numerical solutions. In what follows we present such a sufﬁcient condition (Theo- rem 2), which requires the following Proposition 1 that presents bounds for the equilibrium infection probability. The bounds are certainly of independent value. Proposition 1 (bounds for equilibrium infection probabilities) For any dependence structures C and Cv, which may be unknown, the equilibrium infection probability i∗ v for v ∈V satisﬁes i∗−≤i∗ v ≤i∗+ v , where i∗−= γ −β γ I{γ > α + β} + α β + αI{γ ≤α + β}, i∗+ v = min n α + γdeg(v) β+1 , 1 o β + min n α + γdeg(v) β+1 , 1 o. Proof Rewrite Eq. (5) as i∗ v = 1 −C  Cv  1 −γi∗ v,1, . . . , 1 −γi∗ v,deg(v)  , 1 −α  β + 1 −C  Cv  1 −γi∗ v,1, . . . , 1 −γi∗ v,deg(v)  , 1 −α . (9) By noticing the monotonicity in (9) and applying Lemma 1, we obtain max n γi∗ v,1, . . . , γi∗ v,deg(v), α o β + max n γi∗ v,1, . . . , γi∗ v,deg(v), α o ≤i∗ v ≤ min n α + γ Pdeg(v) j=1 i∗ v,j, 1 o β + min n α + γ Pdeg(v) j=1 i∗ v,j, 1 o. (10) Let us ﬁrst consider the lower bound. Note that for each v ∈V, i∗ v ≥x1 def = α β + α. By substituting x1 for i∗ v,j in Ineq. (10), we have i∗ v ≥x2 △= max {γx1, α} β + max {γx1, α}. By substituting x2 for i∗ v,j in Ineq. (10), we obtain x3. By repeating the substitution, we obtain a sequence {xn, n ≥1} with xn = max {γxn−1, α} β + max {γxn−1, α}, x0 = 0. Since {xn, n ≥1} is increasing and bounded, we can get its limit, namely i∗−, by solving the following equation max{γx, α} β + max{γx, α} = x. For the upper bound, note that i∗ v ≤ 1 β + 1 for v ∈V. By substituting 1/(β + 1) for i∗ v,j in Ineq. (10), we get i∗+ v . It is useful to know when the bounds in Proposition 1 are tight. For this purpose, we observe that if γ β+1 deg(v) ≈ 0, meaning that γ deg(v) << 1 and that the attack-power is not strong, we have i∗+ v ≈i∗−= α β + α. This means that the bounds are tight when the attack-power is not strong. On the other hand, Proposition 1 allows us to derive the following more succinct, but more restrictive (than Corollary 1 and therefore Theorem 1), sufﬁcient condition for the epidemic spreading converges to the equilibrium (i.e., epidemic equilibrium threshold). The new sufﬁcient condition involves the bounds i∗−and i∗+ v only (i.e., none of the equilibrium probabilities that are hard to obtain analytically). 9 Theorem 2 (succinct epidemic equilibrium threshold) The spreading enters the unique equilibrium if ρ(A) ≤ 1 −max v∈V  max  1 − β 1 −i∗− , 1 − β 1 −i∗+ v  γ , where i∗−and i∗+ v are deﬁned in Proposition 1. Proof Note that for any v ∈V, we have max v∈V h(α, β, γ, i∗ v) = max v∈V 1 − β 1 −i∗v ≤max v∈V  max  1 − β 1 −i∗− , 1 − β 1 −i∗+ v  . Note that 1 − β 1 −i∗− ≥1 −(β + α)2 β , which implies max v∈V  max  1 − β 1 −i∗− , 1 − β 1 −i∗+ v  ≥1 −(β + α)2 β . Therefore, 1 −max v∈V  max  1 − β 1 −i∗− , 1 − β 1 −i∗+ v  ≤min  1 −max v∈V |1 −β/(1 −i∗ v)| , (β + α)2 β  . According to Corollary 1, we obtain the desired result. 3.3 Tighter Bounds for Equilibrium Infection Probabilities in Star and Regular Networks Star networks. A star-shaped network consists of a hub and (N −1) leaves that are connected only to the hub. Hence, the adjacency matrix A can be represented as A =      0 1 . . . 1 1 0 . . . 0 ... ... . . . 0 1 0 . . . 0      N×N The spectral radius is ρ(A) = √ N −1. In this case, Eq. (5) becomes: i∗ h = 1 −C (δCh (1 −γi∗ l ) , 1 −α) β + 1 −C (δCh (1 −γi∗ l ) , 1 −α), (11) i∗ l = 1 −C (1 −γi∗ h, 1 −α) 1 + β −C (1 −γi∗ h, 1 −α), (12) where i∗ h and i∗ l are the equilibrium probabilities that the hub and the leaves are infected, respectively. Note that the effect of the copula Ch on the equilibrium probabilities only depends on its diagonal section δCh. In what follows we present two results about the equilibrium infection probabilities, which are not implied by the above general results that apply to arbitrary network structures. First, we can prove i∗ h ≥i∗ l . Proposition 2 For the star networks, it holds that i∗ h ≥i∗ l . 10 Proof Denote by f(x) = 1 −C (δCh (1 −γx) , 1 −α) β + 1 −C (δCh (1 −γx) , 1 −α) and g(x) = 1 −C (1 −γx, 1 −α) 1 + β −C (1 −γx, 1 −α) where x ∈[0, 1]. Since δCh(x) ≤x, we have f(x) ≥g(x). Suppose i∗ h < i∗ l and (i∗ h, i∗ l ) is a solution to Eqs. (11) and (12). Then, i∗ h = f(i∗ l ) = g−1(i∗ l ) < i∗ l . Since g(x) is increasing in x and so is g−1, we have i∗ l ≤ g(i∗ l ) and f(i∗ l ) < i∗ l ≤g(i∗ l ), which contradicts with f(x) ≥g(x) for x ∈[0, 1]. Second, we present reﬁned bounds for equilibrium infection probabilities i∗ h and i∗ l . The bounds are useful because even in the case of star networks, it is hard to derive analytic expressions and infeasible to numerically compute (especially for complex dependence structures) i∗ h and i∗ l . Proposition 3 (tighter upper bounds for the equilibrium infection probabilities in star networks) For star networks and regardless of the dependence structures (which can be unknown), we have i∗−≤i∗ h ≤i∗+ h and i∗−≤i∗ l ≤ i∗+ l , where i∗−is deﬁned in Proposition 1 and i∗+ h = 1 β + 1I  1 β + 1 ≥ 1 −α (N −1)γ  +(N −1)γ −α −β + p ((N −1)γ −α −β)2 + 4(N −1)γα 2(N −1)γ I  1 β + 1 < 1 −α (N −1)γ  . and i∗+ l = 1 β + 1I  1 β + 1 ≥1 −α γ  + γ −α −β + p (γ −α −β)2 + 4γα 2γ I  1 β + 1 < 1 −α γ  . Proof The lower bound i∗−is the same as in Proposition 1. Let’s focus on i∗+ h . From Ineq. (10), we have i∗ h ≤ min{α + (N −1)γi∗ l , 1} β + min{α + (N −1)γi∗ l , 1} △= f(i∗ l ). Since the right-hand side of the above inequality increases in i∗ l , by Proposition 2 we have i∗ h ≤f(i∗ h), and therefore i∗ h ≤i∗+ h , where i∗+ h is the solution to equation x = f(x). (13) For the upper bound i∗+ l , we can similarly obtain the desired result by solving equation x = f  x N −1  . (14) Now we explain why the upper bounds i∗+ h and i∗+ l given by Proposition 3 are smaller (i.e., tighter) than the general upper bounds that can be derived from Proposition 1 by instantiating G = (V, E) as star networks. To see this, we note that i∗+ h is the solution to Eq. (13) and i∗+ h ≤ 1 β+1, meaning that i∗+ h ≤ min n α + (N −1) γ β+1, 1 o β + min n α + (N −1) γ β+1, 1 o, where the right-hand side of the inequality is exactly the upper bound that can be derived from Proposition 1 by sub- stituting deg(v) with the degree of the hub. This means that i∗+ h is smaller than the upper bound given by Proposition 11 1. Similarly, we can show that i∗+ l is smaller than the upper bound given by Proposition 1. Moreover, by comparing (13) and (14), we see that i∗+ h ≥i∗+ l . Since the lower bound i∗−is the same as the lower bound given by Proposition 1, we conclude that the bounds given by Proposition 3 are tighter than the bounds given by Proposition 1. To see the tightness of the bounds given by Proposition 3, we consider two combinations of dependence structures: (C, Cv)=(Gaussian,Frank) and (C, Cv)=(Gaussian, Clayton) with parameters σ = θ = ξ = 0.1 as reviewed in Section 2. Figure 1 plots i∗ h, i∗ l , i∗−, i∗+ h , and i∗+ l for N = 3, . . . , 81 with (α, β, γ) = (0.5, 0.1, 0.1); all these parameter settings satisfy condition (8). We observe that the upper bound i∗+ h becomes ﬂat for N ≥5, because it causes i∗+ h = 1 β+1 (i.e., independent of N); whereas, the upper bound i∗+ l is ﬂat because it is always independent of N. We observe that the upper bound for hub node, i∗+ h , becomes extremely tight for dense star networks with N > 40. However, the upper bound for leave nodes almost always exhibits that i∗+ l −i∗ l ≈0.011 (i.e., the upper bound overestimates about 0.88 infected nodes for a star network of N = 80 nodes). In any case, the upper bounds only somewhat overestimate the numerical solutions i∗ v’s and thus can be used for decision-making purpose when i∗ v’s are infeasible to compute. 0 20 40 60 80 0.75 0.80 0.85 0.90 0.95 Star Leaves upper bound numerical solution lower bound (a) Hub: (Gaussian, Frank) 0 20 40 60 80 0.83 0.84 0.85 0.86 0.87 Star Leaves upper bound numerical solution lower bound (b) Leaves: (Gaussian, Frank) 0 20 40 60 80 0.75 0.80 0.85 0.90 0.95 Star Leaves upper bound numerical solution lower bound (c) Hub: (Gaussian, Clayton) 0 20 40 60 80 0.83 0.84 0.85 0.86 0.87 Star Leaves upper bound numerical solution lower bound (d) Leaves: (Gaussian, Clayton) Figure 1: Star networks: upper bound i∗+ h for hub (i∗+ l for leaves) vs. numerical solution i∗ h for hub (i∗ l for leaves) vs. lower bound i∗−(for both hub and leaves) with respect to (α, β, γ) = (0.5, 0.1, 0.1) and (C, Cv). Regular networks. For regular networks, each node v ∈V has degree d for some d ∈[1, N −1] and ρ(A) = d. According to Proposition 1, we have i∗ v = 1 −C  Cv  1 −γi∗ v,1, . . . , 1 −γi∗ v,d  , 1 −α  β + 1 −C  Cv  1 −γi∗ v,1, . . . , 1 −γi∗ v,d  , 1 −α , v ∈V. Now we want to present reﬁned bounds for equilibrium infection probability i∗ v. Proposition 4 (tighter upper bound for the equilibrium infection probability in regular networks) For regular network G = (V, E) and regardless of the dependence structures (which can be unknown), we have i∗−≤i∗ v ≤i∗+ for any v ∈V, where i∗−is deﬁned in Proposition 1 and i∗+ = 1 β + 1I  1 β + 1 ≥1 −α γd  + γd −α −β + p (γd −α −β)2 + 4γαd 2γd I  1 β + 1 < 1 −α γd  . Proof Deﬁne function f(x) = min{α + γdx, 1} β + min{α + γdx, 1} and a sequence {xn, n ≥0} with xn = f(xn−1), x0 = 1/(β + 1). Observe that for all v ∈V, we have i∗ v ≤x0 and hence from Ineq. (10), it follows that i∗ v ≤x1 for all v ∈V. By repeating this process, we have i∗ v ≤xn for all n. Since f(x) is increasing and x1 ≤x0, xn is decreasing in n. Thus, we have i∗ v ≤i∗+, which is the solution of the equation x = f(x). If 1 β+1 ≥ 1−α γd , then i∗+ = 1 β+1; otherwise, i∗+ is the positive solution to equation γdx2 + (α + β −γd)x −α = 0. Thus, we obtain the desired result. 12 Note that the upper bound i∗+ given by Proposition 4 is smaller than the upper bound i∗+ v obtained by instantiating deg(v) = d in Proposition 1, because i∗+ v is exactly the x1 deﬁned in the proof of Proposition 4. To see the tightness of bounds i∗−and i∗+ given by Proposition 4, we consider (C, Cv)=(Gaussian,Frank) and (C, Cv)=(Gaussian, Clayton) with parameters σ = θ = ξ = 0.1 as reviewed in Section 2. Figure 2 plots numerical i∗ v, i∗−and i∗+ with respect to node degree d = 2, . . . , 80 with (α, β, γ) = (0.5, 0.1, 0.01); all these parameter settings satisfy condition (8). We observe that i∗+ v becomes ﬂat for sufﬁciently dense regular networks. This is because i∗+ v = 1 β+1 when d ≥ (1−α)(β+1) γ . For (C, Cv)=(Gaussian,Frank), we further observe that the upper bound i∗+ v is reasonably tight especially for relatively sparse regular networks, with i∗+ v −i∗ v < 0.021 for d < 20 (i.e., for a sparse regular network of N = 1000 nodes, the upper bound only overestimates at most 21 infected nodes). Even for dense regular network with d > 20, we have i∗+ v −i∗ v ≤0.038 (i.e., for a dense regular network of N = 1000 nodes, the upper bound only overestimates at most 38 infected nodes), where equality holds for d = 54. For (C, Cv)=(Gaussian, Clayton), we also observe that the upper bound i∗+ v is tight especially for relatively sparse regular networks with d < 20 and i∗+ v −i∗ v < 0.021 (i.e., for a sparse regular network of N = 1000 nodes, the upper bound only overestimates at most 21 infected nodes). Even for dense regular network with d > 20, we have i∗+ v −i∗ v ≤0.039, where equality holds for d = 54. This means that for decision-making purpose, the defender can use the upper bound i∗+ v instead of the numerical solution i∗ v, especially when i∗ v is infeasible to compute. 0 20 40 60 80 0.80 0.85 0.90 0.95 1.00 Regular Degree upper bound numerical solution lower bound (a) (Gaussian,Frank,0.5,0.1,0.01) 0 20 40 60 80 0.80 0.85 0.90 0.95 1.00 Regular Degree upper bound numerical solution lower bound (b) (Gaussian,Clayton,0.5,0.1,0.01) Figure 2: Regular networks: upper bound i∗+ v vs. numerical solution i∗ v vs. lower bound i∗− v with respect to (C, Cv, α, β, γ) 3.4 Approximating Equilibrium Infection Probabilities in ER and Power-law Networks For star and regular networks, we have derived tighter bounds for equilibrium infection probabilities (than the general bounds given by Proposition 1). Unfortunately, we do not know how to derive tighter bounds for ER and power-law networks. As an alternative, we propose to approximate equilibrium infection probabilities by taking advantage of the upper and lower bounds. The approximation is useful because it is often smaller than the upper bound, which never underestimates, but may substantially overestimate, the threats in terms of equilibrium infection probabilities. That is, the approximation method can lead to more cost-effective defense than the upper bound. The approximation method is the following: We ﬁrst compute lower bounds, upper bounds, and numerical solu- tions for a feasible number of instances of (G, C, Cv, α, β, γ), based on given computer resources. We then use the resulting data to derive (via statistical methods) some function of the lower and upper bounds. For even larger G of the same type as well as (C, Cv) of the same kind, the resulting function would be smaller than the upper bound and would not underestimate the equilibrium infection probabilities. The key insight is that we can compute, for networks of any size, the upper and lower bounds according to Proposition 1. This means that we can approximate the equi- librium infection probabilities for arbitrarily large networks, for which it is often infeasible to numerically (let alone analytically) compute the equilibrium infection probabilities. To illustrate the approximation method, we also consider (C, Cv)=(Gaussian,Frank) and (C, Cv)=(Gaussian, Clayton) with parameters σ = θ = ξ = 0.1 as reviewed in Section 2. We use the erdos.renyi.game generator of the igraph package in the R system to generate a random ER network of N = 1000 nodes and edge proba- bility 0.01; the resulting network instance has spectral radius 11.38045. We use the static.power.law.game 13 generator of the igraph package in the R system to generate a random power-law network of N = 1000 nodes, 5000 edges, and power-law exponent 2.1 (note that 2.1 is the power-law exponent of the Internet AS-level net- work [6]); the resulting network instance has spectral radius 22.97582. We consider combinations of (α, β, γ) that satisfy condition (8), where α ∈{0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5}, β ∈{0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9}, γ ∈{0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1}. It turns out that for (C, Cv)=(Gaussian, Frank), the ER network has 307 combinations of (α, β, γ) that satisfy condition (8); the power-law network has 125 combinations of (α, β, γ) that satisfy condition (8), because the spectral radius is larger. For (C, Cv)=(Gaussian, Clayton), the ER network has 307 combinations of (α, β, γ) that satisfy condition (8); the power-law network has 126 combinations of (α, β, γ) that satisfy condition (8). We compute equilibrium infection probability i∗ v numerically by solving Eqs. (5) for v ∈V via the BB package in the R system. We compute the upper and lower bounds, namely i∗−and i∗+ v , according to Proposition 1. Since it is infeasible to numerically compute i∗ v for large networks, we propose to approximate i∗ v for node v ∈V via bi∗v = 1 2  ei∗v + i∗+ v  , where ei∗v = f(C,Cv)(i∗−, i∗+ v , deg(v)) = k0 + k1i∗−+ k2i∗+ v + k3 deg(v) can be statistically derived from the data. Note that the heuristic function bi∗v could be reﬁned via more extensive numerical studies. We deﬁne the approximation error for network G as errG = P v∈V(bi∗v −i∗ v), because P v∈V i∗ v is an important factor for cyber defense decision-making. For practical use, it is desired that errG ≥0, meaning that the defender never underestimates the threats, and at the same time errG ≈0, meaning that the defender does not overestimate the threats (i.e., does not overprovision defense resources) too much. ER networks. For the ER network, we obtain the following formulas : • For (C, Cv)=(Gaussian, Frank), we have bi∗v = −0.01759 + 0.3142i∗−+ 0.7294i∗+ v −0.0002575 deg(v). • For (C, Cv)=(Gaussian, Clayton), we have bi∗v = −0.0174076+0.3150585i∗−+0.7281992i∗+ v −0.0002596 deg(v). For (C, Cv)=(Gaussian, Frank), the average of the errG’s over the 307 combinations of (C, Cv, α, β, γ) is 46, meaning that the approximation method only overestimates 46 infected nodes in an ER network of 1000 nodes. In comparison, the average of the P v∈V(i∗+ v −i∗ v)’s over the 307 combinations of (C, Cv, α, β, γ) is 93, meaning that the upper bound overestimates 93 infected nodes (i.e., the approximation method is indeed better); the average of the P v∈V(i−−i∗ v)’s is -52.7, meaning that the lower bound underestimates 52.7 infected nodes in an ER network of 1000 nodes. Finally, we note that among the 307 combinations of (C, Cv, α, β, γ), the maximum errG is 165.2, which is elaborated in Figure 3(a) and will be discussed further, and the minimum errG is 4.1, which is elaborated in Figure 3(b) and will be discussed further as well. For (C, Cv)=(Gaussian, Clayton), the average of the errG’s over the 307 combinations of (C, Cv, α, β, γ) is 46.5, meaning that the approximation method only overestimates 46.5 infected nodes in an ER network of 1000 nodes. In comparison, the average of the P v∈V(i∗+ v −i∗ v)’s over the 307 combinations of (C, Cv, α, β, γ) is 93, meaning that the upper bound overestimates 93 infected nodes in an ER network of 1000 nodes; the average of the 307 P v∈V(i−−i∗ v)’s is -52.5, meaning that the lower bound underestimates 52.5 infected nodes in an ER network of 1000 nodes. Among the 307 instances, the maximum errG is 165.0, which is elaborated in Figure 3(d) and will be discussed further, and the minimum errG is 4.2, which is elaborated in Figure 3(e) and will be discussed further. In summary, cyber defense decision-making can be based on the approximation method, which takes advantage of the upper and lower bounds and would be better (smaller) than the upper bound. As a side-product, we would like to highlight the phenomenon that the equilibrium infection probability i∗ v in- creases with node degree deg(v). This phenomenon was observed in [19] in the absence of dependence, and persists in the presence of dependence as we elaborate below. We consider i∗+ v , i∗ v, bi∗v and i∗−with respect to distinct node de- grees, by taking the average over the nodes of the same degree when needed. For (C, Cv)=(Gaussian,Frank), Figures 3(a)-3(b) plot the infection probabilities corresponding to the (α, β, γ) that leads to the maximum and minimum errG, respectively; Figure 3(c) plots the infection probabilities averaged over the 307 combinations of (α, β, γ) that satisfy condition (8). For (C, Cv)=(Gaussian,Clayton), Figures 3(d)-3(e) plot the infection probabilities corresponding to 14 5 10 15 20 0.0 0.2 0.4 0.6 0.8 ER Degree upper bound approximation numerical solution lower bound (a) (Gaussian,Frank, 0.01,0.4,0.03) 5 10 15 20 0.20 0.25 0.30 0.35 0.40 ER Degree upper bound approximation numerical solution lower bound (b) (Gaussian,Frank, 0.3,0.9,0.01) 5 10 15 20 0.2 0.4 0.6 0.8 1.0 ER Degree upper bound approximation numerical solution lower bound (c) (Gaussian,Frank) 5 10 15 20 0.0 0.2 0.4 0.6 0.8 ER Degree upper bound approximation numerical solution lower bound (d) (Gaussian,Clayton, 0.01,0.4,0.03) 5 10 15 20 0.20 0.25 0.30 0.35 0.40 ER Degree upper bound approximation numerical solution lower bound (e) (Gaussian,Clayton, 0.3,0.9,0.01) 5 10 15 20 0.2 0.4 0.6 0.8 1.0 ER Degree upper bound approximation numerical solution lower bound (f) (Gaussian,Clayton) Figure 3: ER networks: upper bound vs. approximation vs. numerical solution vs. lower bound with respect to (C, Cv, α, β, γ) or (C, Cv). the (α, β, γ) that leads to the maximum and minimum errG, respectively; Figure 4(f) plots the infection probabilities averaged over the 307 combinations of (α, β, γ) that satisfy condition (8). We observe that the approximation bi∗v can slightly underestimate the infection probability i∗ v for node v of degree deg(v) ≤5, but the overall estimation P v∈V bi∗v is still above the actual threats P v∈V i∗ v (as mentioned above). More importantly, we observe that i∗ v (solid curves) increases with deg(v). This hints that there might be some universal scaling laws, in the presence or absence of dependence. It is an interesting future work to identify the possible scaling law. Power-law networks. For power-law networks, we obtain the following formulas in a similar fashion: • For (C, Cv)=(Gaussian, Frank), we have bi∗v = −0.007395 + 0.34705i∗−+ 0.67205i∗+ v + 0.00013505 deg(v). • For (C, Cv)=(Gaussian, Clayton), we have bi∗v = −0.007365 + 0.34765i∗−+ 0.6714i∗+ v + 0.00013525 deg(v). For (C, Cv)=(Gaussian, Frank), the average of the errG’s over the 125 combinations of (C, Cv, α, β, γ) is 25, mean- ing that the approximation only overestimates 25 infected nodes in a power-law network of 1000 nodes. In com- parison, the average of the P v∈V(i∗+ v −i∗ v)’s over the 125 combinations of (C, Cv, α, β, γ) is 50.8, meaning that the upper bound overestimates 50.8 infected nodes (i.e., the approximation method is better); the average of the P v∈V(i−−i∗ v)’s is -26, meaning that the lower bound underestimates 26 infected nodes. Among the 125 combina- tions of (C, Cv, α, β, γ), the maximum errG is 84.5, which is elaborated in Figure 4(a) and will be discussed further, and the minimum errG is 7.1, which is elaborated in Figure 4(b). For (C, Cv)=(Gaussian, Clayton), the average of the errG’s over the 126 combinations of (C, Cv, α, β, γ) is 25.4, meaning that the approximation only overestimates 25.4 infected nodes in a power-law network of 1000 nodes. In comparison, the average of the P v∈V(i∗+ v −i∗ v)’s over the 126 combinations of (C, Cv, α, β, γ) is 50.8, meaning that the upper bound overestimates 50.8 infected nodes; the average of the 126 P v∈V(i−−i∗ v)’s is -26, meaning that the lower bound underestimates 26 infected nodes. Among the 126 instances, the maximum errG is 84.5, which is elaborated in Figure 4(d), and the minimum errG is 7.2, which 15 is elaborated in Figure 4(e). In summary, cyber defense decision-making can use the approximation method, which takes advantage of the upper and lower bounds. 0 20 40 60 80 0.0 0.2 0.4 0.6 0.8 1.0 Power−law Degree upper bound approximation numerical solution lower bound (a) (Gaussian,Frank, 0.01,0.5,0.02) 0 20 40 60 80 0.4 0.6 0.8 1.0 Power−law Degree upper bound approximation numerical solution lower bound (b) (Gaussian,Frank, 0.2,0.1,0.01) 0 20 40 60 80 0.2 0.4 0.6 0.8 1.0 Power−law Degree upper bound approximation numerical solution lower bound (c) (Gaussian,Frank) 0 20 40 60 80 0.2 0.4 0.6 0.8 1.0 Power−law Degree upper bound approximation numerical solution lower bound (d) (Gaussian,Clayton, 0.01,0.5,0.02) 0 20 40 60 80 0.4 0.6 0.8 1.0 Power−law Degree upper bound approximation numerical solution lower bound (e) (Gaussian,Clayton, 0.2,0.1,0.01) 0 20 40 60 80 0.2 0.4 0.6 0.8 1.0 Power−law Degree upper bound approximation numerical solution lower bound (f) (Gaussian,Clayton) Figure 4: Power-law networks: upper bound vs. approximation vs. numerical solution vs. lower bound with respect to (C, Cv, α, β, γ) or (C, Cv). In Figures 4(b) and 4(e), the approximation result matches the numerical solution almost perfectly. We also would like to highlight the phenomenon that the equilibrium infection probability i∗ v increases with node degree deg(v) in power-law networks. Similarly, for (C, Cv)=(Gaussian,Frank), Figures 4(a)-4(b) plot respectively the infection probabilities corresponding to the (α, β, γ) that leads to the maximum and minimum errG, and Figure 4(c) plots the infection probabilities averaged over the 125 combinations of (C, Cv, α, β, γ) that satisfy condition (8). For (C, Cv)=(Gaussian,Clayton), Figures 4(a)-4(b) plot respectively the infection probabilities corresponding to the (α, β, γ) that leads to the maximum errG, and Figure 4(c) plots the infection probabilities averaged over the 126 combinations of (C, Cv, α, β, γ) that satisfy condition (8). We observe that the approximation bi∗v never underestimates the infection probability i∗ v for any node v. We also observe that i∗ v (solid curves) increases with deg(v), but exhibits a higher nonlinearity when compared with the ER networks. 3.5 Bounds for Non-Equilibrium Infection Probabilities It is important to characterize the behavior of iv(t) even if it never enters any equilibrium. For this purpose, we want to seek some bounds for iv(t), no matter whether the system converges to an equilibrium or not. Such characterization is useful because, for example, the upper bound can be used for the worst-case scenario decision-making. It is worth mentioning that non-equilibrium states/behaviors are always hard to characterize. Proposition 5 (bounds for non-equilibrium probabilities) Let limt→∞iv(t) and limt→∞iv(t) denote the upper and lower limits of iv(t), v ∈V. Then, i− v ≤limt→∞iv(t) ≤limt→∞iv(t) ≤i+ v , 16 where i− v =      1 −C(δCv(1 −γν), 1 −α) β + 1 −C(δCv(1 −γν), 1 −α), C(δCv(1 −γν), 1 −α) ≥β, [β −C(δCv(1 −γν), 1 −α)] (1 −µv) + 1 −β, otherwise, and i+ v =      1 −C  Cv  1 −γµv,1, . . . , 1 −γµv,deg(v)  , 1 −α  β + 1 −C  Cv  1 −γµv,1, . . . , 1 −γµv,deg(v)  , 1 −α , C  Cv  1 −γµv,1, . . . , 1 −γµv,deg(v)  , 1 −α  > β  β −C  Cv  1 −γµv,1, . . . , 1 −γµv,deg(v)  , 1 −α  (1 −i− v ) + 1 −β, otherwise with δCv(1 −γν) = Cv(1 −γν, . . . , 1 −γν), µv = max {1 −β, min{γdeg(v) + α, 1}} and ν = min{1 −β, α}. Proof By observing the monotonicity in Eq. (4), we note that iv(t) ≥ν for all v ∈V. Replacing iv,j(t) with ν in Eq. (4) yields iv(t + 1) ≥ (1 −β)iv(t) + [1 −C (δCv(1 −γν), 1 −α)] (1 −iv(t)) = [C (δCv(1 −γν), 1 −α) −β] iv(t) + 1 −C (δCv(1 −γν), 1 −α) . If C (δCv(1 −γν), 1 −α) > β, by taking the lower limit on both sides we obtain limt→∞iv(t + 1) ≥ 1 −C (δCv(1 −γν), 1 −α) β + 1 −C (δCv(1 −γν), 1 −α). If C (δCv(1 −γν), 1 −α) ≤β, we have iv(t + 1) ≥ [C (δCv(1 −γν), 1 −α) −β] µv + 1 −C (δCv(1 −γν), 1 −α) = [β −C(δCv(1 −γν), 1 −α)] (1 −µv) + 1 −β. Hence, limt→∞iv(t) ≥i− v . For the upper bound, by applying Lemma 1 to Eq. (4) we have iv(t + 1) ≤ (1 −β)iv(t) + [1 −max {max {2 −γdeg(v) −α, 1 −α} −1, 0}] (1 −iv(t)) = (1 −β)iv(t) + min {γdeg(v) + α, 1} (1 −iv(t)) ≤ max {1 −β, min{γdeg(v) + α, 1}} = µv. (15) By replacing iv,j with µv,j’s in Eq. (4) yields iv(t + 1) ≤ (1 −β)iv(t) +  1 −C  Cv  1 −γµv,1, . . . , 1 −γµv,deg(v)  , 1 −α  (1 −iv(t)) =  C  Cv  1 −γµv,1, . . . , 1 −γµv,deg(v)  , 1 −α  −β  iv(t) +1 −C  Cv  1 −γµv,1, . . . , 1 −γµv,deg(v)  , 1 −α  . If C  Cv  1 −γµv,1, . . . , 1 −γµv,deg(v)  , 1 −α  > β, then limt→∞≤ 1 −C  Cv  1 −γµv,1, . . . , 1 −γµv,deg(v)  , 1 −α  β + 1 −C  Cv  1 −γµv,1, . . . , 1 −γµv,deg(v)  , 1 −α . If C  Cv  1 −γµv,1, . . . , 1 −γµv,deg(v)  , 1 −α  ≤β, then we have limt→∞iv(t + 1) ≤ limt→∞  C  Cv  1 −γµv,1, . . . , 1 −γµv,deg(v)  , 1 −α  −β  iv(t) +1 −C  Cv  1 −γµv,1, . . . , 1 −γµv,deg(v)  , 1 −α  ≤  C  Cv  1 −γµv,1, . . . , 1 −γµv,deg(v)  , 1 −α  −β  limt→∞iv(t) +1 −C  Cv  1 −γµv,1, . . . , 1 −γµv,deg(v)  , 1 −α  ≤  C  Cv  1 −γµv,1, . . . , 1 −γµv,deg(v)  , 1 −α  −β  i− v +1 −C  Cv  1 −γµv,1, . . . , 1 −γµv,deg(v)  , 1 −α  . 17 Hence, we have limt→∞iv(t + 1) ≤i+ v . When are the bounds tight? It is important to know when the bounds are tight because the defender can use the upper bound i+ v for decision-making, especially when the spreading never enters any equilibrium. Note that when γ << 1, it holds that C(δCv(1 −γν), 1 −α) ≈C(1, 1 −α) = 1 −α, and C  Cv  1 −γµv,1, . . . , 1 −γµv,deg(v)  , 1 −α  ≈C (Cv (1, . . . , 1) , 1 −α) = 1 −α. Therefore, in the case γ << 1 and α + β < 1, we have i− v ≈ 1 −C(δCv(1 −γν), 1 −α) β + 1 −C(δCv(1 −γν), 1 −α) ≈ α β + α, i+ v ≈ 1 −C  Cv  1 −γµv,1, . . . , 1 −γµv,deg(v)  , 1 −α  β + 1 −C  Cv  1 −γµv,1, . . . , 1 −γµv,deg(v)  , 1 −α  ≈ α β + α. This means that the bounds are tight when the attack-power is not strong. In the case γ deg(v) << 1 and α + β ≥1, we can similarly have i− v ≈α(2 −α −β), i+ v ≈(β + α −1) [1 −α(2 −α −β)] + 1 −β. Therefore, the difference between the upper bound and lower bound is i+ v −i− v ≈α(α + β −1)2. Therefore, the bounds are tight when (α + β) is not far from 1 or α is close to zero. Are the equilibrium bounds always tighter than the non-equilibrium bounds? We observe the following: under the condition γ deg(v) << 1, we have i∗−≈i∗+ v ≈α/(α+β); under the condition γ deg(v) << 1 and the condition α + β < 1, we have i− v ≈i+ v ≈α/(α + β). This means that the equilibrium bounds are widely applicable than the same non-equilibrium bounds, namely that the equilibrium bounds are strictly tighter than the non-equilibrium bounds. 4 Side-Effects of Assuming Away the Dependences In the above we have characterized epidemic equilibrium thresholds, equilibrium infection probabilities, and non- equilibrium infection probabilities while accommodating arbitrary dependences. In order to characterize the side- effects of assuming away the dependences, we consider the degree of dependences as captured by the concordance order between copulas (reviewed in Section 2). In order to draw cyber security insights at a higher level of abstraction, we also consider three kinds of qualitative dependences: positive dependence, independence and negative dependence, whose degrees of dependence are in decreasing order. Speciﬁcally, positive (negative) dependence between the push- based attacks means 1 −Cv  1 −γiv,1, . . . , 1 −γiv,deg(v)  ≥(≤)1 − deg(v) Y j=1 (1 −γiv,j) , and positive (negative) dependence between the push-based attacks and the pull-based attacks means 1 −C  Cv  1 −γiv,1(t), . . . , 1 −γiv,deg(v)(t)  , 1 −α  ≥(≤)1 −(1 −α)Cv  1 −γiv,1(t), . . . , 1 −γiv,deg(v)(t)  , where equality means independence. To simplify the notations, let pd stand for positive dependence, ind stand for independence, and nd stand for negative dependence. Let x ∈{pd, ind, nd} denote the dependence structure between the push-based attacks and the pull-based attacks, as captured by copula C. Let y ∈{pd, ind, nd} denote the dependence structure between the push-based attacks, as captured by copula Cv. Therefore, the dependence structures can be represented by a pair (x, y). 18 4.1 Side-Effects on Equilibrium Infection Probabilities and Thresholds For ﬁxed G = (V, E), α, β, γ, we compare the effects of two groups of dependences (i.e., copulas) {C, Cv, v ∈V} and {C′, C′ v, v ∈V}. Corresponding to the two groups of copulas, we denote by iv(t) and i′ v(t) the respective infection probabilities of node v ∈V at time t ≥0. Let i∗ v,x,y denote the equilibrium infection probability of node v, namely i∗ v, under dependence structure (x, y). Side-effects on the equilibrium infection probabilities. We present a result about the impact of the dependence structures on the equilibrium infection probabilities. This result will allow us to derive the side-effects of assuming away the dependences. Proposition 6 (comparison between the effects of different dependence structures on equilibrium infection probabil- ities) Suppose the condition underlying Lemma 3 holds, namely ρ(A) < (β + α)2 γβ so that system (4) has a unique equilibrium. If for all v ∈V, we have C  Cv  u1, . . . , udeg(v)  , u0  ≤C′  C′ v  u1, . . . , udeg(v)  , u0  , (16) where 0 ≤uj ≤1 for j = 0, . . . , deg(v), then we have i∗≥i′∗. Proof Note that i∗and i′∗are respectively the unique positive solutions of f(i∗) = 0 and g(i′∗) = 0, where f = (f1, . . . , fN) and g = (g1, . . . , gN) with fv(i) =  1 −C  Cv  1 −γiv,1, . . . , 1 −γiv,deg(v)  , 1 −α  (1 −iv) −βiv, v ∈V gv(i) =  1 −C′  C′ v  1 −γiv,1, . . . , 1 −γiv,deg(v)  , 1 −α  (1 −iv) −βiv, v ∈V. Since f(0) = g(0) = α > 0 and f ≥g, we have g(i∗) ≤f(i∗) = 0. Since both f and g are continuous, we have i′∗≤i∗. The cyber security insights/implications of Proposition 6 is: The stronger the negative (positive) dependences between the attack events, the lower (higher) the equilibrium infection probabilities. More speciﬁcally, we have i∗ v,pd,y ≥i∗ v,ind,y ≥i∗ v,nd,y for any y ∈{pd, ind, nd} and i∗ v,x,pd ≥i∗ v,x,ind ≥i∗ v,x,nd for any x ∈{pd, ind, nd}. Therefore, the side-effects of assuming away the dependences between attack events are: If the positive (negative) dependence is assumed away, the resulting equilibrium infection probability underestimates (overestimates) the actual equilibrium infection probability. This means the following: when the positive dependence between attack events is assumed away, the cyber defense decisions based on i∗ v,ind,ind (< i∗ v,pd,pd) can render the deployed defense useless; when the negative dependence is assumed away between attack events, the cyber defense decisions based on i∗ v,ind,ind (> i∗ v,nd,nd) can waste defense resources. We will use numerical examples below to conﬁrm these insights. Another important insight is: if the defender can seek to impose negative dependence on the cyber attacks, the cyber defense effect is better of. We believe that this insight will shed light on research of future cyber defense mechanisms, and highlights the value of theoretical studies in terms of their practical guidance. Side-effects on the epidemic equilibrium threshold. Corollary 1 gives a sufﬁcient condition under which the epidemic spreading enters the equilibrium. Here we deﬁne τ def = min 1 −maxv∈V |1 −β/(1 −i∗ v)| γ , (β + α)2 γβ  , (17) with respect to a group of copulas {C, Cv, v ∈V}. According to Eq. (8), ρ(A) ≤τ means that the epidemic spreading converges to the equilibrium. Similarly, we can deﬁne τ ′ with respect to another group of copulas {C′, C′ v, v ∈V}. We want to compare τ and τ ′ with respect to the relation between {C, Cv, v ∈V} and {C′, C′ v, v ∈V}. 19 Proposition 7 Under the conditions of Proposition 6, namely ρ(A) < (β + α)2 γβ so that system (4) has a unique equilibrium and C  Cv  u1, . . . , udeg(v)  , u0  ≤C′  C′ v  u1, . . . , udeg(v)  , u0  for all v ∈V, we have (i) if 1 −β ≤i∗−, then τ ≤τ ′; (ii) if 1 −β ≥i∗+, then τ ≥τ ′, where i∗+ def = maxv∈V i∗+ v , i∗−and i∗+ v are deﬁned in Proposition 1. Proof According to Proposition 1, we know that i∗−≤i∗ v ≤i∗+, which implies β 1−i∗−≤ β 1−i∗v ≤ β 1−i∗+. According to Eq. (17), τ is decreasing in maxv∈V |1 − β 1−i∗v |. Therefore, τ is decreasing in i∗ v when 1 −β ≤i∗−, and increasing in i∗ v when 1 −β ≥i∗+. By Proposition 6, we get the desired results. In order to draw insights while simplifying the discussion, let τx,y denote the τ as deﬁned in Eq. (17) with respect to dependence structures (x, y). The cyber security implication of Proposition 7 is: First, under some circumstances, the stronger the dependences between the cyber attacks, the more restrictive the epidemic equilibrium threshold. More speciﬁcally, under the condition 1 −β ≤i∗−, we have for all v ∈V: τnd,y ≥τind,y ≥τpd,y and τx,nd ≥τx,ind ≥τx,pd. This means that under the above circumstances, assuming away the positive dependences between the attacks will lead to incorrect epidemic equilibrium threshold, and assuming away the negative dependences between the make the epidemic equilibrium threshold unnecessarily restrictive. This further highlights the value for the defender to render the dependences negative, provided that 1 −β ≤i∗−. Second, under certain other circumstances, the stronger the dependences, the less restrictive the epidemic equilib- rium threshold. More speciﬁcally, under the condition 1 −β ≥i∗+, we have τnd,y ≤τind,y ≤τpd,y and τx,nd ≤τx,ind ≤τx,pd. This means that assuming away the negative dependences between the attacks will lead to incorrect epidemic equi- librium threshold, and assuming away the positive dependences will make the epidemic equilibrium threshold un- necessarily restrictive. Moreover, while rendering the dependences negative can lead to smaller equilibrium infection probabilities, it imposes a very restrictive epidemic equilibrium threshold when 1 −β ≥i∗+. This means that when applying the above insights to guide practice, the defender must be aware of the parameter regions corresponding to the cyber security posture. Numerical examples. In order to illustrate the above analytic results, we consider the example of star network with N = 11 nodes. We assume that the dependence between the push-based and the pull-based attacks can be captured by the Gaussian copula C with parameter σ and the dependence between the push-based attacks launched from the leaves against the hub can be captured by copula Cv, which is the Clayton copula with parameter θ. These two copulas are reviewed in Section 2. We consider two sets of parameters (α, β, γ) = (0.2, 0.5, 0.05) and (α, β, γ) = (0.4, 0.7, 0.05). From Eqs. (11) and (12), we can compute the equilibrium infection probabilities i∗ h for the hub and i∗ l for the leaves, and the threshold τ as deﬁned in (17). Note that the copulas are increasing in their parameters in the concordance order. By Proposition 6, both i∗ h and i∗ l are decreasing in θ (σ) given σ (θ), as conﬁrmed by Tables 1-2. Note that for star networks, the condition 1 −β ≥i∗+ in Proposition 7 can be relaxed as 1 −β ≥i∗+ h , where i∗+ h is deﬁned in Proposition 3. When (α, β, γ) = (0.2, 0.5, 0.05), it is easy to verify 1 −β ≥i∗+ h , meaning that τ is decreasing in θ (σ) for ﬁxed σ (θ). This is conﬁrmed in Table 1. When (α, β, γ) = (0.4, 0.7, 0.05), the condition 1 −β ≤i∗−in Proposition 7 is satisﬁed, meaning that τ is increasing in θ (σ) for ﬁxed σ (θ). This is conﬁrmed in Table 2. These examples also conﬁrm the conclusion i∗ h ≥i∗ l given by Proposition 2. 20 θ σ = 0.5 (nd) σ = 0 (ind) σ = −0.5 (pd) i∗ h i∗ l τ i∗ h i∗ l τ i∗ h i∗ l τ 1.0 .35 .29 14.11 .38 .30 14.31 .40 .31 14.40 1.5 .35 .29 14.11 .38 .30 14.30 .40 .31 14.39 2.0 .35 .29 14.11 .38 .30 14.30 .39 .31 14.39 2.5 .34 .29 14.11 .38 .30 14.30 .39 .31 14.39 3.0 .34 .29 14.11 .37 .30 14.30 .39 .30 14.39 3.5 .34 .29 14.11 .37 .30 14.30 .39 .30 14.38 4.0 .34 .29 14.11 .37 .30 14.30 .39 .30 14.38 4.5 .34 .29 14.11 .37 .30 14.29 .38 .30 14.38 5.0 .34 .29 14.11 .37 .30 14.29 .38 .30 14.38 5.5 .34 .29 14.11 .37 .30 14.29 .38 .30 14.38 6.0 .33 .29 14.11 .36 .30 14.29 .38 .30 14.38 Table 1: (α, β, γ) = (0.2, 0.5, 0.05) θ σ = 0.5 (nd) σ = 0 (ind) σ = −0.5 (pd) i∗ h i∗ l τ i∗ h i∗ l τ i∗ h i∗ l τ 1.0 .39 .37 17.11 .41 .37 16.09 .44 .38 15.20 1.5 .39 .37 17.15 .41 .37 16.16 .43 .38 15.29 2.0 .39 .37 17.18 .41 .37 16.21 .43 .38 15.36 2.5 .39 .37 17.21 .41 .37 16.26 .43 .38 15.43 3.0 .38 .37 17.24 .41 .37 16.31 .43 .38 15.50 3.5 .38 .37 17.27 .41 .37 16.35 .43 .38 15.56 4.0 .38 .37 17.30 .41 .37 16.39 .43 .38 15.62 4.5 .38 .37 17.31 .41 .37 16.43 .42 .38 15.67 5.0 .38 .37 17.33 .41 .37 16.47 .42 .38 15.72 5.5 .38 .37 17.35 .40 .37 16.50 .42 .38 15.77 6.0 .38 .37 17.37 .40 .37 16.53 .42 .38 15.81 Table 2: (α, β, γ) = (0.4, 0.7, 0.05) 21 4.2 Side-Effects on the Non-Equilibrium Infection Probabilities We now investigate the side-effects on the non-equilibrium infection probabilities i(t) = (i1(t), . . . , iN(t)), no matter whether the epidemic spreading converges to equilibrium or not. Proposition 8 (side-effects on the non-equilibrium infection probabilities) Consider two vectors of infection prob- abilities i(t0) ≥i′(t0) at some time t0 ≥0. Let µ = maxv∈V µv = max{1 −β, min{α + γDeg, 1}}, where Deg = maxv∈V deg(v). If condition (16) holds and min v∈V{C (δCv (1 −γµ) , 1 −α)} ≥β, (18) then i(t) ≥i′(t) for all t ≥t0. Proof We need to show that i(t + 1) ≥i′(t + 1) when i(t) ≥i′(t) is given. Note that iv(t + 1) =  C  Cv  1 −γiv,1(t), . . . , 1 −γiv,deg(v)(t)  , 1 −α  −β  (iv(t) −1) + 1 −β, i′ v(t + 1) = h C′  C′ v  1 −γi′ v,1(t), . . . , 1 −γi′ v,deg(v)(t)  , 1 −α  −β i (i′ v(t) −1) + 1 −β. According to Ineq. (15) in the proof of Proposition 5, we have iv(t) ≤µ for all v ∈V. Then, conditions (16) and (18) imply C  Cv  1 −γiv,1(t), . . . , 1 −γiv,deg(v)(t)  , 1 −α  −β ≥ 0, C′  C′ v  1 −γiv,1(t), . . . , 1 −γiv,deg(v)(t)  , 1 −α  −β ≥ 0. Since i(t) ≥i′(t), we have iv(t + 1) ≥  C  Cv  1 −γiv,1(t), . . . , 1 −γiv,deg(v)(t)  , 1 −α  −β  (i′ v(t) −1) + 1 −β ≥  C′  C′ v  1 −γiv,1(t), . . . , 1 −γiv,deg(v)(t)  , 1 −α  −β  (i′ v(t) −1) + 1 −β ≥ h C′  C′ v  1 −γi′ v,1(t), . . . , 1 −γi′ v,deg(v)(t)  , 1 −α  −β i (i′ v(t) −1) + 1 −β = i′ v(t + 1). Since the above holds for all v ∈V, we obtain the desired result. t = 6 t = 7 t = 8 iv(t) i′ v(t) iv(t) i′ v(t) iv(t) i′ v(t) v = 1 0.61 0.60 0.42 0.42 0.57 0.56 2 0.64 0.63 0.39 0.40 0.60 0.58 3 0.56 0.57 0.46 0.45 0.54 0.54 4 0.57 0.57 0.45 0.45 0.55 0.54 5 0.46 0.47 0.54 0.53 0.47 0.48 6 0.60 0.60 0.42 0.42 0.56 0.56 Figure 5: Clayton copulas with (θ, η) = (1, 1.5), (θ, η) = (10, 15), (α, β, γ) = (0.9, 0.9, 0.8). One may wonder if a more succinct result than Proposition 8 could be obtained by, for example, eliminating condition (18). Here we use an example to show that if we eliminate condition (18), then Proposition 8 may not hold. Speciﬁcally, consider the network with six nodes illustrated in Figure 5. Suppose C and the Cv’s for v ∈V are Clayton copulas with positive parameters θ and η, namely C(u1, u2) = h u−θ 1 + u−θ 2 −1 i−1/θ and Cv  u1, . . . , udeg(v)  =   deg(v) X i=1 u−η i −deg(v) + 1   −1/η . 22 Consider two groups of Clayton copulas respectively with parameters (θ, η) = (1, 1.5) and (θ, η) = (10, 15). Denote the corresponding infection probabilities by iv(t) and i′ v(t), respectively. Set (α, β, γ) = (0.9, 0.9, 0.8), and in this case condition (18) is not satisﬁed. Set the initial infection probabilities as i(0) = i′(0) = (0.2, 0.1, 0.3, 0.3, 0.6, 0.2). The table in Figure 5 shows i(t) and i′(t) for t = 6, 7, 8, from which we observe that i(t) ≥i′(t) does not hold. This means that we cannot eliminate condition (18) in Proposition 8. 5 Conclusions We have presented the ﬁrst systematic investigation of cyber epidemic models with dependences. We have derived epidemic equilibrium thresholds, bounds for equilibrium infection probabilities, and bounds for non-equilibrium in- fection probabilities, while accommodating arbitrary dependences between the push-based attacks and the pull-based attacks as well as the dependences between the push-based attacks. In particular, we showed that assuming away the due dependences can render the results thereof unnecessarily restrictive or even incorrect. Our study brings up a range of interesting research problems for further work. First, our characterization study assumes that the dependence or copula structures are given. It is important to know which dependence structures are more relevant than the others in practice. Second, it is ideal to obtain closed-form results on the equilibrium infection probabilities and the non-equilibrium infection probabilities. Third, if we cannot derive closed-form results for the (non-)equilibrium infection probabilities, it is important to seek bounds for these probabilities and systematically analyze their tightness. Acknowledgement. This work was supported in part by ARO Grants # W911NF-12-1-0286 and # W911NF-13-1- 0141, and by AFOSR Grant # FA9550-09-1-0165. References [1] D. Chakrabarti, Y. Wang, C. Wang, J. Leskovec, and C. Faloutsos. Epidemic thresholds in real networks. ACM Trans. Inf. Syst. Secur. 10 (4), 1-26, 2008. [2] F. Chung, L. Lu and V. Vu. Eigenvalues of random power law graphs. Annals of Combinatorics, 7, 21-33, 2003. [3] U. Cherubini, E. Luciano, and W. Vecchiato. Copula methods in ﬁnance. New York: Wiley, 2004. [4] D. Cvetkovic, P. Rowlingson, and S. Simic. An introduction to the theory of graph spectra. Cambridge University Press, UK, 2010. [5] G. Da, M. Xu, and S. Xu. A New Approach to Modeling and Analyzing Security of Networked Systems. Proc. 2014 Symposium and Bootcamp on the Science of Security (HotSoS’14), to appear. [6] A. Ganesh, L. Massoulie, and D. Towsley. The effect of network topology on the spread of epidemics. In Proceed- ings of IEEE Infocom, 2005. [7] A. Granas and J. Dugundji. Fixed Point Theory. Springer-Verlag, New York, 2003. [8] H. Joe. Multivariate models and dependence concepts. Monographs on Statistics and Applied Probability, vol. 73. Chapman & Hall, London, 1997. [9] J. Kephart and S. White. Directed-graph epidemiological models of computer viruses. IEEE Symposium on Se- curity and Privacy, pages 343–361, 1991. [10] W. Kermack and A. McKendrick. A contribution to the mathematical theory of epidemics. Proc. of Roy. Soc. Lond. A, 115:700–721, 1927. [11] X. Li, T. Parker, and S. Xu. A Stochastic Model for Quantitative Security Analysis of Networked Systems. IEEE Transactions on Dependable and Secure Computing, 8(1): 28-43, 2011. 23 [12] C. R. MacCluer. The Many Proofs and Applications of Perron’s Theorem. SIAM Review, 42, 487-498, 2000. [13] A. McKendrick. Applications of mathematics to medical problems. Proc. of Edin. Math. Soceity, 14:98–130, 1926. [14] A.J. McNeila and J. Ne˘slehov´a. Multivariate Archimedean copulas, d-monotone functions and l1-norm symmet- ric distributions. Annals of Statistics, 37, 3059-3097, 2009. [15] R. B. Nelsen. An introduction to copulas, second ed. Springer Series in Statistics. Springer, New York, 2006. [16] P. Van Mieghem, J. Omic and Kooij, R. Virus Spread in Networks. IEEE/ACM Transactions on Networking, 17(1), pp 1-14, 2009. [17] Y. Wang, D. Chakrabarti, C. Wang, and C. Faloutsos. Epidemic spreading in real networks: An eigenvalue viewpoint. Proc. of the 22nd IEEE Symposium on Reliable Distributed Systems (SRDS’03), pages 25–34, 2003. [18] M. Xu and S. Xu. An Extended Stochastic Model for Quantitative Security Analysis of Networked Systems. Internet Mathematics, (8)3, 288-320, 2012. [19] S. Xu, W. Lu, and L. Xu. Push- and Pull-based Epidemic Spreading in Networks: Thresholds and Deeper Insights. ACM Transactions on Autonomous and Adaptive Systems (ACM TAAS), 7(3):32. 2012. [20] S. Xu, W. Lu, and Z. Zhan, A stochastic model of multivirus dynamics, IEEE Trans. Dependable Sec. Comput., vol. 9, no. 1, pp. 30–45, 2012. 24