arXiv:1603.08307v1 [cs.CR] 28 Mar 2016 Cyber Epidemic Models with Dependences Maochao Xu1, Gaofeng Da2 and Shouhuai Xu3 1 Department of Mathematics, Illinois State University mxu2@ilstu.edu 2 Institute for Cyber Security, University of Texas at San Antonio dagfvc@gmail.com 3 Department of Computer Science, University of Texas at San Antonio shxu@cs.utsa.edu (corresponding author) Abstract Studying models of cyber epidemics over arbitrary complex networks can deepen our understanding of cyber security from a whole-system perspective. In this paper, we initiate the investigation of cyber epidemic models that accommodate the dependences between the cyber attack events. Due to the notorious difï¬culty in dealing with such dependences, essentially all existing cyber epidemic models have assumed them away. Speciï¬cally, we introduce the idea of Copulas into cyber epidemic models for accommodating the dependences between the cyber attack events. We investigate the epidemic equilibrium thresholds as well as the bounds for both equilibrium and non- equilibrium infection probabilities. We further characterize the side-effects of assuming away the due dependences between the cyber attack events, by showing that the results thereof are unnecessarily restrictive or even incorrect. Keywords: Copula, Cyber epidemics, dependence, epidemic threshold, spectral radius, infection probability 1 Introduction Cyberspace (or Internet) is perhaps the most complex man-made system. While cyberspace has become an indispens- able part of the society, economy and national security, cyber attacks also have become an increasingly devastating problem. Despite studies and progresses in the past decades, our understanding of cyber security from a whole-system perspective, rather than from a component or building-block perspective, is still at its infant stage. This is caused by many factors, including the dearth of powerful mathematical models that can capture and reason the interactions between the cyber attacks and the cyber defenses. Recently, researchers have started pursuing the cyber-security value of â€œbiological epidemicsâ€-like mathematical models. While conceptually attractive, biological epidemic models cannot be directly used to describe cyber security because there are many cyber-speciï¬c issues. One particular issue, which we initiate its study in the present paper, is the dependences between the cyber attack events. To the best of our knowledge, these dependences have been explic- itly assumed away in essentially all existing cyber epidemic models, perhaps because they are notoriously difï¬cult to cope with. Indeed, accommodating the dependences introduces yet another dimension of difï¬culty to cyber epidemic models that incorporate arbitrary complex network structures. However, the dependences are inherent because, for example, the events that computers get infected are not independent of each other, and a malware may ï¬rst infect some computers because the users visit some malicious websites and then spread over the network. Moreover, cyber attacks may be well coordinated by intelligent malwares, and the coordination causes positive dependences between the attack events. 1.1 Our contributions In this paper, we initiate the systematic study of a new sub-ï¬eld in cyber epidemic models, namely understanding and characterizing the importance of the dependences between the attack events in cyber epidemic models that ac- commodate arbitrary complex network structures. This is demonstrated through a non-trivial generalization of the 1 powerful push- and pull-based cyber epidemic model that was recently investigated in [19]. Speciï¬cally, we capture the dependences between the cyber attack events by incorporating the idea of Copulas into cyber epidemic models. To the best of our knowledge, this is the ï¬rst systematic study of cyber epidemic models that accommodate dependences, rather than assuming them away. Speciï¬cally, we make two contributions. First, we derive epidemic equilibrium thresholds, namely sufï¬cient conditions under which the epidemic spread- ing enters a non-negative equilibrium (the spreading never dies out when there are pull-based attacks, meaning that only positive equilibrium is relevant under this circumstance). Some of the sufï¬cient conditions are less restrictive but require hard-to-obtain information (i.e., these conditions are theoretically more interesting), and the others are more restrictive but require easy-to-obtain information (i.e., these conditions are practically more useful). We also derive bounds for the equilibrium infection probabilities and discuss their tightness. The bounds are easy to obtain/compute, and are useful especially when it is infeasible to obtain the equilibrium infection probabilities numerically (let alone analytically). For example, the upper bounds can be treated as the worst-case scenarios when provisioning defense resources. For ErdËos-RÂ´enyi (ER) and power-law networks, we further propose to approximate the equilibrium infec- tion probabilities by taking advantage of the bounds. The approximation results are smaller than the upper bounds and would not underestimate the number of infected nodes, meaning that the approximation results can lead to more cost-effective defense. We further present bounds for non-equilibrium infection probabilities, no matter whether the spreading converges to equilibrium or not. All the results are obtained by explicitly accommodating the dependence structures between the cyber attack events. Second, we characterize the side-effects of assuming away the due dependences on the bounds for equilibrium infection probabilities, on the epidemic equilibrium thresholds, and on the non-equilibrium infection probabilities. We show that assuming away the due dependences can make the results thereof unnecessarily restrictive or even incorrect. We further discuss the cyber security implications of the side-effects. It is worth mentioning that as a ï¬rst step towards ultimately tackling the dependence problem in cyber epidemic models, the Copulas technique, which we use in the present paper, is appealing because of the following. On one hand, it leads to tractable models, while capable of coping with high-dimensional dependence (i.e., dependence between a large vector of random variables). On the other hand, there are families of copula structures that have been extensively investigated in the literature of Applied Probability Theory and Risk Management, and various methods have been developed for estimating the types and parameters of copula structures in practice. Of course, much research remains to be done before we can answer questions such as: What approach is the most appropriate for accommodating dependence in cyber epidemic models, under what circumstances? 1.2 Related work Biological epidemic models can be traced back to McKendrick and Kermack [13, 10]. Such homogeneous biological epidemic models were introduced to computer science for characterizing the spreading of computer viruses in [9]. Heterogeneous epidemic models, especially the ones that accommodate arbitrary network structures, were not studied until recently [17, 6, 1]. These studies led to the full-ï¬‚edged push- and pull-based cyber epidemic model [19], which is the starting point of the present paper. To the best of our knowledge, all existing cyber epidemic models, which aim to accommodate arbitrary network structures (including other recent studies such as [16, 11, 20] and the references therein), assumed that the attacks are independent of each other. This is plausible because accommodating arbitrary network structures in cyber epidemic models already make the resulting models difï¬cult to analyze, and accommodating dependences introduces, as we show in the present paper, another dimension of difï¬culty to the models. The only exception is due to our recent study [18], which is based on a different approach to modeling cyber epi- demics [11]. The main contribution of [18] is to get rid of the exponential distribution assumptions for certain random variables. Moreover, the model in [18] can only accommodate the speciï¬c Marshall-Olkin dependence structure be- tween the attack events. In contrast, we here accommodate arbitrary dependence structures between the attack events, while investigating the epidemic equilibrium thresholds, the equilibrium and non-equilibrium infection probabilities, and the side-effects of assuming away the due dependences. Many of these issues are not studied in the context of [18] because its focus is different. This explains why the present paper is the ï¬rst systematic treatment of dependences in 2 cyber epidemic models. The dependence modeled in the present paper is static (i.e., time-invariant). This study inspired [5], which makes a further step towards modeling dynamic dependence between cyber attacks, but using a different modeling approach. The rest of the paper is organized as follows. In Section 2 we brieï¬‚y review some facts about Copulas. In Section 3 we investigate the generalized cyber epidemic model that accommodates the dependences between the cyber attack events. In Section 4 we characterize the side-effects as caused by assuming away the due dependences. In Section 5, we conclude the paper with future research problems. The following table summarizes the main notations used in the paper. G = (V, E) the graph/network in which cyber epidemics occurs, where V is the node set and E is the edge set deg(v) the degree of node v in graph G = (V, E), which can be represented by adjacency matrix A Iv(t), Iv,j(t) the state of node v at time t: Iv(t) = 1 means infected and 0 means secure; Iv,j(t) is the state of the jth neighbor of node v (1 means infected and 0 means secure), where 1 â‰¤j â‰¤deg(v) iv(t) the probability that node v âˆˆV is infected at time t iv,j(t) the condition probability that at time t node v âˆˆV is secure but the jth neighbor of node v is infected iâˆ’ v , i+ v lower and upper bounds for the non-equilibrium infection probability limtâ†’âˆiv(t), where the sys- tem does not converge to any equilibrium iâˆ— v, iâˆ— v,j the equilibrium infection probabilities that node v and its jth neighbor are infected, respectively iâˆ—âˆ’, iâˆ—+ v iâˆ—âˆ’is the lower bound for the equilibrium infection probability iâˆ— v for every v, iâˆ—+ v is the upper bound for the equilibrium infection probability iâˆ— v of node v iâˆ—, iâˆ— v iâˆ—= (iâˆ— 1, . . . , iâˆ— N) where N = |V|, iâˆ— v = (iâˆ— v,1, . . . , iâˆ— v,deg(v)) Î± the probability that a secure node v âˆˆV is infected by pull-based cyber attacks at a time step Î² the probability that an infected node v âˆˆV becomes secure at a time step Î³ the probability that an infected node u successfully attacks node v over (u, v) âˆˆE at a time step Ï(M) spectral radius of matrix M Cv deg(v)-copula describing the dependence between the push-based cyber attacks against node v C 2-copula describing the dependence between the pull-based attacks and the push-based attacks against a node Î´C the diagonal section of copula C, i.e., Î´C(u) = C(u, . . . , u) 2 Preliminaries Copulas can model dependences by relating the individual marginal distributions to their multivariate joint distribu- tion. In this paper we will use the n-copulas [8, 15]. Speciï¬cally, a function C : [0, 1]n 7â†’[0, 1] is called n-copula if: â€¢ C(u1, . . . , un) is increasing in each component uz, z âˆˆ{1, . . . , n}. â€¢ C(u1, . . . , uzâˆ’1, 0, uz+1, . . . , un) = 0 for all uj âˆˆ[0, 1], j = 1, . . . , n, j Ì¸= z. â€¢ C(1, . . . , 1, uz, 1, . . . , 1) = uz for all uz âˆˆ[0, 1], z = 1, . . . , n. â€¢ C is n-increasing, i.e., for all (u1,1, . . . , u1,n) and (u2,1, . . . , u2,n) in [0, 1]n with u1,j â‰¤u2,j and for all j = 1, . . . , n, it holds that 2 X z1=1 . . . 2 X zn=1 (âˆ’1) Pn j=1 zjC(uz1,1, . . . , uzn,n) â‰¥0. Let R1, . . . , Rn be random variables with distribution functions F1, . . . , Fn, respectively. The joint distribution function is F(r1, . . . , rn) = P (R1 â‰¤r1, . . . , Rn â‰¤rn). The well-known Sklarâ€™s theorem states that there exists an n-copula C such that F(r1, . . . , rn) = C (F1(r1), . . . , Fn(rn)) . 3 There are many families of copulas [8, 15]. One example is the Gaussian copula with C(u1, . . . , un) = Î¦P  Î¦âˆ’1(u1), . . . , Î¦âˆ’1(un)  , where Î¦âˆ’1 is the inverse cumulative distribution function of the standard normal distribution and Î¦P is the joint cumulative distribution function of a multivariate normal distribution with mean vector zero and covariance matrix equal to the correlation matrix P. For simplicity, we assume that the correlation matrix has the form X = ï£« ï£¬ ï£¬ ï£­ 1 Ïƒ . . . Ïƒ Ïƒ 1 Ïƒ Ïƒ . . . Ïƒ Ïƒ . . . 1 ï£¶ ï£· ï£· ï£¸, where Ïƒ measures the correlation between two random variables. Therefore, the Gaussian copula can be rewritten as C(u1, . . . , un) = Î¦Ïƒ  Î¦âˆ’1(u1), . . . , Î¦âˆ’1(un)  . Another example is the Archimedean family with C(u1, . . . , un) = Ï†âˆ’1 (Ï†(u1) + . . . + Ï†(un)) , where function Ï† is called a generator of C and satisï¬es certain properties (see [14] for details). The Archimedean family contains many well-known copula functions such as the Clayton and Frank copulas [15, 3]. The generator of the Clayton copula is Ï†Î¸(u) = uâˆ’Î¸ âˆ’1, and we have C(u1, . . . , un) = ï£® ï£° n X j=1 uâˆ’Î¸ j âˆ’n + 1 ï£¹ ï£» âˆ’1/Î¸ , Î¸ > 0. The generator of the Frank copula is ÏˆÎ¾(u) = log  eâˆ’Î¾uâˆ’1 eâˆ’Î¾âˆ’1  , and we have C(u1, . . . , un) = âˆ’1 Î¾ log ( 1 + Qn j=1(eâˆ’Î¾uj âˆ’1) (eâˆ’Î¾ âˆ’1)nâˆ’1 ) , Î¾ > 0. For illustration purpose, we will use the Gaussian, Clayton and Frank copulas as examples. In order to compare the effects of dependences, we need to compare the degrees of dependences. For this purpose, we use the concordance order [15, 8]. Let C1 and C2 be two copulas, we say C1 is less than C2 in concordance order if C1(u1, . . . , un) â‰¤C2(u1, . . . , un) for all 0 â‰¤ui â‰¤1, i = 1, . . . , n. In particular, Gaussian copulas and Clayton copulas are increasing in Ïƒ and Î¸ in concordance order, respectively. The following lemmas will be used in the paper. Lemma 1 ([15]) Let C be any n-copula, then max ï£± ï£² ï£³ n X j=1 uj âˆ’n + 1, 0 ï£¼ ï£½ ï£¾â‰¤C(u1, . . . , un) â‰¤min{u1, . . . , un}. Lemma 2 ([15]) Let C be an n-copula, then |C(u1, . . . , un) âˆ’C(v1, . . . , vn)| â‰¤ n X j=1 |uj âˆ’vj|. 4 3 Cyber Epidemic Model With Arbitrary Dependences Now we present and investigate the cyber epidemic model that accommodates the dependences between the cyber attack events. This is the ï¬rst systematic treatment of dependences in cyber epidemic models. 3.1 The Model As in [19], we consider an undirected ï¬nite network graph G = (V, E), where V = {1, 2, . . . , N} is the set of N = |V| nodes (vertices) that can abstract computers (or software components at an appropriate resolution), and E = {(u, v) : u, v âˆˆV} is the set of edges. Note that G abstracts the network structure according to which the push-based cyber attacks take place (e.g., malware spreading), where (u, v) âˆˆE abstracts that node u can attack node v. In both principle and practice, G can range from a complete graph (i.e., any u âˆˆV can directly attack any v âˆˆV) to any speciï¬c graph structure (i.e., node u may not be able to attack node v directly because, for example, the trafï¬c from node u is ï¬ltered or u is blacklisted by v), which explains why we should pursue general results without restricting the network/graph structures. Denote by A = (avu) the adjacency matrix of G, where avu = 1 if and only if (u, v) âˆˆE, and avu = 0 otherwise. Note that the problem setting naturally implies avv = 0. Denote by deg(v) the degree of node v. In a discrete-time model, node v âˆˆV is either secure (but vulnerable to attacks) or infected (and can attack other nodes) at any time t = 0, 1, . . .. At each time step, an infected node v becomes secure with probability Î², which abstracts the defense power. The model accommodates two large classes of cyber attacks: a secure node v can become infected because of (i) pull-based cyber attacks with probability Î±, which include drive-by-download attacks (i.e., node v getting infected because its user visits a malicious website) and insider attacks (i.e., the user intentionally runs a malware on node v), or (ii) push-based cyber attacks launched by vâ€™s infected neighbor u over edge (u, v) âˆˆE with probability Î³. Our extension to the above model is to accommodate the dependences between the push-based attacks as well as the dependences between the push-based attacks and the pull-based attacks. These attacks are not independent because the events that the nodes get infected are not independent of each other, and because the push-based attacks are not independent of the pull-based attacks (e.g., a malware could ï¬rst infect some nodes via the pull-based cyber attacks and then launch the push-based cyber attacks from the infected nodes). Moreover, the dependences between the push-based attacks can model that intelligent malwares launch coordinated attacks against the secure nodes. Speciï¬cally, let Iv(t) denote the state of node v at time t, where Iv(t) = 1 means v is infected and 0 means v is secure. Let  Iv,1(t), . . . , Iv,deg(v)(t)  denote the state vector of node vâ€™s neighbors at time t, where Iv,j(t) =  1, the jth neighbor of node v is infected at time t, 0, otherwise. Deï¬ne iv(t) = P(Iv(t) = 1) and iv,j(t) = P(Iv,j(t) = 1|Iv(t) = 0) where j = 1, . . . , deg(v). Let Xv(t) = 1 denote the event that node v is infected at time t + 1 because of the push-based cyber attacks, and Xv(t) = 0 otherwise. Let Xv,j(t + 1) = 1 denote the event that node v is infected at time t + 1 by its jth neighbor, and Xv,j(t + 1) = 0 otherwise. Note that P(Xv,j(t + 1) = 1|Iv(t) = 0) = Î³ Â· iv,j(t). Since any dependence structure between Xv,1(t + 1), . . . , Xv,deg(v)(t + 1) always can be accommodated by some copula function Cv, we have P(Xv(t + 1) = 0|Iv(t) = 0) = Cv  1 âˆ’P(Xv,1(t + 1) = 1|Iv(t) = 0), . . . , 1 âˆ’P(Xv,deg(v)(t + 1) = 1|Iv(t) = 0)  = Cv  1 âˆ’Î³iv,1(t), . . . , 1 âˆ’Î³iv,deg(v)(t)  . (1) Similarly, let Yv(t + 1) = 1 denote the event that node v is infected at time t + 1 because of the pull-based cyber attacks. Then, we have P(Yv(t + 1) = 1|Iv(t) = 0) = Î±. By further accommodating the dependence structure between the push-based attacks and the pull-based attacks via some copula function C, we have P(Iv(t + 1) = 1|Iv(t) = 0) = 1 âˆ’P (Xv(t + 1) = 0, Yv(t + 1) = 0|Iv(t) = 0) = 1 âˆ’C  Cv  1 âˆ’Î³iv,1(t), . . . , 1 âˆ’Î³iv,deg(v)(t)  , 1 âˆ’Î±  . (2) 5 Note that P(Iv(t + 1) = 1|Iv(t) = 1) = (1 âˆ’Î²)iv(t). (3) From Eqs. (1), (2) and (3), we obtain the probability that node v âˆˆV is infected at time t + 1 as: iv(t + 1) = P(Iv(t + 1) = 1) = P(Iv(t + 1) = 1|Iv(t) = 1)P(Iv(t) = 1) + P(Iv(t + 1) = 1|Iv(t) = 0)P(Iv(t) = 0) = (1 âˆ’Î²) Â· iv(t) + P(Iv(t + 1) = 1|Iv(t) = 0) Â· (1 âˆ’iv(t)) = (1 âˆ’Î²)iv(t) +  1 âˆ’C  Cv  1 âˆ’Î³iv,1(t), . . . , 1 âˆ’Î³iv,deg(v)(t)  , 1 âˆ’Î±  (1 âˆ’iv(t)). (4) We will analyze Eq. (4) for v âˆˆV to characterize the effects of the dependence structures C and Cv and the side-effects of assuming them away. Note that for the special case that the Xv,jâ€™s are independent of each other and the push-based attacks and the pull-based attacks are also independent of each other, Eq. (4) degenerates to the model in [19]. Note also that in order to characterize the side-effects of assuming away the dependences, we need to accommodate the dependences at a higher-level of abstraction than the model parameters Î± and Î³. This is because the parameters are indeed relatively easier to obtain in experiments/practice (e.g., considering a single compromised neighbor that is launching the push-based attacks, and considering the pull-based attacks in the absence of the push- based attacks). 3.2 Epidemic Equilibrium Threshold and Bounds for Equilibrium Infection Probabilities The concept of epidemic equilibrium threshold [19] naturally extends the well-known concept of epidemic threshold in that the former describes the condition under which the epidemic spreading converges to a non-negative equilibrium, whereas the latter traditionally describes the condition under which the epidemic spreading converges to 0 (i.e., the spreading dies out). Note that Î± > 0 implies that the spreading will never die out and that Î± = 0 is necessary for the spreading to die out. Denote by iâˆ— v the equilibrium infection probability for node v âˆˆV. In the equilibrium, Eq. (4) becomes: iâˆ— v = (1 âˆ’Î²)iâˆ— v + h 1 âˆ’C  Cv  1 âˆ’Î³iâˆ— v,1, . . . , 1 âˆ’Î³iâˆ— v,deg(v)  , 1 âˆ’Î± i (1 âˆ’iâˆ— v), v âˆˆV. (5) In what follows, Theorem 1 gives a general epidemic equilibrium threshold (i.e., sufï¬cient condition under which the spreading enters the equilibrium), and Theorem 2 gives a more succinct but more restrictive sufï¬cient condition. Lemma 3 Let A be the adjacency matrix of G. If Ï(A) < (Î² + Î±)2 Î³Î² , (6) then system (4) has a unique equilibrium (iâˆ— 1, . . . , iâˆ— N) âˆˆ[0, 1]N. Proof For any v âˆˆV, deï¬ne fv(x) : [0, 1]N â†’[0, 1] as fv(x) = 1 âˆ’C  Cv  1 âˆ’Î³xv,1, . . . , 1 âˆ’Î³xv,deg(v)  , 1 âˆ’Î±  Î² + 1 âˆ’C  Cv  1 âˆ’Î³xv,1, . . . , 1 âˆ’Î³xv,deg(v)  , 1 âˆ’Î± , v = 1, . . . , N, where x = (x1, . . . , xN) âˆˆ[0, 1]N. Deï¬ne f(Â·) : [0, 1]N â†’[0, 1]N, where f(x) = (f1(x), . . . , fN(x)). According to the Banach ï¬xed-point theorem [7], it is sufï¬cient to show that f(x) = x has a unique solution iâˆ—; that is, we need to prove that f(Â·) is a contraction mapping. Let x, y âˆˆ[0, 1]N. Consider the distance between them in the Euclidean norm, ||f(x) âˆ’f(y)|| = v u u t N X v=1 (fv(x) âˆ’fv(y))2 = v u u t N X v=1 Î²Î“v âˆ†v 2 , 6 where Î“v = C  Cv  1 âˆ’Î³xv,1, . . . , 1 âˆ’Î³xv,deg(v)  , 1 âˆ’Î±  âˆ’C  Cv  1 âˆ’Î³yv,1, . . . , 1 âˆ’Î³yv,deg(v)  , 1 âˆ’Î±  , âˆ†v =  Î² + 1 âˆ’C  Cv  1 âˆ’Î³xv,1, . . . , 1 âˆ’Î³xv,deg(v)  , 1 âˆ’Î±  Â·  Î² + 1 âˆ’C  Cv  1 âˆ’Î³yv,1, . . . , 1 âˆ’Î³yv,deg(v)  , 1 âˆ’Î±  . By Lemmas 1 and 2, it follows that |Î“v| â‰¤Î³ deg(v) X k=1 |xv,k âˆ’yv,k| and âˆ†v â‰¥(Î² + Î±)2. Therefore, we have ||f(x) âˆ’f(y)|| â‰¤ Î²Î³ (Î² + Î±)2 v u u u t N X v=1 ï£« ï£­ deg(v) X k=1 |xv,k âˆ’yv,k| ï£¶ ï£¸ 2 . Moreover, N X v=1 ï£« ï£­ deg(v) X k=1 |xv,k âˆ’yv,k| ï£¶ ï£¸ 2 = (|x1 âˆ’y1|, . . . , |xN âˆ’yN|)A2(|x1 âˆ’y1|, . . . , |xN âˆ’yN|)T â‰¤ ||(|x1 âˆ’y1|, . . . , |xN âˆ’yN|)||2||A||2 = ||x âˆ’y||2||A||2, where ||A|| denotes the operator norm of A. Since A is symmetric matrix, we have ||A|| = Ï(A). From condition (6), it follows that ||f(x) âˆ’f(y)|| â‰¤ Î²Î³Ï(A) (Î² + Î±)2 ||x âˆ’y|| < ||x âˆ’y||, which means that f(Â·) is a contraction mapping. Theorem 1 (general epidemic equilibrium threshold) Let A be the adjacency matrix of G and D be the diagonal matrix with the vth (1 â‰¤v â‰¤N) diagonal element equal to h(Î±, Î², Î³, iâˆ— v) = C  Cv  1 âˆ’Î³iâˆ— v,1, . . . , 1 âˆ’Î³iâˆ— v,deg(v)  , 1 âˆ’Î±  âˆ’Î² , where iâˆ— v is the equilibrium infection probability that satisï¬es Eq. (5). Let W = D+Î³A. If condition (6) holds, namely that system (4) has a unique equilibrium, and the spectral radius Ï(W) < 1, then limtâ†’âˆiv(t) = iâˆ— v exponentially for all v âˆˆV. Proof According to Lemma 3, there is a unique solution for iâˆ— v under condition (6). Denote by rv(t) = iv(t) âˆ’iâˆ— v. We want to identify a sufï¬cient condition under which limtâ†’âˆ|rv(t)| = 0 for all v âˆˆV . Note that rv(t + 1) = rv(t) h C  Cv  1 âˆ’Î³iâˆ— v,1, . . . , 1 âˆ’Î³iâˆ— v,deg(v)  , 1 âˆ’Î±  âˆ’Î² i + (1 âˆ’iv(t)) Ã— h C  Cv  1 âˆ’Î³iâˆ— v,1, . . . , 1 âˆ’Î³iâˆ— v,deg(v)  , 1 âˆ’Î±  âˆ’C  Cv  1 âˆ’Î³iv,1(t), . . . , 1 âˆ’Î³iv,deg(v)(t)  , 1 âˆ’Î± i . 7 By Lemma 2, we have |rv(t + 1)| â‰¤ |rv(t)|h(Î±, Î², Î³, iâˆ— v) + (1 âˆ’iv(t)) Ã— Cv  1 âˆ’Î³iâˆ— v,1, . . . , 1 âˆ’Î³iâˆ— v,deg(v)  âˆ’Cv  1 âˆ’Î³iv,1(t), . . . , 1 âˆ’Î³iv,deg(v)(t)  â‰¤ |rv(t)|h(Î±, Î², Î³, iâˆ— v) + Î³ (1 âˆ’iv(t)) deg(v) X j=1 |iâˆ— v,j âˆ’iv,j(t)| â‰¤ |rv(t)|h(Î±, Î², Î³, iâˆ— v) + Î³ deg(v) X j=1 |rv,j(t)|, where h(Î±, Î², Î³, iâˆ— v) = C  Cv  1 âˆ’Î³iâˆ— v,1, . . . , 1 âˆ’Î³iâˆ— v,deg(v)  , 1 âˆ’Î±  âˆ’Î² . Deï¬ne zv(t + 1) = zv(t)h(Î±, Î², Î³, iâˆ— v) + Î³ deg(v) X j=1 zv,j(t), with zv(0) â‰¡|rv(0)| and zv,j(0) â‰¡|rv,j(0)| for j = 1, . . . , deg(v). We see |rv(t)| â‰¤zv(t) for any t. Let z(t) = (z1(t), . . . , zn(t))T . Then, we have the following matrix form z(t + 1) = Wz(t) = W t+1z(0), (7) where W = D + Î³A, D is the diagonal matrix with diagonal element h(Î±, Î², Î³, iâˆ— v), and A is the adjacency matrix of G. Since matrix W is nonnegative and symmetric, the Spectral Theorem [12] says that Ï(W) is real. By using the well-known Gelfand formula, if Ï(W) < 1, then limtâ†’âˆW t = 0 and therefore limtâ†’âˆz(t) = 0. Since Ï(W) = lim tâ†’âˆâˆ¥W t âˆ¥1/t and âˆ¥W t âˆ¥âˆ¼[Ï(W)]t , t â†’âˆ, where âˆ¥Â· âˆ¥is the norm in real space Rn, we conclude that âˆ¥W t âˆ¥converges to 0 exponentially when Ï(W) < 1. This means that the convergence rate of limtâ†’âˆi(t) = iâˆ—is at least exponential. Use of the sufï¬cient condition given by Theorem 1 requires to know iâˆ—(i.e., iâˆ— v for all v), which is difï¬cult to obtain analytically. It is therefore important to weaken this requirement. Now we present a sufï¬cient condition that only requires the equilibrium infection probability iâˆ— v for some v (rather than for all v âˆˆV). According to [4], we have Ï(W) â‰¤max vâˆˆV h(Î±, Î², Î³, iâˆ— v) + Î³Ï(A). Therefore, a more restrictive (than the one given by Theorem 1) sufï¬cient condition is to require max vâˆˆV h(Î±, Î², Î³, iâˆ— v) + Î³Ï(A) < 1, namely Ï(A) < 1 âˆ’maxvâˆˆV h(Î±, Î², Î³, iâˆ— v) Î³ . According to Eq. (5), we have h(Î±, Î², Î³, iâˆ— v) = 1 âˆ’ Î² 1 âˆ’iâˆ—v . Therefore, we obtain the following more restrictive, but more succinct, sufï¬cient condition: Corollary 1 limtâ†’âˆiv(t) = iâˆ— v exponentially for all v âˆˆV, if Ï(A) â‰¤min 1 âˆ’maxvâˆˆV |1 âˆ’Î²/(1 âˆ’iâˆ— v)| Î³ , (Î² + Î±)2 Î³Î²  . (8) 8 Applying the above sufï¬cient condition still requires to know the minimal and maximal iâˆ— vâ€™s, which is hard to obtain analytically. Although it is always possible to obtain them numerically, we would want to have some more general results without relying on numerical solutions. In what follows we present such a sufï¬cient condition (Theo- rem 2), which requires the following Proposition 1 that presents bounds for the equilibrium infection probability. The bounds are certainly of independent value. Proposition 1 (bounds for equilibrium infection probabilities) For any dependence structures C and Cv, which may be unknown, the equilibrium infection probability iâˆ— v for v âˆˆV satisï¬es iâˆ—âˆ’â‰¤iâˆ— v â‰¤iâˆ—+ v , where iâˆ—âˆ’= Î³ âˆ’Î² Î³ I{Î³ > Î± + Î²} + Î± Î² + Î±I{Î³ â‰¤Î± + Î²}, iâˆ—+ v = min n Î± + Î³deg(v) Î²+1 , 1 o Î² + min n Î± + Î³deg(v) Î²+1 , 1 o. Proof Rewrite Eq. (5) as iâˆ— v = 1 âˆ’C  Cv  1 âˆ’Î³iâˆ— v,1, . . . , 1 âˆ’Î³iâˆ— v,deg(v)  , 1 âˆ’Î±  Î² + 1 âˆ’C  Cv  1 âˆ’Î³iâˆ— v,1, . . . , 1 âˆ’Î³iâˆ— v,deg(v)  , 1 âˆ’Î± . (9) By noticing the monotonicity in (9) and applying Lemma 1, we obtain max n Î³iâˆ— v,1, . . . , Î³iâˆ— v,deg(v), Î± o Î² + max n Î³iâˆ— v,1, . . . , Î³iâˆ— v,deg(v), Î± o â‰¤iâˆ— v â‰¤ min n Î± + Î³ Pdeg(v) j=1 iâˆ— v,j, 1 o Î² + min n Î± + Î³ Pdeg(v) j=1 iâˆ— v,j, 1 o. (10) Let us ï¬rst consider the lower bound. Note that for each v âˆˆV, iâˆ— v â‰¥x1 def = Î± Î² + Î±. By substituting x1 for iâˆ— v,j in Ineq. (10), we have iâˆ— v â‰¥x2 â–³= max {Î³x1, Î±} Î² + max {Î³x1, Î±}. By substituting x2 for iâˆ— v,j in Ineq. (10), we obtain x3. By repeating the substitution, we obtain a sequence {xn, n â‰¥1} with xn = max {Î³xnâˆ’1, Î±} Î² + max {Î³xnâˆ’1, Î±}, x0 = 0. Since {xn, n â‰¥1} is increasing and bounded, we can get its limit, namely iâˆ—âˆ’, by solving the following equation max{Î³x, Î±} Î² + max{Î³x, Î±} = x. For the upper bound, note that iâˆ— v â‰¤ 1 Î² + 1 for v âˆˆV. By substituting 1/(Î² + 1) for iâˆ— v,j in Ineq. (10), we get iâˆ—+ v . It is useful to know when the bounds in Proposition 1 are tight. For this purpose, we observe that if Î³ Î²+1 deg(v) â‰ˆ 0, meaning that Î³ deg(v) << 1 and that the attack-power is not strong, we have iâˆ—+ v â‰ˆiâˆ—âˆ’= Î± Î² + Î±. This means that the bounds are tight when the attack-power is not strong. On the other hand, Proposition 1 allows us to derive the following more succinct, but more restrictive (than Corollary 1 and therefore Theorem 1), sufï¬cient condition for the epidemic spreading converges to the equilibrium (i.e., epidemic equilibrium threshold). The new sufï¬cient condition involves the bounds iâˆ—âˆ’and iâˆ—+ v only (i.e., none of the equilibrium probabilities that are hard to obtain analytically). 9 Theorem 2 (succinct epidemic equilibrium threshold) The spreading enters the unique equilibrium if Ï(A) â‰¤ 1 âˆ’max vâˆˆV  max  1 âˆ’ Î² 1 âˆ’iâˆ—âˆ’ , 1 âˆ’ Î² 1 âˆ’iâˆ—+ v  Î³ , where iâˆ—âˆ’and iâˆ—+ v are deï¬ned in Proposition 1. Proof Note that for any v âˆˆV, we have max vâˆˆV h(Î±, Î², Î³, iâˆ— v) = max vâˆˆV 1 âˆ’ Î² 1 âˆ’iâˆ—v â‰¤max vâˆˆV  max  1 âˆ’ Î² 1 âˆ’iâˆ—âˆ’ , 1 âˆ’ Î² 1 âˆ’iâˆ—+ v  . Note that 1 âˆ’ Î² 1 âˆ’iâˆ—âˆ’ â‰¥1 âˆ’(Î² + Î±)2 Î² , which implies max vâˆˆV  max  1 âˆ’ Î² 1 âˆ’iâˆ—âˆ’ , 1 âˆ’ Î² 1 âˆ’iâˆ—+ v  â‰¥1 âˆ’(Î² + Î±)2 Î² . Therefore, 1 âˆ’max vâˆˆV  max  1 âˆ’ Î² 1 âˆ’iâˆ—âˆ’ , 1 âˆ’ Î² 1 âˆ’iâˆ—+ v  â‰¤min  1 âˆ’max vâˆˆV |1 âˆ’Î²/(1 âˆ’iâˆ— v)| , (Î² + Î±)2 Î²  . According to Corollary 1, we obtain the desired result. 3.3 Tighter Bounds for Equilibrium Infection Probabilities in Star and Regular Networks Star networks. A star-shaped network consists of a hub and (N âˆ’1) leaves that are connected only to the hub. Hence, the adjacency matrix A can be represented as A = ï£« ï£¬ ï£¬ ï£¬ ï£­ 0 1 . . . 1 1 0 . . . 0 ... ... . . . 0 1 0 . . . 0 ï£¶ ï£· ï£· ï£· ï£¸ NÃ—N The spectral radius is Ï(A) = âˆš N âˆ’1. In this case, Eq. (5) becomes: iâˆ— h = 1 âˆ’C (Î´Ch (1 âˆ’Î³iâˆ— l ) , 1 âˆ’Î±) Î² + 1 âˆ’C (Î´Ch (1 âˆ’Î³iâˆ— l ) , 1 âˆ’Î±), (11) iâˆ— l = 1 âˆ’C (1 âˆ’Î³iâˆ— h, 1 âˆ’Î±) 1 + Î² âˆ’C (1 âˆ’Î³iâˆ— h, 1 âˆ’Î±), (12) where iâˆ— h and iâˆ— l are the equilibrium probabilities that the hub and the leaves are infected, respectively. Note that the effect of the copula Ch on the equilibrium probabilities only depends on its diagonal section Î´Ch. In what follows we present two results about the equilibrium infection probabilities, which are not implied by the above general results that apply to arbitrary network structures. First, we can prove iâˆ— h â‰¥iâˆ— l . Proposition 2 For the star networks, it holds that iâˆ— h â‰¥iâˆ— l . 10 Proof Denote by f(x) = 1 âˆ’C (Î´Ch (1 âˆ’Î³x) , 1 âˆ’Î±) Î² + 1 âˆ’C (Î´Ch (1 âˆ’Î³x) , 1 âˆ’Î±) and g(x) = 1 âˆ’C (1 âˆ’Î³x, 1 âˆ’Î±) 1 + Î² âˆ’C (1 âˆ’Î³x, 1 âˆ’Î±) where x âˆˆ[0, 1]. Since Î´Ch(x) â‰¤x, we have f(x) â‰¥g(x). Suppose iâˆ— h < iâˆ— l and (iâˆ— h, iâˆ— l ) is a solution to Eqs. (11) and (12). Then, iâˆ— h = f(iâˆ— l ) = gâˆ’1(iâˆ— l ) < iâˆ— l . Since g(x) is increasing in x and so is gâˆ’1, we have iâˆ— l â‰¤ g(iâˆ— l ) and f(iâˆ— l ) < iâˆ— l â‰¤g(iâˆ— l ), which contradicts with f(x) â‰¥g(x) for x âˆˆ[0, 1]. Second, we present reï¬ned bounds for equilibrium infection probabilities iâˆ— h and iâˆ— l . The bounds are useful because even in the case of star networks, it is hard to derive analytic expressions and infeasible to numerically compute (especially for complex dependence structures) iâˆ— h and iâˆ— l . Proposition 3 (tighter upper bounds for the equilibrium infection probabilities in star networks) For star networks and regardless of the dependence structures (which can be unknown), we have iâˆ—âˆ’â‰¤iâˆ— h â‰¤iâˆ—+ h and iâˆ—âˆ’â‰¤iâˆ— l â‰¤ iâˆ—+ l , where iâˆ—âˆ’is deï¬ned in Proposition 1 and iâˆ—+ h = 1 Î² + 1I  1 Î² + 1 â‰¥ 1 âˆ’Î± (N âˆ’1)Î³  +(N âˆ’1)Î³ âˆ’Î± âˆ’Î² + p ((N âˆ’1)Î³ âˆ’Î± âˆ’Î²)2 + 4(N âˆ’1)Î³Î± 2(N âˆ’1)Î³ I  1 Î² + 1 < 1 âˆ’Î± (N âˆ’1)Î³  . and iâˆ—+ l = 1 Î² + 1I  1 Î² + 1 â‰¥1 âˆ’Î± Î³  + Î³ âˆ’Î± âˆ’Î² + p (Î³ âˆ’Î± âˆ’Î²)2 + 4Î³Î± 2Î³ I  1 Î² + 1 < 1 âˆ’Î± Î³  . Proof The lower bound iâˆ—âˆ’is the same as in Proposition 1. Letâ€™s focus on iâˆ—+ h . From Ineq. (10), we have iâˆ— h â‰¤ min{Î± + (N âˆ’1)Î³iâˆ— l , 1} Î² + min{Î± + (N âˆ’1)Î³iâˆ— l , 1} â–³= f(iâˆ— l ). Since the right-hand side of the above inequality increases in iâˆ— l , by Proposition 2 we have iâˆ— h â‰¤f(iâˆ— h), and therefore iâˆ— h â‰¤iâˆ—+ h , where iâˆ—+ h is the solution to equation x = f(x). (13) For the upper bound iâˆ—+ l , we can similarly obtain the desired result by solving equation x = f  x N âˆ’1  . (14) Now we explain why the upper bounds iâˆ—+ h and iâˆ—+ l given by Proposition 3 are smaller (i.e., tighter) than the general upper bounds that can be derived from Proposition 1 by instantiating G = (V, E) as star networks. To see this, we note that iâˆ—+ h is the solution to Eq. (13) and iâˆ—+ h â‰¤ 1 Î²+1, meaning that iâˆ—+ h â‰¤ min n Î± + (N âˆ’1) Î³ Î²+1, 1 o Î² + min n Î± + (N âˆ’1) Î³ Î²+1, 1 o, where the right-hand side of the inequality is exactly the upper bound that can be derived from Proposition 1 by sub- stituting deg(v) with the degree of the hub. This means that iâˆ—+ h is smaller than the upper bound given by Proposition 11 1. Similarly, we can show that iâˆ—+ l is smaller than the upper bound given by Proposition 1. Moreover, by comparing (13) and (14), we see that iâˆ—+ h â‰¥iâˆ—+ l . Since the lower bound iâˆ—âˆ’is the same as the lower bound given by Proposition 1, we conclude that the bounds given by Proposition 3 are tighter than the bounds given by Proposition 1. To see the tightness of the bounds given by Proposition 3, we consider two combinations of dependence structures: (C, Cv)=(Gaussian,Frank) and (C, Cv)=(Gaussian, Clayton) with parameters Ïƒ = Î¸ = Î¾ = 0.1 as reviewed in Section 2. Figure 1 plots iâˆ— h, iâˆ— l , iâˆ—âˆ’, iâˆ—+ h , and iâˆ—+ l for N = 3, . . . , 81 with (Î±, Î², Î³) = (0.5, 0.1, 0.1); all these parameter settings satisfy condition (8). We observe that the upper bound iâˆ—+ h becomes ï¬‚at for N â‰¥5, because it causes iâˆ—+ h = 1 Î²+1 (i.e., independent of N); whereas, the upper bound iâˆ—+ l is ï¬‚at because it is always independent of N. We observe that the upper bound for hub node, iâˆ—+ h , becomes extremely tight for dense star networks with N > 40. However, the upper bound for leave nodes almost always exhibits that iâˆ—+ l âˆ’iâˆ— l â‰ˆ0.011 (i.e., the upper bound overestimates about 0.88 infected nodes for a star network of N = 80 nodes). In any case, the upper bounds only somewhat overestimate the numerical solutions iâˆ— vâ€™s and thus can be used for decision-making purpose when iâˆ— vâ€™s are infeasible to compute. 0 20 40 60 80 0.75 0.80 0.85 0.90 0.95 Star Leaves upper bound numerical solution lower bound (a) Hub: (Gaussian, Frank) 0 20 40 60 80 0.83 0.84 0.85 0.86 0.87 Star Leaves upper bound numerical solution lower bound (b) Leaves: (Gaussian, Frank) 0 20 40 60 80 0.75 0.80 0.85 0.90 0.95 Star Leaves upper bound numerical solution lower bound (c) Hub: (Gaussian, Clayton) 0 20 40 60 80 0.83 0.84 0.85 0.86 0.87 Star Leaves upper bound numerical solution lower bound (d) Leaves: (Gaussian, Clayton) Figure 1: Star networks: upper bound iâˆ—+ h for hub (iâˆ—+ l for leaves) vs. numerical solution iâˆ— h for hub (iâˆ— l for leaves) vs. lower bound iâˆ—âˆ’(for both hub and leaves) with respect to (Î±, Î², Î³) = (0.5, 0.1, 0.1) and (C, Cv). Regular networks. For regular networks, each node v âˆˆV has degree d for some d âˆˆ[1, N âˆ’1] and Ï(A) = d. According to Proposition 1, we have iâˆ— v = 1 âˆ’C  Cv  1 âˆ’Î³iâˆ— v,1, . . . , 1 âˆ’Î³iâˆ— v,d  , 1 âˆ’Î±  Î² + 1 âˆ’C  Cv  1 âˆ’Î³iâˆ— v,1, . . . , 1 âˆ’Î³iâˆ— v,d  , 1 âˆ’Î± , v âˆˆV. Now we want to present reï¬ned bounds for equilibrium infection probability iâˆ— v. Proposition 4 (tighter upper bound for the equilibrium infection probability in regular networks) For regular network G = (V, E) and regardless of the dependence structures (which can be unknown), we have iâˆ—âˆ’â‰¤iâˆ— v â‰¤iâˆ—+ for any v âˆˆV, where iâˆ—âˆ’is deï¬ned in Proposition 1 and iâˆ—+ = 1 Î² + 1I  1 Î² + 1 â‰¥1 âˆ’Î± Î³d  + Î³d âˆ’Î± âˆ’Î² + p (Î³d âˆ’Î± âˆ’Î²)2 + 4Î³Î±d 2Î³d I  1 Î² + 1 < 1 âˆ’Î± Î³d  . Proof Deï¬ne function f(x) = min{Î± + Î³dx, 1} Î² + min{Î± + Î³dx, 1} and a sequence {xn, n â‰¥0} with xn = f(xnâˆ’1), x0 = 1/(Î² + 1). Observe that for all v âˆˆV, we have iâˆ— v â‰¤x0 and hence from Ineq. (10), it follows that iâˆ— v â‰¤x1 for all v âˆˆV. By repeating this process, we have iâˆ— v â‰¤xn for all n. Since f(x) is increasing and x1 â‰¤x0, xn is decreasing in n. Thus, we have iâˆ— v â‰¤iâˆ—+, which is the solution of the equation x = f(x). If 1 Î²+1 â‰¥ 1âˆ’Î± Î³d , then iâˆ—+ = 1 Î²+1; otherwise, iâˆ—+ is the positive solution to equation Î³dx2 + (Î± + Î² âˆ’Î³d)x âˆ’Î± = 0. Thus, we obtain the desired result. 12 Note that the upper bound iâˆ—+ given by Proposition 4 is smaller than the upper bound iâˆ—+ v obtained by instantiating deg(v) = d in Proposition 1, because iâˆ—+ v is exactly the x1 deï¬ned in the proof of Proposition 4. To see the tightness of bounds iâˆ—âˆ’and iâˆ—+ given by Proposition 4, we consider (C, Cv)=(Gaussian,Frank) and (C, Cv)=(Gaussian, Clayton) with parameters Ïƒ = Î¸ = Î¾ = 0.1 as reviewed in Section 2. Figure 2 plots numerical iâˆ— v, iâˆ—âˆ’and iâˆ—+ with respect to node degree d = 2, . . . , 80 with (Î±, Î², Î³) = (0.5, 0.1, 0.01); all these parameter settings satisfy condition (8). We observe that iâˆ—+ v becomes ï¬‚at for sufï¬ciently dense regular networks. This is because iâˆ—+ v = 1 Î²+1 when d â‰¥ (1âˆ’Î±)(Î²+1) Î³ . For (C, Cv)=(Gaussian,Frank), we further observe that the upper bound iâˆ—+ v is reasonably tight especially for relatively sparse regular networks, with iâˆ—+ v âˆ’iâˆ— v < 0.021 for d < 20 (i.e., for a sparse regular network of N = 1000 nodes, the upper bound only overestimates at most 21 infected nodes). Even for dense regular network with d > 20, we have iâˆ—+ v âˆ’iâˆ— v â‰¤0.038 (i.e., for a dense regular network of N = 1000 nodes, the upper bound only overestimates at most 38 infected nodes), where equality holds for d = 54. For (C, Cv)=(Gaussian, Clayton), we also observe that the upper bound iâˆ—+ v is tight especially for relatively sparse regular networks with d < 20 and iâˆ—+ v âˆ’iâˆ— v < 0.021 (i.e., for a sparse regular network of N = 1000 nodes, the upper bound only overestimates at most 21 infected nodes). Even for dense regular network with d > 20, we have iâˆ—+ v âˆ’iâˆ— v â‰¤0.039, where equality holds for d = 54. This means that for decision-making purpose, the defender can use the upper bound iâˆ—+ v instead of the numerical solution iâˆ— v, especially when iâˆ— v is infeasible to compute. 0 20 40 60 80 0.80 0.85 0.90 0.95 1.00 Regular Degree upper bound numerical solution lower bound (a) (Gaussian,Frank,0.5,0.1,0.01) 0 20 40 60 80 0.80 0.85 0.90 0.95 1.00 Regular Degree upper bound numerical solution lower bound (b) (Gaussian,Clayton,0.5,0.1,0.01) Figure 2: Regular networks: upper bound iâˆ—+ v vs. numerical solution iâˆ— v vs. lower bound iâˆ—âˆ’ v with respect to (C, Cv, Î±, Î², Î³) 3.4 Approximating Equilibrium Infection Probabilities in ER and Power-law Networks For star and regular networks, we have derived tighter bounds for equilibrium infection probabilities (than the general bounds given by Proposition 1). Unfortunately, we do not know how to derive tighter bounds for ER and power-law networks. As an alternative, we propose to approximate equilibrium infection probabilities by taking advantage of the upper and lower bounds. The approximation is useful because it is often smaller than the upper bound, which never underestimates, but may substantially overestimate, the threats in terms of equilibrium infection probabilities. That is, the approximation method can lead to more cost-effective defense than the upper bound. The approximation method is the following: We ï¬rst compute lower bounds, upper bounds, and numerical solu- tions for a feasible number of instances of (G, C, Cv, Î±, Î², Î³), based on given computer resources. We then use the resulting data to derive (via statistical methods) some function of the lower and upper bounds. For even larger G of the same type as well as (C, Cv) of the same kind, the resulting function would be smaller than the upper bound and would not underestimate the equilibrium infection probabilities. The key insight is that we can compute, for networks of any size, the upper and lower bounds according to Proposition 1. This means that we can approximate the equi- librium infection probabilities for arbitrarily large networks, for which it is often infeasible to numerically (let alone analytically) compute the equilibrium infection probabilities. To illustrate the approximation method, we also consider (C, Cv)=(Gaussian,Frank) and (C, Cv)=(Gaussian, Clayton) with parameters Ïƒ = Î¸ = Î¾ = 0.1 as reviewed in Section 2. We use the erdos.renyi.game generator of the igraph package in the R system to generate a random ER network of N = 1000 nodes and edge proba- bility 0.01; the resulting network instance has spectral radius 11.38045. We use the static.power.law.game 13 generator of the igraph package in the R system to generate a random power-law network of N = 1000 nodes, 5000 edges, and power-law exponent 2.1 (note that 2.1 is the power-law exponent of the Internet AS-level net- work [6]); the resulting network instance has spectral radius 22.97582. We consider combinations of (Î±, Î², Î³) that satisfy condition (8), where Î± âˆˆ{0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5}, Î² âˆˆ{0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9}, Î³ âˆˆ{0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1}. It turns out that for (C, Cv)=(Gaussian, Frank), the ER network has 307 combinations of (Î±, Î², Î³) that satisfy condition (8); the power-law network has 125 combinations of (Î±, Î², Î³) that satisfy condition (8), because the spectral radius is larger. For (C, Cv)=(Gaussian, Clayton), the ER network has 307 combinations of (Î±, Î², Î³) that satisfy condition (8); the power-law network has 126 combinations of (Î±, Î², Î³) that satisfy condition (8). We compute equilibrium infection probability iâˆ— v numerically by solving Eqs. (5) for v âˆˆV via the BB package in the R system. We compute the upper and lower bounds, namely iâˆ—âˆ’and iâˆ—+ v , according to Proposition 1. Since it is infeasible to numerically compute iâˆ— v for large networks, we propose to approximate iâˆ— v for node v âˆˆV via biâˆ—v = 1 2  eiâˆ—v + iâˆ—+ v  , where eiâˆ—v = f(C,Cv)(iâˆ—âˆ’, iâˆ—+ v , deg(v)) = k0 + k1iâˆ—âˆ’+ k2iâˆ—+ v + k3 deg(v) can be statistically derived from the data. Note that the heuristic function biâˆ—v could be reï¬ned via more extensive numerical studies. We deï¬ne the approximation error for network G as errG = P vâˆˆV(biâˆ—v âˆ’iâˆ— v), because P vâˆˆV iâˆ— v is an important factor for cyber defense decision-making. For practical use, it is desired that errG â‰¥0, meaning that the defender never underestimates the threats, and at the same time errG â‰ˆ0, meaning that the defender does not overestimate the threats (i.e., does not overprovision defense resources) too much. ER networks. For the ER network, we obtain the following formulas : â€¢ For (C, Cv)=(Gaussian, Frank), we have biâˆ—v = âˆ’0.01759 + 0.3142iâˆ—âˆ’+ 0.7294iâˆ—+ v âˆ’0.0002575 deg(v). â€¢ For (C, Cv)=(Gaussian, Clayton), we have biâˆ—v = âˆ’0.0174076+0.3150585iâˆ—âˆ’+0.7281992iâˆ—+ v âˆ’0.0002596 deg(v). For (C, Cv)=(Gaussian, Frank), the average of the errGâ€™s over the 307 combinations of (C, Cv, Î±, Î², Î³) is 46, meaning that the approximation method only overestimates 46 infected nodes in an ER network of 1000 nodes. In comparison, the average of the P vâˆˆV(iâˆ—+ v âˆ’iâˆ— v)â€™s over the 307 combinations of (C, Cv, Î±, Î², Î³) is 93, meaning that the upper bound overestimates 93 infected nodes (i.e., the approximation method is indeed better); the average of the P vâˆˆV(iâˆ’âˆ’iâˆ— v)â€™s is -52.7, meaning that the lower bound underestimates 52.7 infected nodes in an ER network of 1000 nodes. Finally, we note that among the 307 combinations of (C, Cv, Î±, Î², Î³), the maximum errG is 165.2, which is elaborated in Figure 3(a) and will be discussed further, and the minimum errG is 4.1, which is elaborated in Figure 3(b) and will be discussed further as well. For (C, Cv)=(Gaussian, Clayton), the average of the errGâ€™s over the 307 combinations of (C, Cv, Î±, Î², Î³) is 46.5, meaning that the approximation method only overestimates 46.5 infected nodes in an ER network of 1000 nodes. In comparison, the average of the P vâˆˆV(iâˆ—+ v âˆ’iâˆ— v)â€™s over the 307 combinations of (C, Cv, Î±, Î², Î³) is 93, meaning that the upper bound overestimates 93 infected nodes in an ER network of 1000 nodes; the average of the 307 P vâˆˆV(iâˆ’âˆ’iâˆ— v)â€™s is -52.5, meaning that the lower bound underestimates 52.5 infected nodes in an ER network of 1000 nodes. Among the 307 instances, the maximum errG is 165.0, which is elaborated in Figure 3(d) and will be discussed further, and the minimum errG is 4.2, which is elaborated in Figure 3(e) and will be discussed further. In summary, cyber defense decision-making can be based on the approximation method, which takes advantage of the upper and lower bounds and would be better (smaller) than the upper bound. As a side-product, we would like to highlight the phenomenon that the equilibrium infection probability iâˆ— v in- creases with node degree deg(v). This phenomenon was observed in [19] in the absence of dependence, and persists in the presence of dependence as we elaborate below. We consider iâˆ—+ v , iâˆ— v, biâˆ—v and iâˆ—âˆ’with respect to distinct node de- grees, by taking the average over the nodes of the same degree when needed. For (C, Cv)=(Gaussian,Frank), Figures 3(a)-3(b) plot the infection probabilities corresponding to the (Î±, Î², Î³) that leads to the maximum and minimum errG, respectively; Figure 3(c) plots the infection probabilities averaged over the 307 combinations of (Î±, Î², Î³) that satisfy condition (8). For (C, Cv)=(Gaussian,Clayton), Figures 3(d)-3(e) plot the infection probabilities corresponding to 14 5 10 15 20 0.0 0.2 0.4 0.6 0.8 ER Degree upper bound approximation numerical solution lower bound (a) (Gaussian,Frank, 0.01,0.4,0.03) 5 10 15 20 0.20 0.25 0.30 0.35 0.40 ER Degree upper bound approximation numerical solution lower bound (b) (Gaussian,Frank, 0.3,0.9,0.01) 5 10 15 20 0.2 0.4 0.6 0.8 1.0 ER Degree upper bound approximation numerical solution lower bound (c) (Gaussian,Frank) 5 10 15 20 0.0 0.2 0.4 0.6 0.8 ER Degree upper bound approximation numerical solution lower bound (d) (Gaussian,Clayton, 0.01,0.4,0.03) 5 10 15 20 0.20 0.25 0.30 0.35 0.40 ER Degree upper bound approximation numerical solution lower bound (e) (Gaussian,Clayton, 0.3,0.9,0.01) 5 10 15 20 0.2 0.4 0.6 0.8 1.0 ER Degree upper bound approximation numerical solution lower bound (f) (Gaussian,Clayton) Figure 3: ER networks: upper bound vs. approximation vs. numerical solution vs. lower bound with respect to (C, Cv, Î±, Î², Î³) or (C, Cv). the (Î±, Î², Î³) that leads to the maximum and minimum errG, respectively; Figure 4(f) plots the infection probabilities averaged over the 307 combinations of (Î±, Î², Î³) that satisfy condition (8). We observe that the approximation biâˆ—v can slightly underestimate the infection probability iâˆ— v for node v of degree deg(v) â‰¤5, but the overall estimation P vâˆˆV biâˆ—v is still above the actual threats P vâˆˆV iâˆ— v (as mentioned above). More importantly, we observe that iâˆ— v (solid curves) increases with deg(v). This hints that there might be some universal scaling laws, in the presence or absence of dependence. It is an interesting future work to identify the possible scaling law. Power-law networks. For power-law networks, we obtain the following formulas in a similar fashion: â€¢ For (C, Cv)=(Gaussian, Frank), we have biâˆ—v = âˆ’0.007395 + 0.34705iâˆ—âˆ’+ 0.67205iâˆ—+ v + 0.00013505 deg(v). â€¢ For (C, Cv)=(Gaussian, Clayton), we have biâˆ—v = âˆ’0.007365 + 0.34765iâˆ—âˆ’+ 0.6714iâˆ—+ v + 0.00013525 deg(v). For (C, Cv)=(Gaussian, Frank), the average of the errGâ€™s over the 125 combinations of (C, Cv, Î±, Î², Î³) is 25, mean- ing that the approximation only overestimates 25 infected nodes in a power-law network of 1000 nodes. In com- parison, the average of the P vâˆˆV(iâˆ—+ v âˆ’iâˆ— v)â€™s over the 125 combinations of (C, Cv, Î±, Î², Î³) is 50.8, meaning that the upper bound overestimates 50.8 infected nodes (i.e., the approximation method is better); the average of the P vâˆˆV(iâˆ’âˆ’iâˆ— v)â€™s is -26, meaning that the lower bound underestimates 26 infected nodes. Among the 125 combina- tions of (C, Cv, Î±, Î², Î³), the maximum errG is 84.5, which is elaborated in Figure 4(a) and will be discussed further, and the minimum errG is 7.1, which is elaborated in Figure 4(b). For (C, Cv)=(Gaussian, Clayton), the average of the errGâ€™s over the 126 combinations of (C, Cv, Î±, Î², Î³) is 25.4, meaning that the approximation only overestimates 25.4 infected nodes in a power-law network of 1000 nodes. In comparison, the average of the P vâˆˆV(iâˆ—+ v âˆ’iâˆ— v)â€™s over the 126 combinations of (C, Cv, Î±, Î², Î³) is 50.8, meaning that the upper bound overestimates 50.8 infected nodes; the average of the 126 P vâˆˆV(iâˆ’âˆ’iâˆ— v)â€™s is -26, meaning that the lower bound underestimates 26 infected nodes. Among the 126 instances, the maximum errG is 84.5, which is elaborated in Figure 4(d), and the minimum errG is 7.2, which 15 is elaborated in Figure 4(e). In summary, cyber defense decision-making can use the approximation method, which takes advantage of the upper and lower bounds. 0 20 40 60 80 0.0 0.2 0.4 0.6 0.8 1.0 Powerâˆ’law Degree upper bound approximation numerical solution lower bound (a) (Gaussian,Frank, 0.01,0.5,0.02) 0 20 40 60 80 0.4 0.6 0.8 1.0 Powerâˆ’law Degree upper bound approximation numerical solution lower bound (b) (Gaussian,Frank, 0.2,0.1,0.01) 0 20 40 60 80 0.2 0.4 0.6 0.8 1.0 Powerâˆ’law Degree upper bound approximation numerical solution lower bound (c) (Gaussian,Frank) 0 20 40 60 80 0.2 0.4 0.6 0.8 1.0 Powerâˆ’law Degree upper bound approximation numerical solution lower bound (d) (Gaussian,Clayton, 0.01,0.5,0.02) 0 20 40 60 80 0.4 0.6 0.8 1.0 Powerâˆ’law Degree upper bound approximation numerical solution lower bound (e) (Gaussian,Clayton, 0.2,0.1,0.01) 0 20 40 60 80 0.2 0.4 0.6 0.8 1.0 Powerâˆ’law Degree upper bound approximation numerical solution lower bound (f) (Gaussian,Clayton) Figure 4: Power-law networks: upper bound vs. approximation vs. numerical solution vs. lower bound with respect to (C, Cv, Î±, Î², Î³) or (C, Cv). In Figures 4(b) and 4(e), the approximation result matches the numerical solution almost perfectly. We also would like to highlight the phenomenon that the equilibrium infection probability iâˆ— v increases with node degree deg(v) in power-law networks. Similarly, for (C, Cv)=(Gaussian,Frank), Figures 4(a)-4(b) plot respectively the infection probabilities corresponding to the (Î±, Î², Î³) that leads to the maximum and minimum errG, and Figure 4(c) plots the infection probabilities averaged over the 125 combinations of (C, Cv, Î±, Î², Î³) that satisfy condition (8). For (C, Cv)=(Gaussian,Clayton), Figures 4(a)-4(b) plot respectively the infection probabilities corresponding to the (Î±, Î², Î³) that leads to the maximum errG, and Figure 4(c) plots the infection probabilities averaged over the 126 combinations of (C, Cv, Î±, Î², Î³) that satisfy condition (8). We observe that the approximation biâˆ—v never underestimates the infection probability iâˆ— v for any node v. We also observe that iâˆ— v (solid curves) increases with deg(v), but exhibits a higher nonlinearity when compared with the ER networks. 3.5 Bounds for Non-Equilibrium Infection Probabilities It is important to characterize the behavior of iv(t) even if it never enters any equilibrium. For this purpose, we want to seek some bounds for iv(t), no matter whether the system converges to an equilibrium or not. Such characterization is useful because, for example, the upper bound can be used for the worst-case scenario decision-making. It is worth mentioning that non-equilibrium states/behaviors are always hard to characterize. Proposition 5 (bounds for non-equilibrium probabilities) Let limtâ†’âˆiv(t) and limtâ†’âˆiv(t) denote the upper and lower limits of iv(t), v âˆˆV. Then, iâˆ’ v â‰¤limtâ†’âˆiv(t) â‰¤limtâ†’âˆiv(t) â‰¤i+ v , 16 where iâˆ’ v = ï£± ï£´ ï£² ï£´ ï£³ 1 âˆ’C(Î´Cv(1 âˆ’Î³Î½), 1 âˆ’Î±) Î² + 1 âˆ’C(Î´Cv(1 âˆ’Î³Î½), 1 âˆ’Î±), C(Î´Cv(1 âˆ’Î³Î½), 1 âˆ’Î±) â‰¥Î², [Î² âˆ’C(Î´Cv(1 âˆ’Î³Î½), 1 âˆ’Î±)] (1 âˆ’Âµv) + 1 âˆ’Î², otherwise, and i+ v = ï£± ï£´ ï£² ï£´ ï£³ 1 âˆ’C  Cv  1 âˆ’Î³Âµv,1, . . . , 1 âˆ’Î³Âµv,deg(v)  , 1 âˆ’Î±  Î² + 1 âˆ’C  Cv  1 âˆ’Î³Âµv,1, . . . , 1 âˆ’Î³Âµv,deg(v)  , 1 âˆ’Î± , C  Cv  1 âˆ’Î³Âµv,1, . . . , 1 âˆ’Î³Âµv,deg(v)  , 1 âˆ’Î±  > Î²  Î² âˆ’C  Cv  1 âˆ’Î³Âµv,1, . . . , 1 âˆ’Î³Âµv,deg(v)  , 1 âˆ’Î±  (1 âˆ’iâˆ’ v ) + 1 âˆ’Î², otherwise with Î´Cv(1 âˆ’Î³Î½) = Cv(1 âˆ’Î³Î½, . . . , 1 âˆ’Î³Î½), Âµv = max {1 âˆ’Î², min{Î³deg(v) + Î±, 1}} and Î½ = min{1 âˆ’Î², Î±}. Proof By observing the monotonicity in Eq. (4), we note that iv(t) â‰¥Î½ for all v âˆˆV. Replacing iv,j(t) with Î½ in Eq. (4) yields iv(t + 1) â‰¥ (1 âˆ’Î²)iv(t) + [1 âˆ’C (Î´Cv(1 âˆ’Î³Î½), 1 âˆ’Î±)] (1 âˆ’iv(t)) = [C (Î´Cv(1 âˆ’Î³Î½), 1 âˆ’Î±) âˆ’Î²] iv(t) + 1 âˆ’C (Î´Cv(1 âˆ’Î³Î½), 1 âˆ’Î±) . If C (Î´Cv(1 âˆ’Î³Î½), 1 âˆ’Î±) > Î², by taking the lower limit on both sides we obtain limtâ†’âˆiv(t + 1) â‰¥ 1 âˆ’C (Î´Cv(1 âˆ’Î³Î½), 1 âˆ’Î±) Î² + 1 âˆ’C (Î´Cv(1 âˆ’Î³Î½), 1 âˆ’Î±). If C (Î´Cv(1 âˆ’Î³Î½), 1 âˆ’Î±) â‰¤Î², we have iv(t + 1) â‰¥ [C (Î´Cv(1 âˆ’Î³Î½), 1 âˆ’Î±) âˆ’Î²] Âµv + 1 âˆ’C (Î´Cv(1 âˆ’Î³Î½), 1 âˆ’Î±) = [Î² âˆ’C(Î´Cv(1 âˆ’Î³Î½), 1 âˆ’Î±)] (1 âˆ’Âµv) + 1 âˆ’Î². Hence, limtâ†’âˆiv(t) â‰¥iâˆ’ v . For the upper bound, by applying Lemma 1 to Eq. (4) we have iv(t + 1) â‰¤ (1 âˆ’Î²)iv(t) + [1 âˆ’max {max {2 âˆ’Î³deg(v) âˆ’Î±, 1 âˆ’Î±} âˆ’1, 0}] (1 âˆ’iv(t)) = (1 âˆ’Î²)iv(t) + min {Î³deg(v) + Î±, 1} (1 âˆ’iv(t)) â‰¤ max {1 âˆ’Î², min{Î³deg(v) + Î±, 1}} = Âµv. (15) By replacing iv,j with Âµv,jâ€™s in Eq. (4) yields iv(t + 1) â‰¤ (1 âˆ’Î²)iv(t) +  1 âˆ’C  Cv  1 âˆ’Î³Âµv,1, . . . , 1 âˆ’Î³Âµv,deg(v)  , 1 âˆ’Î±  (1 âˆ’iv(t)) =  C  Cv  1 âˆ’Î³Âµv,1, . . . , 1 âˆ’Î³Âµv,deg(v)  , 1 âˆ’Î±  âˆ’Î²  iv(t) +1 âˆ’C  Cv  1 âˆ’Î³Âµv,1, . . . , 1 âˆ’Î³Âµv,deg(v)  , 1 âˆ’Î±  . If C  Cv  1 âˆ’Î³Âµv,1, . . . , 1 âˆ’Î³Âµv,deg(v)  , 1 âˆ’Î±  > Î², then limtâ†’âˆâ‰¤ 1 âˆ’C  Cv  1 âˆ’Î³Âµv,1, . . . , 1 âˆ’Î³Âµv,deg(v)  , 1 âˆ’Î±  Î² + 1 âˆ’C  Cv  1 âˆ’Î³Âµv,1, . . . , 1 âˆ’Î³Âµv,deg(v)  , 1 âˆ’Î± . If C  Cv  1 âˆ’Î³Âµv,1, . . . , 1 âˆ’Î³Âµv,deg(v)  , 1 âˆ’Î±  â‰¤Î², then we have limtâ†’âˆiv(t + 1) â‰¤ limtâ†’âˆ  C  Cv  1 âˆ’Î³Âµv,1, . . . , 1 âˆ’Î³Âµv,deg(v)  , 1 âˆ’Î±  âˆ’Î²  iv(t) +1 âˆ’C  Cv  1 âˆ’Î³Âµv,1, . . . , 1 âˆ’Î³Âµv,deg(v)  , 1 âˆ’Î±  â‰¤  C  Cv  1 âˆ’Î³Âµv,1, . . . , 1 âˆ’Î³Âµv,deg(v)  , 1 âˆ’Î±  âˆ’Î²  limtâ†’âˆiv(t) +1 âˆ’C  Cv  1 âˆ’Î³Âµv,1, . . . , 1 âˆ’Î³Âµv,deg(v)  , 1 âˆ’Î±  â‰¤  C  Cv  1 âˆ’Î³Âµv,1, . . . , 1 âˆ’Î³Âµv,deg(v)  , 1 âˆ’Î±  âˆ’Î²  iâˆ’ v +1 âˆ’C  Cv  1 âˆ’Î³Âµv,1, . . . , 1 âˆ’Î³Âµv,deg(v)  , 1 âˆ’Î±  . 17 Hence, we have limtâ†’âˆiv(t + 1) â‰¤i+ v . When are the bounds tight? It is important to know when the bounds are tight because the defender can use the upper bound i+ v for decision-making, especially when the spreading never enters any equilibrium. Note that when Î³ << 1, it holds that C(Î´Cv(1 âˆ’Î³Î½), 1 âˆ’Î±) â‰ˆC(1, 1 âˆ’Î±) = 1 âˆ’Î±, and C  Cv  1 âˆ’Î³Âµv,1, . . . , 1 âˆ’Î³Âµv,deg(v)  , 1 âˆ’Î±  â‰ˆC (Cv (1, . . . , 1) , 1 âˆ’Î±) = 1 âˆ’Î±. Therefore, in the case Î³ << 1 and Î± + Î² < 1, we have iâˆ’ v â‰ˆ 1 âˆ’C(Î´Cv(1 âˆ’Î³Î½), 1 âˆ’Î±) Î² + 1 âˆ’C(Î´Cv(1 âˆ’Î³Î½), 1 âˆ’Î±) â‰ˆ Î± Î² + Î±, i+ v â‰ˆ 1 âˆ’C  Cv  1 âˆ’Î³Âµv,1, . . . , 1 âˆ’Î³Âµv,deg(v)  , 1 âˆ’Î±  Î² + 1 âˆ’C  Cv  1 âˆ’Î³Âµv,1, . . . , 1 âˆ’Î³Âµv,deg(v)  , 1 âˆ’Î±  â‰ˆ Î± Î² + Î±. This means that the bounds are tight when the attack-power is not strong. In the case Î³ deg(v) << 1 and Î± + Î² â‰¥1, we can similarly have iâˆ’ v â‰ˆÎ±(2 âˆ’Î± âˆ’Î²), i+ v â‰ˆ(Î² + Î± âˆ’1) [1 âˆ’Î±(2 âˆ’Î± âˆ’Î²)] + 1 âˆ’Î². Therefore, the difference between the upper bound and lower bound is i+ v âˆ’iâˆ’ v â‰ˆÎ±(Î± + Î² âˆ’1)2. Therefore, the bounds are tight when (Î± + Î²) is not far from 1 or Î± is close to zero. Are the equilibrium bounds always tighter than the non-equilibrium bounds? We observe the following: under the condition Î³ deg(v) << 1, we have iâˆ—âˆ’â‰ˆiâˆ—+ v â‰ˆÎ±/(Î±+Î²); under the condition Î³ deg(v) << 1 and the condition Î± + Î² < 1, we have iâˆ’ v â‰ˆi+ v â‰ˆÎ±/(Î± + Î²). This means that the equilibrium bounds are widely applicable than the same non-equilibrium bounds, namely that the equilibrium bounds are strictly tighter than the non-equilibrium bounds. 4 Side-Effects of Assuming Away the Dependences In the above we have characterized epidemic equilibrium thresholds, equilibrium infection probabilities, and non- equilibrium infection probabilities while accommodating arbitrary dependences. In order to characterize the side- effects of assuming away the dependences, we consider the degree of dependences as captured by the concordance order between copulas (reviewed in Section 2). In order to draw cyber security insights at a higher level of abstraction, we also consider three kinds of qualitative dependences: positive dependence, independence and negative dependence, whose degrees of dependence are in decreasing order. Speciï¬cally, positive (negative) dependence between the push- based attacks means 1 âˆ’Cv  1 âˆ’Î³iv,1, . . . , 1 âˆ’Î³iv,deg(v)  â‰¥(â‰¤)1 âˆ’ deg(v) Y j=1 (1 âˆ’Î³iv,j) , and positive (negative) dependence between the push-based attacks and the pull-based attacks means 1 âˆ’C  Cv  1 âˆ’Î³iv,1(t), . . . , 1 âˆ’Î³iv,deg(v)(t)  , 1 âˆ’Î±  â‰¥(â‰¤)1 âˆ’(1 âˆ’Î±)Cv  1 âˆ’Î³iv,1(t), . . . , 1 âˆ’Î³iv,deg(v)(t)  , where equality means independence. To simplify the notations, let pd stand for positive dependence, ind stand for independence, and nd stand for negative dependence. Let x âˆˆ{pd, ind, nd} denote the dependence structure between the push-based attacks and the pull-based attacks, as captured by copula C. Let y âˆˆ{pd, ind, nd} denote the dependence structure between the push-based attacks, as captured by copula Cv. Therefore, the dependence structures can be represented by a pair (x, y). 18 4.1 Side-Effects on Equilibrium Infection Probabilities and Thresholds For ï¬xed G = (V, E), Î±, Î², Î³, we compare the effects of two groups of dependences (i.e., copulas) {C, Cv, v âˆˆV} and {Câ€², Câ€² v, v âˆˆV}. Corresponding to the two groups of copulas, we denote by iv(t) and iâ€² v(t) the respective infection probabilities of node v âˆˆV at time t â‰¥0. Let iâˆ— v,x,y denote the equilibrium infection probability of node v, namely iâˆ— v, under dependence structure (x, y). Side-effects on the equilibrium infection probabilities. We present a result about the impact of the dependence structures on the equilibrium infection probabilities. This result will allow us to derive the side-effects of assuming away the dependences. Proposition 6 (comparison between the effects of different dependence structures on equilibrium infection probabil- ities) Suppose the condition underlying Lemma 3 holds, namely Ï(A) < (Î² + Î±)2 Î³Î² so that system (4) has a unique equilibrium. If for all v âˆˆV, we have C  Cv  u1, . . . , udeg(v)  , u0  â‰¤Câ€²  Câ€² v  u1, . . . , udeg(v)  , u0  , (16) where 0 â‰¤uj â‰¤1 for j = 0, . . . , deg(v), then we have iâˆ—â‰¥iâ€²âˆ—. Proof Note that iâˆ—and iâ€²âˆ—are respectively the unique positive solutions of f(iâˆ—) = 0 and g(iâ€²âˆ—) = 0, where f = (f1, . . . , fN) and g = (g1, . . . , gN) with fv(i) =  1 âˆ’C  Cv  1 âˆ’Î³iv,1, . . . , 1 âˆ’Î³iv,deg(v)  , 1 âˆ’Î±  (1 âˆ’iv) âˆ’Î²iv, v âˆˆV gv(i) =  1 âˆ’Câ€²  Câ€² v  1 âˆ’Î³iv,1, . . . , 1 âˆ’Î³iv,deg(v)  , 1 âˆ’Î±  (1 âˆ’iv) âˆ’Î²iv, v âˆˆV. Since f(0) = g(0) = Î± > 0 and f â‰¥g, we have g(iâˆ—) â‰¤f(iâˆ—) = 0. Since both f and g are continuous, we have iâ€²âˆ—â‰¤iâˆ—. The cyber security insights/implications of Proposition 6 is: The stronger the negative (positive) dependences between the attack events, the lower (higher) the equilibrium infection probabilities. More speciï¬cally, we have iâˆ— v,pd,y â‰¥iâˆ— v,ind,y â‰¥iâˆ— v,nd,y for any y âˆˆ{pd, ind, nd} and iâˆ— v,x,pd â‰¥iâˆ— v,x,ind â‰¥iâˆ— v,x,nd for any x âˆˆ{pd, ind, nd}. Therefore, the side-effects of assuming away the dependences between attack events are: If the positive (negative) dependence is assumed away, the resulting equilibrium infection probability underestimates (overestimates) the actual equilibrium infection probability. This means the following: when the positive dependence between attack events is assumed away, the cyber defense decisions based on iâˆ— v,ind,ind (< iâˆ— v,pd,pd) can render the deployed defense useless; when the negative dependence is assumed away between attack events, the cyber defense decisions based on iâˆ— v,ind,ind (> iâˆ— v,nd,nd) can waste defense resources. We will use numerical examples below to conï¬rm these insights. Another important insight is: if the defender can seek to impose negative dependence on the cyber attacks, the cyber defense effect is better of. We believe that this insight will shed light on research of future cyber defense mechanisms, and highlights the value of theoretical studies in terms of their practical guidance. Side-effects on the epidemic equilibrium threshold. Corollary 1 gives a sufï¬cient condition under which the epidemic spreading enters the equilibrium. Here we deï¬ne Ï„ def = min 1 âˆ’maxvâˆˆV |1 âˆ’Î²/(1 âˆ’iâˆ— v)| Î³ , (Î² + Î±)2 Î³Î²  , (17) with respect to a group of copulas {C, Cv, v âˆˆV}. According to Eq. (8), Ï(A) â‰¤Ï„ means that the epidemic spreading converges to the equilibrium. Similarly, we can deï¬ne Ï„ â€² with respect to another group of copulas {Câ€², Câ€² v, v âˆˆV}. We want to compare Ï„ and Ï„ â€² with respect to the relation between {C, Cv, v âˆˆV} and {Câ€², Câ€² v, v âˆˆV}. 19 Proposition 7 Under the conditions of Proposition 6, namely Ï(A) < (Î² + Î±)2 Î³Î² so that system (4) has a unique equilibrium and C  Cv  u1, . . . , udeg(v)  , u0  â‰¤Câ€²  Câ€² v  u1, . . . , udeg(v)  , u0  for all v âˆˆV, we have (i) if 1 âˆ’Î² â‰¤iâˆ—âˆ’, then Ï„ â‰¤Ï„ â€²; (ii) if 1 âˆ’Î² â‰¥iâˆ—+, then Ï„ â‰¥Ï„ â€², where iâˆ—+ def = maxvâˆˆV iâˆ—+ v , iâˆ—âˆ’and iâˆ—+ v are deï¬ned in Proposition 1. Proof According to Proposition 1, we know that iâˆ—âˆ’â‰¤iâˆ— v â‰¤iâˆ—+, which implies Î² 1âˆ’iâˆ—âˆ’â‰¤ Î² 1âˆ’iâˆ—v â‰¤ Î² 1âˆ’iâˆ—+. According to Eq. (17), Ï„ is decreasing in maxvâˆˆV |1 âˆ’ Î² 1âˆ’iâˆ—v |. Therefore, Ï„ is decreasing in iâˆ— v when 1 âˆ’Î² â‰¤iâˆ—âˆ’, and increasing in iâˆ— v when 1 âˆ’Î² â‰¥iâˆ—+. By Proposition 6, we get the desired results. In order to draw insights while simplifying the discussion, let Ï„x,y denote the Ï„ as deï¬ned in Eq. (17) with respect to dependence structures (x, y). The cyber security implication of Proposition 7 is: First, under some circumstances, the stronger the dependences between the cyber attacks, the more restrictive the epidemic equilibrium threshold. More speciï¬cally, under the condition 1 âˆ’Î² â‰¤iâˆ—âˆ’, we have for all v âˆˆV: Ï„nd,y â‰¥Ï„ind,y â‰¥Ï„pd,y and Ï„x,nd â‰¥Ï„x,ind â‰¥Ï„x,pd. This means that under the above circumstances, assuming away the positive dependences between the attacks will lead to incorrect epidemic equilibrium threshold, and assuming away the negative dependences between the make the epidemic equilibrium threshold unnecessarily restrictive. This further highlights the value for the defender to render the dependences negative, provided that 1 âˆ’Î² â‰¤iâˆ—âˆ’. Second, under certain other circumstances, the stronger the dependences, the less restrictive the epidemic equilib- rium threshold. More speciï¬cally, under the condition 1 âˆ’Î² â‰¥iâˆ—+, we have Ï„nd,y â‰¤Ï„ind,y â‰¤Ï„pd,y and Ï„x,nd â‰¤Ï„x,ind â‰¤Ï„x,pd. This means that assuming away the negative dependences between the attacks will lead to incorrect epidemic equi- librium threshold, and assuming away the positive dependences will make the epidemic equilibrium threshold un- necessarily restrictive. Moreover, while rendering the dependences negative can lead to smaller equilibrium infection probabilities, it imposes a very restrictive epidemic equilibrium threshold when 1 âˆ’Î² â‰¥iâˆ—+. This means that when applying the above insights to guide practice, the defender must be aware of the parameter regions corresponding to the cyber security posture. Numerical examples. In order to illustrate the above analytic results, we consider the example of star network with N = 11 nodes. We assume that the dependence between the push-based and the pull-based attacks can be captured by the Gaussian copula C with parameter Ïƒ and the dependence between the push-based attacks launched from the leaves against the hub can be captured by copula Cv, which is the Clayton copula with parameter Î¸. These two copulas are reviewed in Section 2. We consider two sets of parameters (Î±, Î², Î³) = (0.2, 0.5, 0.05) and (Î±, Î², Î³) = (0.4, 0.7, 0.05). From Eqs. (11) and (12), we can compute the equilibrium infection probabilities iâˆ— h for the hub and iâˆ— l for the leaves, and the threshold Ï„ as deï¬ned in (17). Note that the copulas are increasing in their parameters in the concordance order. By Proposition 6, both iâˆ— h and iâˆ— l are decreasing in Î¸ (Ïƒ) given Ïƒ (Î¸), as conï¬rmed by Tables 1-2. Note that for star networks, the condition 1 âˆ’Î² â‰¥iâˆ—+ in Proposition 7 can be relaxed as 1 âˆ’Î² â‰¥iâˆ—+ h , where iâˆ—+ h is deï¬ned in Proposition 3. When (Î±, Î², Î³) = (0.2, 0.5, 0.05), it is easy to verify 1 âˆ’Î² â‰¥iâˆ—+ h , meaning that Ï„ is decreasing in Î¸ (Ïƒ) for ï¬xed Ïƒ (Î¸). This is conï¬rmed in Table 1. When (Î±, Î², Î³) = (0.4, 0.7, 0.05), the condition 1 âˆ’Î² â‰¤iâˆ—âˆ’in Proposition 7 is satisï¬ed, meaning that Ï„ is increasing in Î¸ (Ïƒ) for ï¬xed Ïƒ (Î¸). This is conï¬rmed in Table 2. These examples also conï¬rm the conclusion iâˆ— h â‰¥iâˆ— l given by Proposition 2. 20 Î¸ Ïƒ = 0.5 (nd) Ïƒ = 0 (ind) Ïƒ = âˆ’0.5 (pd) iâˆ— h iâˆ— l Ï„ iâˆ— h iâˆ— l Ï„ iâˆ— h iâˆ— l Ï„ 1.0 .35 .29 14.11 .38 .30 14.31 .40 .31 14.40 1.5 .35 .29 14.11 .38 .30 14.30 .40 .31 14.39 2.0 .35 .29 14.11 .38 .30 14.30 .39 .31 14.39 2.5 .34 .29 14.11 .38 .30 14.30 .39 .31 14.39 3.0 .34 .29 14.11 .37 .30 14.30 .39 .30 14.39 3.5 .34 .29 14.11 .37 .30 14.30 .39 .30 14.38 4.0 .34 .29 14.11 .37 .30 14.30 .39 .30 14.38 4.5 .34 .29 14.11 .37 .30 14.29 .38 .30 14.38 5.0 .34 .29 14.11 .37 .30 14.29 .38 .30 14.38 5.5 .34 .29 14.11 .37 .30 14.29 .38 .30 14.38 6.0 .33 .29 14.11 .36 .30 14.29 .38 .30 14.38 Table 1: (Î±, Î², Î³) = (0.2, 0.5, 0.05) Î¸ Ïƒ = 0.5 (nd) Ïƒ = 0 (ind) Ïƒ = âˆ’0.5 (pd) iâˆ— h iâˆ— l Ï„ iâˆ— h iâˆ— l Ï„ iâˆ— h iâˆ— l Ï„ 1.0 .39 .37 17.11 .41 .37 16.09 .44 .38 15.20 1.5 .39 .37 17.15 .41 .37 16.16 .43 .38 15.29 2.0 .39 .37 17.18 .41 .37 16.21 .43 .38 15.36 2.5 .39 .37 17.21 .41 .37 16.26 .43 .38 15.43 3.0 .38 .37 17.24 .41 .37 16.31 .43 .38 15.50 3.5 .38 .37 17.27 .41 .37 16.35 .43 .38 15.56 4.0 .38 .37 17.30 .41 .37 16.39 .43 .38 15.62 4.5 .38 .37 17.31 .41 .37 16.43 .42 .38 15.67 5.0 .38 .37 17.33 .41 .37 16.47 .42 .38 15.72 5.5 .38 .37 17.35 .40 .37 16.50 .42 .38 15.77 6.0 .38 .37 17.37 .40 .37 16.53 .42 .38 15.81 Table 2: (Î±, Î², Î³) = (0.4, 0.7, 0.05) 21 4.2 Side-Effects on the Non-Equilibrium Infection Probabilities We now investigate the side-effects on the non-equilibrium infection probabilities i(t) = (i1(t), . . . , iN(t)), no matter whether the epidemic spreading converges to equilibrium or not. Proposition 8 (side-effects on the non-equilibrium infection probabilities) Consider two vectors of infection prob- abilities i(t0) â‰¥iâ€²(t0) at some time t0 â‰¥0. Let Âµ = maxvâˆˆV Âµv = max{1 âˆ’Î², min{Î± + Î³Deg, 1}}, where Deg = maxvâˆˆV deg(v). If condition (16) holds and min vâˆˆV{C (Î´Cv (1 âˆ’Î³Âµ) , 1 âˆ’Î±)} â‰¥Î², (18) then i(t) â‰¥iâ€²(t) for all t â‰¥t0. Proof We need to show that i(t + 1) â‰¥iâ€²(t + 1) when i(t) â‰¥iâ€²(t) is given. Note that iv(t + 1) =  C  Cv  1 âˆ’Î³iv,1(t), . . . , 1 âˆ’Î³iv,deg(v)(t)  , 1 âˆ’Î±  âˆ’Î²  (iv(t) âˆ’1) + 1 âˆ’Î², iâ€² v(t + 1) = h Câ€²  Câ€² v  1 âˆ’Î³iâ€² v,1(t), . . . , 1 âˆ’Î³iâ€² v,deg(v)(t)  , 1 âˆ’Î±  âˆ’Î² i (iâ€² v(t) âˆ’1) + 1 âˆ’Î². According to Ineq. (15) in the proof of Proposition 5, we have iv(t) â‰¤Âµ for all v âˆˆV. Then, conditions (16) and (18) imply C  Cv  1 âˆ’Î³iv,1(t), . . . , 1 âˆ’Î³iv,deg(v)(t)  , 1 âˆ’Î±  âˆ’Î² â‰¥ 0, Câ€²  Câ€² v  1 âˆ’Î³iv,1(t), . . . , 1 âˆ’Î³iv,deg(v)(t)  , 1 âˆ’Î±  âˆ’Î² â‰¥ 0. Since i(t) â‰¥iâ€²(t), we have iv(t + 1) â‰¥  C  Cv  1 âˆ’Î³iv,1(t), . . . , 1 âˆ’Î³iv,deg(v)(t)  , 1 âˆ’Î±  âˆ’Î²  (iâ€² v(t) âˆ’1) + 1 âˆ’Î² â‰¥  Câ€²  Câ€² v  1 âˆ’Î³iv,1(t), . . . , 1 âˆ’Î³iv,deg(v)(t)  , 1 âˆ’Î±  âˆ’Î²  (iâ€² v(t) âˆ’1) + 1 âˆ’Î² â‰¥ h Câ€²  Câ€² v  1 âˆ’Î³iâ€² v,1(t), . . . , 1 âˆ’Î³iâ€² v,deg(v)(t)  , 1 âˆ’Î±  âˆ’Î² i (iâ€² v(t) âˆ’1) + 1 âˆ’Î² = iâ€² v(t + 1). Since the above holds for all v âˆˆV, we obtain the desired result. t = 6 t = 7 t = 8 iv(t) iâ€² v(t) iv(t) iâ€² v(t) iv(t) iâ€² v(t) v = 1 0.61 0.60 0.42 0.42 0.57 0.56 2 0.64 0.63 0.39 0.40 0.60 0.58 3 0.56 0.57 0.46 0.45 0.54 0.54 4 0.57 0.57 0.45 0.45 0.55 0.54 5 0.46 0.47 0.54 0.53 0.47 0.48 6 0.60 0.60 0.42 0.42 0.56 0.56 Figure 5: Clayton copulas with (Î¸, Î·) = (1, 1.5), (Î¸, Î·) = (10, 15), (Î±, Î², Î³) = (0.9, 0.9, 0.8). One may wonder if a more succinct result than Proposition 8 could be obtained by, for example, eliminating condition (18). Here we use an example to show that if we eliminate condition (18), then Proposition 8 may not hold. Speciï¬cally, consider the network with six nodes illustrated in Figure 5. Suppose C and the Cvâ€™s for v âˆˆV are Clayton copulas with positive parameters Î¸ and Î·, namely C(u1, u2) = h uâˆ’Î¸ 1 + uâˆ’Î¸ 2 âˆ’1 iâˆ’1/Î¸ and Cv  u1, . . . , udeg(v)  = ï£® ï£° deg(v) X i=1 uâˆ’Î· i âˆ’deg(v) + 1 ï£¹ ï£» âˆ’1/Î· . 22 Consider two groups of Clayton copulas respectively with parameters (Î¸, Î·) = (1, 1.5) and (Î¸, Î·) = (10, 15). Denote the corresponding infection probabilities by iv(t) and iâ€² v(t), respectively. Set (Î±, Î², Î³) = (0.9, 0.9, 0.8), and in this case condition (18) is not satisï¬ed. Set the initial infection probabilities as i(0) = iâ€²(0) = (0.2, 0.1, 0.3, 0.3, 0.6, 0.2). The table in Figure 5 shows i(t) and iâ€²(t) for t = 6, 7, 8, from which we observe that i(t) â‰¥iâ€²(t) does not hold. This means that we cannot eliminate condition (18) in Proposition 8. 5 Conclusions We have presented the ï¬rst systematic investigation of cyber epidemic models with dependences. We have derived epidemic equilibrium thresholds, bounds for equilibrium infection probabilities, and bounds for non-equilibrium in- fection probabilities, while accommodating arbitrary dependences between the push-based attacks and the pull-based attacks as well as the dependences between the push-based attacks. In particular, we showed that assuming away the due dependences can render the results thereof unnecessarily restrictive or even incorrect. Our study brings up a range of interesting research problems for further work. First, our characterization study assumes that the dependence or copula structures are given. It is important to know which dependence structures are more relevant than the others in practice. Second, it is ideal to obtain closed-form results on the equilibrium infection probabilities and the non-equilibrium infection probabilities. Third, if we cannot derive closed-form results for the (non-)equilibrium infection probabilities, it is important to seek bounds for these probabilities and systematically analyze their tightness. Acknowledgement. This work was supported in part by ARO Grants # W911NF-12-1-0286 and # W911NF-13-1- 0141, and by AFOSR Grant # FA9550-09-1-0165. References [1] D. Chakrabarti, Y. Wang, C. Wang, J. Leskovec, and C. Faloutsos. Epidemic thresholds in real networks. ACM Trans. Inf. Syst. Secur. 10 (4), 1-26, 2008. [2] F. Chung, L. Lu and V. Vu. Eigenvalues of random power law graphs. Annals of Combinatorics, 7, 21-33, 2003. [3] U. Cherubini, E. Luciano, and W. Vecchiato. Copula methods in ï¬nance. New York: Wiley, 2004. [4] D. Cvetkovic, P. Rowlingson, and S. Simic. An introduction to the theory of graph spectra. Cambridge University Press, UK, 2010. [5] G. Da, M. Xu, and S. Xu. A New Approach to Modeling and Analyzing Security of Networked Systems. Proc. 2014 Symposium and Bootcamp on the Science of Security (HotSoSâ€™14), to appear. [6] A. Ganesh, L. Massoulie, and D. Towsley. The effect of network topology on the spread of epidemics. In Proceed- ings of IEEE Infocom, 2005. [7] A. Granas and J. Dugundji. Fixed Point Theory. Springer-Verlag, New York, 2003. [8] H. Joe. Multivariate models and dependence concepts. Monographs on Statistics and Applied Probability, vol. 73. Chapman & Hall, London, 1997. [9] J. Kephart and S. White. Directed-graph epidemiological models of computer viruses. IEEE Symposium on Se- curity and Privacy, pages 343â€“361, 1991. [10] W. Kermack and A. McKendrick. A contribution to the mathematical theory of epidemics. Proc. of Roy. Soc. Lond. A, 115:700â€“721, 1927. [11] X. Li, T. Parker, and S. Xu. A Stochastic Model for Quantitative Security Analysis of Networked Systems. IEEE Transactions on Dependable and Secure Computing, 8(1): 28-43, 2011. 23 [12] C. R. MacCluer. The Many Proofs and Applications of Perronâ€™s Theorem. SIAM Review, 42, 487-498, 2000. [13] A. McKendrick. Applications of mathematics to medical problems. Proc. of Edin. Math. Soceity, 14:98â€“130, 1926. [14] A.J. McNeila and J. NeË˜slehovÂ´a. Multivariate Archimedean copulas, d-monotone functions and l1-norm symmet- ric distributions. Annals of Statistics, 37, 3059-3097, 2009. [15] R. B. Nelsen. An introduction to copulas, second ed. Springer Series in Statistics. Springer, New York, 2006. [16] P. Van Mieghem, J. Omic and Kooij, R. Virus Spread in Networks. IEEE/ACM Transactions on Networking, 17(1), pp 1-14, 2009. [17] Y. Wang, D. Chakrabarti, C. Wang, and C. Faloutsos. Epidemic spreading in real networks: An eigenvalue viewpoint. Proc. of the 22nd IEEE Symposium on Reliable Distributed Systems (SRDSâ€™03), pages 25â€“34, 2003. [18] M. Xu and S. Xu. An Extended Stochastic Model for Quantitative Security Analysis of Networked Systems. Internet Mathematics, (8)3, 288-320, 2012. [19] S. Xu, W. Lu, and L. Xu. Push- and Pull-based Epidemic Spreading in Networks: Thresholds and Deeper Insights. ACM Transactions on Autonomous and Adaptive Systems (ACM TAAS), 7(3):32. 2012. [20] S. Xu, W. Lu, and Z. Zhan, A stochastic model of multivirus dynamics, IEEE Trans. Dependable Sec. Comput., vol. 9, no. 1, pp. 30â€“45, 2012. 24