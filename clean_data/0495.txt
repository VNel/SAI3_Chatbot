From Cyber Security Incident Management to Cyber Security Crisis Management in the European Union Jukka Ruohonena,∗, Kalle Rindellb, Simone Busettic aUniversity of Southern Denmark, Denmark bUniversity of Turku, Finland cUniversity of Teramo, Italy Abstract Incident management is a classical topic in cyber security. Recently, the European Union (EU) has started to consider also the relation between cyber security incidents and cyber security crises. These considerations and preparations, including those specified in the EU’s new cyber security laws, constitute the paper’s topic. According to an analysis of the laws and associated policy documents, (i) cyber security crises are equated in the EU to large-scale cyber security incidents that either exceed a handling capacity of a single member state or affect at least two member states. For this and other purposes, (ii) the new laws substantially increase mandatory reporting about cyber security incidents, including but not limited to the large-scale incidents. Despite the laws and new governance bodies established by them, however, (iii) the working of actual cyber security crisis management remains unclear particularly at the EU-level. With these policy research results, the paper advances the domain of cyber security incident management research by elaborating how European law perceives cyber security crises and their relation to cyber security incidents, paving the way for many relevant further research topics with practical relevance, whether theoretical, conceptual, or empirical. Keywords: risk management, risk analysis, incident management, crisis management, regulations, governance, EU 1. Introduction “Europe has been in crisis management mode for a decade and a half” (Handler, 2024, p. 1). Although the statement quoted is true in many respects, it does not (yet) apply to the cyber security domain. In other words, to the best of the authors’ knowledge, there has not been a truly large-scale, pan-European cyber security crisis thus far. This statement does not mean that the EU would not have prepared for such a crisis. These preparations, including those mandated by the EU’s new cyber security laws, are what the paper is about. The paper’s relevance and contributions can be elaborated with four brief points. To start from practical relevance, first, the topic is timely. In fact, the European Commission (EC) just re- cently released a new proposal for handling large-scale, cross-country cyber security crises in Europe (EC, 2025a). The second point follows from this timeliness; again to the best of the authors’ knowledge, the paper is the first to elaborate cyber security crisis management in the EU context. While there are some existing works, they have concentrated on national cyber security crisis manage- ment (Boeke, 2017; Collier, 2016; Østby and Katt, 2020). That is, the EU context has been missing thus far, includ- ing with respect to the EU’s new judicial framework. In ∗Corresponding author. Email address: juk@mmmi.sdu.dk (Jukka Ruohonen) addition, governance below national administrations has received limited attention in general (B´eland et al., 2024). Subsequently, third, the paper contributes to the recent ef- forts to digest and analyze the EU’s many new cyber secu- rity laws and their implications (Alexopoulos et al., 2025; Busetti and Scanni, 2025; Mueck and Gaie, 2025; Rataj, 2025; Ruohonen, 2024b; Ruohonen et al., 2025, among many others). Regarding existing research and knowledge more generally, fourth and last, the paper contributes to the incident management research domain by elaborating, analyzing, and theorizing on how incidents are related to and may transform into crises. Because crises typically have immense consequences, the paper’s overall relevance is well-justified; it is important to understand how the EU’s new cyber security legal framework is designed with crisis management in mind. With respect to the last point, both incident manage- ment research and frameworks for it have traditionally op- erated at the organizational level; incidents are something that organizations may face, and thus they should also pre- pare for them. For instance, a classical incident manage- ment framework from the National Institute of Standards and Technology (NIST) defines cyber security incident as “a violation or imminent threat of violation” of any cy- ber “security policies, acceptable use policies, or standard security practices” established and enforced by organiza- tions (Cichonski et al., 2012, p. 6). The organizational fo- cus is thus clear. According to an early literature review, Preprint submitted to Elsevier April 22, 2025 arXiv:2504.14220v1 [cs.CR] 19 Apr 2025 a similar focus is present in many other well-known frame- works and standards for incident management and closely related topics (Tøndel et al., 2014). From the previous quotation it also follows that an organization should have cyber security policies established and enforced because otherwise an incident remains only implicit and vaguely defined. A similar claim applies to cyber security crisis management; also larger entities, whether industry sec- tors, geographic regions, or countries and beyond, should have policies in place for handling cyber security crises. As will be seen, in the EU these policies are partially but still explicitly written in recent cyber security laws. A further point about the organizational focus is that it has typically been present also in different socio-technical frameworks for incident management and cyber security management in general (Al Sabbagh and Kowalski, 2015; Jaatun et al., 2009; van Haastrecht et al., 2021). Moti- vated by a recent work on layered cyber security frame- works (Panteli et al., 2025), the paper adopts a multi-level perspective sometimes used in the socio-technical frame- works (Malatji et al., 2019), but extends it beyond orga- nizations. Thus, the first part in the socio-technical term refers to an adjective societal and particularly a noun Eu- ropean. Although societal cyber security is not a well- defined concept, it has sometimes been discussed in a con- text of critical infrastructure protection (Gjesvik, 2019). Such a framing serves also the paper’s purposes well be- cause among the EU laws considered is an important new law for critical infrastructure protection in Europe. With these motivating remarks in mind, the following three research questions (RQs) are examined: • RQ.1: What constitutes a cyber security crisis in the European Union? • RQ.2: What do recent EU laws impose upon cyber security incident and crisis management? • RQ.3: How cyber security crises are managed, gov- erned, and coordinated in the EU and by whom? The paper’s remainder is structured into four sections. The opening Section 2 motivates the background further, including with respect to the multi-level approach pursued and the EU laws considered. The methodology for analyz- ing these is also elaborated, and a few clarifying framings are also done to restrict and limit the paper’s scope. Sec- tion 3 continues by elaborating how different law-imposed incident types are related to the multi-level approach. In general, the section answers to RQ.1 and RQ.2. The sub- sequent Section 4 answers to RQ.3 by elaborating the var- ious institutions, organizations, and networks involved in cyber security crisis management in the EU context. The final Section 5 presents a concluding discussion. 2. Background 2.1. Framings Some framings are required for limiting and aligning the paper’s scope to a manageable composition. To be- gin with, the paper is framed toward cyber security alone. The paper’s opening quotation about Europe having been in a crisis management mode for a long time helps to un- derstand that crises vary a lot; from financial crises all the way to wars and the existential climate change crisis. While notions such as cascading effects and risks (Adkins et al., 2020; Ruohonen, 2024a; Ruohonen et al., 2025) make it understandable that many crises may be interconnected to each other, no attempts are made to connect cyber se- curity crises to other crises. The same applies regarding threats. Some cyber security threats, including particu- larly those related to advanced persistent threat (APT) ac- tors, are today, in Europe, often perceived to be linked with a broader class of so-called hybrid threats (Anagnos- takis, 2023; Jungwirth et al., 2023). While acknowledging the linkage’s theoretical and practical validity, no attempts are made to move beyond plain cyber security. By implica- tion, as hybrid threats may involve also a military dimen- sion, also the EU’s other cyber security pillars (Christou, 2016; Ruohonen, 2024b), whether cyber defense or data protection, are excluded from the paper’s scope. Further- more, theorizing about different types of cyber security crises are further omitted for brevity, clarity, and align- ment with the EU’s laws. With respect to large-scale cyber security crises, ENISA (2024, p. 12) emphasizes a need to distinguish between a creeping crisis, “which simmers under the radar” before “suddenly and unexpectedly erupting”, an acute crisis, “which is sudden, unforeseen and can have a massive im- pact in a very short amount of time”, and a recurring cri- sis, which occurs almost continuously. Similar categoriza- tions have been presented in the academic literature (Boin et al., 2018; Head, 2022). Of these three types, denial of service attacks, in particular, could be seen as something recurrent, whereas a severe data breach or a successful ransomware attack might be seen to belong to the cate- gory of acute crises. Though, these examples are more about incidents than crises; therefore, also risk analysis is presumably more challenging when trying to assess crises rater than incidents; when operating at a level of societies or beyond rather than at the conventional organizational level. At the societal level, an example of a creeping crisis might involve a discovered large-scale espionage campaign conducted by an APT actor. Beyond these brief remarks, as said, more elaborate theorization is left for further work. 2.2. Methodology The paper operates in the domain of policy studies. Within this domain, a separation between policy analysis and policy (process) research is sometimes done. Broadly 2 speaking, the former is about prescriptive research seek- ing to inform policy-making, whether in terms of evalua- tions, impact assessments, or something else, while the lat- ter is descriptive research focused particularly on theory- building (DeLeon and Weible, 2010; Secchi, 2016). Given this characterization, the paper is about policy research. Regarding descriptive policy research, an ex post, post hoc, or retrospective approach is used (cf. Patton et al., 2016). This choice is also unavoidable because the EU laws con- sidered have already been enacted. Regarding ex ante policy analysis, it is worth remarking that the EC did prior impact assessments for most—but not all (EP, 2024)—of the laws considered in the paper. For the paper’s purposes, it is particularly worth remark- ing that these assessments indicated a lack of joint situa- tional awareness and crisis management between the mem- ber states, and between them and the EU-level administra- tion; information sharing was concluded to operate on an ad hoc basis and cross-border spillovers were omitted from risk analyses (EC, 2020, pp. 21–22). This point justifies an academic expert evaluation of the three RQs postulated. Regarding theory-building, the paper analyzes and the- orizes how the EU’s new laws align with common analyt- ical frameworks used in incident and crisis management research. On the side of engineering and computer sci- ence, within which theory-building often has a different meaning, the paper aligns with requirements engineering research within which legal requirements are a distinct genre (Ruohonen et al., 2025). This research branch jus- tifies RQ.2. In other words, it is important to know what laws require, whether from organizations, producers, or public administrations. Once an answer is known, it is pos- sible to continue toward empirical policy research; with- out knowing the legal requirements, formulation of rele- vant research questions is difficult—if not questionable al- together. This point also applies to the framings done; in- sofar as policy analysis is concerned, it is pointless to eval- uate responses to hybrid threats without knowing about the preparations and frameworks for handling them. 2.3. Analytical Levels The paper’s conceptual and theoretical background can be motivated by considering an analytical relation be- tween incidents and crisis through different vertical levels of analysis often used in social sciences. A term multi- level analysis is sometimes used to refer to approaches that operate at two or more such levels (B´eland et al., 2024; Hutzschenreuter et al., 2020). The term should not be equated to multi-level (cyber) security, although there is a rough conceptual similarity because both involve a hi- erarchy (Anderson, 2020). In any case, an incident that involves multiple analytical levels could be called a multi- level incident—or, depending on which levels an incident has transcended, a cyber security crisis. 2.3.1. The International Level The international level is at the top of the hierarchy. When operating at this level, an analysis typically func- tions horizontally, focusing on relations between states. In terms of cyber security, good examples about such inter- state, transnational relations would cover cyber norms, cy- ber diplomacy, and even what is known and debated as cyber war. However, as said, such topics are beyond the paper’s scope. Another point is that it is also possible to consider information systems and other technical solu- tions at this level; such systems and solutions are those that transcend both national and organizational bound- aries (Rukanova et al., 2015). Such transcendence can also been seen as something that separates cyber security inci- dents from cyber security crises. If a cyber security incident escalates to the international level, it is not really any more a mere incident but rather a crisis. With this point in mind, Fig. 1 displays seven an- alytical levels through which incidents may become crises. As can be seen, the impact is taken to increase the further a cyber security event is from an incident. Incident Crisis Individual Organizational Sectoral Regional National Supranational International Vertical level Impact Horizontal governance at the same vertical level Figure 1: Analytical Levels (adopted from ENISA 2024, pp. 17–18) 2.3.2. The Supranational Level Below the international level is a supranational level. This level is at which the EU operates; the European Union is a supranational union. At the same time, how- ever, it operates in intergovernmental terms; the Council of the European Union would be the prime example in this regard. In contrast, the European Union Agency for Cy- bersecurity (ENISA) operates at the supranational level, although intergovernmental tenets may still be present in terms of staffing and related aspects. While there is a classical debate regarding the meaning of and interplay be- tween these two theoretical governance terms (Bickerton et al., 2022; Handler, 2024; Tsebelis and Garrett, 2021), without a particular loss of specificity and rigor, the term supranationalism is used in case there is no particular rea- son to emphasize the intergovernmental dimension. Note also a difference between the terms transnational and intergovernmental; the latter is about relations be- tween governments, as is the case in the Council in which ministers or other heads of states represent their mem- 3 ber states, whereas the former can be seen to cover also supranational governance because the meaning is essen- tially about relations between nations. These relations may be about states, but they may also include transna- tional non-governmental organizations, different transna- tional collaboration and coordination networks, and inter- national organizations (G¨anzle et al., 2022). When such transnational relations are accounted for, the term multi- level governance can be seen to cover also a horizontal dimension; a coordination and collaboration between dif- ferent entities not directly linked to governmental repre- sentatives. These terminological clarifications are impor- tant because the EU’s overall multi-level crisis manage- ment framework covers numerous actors operating at dif- ferent governance levels and policy areas (Anagnostakis, 2023). The concepts also provide a theoretical foundation for analyzing the EU’s cyber security crisis management framework in terms of governance and coordination. 2.3.3. The National, Regional, and Sectoral Levels When taking a step downwards from the supranational level, the national level is encountered. Regarding gover- nance, authoritative computer security incident response teams (CSIRTs) are particularly relevant in Europe; ac- cording to both old and new EU laws, each member state should have an authoritative CSIRT or a related com- petent authority for nationwide incident management.1 However, presently it remains still somewhat unclear how national administrations are, or will be, arranged in each and every member state. By hypothesis, the divergence is, or will be, large across the twenty-seven member states. Although there are no clear demarcations, operations at the national level are sometimes (but not always) about crisis management rather than incident management. The same could be said even about the regional level, espe- cially when keeping in mind that it includes both smaller geographically bound administrative units as well as larger geographic units, such as is the case in the Germany’s fed- eralist administration. Also crisis management tends to be decentralized to the regional, L¨ander, level in Germany, although strategic management and high-level political co- ordination occurs at the federal level (Christensen et al., 2016). Without the federalist twist, the setup is rather similar to many other European countries within which strategic and political aspects are oftentimes centralized, while the operational level is often more or less decen- tralized (Christensen et al., 2016; Gjesvik, 2019; Ramsell and Wihlborg, 2012). Regions also intervene with indus- try sectors in many member states. Whether an exam- ple is about the Ruhr region in Germany or the Emilia- Romagna region in Italy, specialized industry activity has 1 Here, the adjective authoritative is used for emphasizing a dif- ference to other CSIRTs, including sectoral teams as well as teams within organizations and companies. Note also that in practice the abbreviation CSIRT is equivalent to an abbreviation CERT, denot- ing a computer emergency response team. often concentrated to specific regions in Europe and also elsewhere. Authoritative CSIRTs in some European coun- tries have also been decentralized with sectoral special- ization in mind (Boin et al., 2018). In terms of incident management, many industries also have different sectoral and regional coordination networks and governance hubs. 2.3.4. The Organizational and Individual Levels Then, below the sectoral level is the organizational level. As said in the introduction, this level has been the traditional focal point in incident management and its research. Again, coordination may occur horizon- tally between organizations (inter-organizational coordi- nation) and within organizations (intra-organizational co- ordination), and vertically between organizations and in- dividuals (Heine, 2019; Panteli et al., 2025). The intra- organizational coordination is relevant also for establish- ing organizational CSIRTs; typical choices for large orga- nizations include outsourcing, a centralized organization- wide team, or distributed teams across an organization’s departments (Mitropoulos et al., 2006; Cichonski et al., 2012). Organizations may also coordinate vertically with sectoral or regional entities, such as industry associations, as well as entities operating at a national level, including authoritative CSIRTs in particular. Finally, as seen from Fig. 1, it is also possible to consider incidents at a level of individuals, whether employees, citizens, or consumers. Given the extensive research and evidence on the human factors in cyber security, it is also possible that an incident affecting an individual escalates to the organizational level or even beyond that. 2.3.5. An Example of a Multi-Level Incident A good example about a multi-level incident would be the attacks against Danish energy sector companies in 2023. Given that over twenty energy sector companies were compromised, the incident prompted also interna- tional media attention (Antoniuk, 2023). Regarding the analytical levels, the example is illuminating because it involved three or four levels in Fig. 1. To begin with, the incident was not only organizational but also sectoral due to the involvement of multiple com- panies in the same sector. Given the potential concen- tration of the energy sector companies to some particular regions in Denmark, the incident could be perhaps inter- preted to involve also the regional level. In any case, the sectoral level manifested itself also in the investigation con- ducted by SektorCERT (2023), a non-profit CSIRT com- posed by Danish critical infrastructure companies and op- erators. The investigation revealed that the compromises were conducted by exploiting a vulnerability in a firewall product.2 Furthermore, an update had been available but the energy sector companies had not patched their firewalls for a reason or another. During the incident management, the issue escalated further to the national level. 2 CVE-2023-28771. 4 Among other things, CFCS (2023), the authoritative CSIRT in Denmark, raised the threat level against the Danish energy sector to the very high level category. How- ever: while multiple levels were involved, the incident is not yet something that could be interpreted as a cyber se- curity crisis according to the EU’s laws. This point will become clear in Subsection 3.1 that elaborates different incident types present in the recently enacted EU laws. 2.4. The EU’s Strategy The EU’s new cyber security strategy can be sum- marized in the form of Fig. 2. Three of the strategy’s pillars—prevention, detection, and response—resemble rather similar phases in incident management frameworks. For instance, the NIST’s noted framework is structured around preparation, detection and analysis, containment, eradication, and recovery, and post-incident phases (Ci- chonski et al. 2012; cf. also Mitropoulos et al. 2006). Rather analogously, ENISA (2024) builds upon preven- tion, preparedness, and response and recovery phases. An- other example would be prepare, detect and recover, and learn (Jaatun et al., 2009). A further point is that the EU’s strategy is structured around specific laws, which are also supported by funding instruments, education, re- search, development, and innovation projects, and specific governance bodies, some of which are new. Prevent Detect Respond Deter NIS2 CRA CSA CSOA CRA CSOA NIS2 CRA CSOA Diplomacy Defense Law enfor. International cooperation Investments, skills, science, development, and institutions Figure 2: The EU’s Current Cyber Security Strategy in a Nutshell (adopted from EC 2025b) Before continuing to enumerate the laws covered, it should be emphasized that there are many further EU laws explicitly or implicitly related to cyber security, some of which are sector-specific and some others of which over- lap with each other (EC, 2025a; Fischer-H¨ubner et al., 2021; Ruohonen et al., 2025). Against this backdrop, it is no wonder that regulatory fragmentation and complexity have been a source of commonly expressed criticism (Alex- opoulos et al., 2025; Ruohonen, 2024b). In any case, it should be emphasized that the specific laws considered are particularly relevant for the paper’s topic. In other words, as will elaborated in Section 3, the laws also help to understand how a transcendence from an incident to a unionwide crisis is legally perceived and structured. Of the four laws abbreviated in Fig. 2, particularly im- portant are the so-called NIS2 directive (EU, 2022) and the Cyber Resilience Act (CRA) regulation (EU, 2024). Although a concept of essential and important entities (EAIEs) is used in the NIS2 directive, the directive is es- sentially about critical infrastructure protection. Overall, the directive builds upon a sectoral approach; numerous sectors are enumerated as carrying “critical societal or eco- nomic activities”, to quote from the NIS2’s Article 2(2)(b). This quotation aligns with the notion of societal cyber se- curity noted in the introduction. The actual sectors spec- ified range from traditional critical infrastructure sectors, such as energy and transport, to banking, healthcare, fi- nance, drinking and waste water management, the Inter- net’s core infrastructure, and space technologies. In contrast, the CRA regulation is a product-specific law; among other things, it specifies so-called essential cy- ber security requirements for almost all information tech- nology products. As these requirements have already been considered in detail (Ruohonen et al., 2025), including with respect to new obligations regarding vulnerability co- ordination and disclosure (Ruohonen and Timmers, 2024), in what follows, the CRA is only discussed with respect to its mandates for incident reporting. Having said that, it is worth remarking that the CRA’s essential requirement about preferably automated security updates would have prevented the Danish energy sector case noted earlier in Subsection 2.3.5, and, furthermore, some of the essential requirements contain also elements aligning with the tech- nical detection and prevention of incidents. Regarding the CRA more generally, also the older Cy- bersecurity Act (CSA) can be mentioned (EU, 2019). While it strengthened the role and mandates of ENISA, it also introduce a common cyber security certification scheme for information technology products. This certi- fication scheme aligns with the CRA in that conformance can be attained also (but not only) through certification. Given that standards are also an important part of the CRA and compliance with it, the regulation seems to have at least partially answered to criticism from the industry and practitioners (Fischer-H¨ubner et al., 2021). Finally, recently a new Cyber Solidarity Act (CSOA) regulation was agreed upon (EU, 2025). As can be seen from Fig. 2, it covers aspects from all the three pillars noted earlier. A couple of additional remarks are in order before con- tinuing to elaborate the laws and their implications in de- tail. The first remark is that deterring of cyber security threats appears in Fig. 2. While this topic is beyond the paper’s scope, it can be noted that deterrence has long been debated in the literature (Goodman, 2010, among many others), some authors having taken a critical stance about the working of deterrence in the cyber security con- text (among them Soesanto and Smeets, 2021). The sec- ond remark is that all of the laws are more or less risk- based, some explicitly and some only implicitly. In partic- ular, the NIS2 directive’s Article 21 obliges EAIEs to carry out comprehensive risk analyses. These should be done by following a so-called “all-hazards” approach, which is also familiar from the academic literature (Ayyub et al., 2007; Izumi, 2024). According to NIS2, the approach means that 5 anything and everything from incident handling, backups, and supply-chain security to security awareness campaigns and business continuity should be assessed. The CRA too is a risk-based regulation; the essential cyber security re- quirements should be prioritized, designed, implemented against particular, product-specific risks identified. 3. Incident Types 3.1. Events Events, including alerts, whether from intrusion detec- tion systems, other monitoring systems, or somewhere else, are important building blocks for incident manage- ment (Cichonski et al., 2012). These also allow under- standing how incidents may transform into crises accord- ing to the EU’s jurisprudence. Thus, Fig. 3 displays the core event types in the new EU laws. The figure can be elaborated by moving from the bottom to the top, from alerts to incidents, severe incidents, and beyond. In line with the previous discussion, at least the last incident type shown is analytically already on the side of crises. a Incident Crisis Alert Near miss Incident Severe incident Significant incident Event type Impact True positive Alert False positive Near miss Other Incident ... Large-scale incident Figure 3: An Event Type Hierarchy As was remarked in Subsection 2.4, the CRA’s essen- tial cyber security requirements for products contain el- ements that may (or should) foster the detection cyber security incidents. For instance, the requirements include a monitoring functionality for a product’s internal activ- ity, including with respect to authorizations and integrity guarantees (Ruohonen et al., 2025). In addition, as seen also from the earlier Fig. 2, the CSOA regulation is rele- vant too with respect to incident detection. In particular, the regulation envisions a development of a large-scale, pan-European network of cyber security alert systems for coordinated incident detection and improved situational awareness capabilities. While these systems are labeled as “cyber hubs” in the regulation, they are essentially what security operation centers (SOCs) and threat intelligence systems in general are about. The network is planned upon voluntary pooling of national alert systems into large cross-border systems. The national systems may include not only those maintained by authoritative CSIRTs but also those operated by private sector companies. 3.1.1. Near Misses An alert can be a false positive or a true positive. Al- though the NIST’s definition noted in the introduction covers both, for the present purposes, it makes sense to frame incidents only toward true positives. Regarding false positives, the EU’s recent laws introduce a concept of near misses. A near miss is defined in the NIS2’s Article 6(5) to mean “an event that could have compromised the avail- ability, authenticity, integrity or confidentiality of stored, transmitted or processed data or of the services offered by, or accessible via, network and information systems, but that was successfully prevented”. Thus, within the context of incident management, the concept can be seen to be about false positives; about alerts that were suc- cessfully prevented from becoming actual incidents (true positives). In any case, reporting about near misses is vol- untary. According to Article 15(2) in the CRA regulation, manufacturers and other parties, whether natural or le- gal persons, may voluntarily report near misses either to a national authoritative CSIRT or ENISA. Likewise, ac- cording to Article 30 in the NIS2 directive, EAIEs may voluntary report near misses to a authoritative CSIRT or some related public sector authority. Voluntary reporting seems sensible already due to over- head and related reasons. Because alerts are voluminous due to various monitoring systems deployed by organiza- tions, most of them are false positives, and interoperability is a typical issue with the monitoring systems and their re- porting formats (Alahmadi et al., 2022; Zibak et al., 2022). Analogously to abuse reporting in the Internet (Jhaveri et al., 2017), a signal to noise ratio is often also low. Against these backdrops, a mandatory reporting of near misses would have presumably required large financial in- vestments and considerable coordination between various stakeholders involved, including the authoritative Euro- pean CSIRTs and producers of cyber security monitoring solutions. The issues with false positives in the cyber secu- rity context are well-recognized in the literature also more generally; not only is a minimization of them generally difficult but also a cost of handling them is often signifi- cant (Bhatt et al., 2014). However, the EU laws do not say anything how organizations should actually demarcate be- tween false and true positives, and whether there are any consequences from accidentally reporting a false positive as a true positive or the other way around. 3.1.2. Incidents Also reporting of most (but not all) true positives—that is, according to the terminology adopted, incidents—is vol- untary. According to the NIS2’s Article 6(6), an incident is defined as “an event compromising the availability, au- thenticity, integrity or confidentiality of stored, transmit- ted or processed data or of the services offered by, or acces- sible via, network and information systems”. When com- pared to the earlier definition for near misses, an incident is thus something that has actually compromised data or 6 services. While the definition aligns with classical fram- ings (Brownlee and Guttman, 1998), there is a difference to the NIST’s definition noted in the introduction is also present. Although availability, authenticity, integrity, and confidentiality may well belong to an organization’s cyber security policy, the NIS2 only notes, in Article 24, cyber security policies with respect to open source software asso- ciations. In any case, according to the NIS2’s Article 30, reporting of these “conventional” incidents is voluntary. 3.1.3. Severe Incidents When moving a step upward in the event hierarchy (see Fig. 3), the CRA regulation (but not the NIS2 direc- tive) uses a concept of severe incidents. It is mandatory to report such incidents to both a national authoritative CSIRT and ENISA according to the CRA’s Article 14(3). A twofold definition for severe incidents is given in the reg- ulation’s Article 14(5). The first part emphasizes negative impacts and potential negative impacts upon a product’s ability to protect the availability, authenticity, integrity, or confidentiality of data or services, whereas the second part emphasizes an execution and a potential execution of malicious code. It remains to be seen how manufac- turers will interpret the demarcation between the impacts and executions on one hand and the potential impacts and executions on the other hand. Another important point is that the CRA is about man- ufacturers of information technology products, not about operators of such products, including EAIEs covered by the NIS2 directive. With some relaxations, manufacturers are also mandated to report about actively exploited vul- nerabilities (Ruohonen and Timmers, 2024). In any case, the divergence between the scopes of the two EU laws reiterates a criticism expressed in the literature about a lack of an explicit legal synchronization between different reporting obligations imposed by different laws (Fischer- H¨ubner et al., 2021; Ruohonen, 2024a). In particular, in case a manufacturer reports to a national authoritative CSIRT and ENISA about a severe incident, either the given CSIRT or ENISA, or both, should presumably con- sequently report to all EAIEs and others using the man- ufacturer’s given product to which the severe incident ap- plies. Again, it remains to be seen how such consecutive reporting will work in practice. 3.1.4. Significant Incidents The remaining two incident types are specified in the NIS2 directive. According to the directive’s Article 23(3), a significant incident either “has caused or is capable of causing severe operational disruption of the services or fi- nancial loss for the entity concerned”, or it “has affected or is capable of affecting other natural or legal persons by causing considerable material or non-material damage”. The again twofold definition warrants three brief remarks. The first remark is related to the earlier point about potential effects; the wording “capable of” yet again en- tails a demarcation problem between actual significant in- cidents and those merely conveying a probability of such incidents. Presently, no guidance is available upon this demarcation (Busetti and Scanni, 2025). The second re- mark is related to the wording about “severe operational disruption”. Here, it would seem that anything from se- vere denial of service attacks to severe ransomware attacks are in the scope. The definition’s emphasis of severe finan- cial losses further underlines ransomware attacks, although also other so-called destructive cyber attacks are likely in the NIS2’s scope. The third remark is about the empha- sis about “considerable material or non-material damage” to natural persons. Therefore, it has been suspected that also severe personal data breaches are in the directive’s scope (Ruohonen et al., 2025), but a definite conclusion can likely be given only after guidelines have been released or enforcement has occurred. While keeping these and other potential interpretation issues in mind, EAIEs must report about significant incidents to a national authorita- tive CSIRTs or, where applicable, other public authorities, as well as other entities concerned according to the NIS2’s Article 23(1). Thus, broadly speaking, unlike “conven- tional” incidents, significant incidents fall into a category of mandatory reporting by EAIEs. 3.1.5. Large-Scale Incidents Finally, there is the notion about large-scale cyber se- curity incidents. A large-scale incident is defined in the NIS2 directive’s Article 6(7) as an incident which either (a) exceeds a handling capacity of a single member state or which (b) has a significant impact on at least two mem- ber states. Regarding incident management frameworks, the first part of the definition resembles a concept of esca- lation at the organizational level; an organizational CSIRT or some related security team cannot get an incident under control on its own (cf. Jaatun et al., 2009). Another point is that the EC’s (2025a, p. 12) noted recent proposal clar- ifies that these large-scale incidents are what is meant by a cyber security crisis in the EU context. While keeping the earlier remarks about terminology in mind, a cyber security crisis is thus something that moves from the na- tional level to the supranational level in Fig. 1. Also the NIS2’s recital 69 clarifies this point by noting that large- scale incidents “may escalate and turn into fully-fledged crises”. Despite such an escalation potential and interest- ingly enough, NIS2 does not explicitly say about reporting obligations of large-scale incidents, but because these must be something that also satisfy the definition for significant incidents, reporting can be interpreted as mandatory. The CSOA’s cyber security alert systems noted in Sub- section 3.1 are also related to large-scale cyber security incidents. According to the regulation’s Article 7, partic- ularly the envisioned cross-border alert systems are seen as relevant for detecting large-scale incidents and shar- ing information about them. There are also a couple of other important points to make about the relation between large-scale incidents and the CSOA regulation. The first point is about the exceeding of a member 7 state’s handling capacity used in the definition for a large- scale cyber security incident. Here, the CSOA’s Article 14 specifies an establishment of a specific cyber security “re- serve” for handling large-scale incidents. The reserve is composed by national public sector representatives as well as other trusted parties. According to Article 15, a mem- ber state in need may then request help from the reserve to recover from both significant and large-scale cyber secu- rity incidents. Furthermore, the CSOA’s Article 19 spec- ifies that help can be requested also by countries outside of the EU, provided that they are taking part in the EU’s Digital Europe Programme (DEP), a funding instrument for digital technologies and digitalization in general. The second point is that the CSOA specifies a new cyber security incident review mechanism. Its scope is restricted to significant and large-scale incidents. ENISA and a net- work of authoritative CSIRT are specified as the respon- sible parties for the actual reviews according to the regu- lation’s Article 21(1). In line with the post-incident activ- ities in the NIST’s incident management framework (Ci- chonski et al., 2012), the reviews are used for improving the union’s and the member states’ cyber security practices. Despite an incident’s or a crisis’ negative consequences, there is always also something to learn from them. 3.2. Deadlines There are strict deadlines for incidents that are manda- tory to report. When comparing the CRA’s Article 14 and the NIS2 directive’s Article 23, the wordings about the deadlines are not verbatim similar but their meaning is more or less the same. For this reason, the deadlines can be summarized in the form of Fig. 4. As was noted in the preceding Subsection 3.1.5, the deadlines for report- ing about large-scale incidents are implicit but follow from their inevitable connection to significant incidents. An- other clarifying remark needed is that the CRA’s notion about actively exploited vulnerabilities is not about inci- dents per se but can be discussed alongside them because the reporting deadlines are similar. ... Time Within 24 hours Within 72 hours Upon request Notification Status updates Final report Within 14 days Early warning Within a month Actively exploited vulnerabilities Incidents Figure 4: Reporting Deadlines for Actively Exploited Vulnerabilities and Severe, Significant, and, by implication, Large-Scale Incidents Thus, severe, significant, and large-scale incidents should be initially reported to an authoritative CSIRT, or some other competent authority, no later than twenty- four hours after becoming aware of them. Then, a more detailed incident report should be delivered no later than seventy-two hours after becoming aware of a given inci- dent. The report delivered should include an initial as- sessment about a given incident, including its severity and impact, as well as, where applicable, any indicators of a compromise. After these two reports, an authoritative CSIRT may request status updates at any time. A final report should be delivered within a month. In addition to severity and impact, the final report should contain a root cause analysis, any applied and ongoing mitigation measures, and, where applicable, an assessment about any cross-border impacts. The cross-border impact assessment again signifies the relation to large-scale incidents. Re- garding actively exploited vulnerabilities, the CRA’s Arti- cle 14(2)(c) specifies that a final report should be delivered already no later than fourteen days. It should describe a given vulnerability’s severity and impact, information about potential exploitation, and details about security updates or other corrective measures made available. Finally, it should be emphasized that while these re- porting obligations and their deadlines are only toward public authorities, also other parties typically need to be informed, including further external parties, such as stake- holders and business partners, and internal parties, such as an organization’s management and, where applicable, its employees (Kulikova et al., 2012). Thus, existing incident management plans at the organizational level presumably require or benefit from updating; a synchronization with the law-imposed obligations might be a good idea. Due to the various reporting obligations and strict deadlines, an analogous point applies on the public sector side; so-called incident triaging (ENISA, 2010) likely requires planning. 4. Crisis Management 4.1. Governance Units The management of cyber security crises is generally challenging in the EU due to the involvement of at least two member states, given the definition for a large-scale cyber security incident noted in Subsection 3.1.5. Given the analytical levels discussed in Subsection 2.3, the man- agement is about the national level and the supranational level. In terms of the former, the term transnational could be used to characterize the horizontal interstate manage- ment and coordination between the member states in- volved. While governments may be involved too in a case of particularly severe crises, the term intergovernmental might be too strong or even misleading because the ac- tual day-to-day crisis management would not likely involve governmental representatives in most cases. The NIS2 di- rective also established new crisis management bodies that are not explicitly and directly about the member states’ central governments. These also coordinate vertically to- ward units operating at the supranational level. In general, the NIS2 directive specifies cyber security cri- sis management to occur through three governance bodies: 8 1. The first is the authoritative network of European CSIRTs upon with the EU’s whole cyber security framework was initially built (Ruohonen et al., 2016). As the CSIRT network extends beyond Europe, the international level may be involved too, as also in- dicated by Fig. 2. In general, NIS2 strengthens the European CSIRT network further, obliging also the authoritative CSIRTs to carry out further tasks. 2. The second is a specific NIS2 cooperation group. However, as specified in the NIS2’s Article 14(4), its tasks are largely on the political side instead of the operational crisis management side. Among other things, the group is specified to help at formulating further policies, exchanging best practices and view- points, including regarding sectoral implementations, carrying out risk analyses, providing strategic guid- ance, and meeting with private sector stakeholders. 3. The third is a new European cyber crisis liaison or- ganisation network (EU-CyCLONe). As specified in the NIS2’s Article 16, unlike the cooperation group, EU-CyCLONe is on the operational side; in partic- ular, it is explicitly tasked to manage large-scale cy- ber security incidents. In general, the management involves similar phases that were noted in Subsec- tion 2.4, among them preparedness and response. The EU-CyCLONe network is specified to also coordinate with the network of authoritative European CSIRTs. The political side of crisis management deserves a fur- ther comment. This side is seen in the composition of the NIS2 cooperation group. As specified in the NIS2’s Arti- cle 14(3), it is composed of representatives of the member states, the EC, and ENISA, but also other public sector au- thorities may be present, including the European External Action Service (EEAS) who is responsible for the EU’s for- eign policy. While the activities of the EEAS were framed to outside of the paper’s scope via the discussion in Sub- section 2.1, it is still worth emphasizing that cyber security crisis management in the EU may involve also diplomacy and related foreign policy activities, as also indicated by the summary in Fig. 2. Analogously, the NIS2 directive’s Article 16(3)(d) specifies that the EU-CyCLONe network should also “support decision-making at political level”. Given these elaborations, it is understandable that some criticism has been levied about increased administrative complexity, fragmentation, and bureaucratization of the EU’s cyber security governance model in general (Ruoho- nen, 2024a,b). Such criticism aligns with a broader branch of research on the “bureau-politics” of crisis management (Rosenthal et al., 1991), including potential “turf wars” between governance bodies (Finke, 2020; Senninger et al., 2021). This research branch is relevant to note because rapid responses and timeliness in general are important particularly in the cyber security context. As already the deadlines in Fig. 4 demonstrate, rapid responses are re- quired from EAIEs and others, but it remains generally unclear how fast and well the responses travel through the bureaucracy and politics at the receiving end. 4.2. Management at the Supranational Level The CSIRT and EU-CyCLONe networks as well as the NIS2 cooperation group operate both at the national level and the supranational level. At the former level, these al- low horizontal coordination between the member states; at the latter level, these enable the member states to co- ordinate with EU-level institutions, among them the EC and ENISA. As was noted in Subsection 2.3.2, the Council is on the side of intergovernmental governance, and within the Council, the member states have permanent represen- tatives through the Committee of the Permanent Repre- sentatives of the Governments of the Member States to the European Union—or Coreper in short. With these clarifi- cations, a high-level crisis management framework at the EU-level can be illustrated in the form of Fig. 5. The process starts when an early warning or a later in- cident notification is received, possibly from an EAIE or a larger set of EAIEs, through an authoritative CSIRT or multiple authoritative CSIRTs. For the present purposes, the phase after the initial assessment, the EU activation phase, is the crucial one; during this phase, the two part definition for a large-scale cyber security incident should be likely assessed. Politically, the activation is done by the rotating Presidency of the Council after consulting the EC and the EEAS’ high representative (EU, 2018). As noted in the CSOA’s Article 20, the political activa- tion procedure is similar to requesting help from the new cyber reserve as well as those used for natural and other disasters requiring civil protection. Technically, however, the available documentation is unclear about the actual incident analysis. The EEAS, EC, ENISA, CSIRT and EU-CyCLONe networks are mentioned alongside Europol, the EU’s own CSIRT (known as CERT-EU), and even the EU’s intelligence and satellite institutions (EC, 2025a; EU, 2017). Given that the political activation depends on, or should depend on, the adequacy and correctness of a tech- nical incident analysis, already the amount of potential ac- tors is enough to reiterate the earlier point about adminis- trative complexity and its possible consequences. Nor is it possible to deduce what might be a cost of a false positive. Assuming that political activation is done, a further bot- tleneck might be the subsequent phases. As seen from Fig. 5, there are preparations and meetings before the ac- tual EU-level coordination starts looping. If a response time is short, these phases may cause undesirable delays. In addition to a technical response, including the con- tainment, eradication, and recovery tasks in the NIST’s framework (Cichonski et al., 2012), the EU’s crisis man- agement plans include also considerations about funding needs, diplomatic responses, and crisis communication. In addition to academic research (Kulikova et al., 2012), the role and importance of crisis communication have re- cently been emphasized also by ENISA (2024) who further 9 Constant monitoring Analysis and advice Incident Assessment No Preparation Yes Presidency round table Council (or Coreper) meeting EU-level coordination Impact monitoring Technical response Cyber diplomacy Emergency funding Crisis communication Ongoing? Yes Phasing out No ENISA's report EU activation? Figure 5: Cyber Security Crisis Management at the EU-Level (adopted and modified from EU 2017, Fig. 2) stressed a need to develop clear technical indicators and decision mechanisms for activating the EU machinery. 5. Discussion 5.1. Conclusion The paper’s conclusion can be summarized by answering to the three RQs specified in the introduction. Thus: 1. The EU’s new cyber security laws distinguish four incident types: “conventional” incidents, severe inci- dents, significant incidents, and large-scale incidents. Albeit only implicitly, the last incident type is equated to the concept of a cyber security crisis. The definition for such a crisis is twofold: a cyber security incident becomes a cyber security crisis either in case it ex- ceeds a handling capacity of a single member state of the EU or in case it significantly affects at least two member states simultaneously. 2. The EU’s new cyber security laws significantly extend reporting obligations toward public sector authorities. Both operators of critical infrastructures and produc- ers of many information technology products are man- dated to report incidents; only reporting of the “con- ventional” incidents is voluntary. The deadlines for reporting are also strict. 3. Cyber security crisis management and its governance in the EU are still strongly built upon national au- thoritative CSIRTs and their EU-level coordination bodies, including ENISA in particular. However, the new laws have also brought additional governance bodies, among them EU-CyCLONe that was specif- ically established for cyber security crisis manage- ment. In addition, a new staff reserve has been es- tablished for helping countries facing cyber security crises. Despite—or due to—these new crisis manage- ment bodies and recent policy proposals, it remains generally unclear how—and how well—crisis manage- ment works at the EU-level administration. 5.2. Further Work The three concluding answers can be accompanied by three points about further research. To motivate the first point, it can be noted that despite uncertainties about actual crisis management particularly at the EU-level, it seems the NIS2 directive has addressed a commonplace problem among many member states whose national laws and frameworks lacked a definition for a cyber security cri- sis (Boin et al., 2018). However, the NIS2’s definition for a large-scale cyber security incident might also be argued to be about too large crises in a sense that an escalation to a national level might already be perceived as a crisis in some severe cases. Given the overall escalation theme in incident management research (Mitropoulos et al., 2006), (1) further theoretical and comparative research is needed about the analytical levels in Fig. 1. Regarding compar- isons, a good starting point would be a comparative exam- ination of national laws and frameworks for cyber security crisis management in the member states. Despite the new EU laws, national and other definitions for alert levels and criticality itself remain unclear, non-harmonized, and gen- erally vague (Alexopoulos et al., 2025; Ruohonen, 2024a). Also the paper’s framings noted in Subsection 2.1 would deserve a theoretical visit. Despite the research on hy- brid threats, the relation between cyber security incidents and crises, including their potential cascading effects, and other incidents and crises remain arguably poorly under- stood and theorized. These points justify the need for more theoretical and conceptual research. Regarding the EU-level cyber security crisis manage- ment, (2) further research is required also on the roles, duties, and other functions of various different administra- tive units, whether national, supranational, or something in-between. Composites such accountability, collaboration and coordination, transparency, information sharing, de- centralization and autonomy, and responsiveness could be used to frame an evaluation (cf. Vu et al., 2025). How- ever: even though it is easy to agree with an argument that more empirical research is needed on incident man- agement in general (Tøndel et al., 2014), a problem with the NIS2’s large-scale incidents is that thus far at least 10 publicly disclosed cases are missing. In other words, it is difficult to properly evaluate a management of something that has not supposedly yet happened in Europe. Therefore, regarding empirical research, it might make sense to start from smaller evaluations. In particular, (3) the increased reporting obligations, including the strict deadlines, would offer a good topic for empirical evalu- ation research. A lot of research and other work have also been done to help at evaluating the efficiency, accu- racy, and other aspects CSIRTs and their incident manage- ment practices (Connell and Waits, 2013; Dorofee et al., 2007, among many others). However, a broader evalu- ation is required also with respect to EAIEs and others who are obliged to report about incidents or do so volun- tarily. Given the CRA’s and NIS2’s strict deadlines, as well as the penalties from non-compliance, it may be that organizations and others will report eagerly and possibly incautiously. Thus, the quality of early warnings, inci- dents notifications, and particularly final reports (Busetti and Scanni, 2025), including a rate of false positives, would provide a good research topic with practical relevance. A related topic would involve examining whether reporting guidelines and a systematic reporting format might in- crease reporting quality and reduce noise. As it stands, neither the NIS2 directive nor the other laws say anything about what should be reported. The topic is generally im- portant because regulatory obligations upon incident man- agement have recently been argued to work poorly in im- proving organizations’ cyber security postures (Patterson et al., 2024). This point serves well to end the paper by reiterating that something should always be learned from cyber security incidents and crises. Acknowledgements The authors thank Muhammad Mohsin Hussain for helpful comments. References Adkins, H., Beyer, B., Blankinship, P., Oprea, A., Lewandowski, P., and Stubblefield, A. (2020). Building Secure and Reliable Sys- tems: Best Practices for Designing, Implementing, and Main- taining Systems. O’Reilly, Sebastopol. Al Sabbagh, B. and Kowalski, S. (2015). A Socio-Technical Frame- work for Threat Modeling a Software Supply Chain. IEEE Secu- rity & Privacy, 13(4):30–39. Alahmadi, B. A., Axon, L., and Martinovic, I. (2022). 99% False Positives: A Qualitative Study of SOC Analysts’ Perspectives on Security Alarms. In Proceedings of the 31st USENIX Security Symposium, pages 2783–2800, Boston. USENIX. Alexopoulos, M. J., Niemi, A., Skobiej, B., and Torres, F. S. (2025). Examination of the Critical Infrastructure Resilience Directive From the Maritime Point of View. Journal of Common Market Studies, 63(2):667–678. Anagnostakis, D. (2023). Hybrid Threats: A European Response. In Balomenos, K. P., Fytopoulos, A., and Pardalos, P. M., editors, Handbook for Management of Threats: Security and Defense, Re- silience and Optimal Strategies, pages 425–441. Springer, Cham. Anderson, R. (2020). Security Engineering. Wiley, New York, third edition. Antoniuk, D. (2023). Nearly Two Dozen Danish Energy Com- panies Hacked Through Firewall Bug in May. The Record, available online in March 2025: https://therecord.media/ danish-energy-companies-hacked-firewall-bug. Ayyub, B. M., McGill, W. L., and Kaminskiy, M. (2007). Critical Asset and Portfolio Risk Analysis: An All-Hazards Framework. Risk Analysis, 27(4):789–801. B´eland, D., Marier, P., and Paquet, M. (2024). Subnational Com- parative Policy Analysis: Institutions, Methodology, and Research Agenda. Journal of Comparative Policy Analysis: Research and Practice, 26(6):553–566. Bhatt, S., Manadhata, P. K., and Zomlot, L. (2014). The Operational Role of Security Information and Event Management Systems. IEEE Security & Privacy, 12(5):35–41. Bickerton, C., Brack, N., Coman, R., and Crespy, A. (2022). Con- ficts of Sovereignty in Contemporary Europe: A Framework of Analysis. Comparative European Politics, 20:257–274. Boeke, S. (2017). National Cyber Crisis Management: Different Eu- ropean Approaches. Governance, 31(3):449–464. Boin, A., Ekengren, M., and Rhinard, M. (2018). Hiding in Plain Sight: Conceptualizing the Creeping Crisis. Risk, Hazards & Cri- sis in Public Policy, 9(2):116–138. Brownlee, N. and Guttman, E. (1998). Expectations for Computer Security Incident Response. RFC 2350, the Internet Engineering Task Force (IETF), available online in March 2025: https://www. ietf.org/rfc/rfc2350.txt. Busetti, S. and Scanni, F. M. (2025). Evaluating Incident Report- ing in Cybersecurity. From Threat Detection to Policy Learning. Government Information Quarterly, 42(1):102000. CFCS (2023). The Cyber Threat Against the Danish Energy Sector. Centre for Cyber Security (CFCS), available online in March 2025: https://www.cfcs.dk/ globalassets/cfcs/dokumenter/trusselsvurderinger/en/ -cyber-threat-against-the-danish-energy-sector.pdf. Christensen, T., Danielsen, O. A., Pægreid, and Rykkja, L. H. (2016). Comparing Coordination Structures for Crisis Manage- ment in Six Countries. Public Administration, 94(2):316–332. Christou, G. (2016). Cybersecurity in the European Union: Re- silience and Adaptability in Governance and Policy. Palgrave Macmillan, New York. Cichonski, P., Millar, T., Grance, T., and Scarfone, K. (2012). Cm- puter Security Incident Handling Guide Recommendations of the National Institute of Standards and Technology. National Insti- tute of Standards and Technology (NIST), Special Publication 800-61, available online in January 2025: https://nvlpubs.nist. gov/nistpubs/specialpublications/nist.sp.800-61r2.pdf. Collier, J. (2016). Strategies of Cyber Crisis Management: Lessons from the Approaches of Estonia and the United Kingdom. In Taddeo, M. and Glorioso, L., editors, Ethics and Policies for Cy- ber Operations: A NATO Cooperative Cyber Defence Centre of Excellence Initiative, pages 187–212. Springer, Cham. Connell, A. and Waits, T. (2013). The CERT Assessment Tool: In- creasing a Security Incident Responder’s Ability to Assess Risk. In Proceedings of the IEEE International Conference on Tech- nologies for Homeland Security (HST 2013), pages 236–240, Waltham. DeLeon, P. and Weible, C. M. (2010). Policy Process Research for Democracy: A Commentary on Lasswell’s Vision. International Journal of Policy Studies, 1(2):23–34. Dorofee, A., Killcrece, G., Ruefle, R., and Zajicek, M. (2007). Incident Management Capability Metrics Ver- sion 0.1. Software Engineering Institute, CERT Pro- gram, Carnegie Mellon University, available online in March 2025: http://pstorage-cmu-348901238291901.s3.amazonaws. com/12060836/file.pdf. EC (2020). COMMISSION STAFF WORKING DOCUMENT: IMPACT ASSESSMENT REPORT Accompanying the Docu- ment Proposal for a Directive of the European Parliament and of the Council on Measures for a High Common Level of Cybersecurity Across the Union, Repealing Directive (eu) 2016/1148. COM(2020) 823 final – SEC(2020) 430 final – 11 SWD(2020) 344 final, the European Commission (EC), avail- able online in March 2025: https://ec.europa.eu/newsroom/ dae/redirection/document/72176. EC (2025a). Proposal for a COUNCIL RECOMMENDATION for an EU Blueprint on Cybersecurity Crisis Management. COM(2025) 66 final, 2025/0036 (NLE), the European Commission (EC), avail- able online in March 2025: https://ec.europa.eu/newsroom/ dae/redirection/document/113086. EC (2025b). Shaping Europe’s Digital Future: Cybersecurity. The European Commission (EC), available online in March 2025: https://digital-strategy.ec.europa.eu/en/policies/ cybersecurity. ENISA (2010). Good Practice Guide for Incident Management. The European Union Agency for Cybersecurity (ENISA). Avail- able online in March 2025: https://enisa.europa.eu/sites/ default/files/publications/Incident_Management_guide.pdf. ENISA (2024). Best Practices for Cyber Crisis Management. The European Union Agency for Cybersecurity (ENISA). Avail- able online in March 2025: https://enisa.europa.eu/sites/ default/files/2024-11/ENISA%20Study%20Best%20Practices% 20Cyber%20Crisis%20Management.pdf. EP (2024). Cyber Solidarity Act. Briefings: EU Legisla- tion in Progress, the European Parliament (EP), available on- line in March 2025: https://www.europarl.europa.eu/RegData/ etudes/BRIE/2023/754614/EPRS_BRI(2023)754614_EN.pdf. EU (2017). Commission Recommendation (EU) 2017/1584 of 13 September 2017 on Coordinated Response to Large-Scale Cyberse- curity Incidents and Crises. The European Union (EU), available online in March 2025: https://eur-lex.europa.eu/eli/reco/ 2017/1584/oj/eng. EU (2018). Council Implementing Decision (EU) 2018/1993 of 11 December 2018 on the EU Integrated Political Crisis Response Arrangements. The European Union (EU), available online in March 2025: https://eur-lex.europa.eu/eli/dec_impl/2018/ 1993/oj/eng. EU (2019). Regulation (EU) 2019/881 of the European Parliament and of the Council of 17 April 2019 on ENISA (the European Union Agency for Cybersecurity) and on Information and Com- munications Technology Cybersecurity Certification and Repeal- ing Regulation (EU) No 526/2013 (Cybersecurity Act) (Text With EEA Relevance). The European Union (EU), available online in March 2025: https://eur-lex.europa.eu/eli/reg/2019/881/ oj/eng. EU (2022). Directive (EU) 2022/2555 of the European Parliament and of the Council of 14 December 2022 on Measures for a High Common Level of Cybersecurity Across the Union, Amending Regulation (EU) No 910/2014 and Directive (EU) 2018/1972, and Repealing Directive (EU) 2016/1148 (NIS 2 Directive) (Text With EEA Relevance). The European Union (EU), available on- line in March 2025: https://eur-lex.europa.eu/eli/dir/2022/ 2555/oj/eng. EU (2024). Regulation (EU) 2024/2847 of the European Parliament and of the Council of 23 October 2024 on Horizontal Cybersecurity Requirements for Products With Digital Elements and Amending Regulations (EU) No 168/2013 and (EU) 2019/1020 and Direc- tive (EU) 2020/1828 (Cyber Resilience Act) (Text With EEA Relevance). The European Union (EU), available online in March 2025: https://eur-lex.europa.eu/eli/reg/2024/2847/oj/eng. EU (2025). Regulation (EU) 2025/38 of the European Parliament and of the Council of 19 December 2024 Laying Down Measures to Strengthen Solidarity and Capacities in the Union to Detect, Prepare for and Respond to Cyber Threats and Incidents and Amending Regulation (EU) 2021/694 (Cyber Solidarity Act). The European Union (EU), available online in March 2025: https: //eur-lex.europa.eu/eli/reg/2025/38/oj/eng. Finke, D. (2020). Turf Wars in Government Administration: Inter- departmental Cooperation in the European Commission. Public Administration, 98(2):498–514. Fischer-H¨ubner, S., Alcaraz, C., Ferreira, A., Fernandez-Gago, C., Lopez, J., Markatos, E., Islami, L., and Akil, M. (2021). Stakeholder Perspectives and Requirements on Cybersecurity in Europe. Journal of Information Security and Applications, 61:102916. G¨anzle, S., Kern, K., and Tynkkynen, N. (2022). Governing the Baltic Sea Region at Critical Junctures (1991–2021): How Do Transnational and Intergovernmental Organizations Cope With External Regional Change? Journal of Baltic Studies, 54(3):421– 442. Gjesvik, L. (2019). Comparing Cyber Security: Critical Infrastruc- ture Protection in Norway, the UK and Finland. Norwegian In- stitute of International Affairs (NUPI), available online in March 2025: https://nupi.brage.unit.no/nupi-xmlui/bitstream/ handle/11250/2598280/NUPI_Report_5_2019_Gjesvik.pdf. Goodman, W. (2010). Cyber Deterrence: Tougher in Theory Than in Practice? Strategic Studies Quarterly, 4(3):102–135. Handler, H. (2024). Europe Tested by Crises: The EU on the Path to a New Identity. Springer, Wiesbaden. Head, B. W. (2022). Wicked Problems in Public Policy: Understand- ing and Responding to Complex Challenges. Palgrave Macmillan, Cham. Heine, M. (2019). Managing Systemic Risks: Opening Up Public Crisis. In Proceedings of the First Workshop on Systemic Risks in Global Networks, Co-Located with the 14. Internationale Tagung Wirtschaftsinformatik (WI 2019), Siegen. CEUR-WS. Hutzschenreuter, T., Matt, T., and Kleindienst, I. (2020). Going Subnational: A Literature Review and Research Agenda. Journal of World Business, 55:101076. Izumi, T. (2024). Introduction and Overview of the All-Hazard Ap- proach. In Izumi, T., Abe, M., Fujita, K., and Shaw, R., editors, All-Hazards Approach: Towards Resilience Building, pages 3–15. Springer, Singapore. Jaatun, M. G., Albrechtsen, E., Line, M. B., Tøndel, I. A., and Longva, O. H. (2009). A Framework for Incident Response Man- agement in the Petroleum Industry. International Journal of Crit- ical Infrastructure Protection, 2(1–2):26–37. Jhaveri, M. H., Cetin, O., Ga˜n´an, C., Moore, T., and van Eeten, M. (2017). Abuse Reporting and the Fight Against Cybercrime. ACM Computing Surveys, 49(4):1–17. Jungwirth, R., Smith, H., Willkomm, E., Savolainen, J., Vil- lota, M. A., Lebrun, M., Aho, A., and Giannopoulos, G. (2023). Hybrid Threats: A Comprehensive Resilience Ecosys- tem. Publications Office of the European Union, Luxem- bourg. A report prepared by the Joint Research Centre (JRC) and the European Centre of Excellence for Coun- tering Hybrid Threats (Hybrid CoE), available online in March 2025: https://www.hybridcoe.fi/wp-content/uploads/ 2023/04/CORE_comprehensive_resilience_ecosystem.pdf. Kulikova, O., Heil, R., van den Berg, J., and Pieters, W. (2012). Cyber Crisis Management: A Decision-Support Framework for Disclosing Security Incident Information. In Proceedings of the In- ternational Conference on Cyber Security (CyberSecurity 2012), pages 103–112, Alexandria. Malatji, M., von Solms, S., and Marnewick, A. (2019). Socio- Technical Systems Cybersecurity Framework Cybersecurity Framework. Information & Computer Security, 27(2):233–272. Mitropoulos, S., Patsos, D., and Douligeris, C. (2006). On Incident Handling and Response: A State-of-the-Art Approach. Computers & Security, 25(5):351–370. Mueck, M. and Gaie, C. (2025). Introduction to the European Cy- bersecurity Act. In Mueck, M. and Gaie, C., editors, European Digital Regulations, pages 229–247. Springer, Cham. Østby, G. and Katt, B. (2020). Cyber Crisis Management Roles – A Municipality Responsibility Case Study. In Proceedings of the 4th IFIP TC 5 DCITDRR International Conference (ITDRR 2019), pages 168–181, Kyiv. Springer. Panteli, N., Nthubu, B. R., and Mersinas, K. (2025). Being Respon- sible in Cybersecurity: A Multi-Layered Perspective. Information Systems Frontiers, (Published online in February):1–19. Patterson, C. M., Nurse, J. R. C., and Franqueira, V. N. L. (2024). “I Don’t Think We’re There Yet”: The Practices and Challenges of Organisational Learning from Cyber Security Incidents. Com- puters & Security, 139:103699. Patton, C. V., Sawicki, D. S., and Clark, J. J. (2016). Basic Meth- 12 ods of Policy Analysis and Planning. Routledge, London, third edition. Ramsell, E. and Wihlborg, E. (2012). Governing Technical Informa- tion Systems in Local Crisis Management. Public Works Manage- ment & Policy, 17(3):303–318. Rataj, P. (2025). Botnet Defense Under EU Data Protection Law. Computer Law & Security Review, 56:106080. Rosenthal, U., ’t Hart, P., and Kouzmin, A. (1991). The Bureau- Politics of Crisis Management. Public Administration, 69:211– 233. Rukanova, B., Wigand, R. T., van Stijn, E., and Tan, Y.-H. (2015). Understanding Transnational Information Systems With Supra- national Governance: A Multi-Level Conflict Management Per- spective. Government Information Quarterly, 32(2):182–197. Ruohonen, J. (2024a). A Systematic Literature Review on the NIS2 Directive. Archived manuscript, available online: https://arxiv. org/abs/2412.08084. Ruohonen, J. (2024b). The Incoherency Risk in the EU’s New Cyber Security Policies. In Proceedings of the 23rd IFIP Conference on e-Business, e-Services, and e-Society (I3E 2024), Lecture Notes in Computer Science (Volume 14907), pages 284–295, Heerlen. Springer. Ruohonen, J., Hjerppe, K., and Kang, E.-Y. (2025). A Mapping Analysis of Requirements Between the CRA and the GDPR. Archived manuscript, available online: https://arxiv.org/abs/ 2503.01816. Ruohonen, J., Hyrynsalmi, S., and Lepp¨anen, V. (2016). An Outlook on the Institutional Evolution of the European Union Cyber Secu- rity Apparatus. Government Information Quarterly, 33(4):746– 756. Ruohonen, J. and Timmers, P. (2024). Vulnerability Coordination Under the Cyber Resilience Act. Archived manuscript, available online: https://arxiv.org/abs/2412.06261. Secchi, L. (2016). Policy Analysis in Brazil: A Comparison of Ra- tionalist and Argumentative Approaches. Journal of Comparative Policy Analysis: Research and Practice, 18(1):88–101. SektorCERT (2023). The Attack Against Danish, Crit- ical Infrastructure. Available online in March 2025: https://sektorcert.dk/wp-content/uploads/2023/11/ SektorCERT-The-attack-against-Danish-critical-infrastructure-TLP- pdf. Senninger, R., Finke, D., and Blom-Hansen, J. (2021). Coordina- tion Inside Government Administrations: Lessons from the EU Commission. Governance, 34(3):707–726. Soesanto, S. and Smeets, M. (2021). Cyber Deterrence: The Past, Present, and Future. In Osinga, F. and Sweijs, T., editors, NL ARMS Netherlands Annual Review of Military Studies 2020: De- terrence in the 21st Century—Insights from Theory and Practice, pages 385–400. Asser Press, The Hague. Tøndel, I. A., Line, M. B., and Jaatun, M. G. (2014). Information Security Incident Management: Current Practice as Reported in the Literature. Computers & Security, 45:42–57. Tsebelis, G. and Garrett, G. (2021). The Institutional Foundations of Intergovernmentalism and Supranationalism in the European Union. International Organization, 55(2):357–390. van Haastrecht, M., Ozkan, B. Y., Brinkhuis, M., and Spruit, M. (2021). Respite for SMEs: A Systematic Review of Socio- Technical Cybersecurity Metrics. Applied Sciences, 11:6909. Vu, B. T., Obaitor, O. S., Grobusch, L. C., Sett, D., Hagenlocher, M., Schinkel, U., Nguyen, L. K. H., Bachofer, F., Ngo, S. T., and Garschagen, M. (2025). Enablers and Barriers to Implementing Effective Disaster Risk Management According to Good Gover- nance Principles: Lessons from Central Vietnam. International Journal of Disaster Risk Reduction, 120:105344. Zibak, A., Sauerwein, C., and Simpson, A. C. (2022). Threat In- telligence Quality Dimensions for Research and Practice. Digital Threats: Research and Practice, 3(4):1–22. 13