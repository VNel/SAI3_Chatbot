1 Real-Time Detection of Hybrid and Stealthy Cyber-Attacks in Smart Grid Mehmet Necip Kurt, Yasin Yılmaz, Member, IEEE, and Xiaodong Wang, Fellow, IEEE Abstract For a safe and reliable operation of the smart grid, timely detection of cyber-attacks is of critical importance. Moreover, considering smarter and more capable attackers, robust detection mechanisms are needed against a diverse range of cyber-attacks. With these purposes, we propose a robust online detection algorithm for (possibly combined) false data injection (FDI) and jamming attacks, that also provides online estimates of the unknown and time-varying attack parameters and recovered state estimates. Further, considering smarter attackers that are capable of designing stealthy attacks to prevent the detection or to increase the detection delay of the proposed algorithm, we propose additional countermeasures. Numerical studies illustrate the quick and reliable response of the proposed detection mechanisms against hybrid and stealthy cyber-attacks. Index Terms Smart grid, Kalman ﬁlter, quickest detection, cumulative sum (CUSUM), online estimation, state recovery, false data injection attack, jamming attack, hybrid attack, stealthy attack, Shewhart test, chi-squared test. I. INTRODUCTION A. A Brief Overview of Cyber-Attacks and Countermeasures in Smart Grid Due to the integration of advanced signal processing, communication, and control technologies, smart grid relies on a critical cyber infrastructure that is subject to adversarial cyber threats [1]–[4]. The smart grid is regulated based on estimated system states and the main aim of attackers is to damage/mislead the state estimation mechanism and thereby to cause wrong/manipulated decisions in the energy management system of the smart grid. Some potential consequences of a successful cyber-attack are regional power blackouts, manipulated electricity market prices [5], [6], and destabilization of the power grid [7]. Such cyber-attacks are also seen in practice. For instance, on December 23, 2015, the Ukrainian power system was attacked and the resulting power blackout affected around 200,000 people for several hours [8]. The Ukraine attack has demonstrated that attackers have more capabilities than predicted [8]. Namely, (i) attackers can access and monitor the power system over long periods of time without being detected, (ii) attackers are able to perform cyber-attacks by hacking smart grid components (smart meters, control centers, etc.), manipulating/jamming the network communication channels, and accessing and manipulating the database of the control center [2], [8], [9]. Hence, cyber-attacks signiﬁcantly This work was supported in part by the U.S. National Science Foundation (NSF) under Grant ECCS-1405327, and in part by the U.S. Ofﬁce of Naval Research under Grant N000141410667. The work of Y. Yılmaz was supported in part by the NSF under Grant CNS-1737598 and in part by the Southeastern Center for Electrical Engineering Education. M. N. Kurt and X. Wang are with the Department of Electrical Engineering, Columbia University, New York, NY 10027, USA (e-mail: m.n.kurt@columbia.edu; wangx@ee.columbia.edu). Y. Yılmaz is with the Department of Electrical Engineering, University of South Florida, Tampa, FL 33620, USA (e-mail: yasiny@usf.edu). arXiv:1803.00128v2 [cs.IT] 28 Jun 2018 2 threaten the safe and reliable operation of the power grid in practice. Effective countermeasures need to be developed considering the worst-case scenarios where the attackers are fully capable of performing a diverse range of cyber-attacks. The ﬁrst step in a defense mechanism is early detection of cyber-attacks. After detecting an attack, effective mitigation schemes should then be implemented. Recently, the false data injection (FDI) attacks [2], [10]–[12] and the jamming attacks [9], [13]–[15] against the smart grid are extensively studied in the literature and several detectors are proposed. The proposed detectors are mostly outlier detectors, i.e., they classify a sample measurement as either normal or anomalous. Conventional detectors classify a measurement as anomalous if the measurement residual exceeds a certain threshold [10], [16]–[19]. More advanced machine learning techniques are also considered for classiﬁcation of anomalous measurements [20], [21]. Moreover, in [12], ﬁrstly a Markov graph model for system states is learned under normal system operation and then attacks/anomalies are detected based on the consistency of new measurements compared to the learned nominal model. Further, in [22], based on the least squares (LS) state estimator, a multi-step procedure is presented to detect and classify cyber-attacks on meter measurements, network line parameters, and network topology, and then to make corrections for attack mitigation. In [23]–[25], robust extended Kalman ﬁlters have been proposed where the main aim is to bound the effects of outliers on the state estimation mechanism. No speciﬁc attack types are considered so that using such schemes, it is not possible to distinguish a real attack from random outliers, e.g., due to heavy-tailed non-Gaussian noise processes. Moreover, such schemes have breakdown points such that if outliers, signiﬁcantly far away from the nominal measurements, are observed, then the proposed ﬁlters fail to keep track of the system state. In order to improve the time resolution and also to detect cyber-attacks more reliably, several online detectors based on the quickest detection theory are proposed. For instance, in [26] and [27], cumulative sum (CUSUM)-based schemes are considered to detect FDI attacks where the state estimation is based on the conventional LS methods. More recently, in [28], CUSUM-based detection schemes are proposed to detect FDI and denial of service (DoS) attacks (separately) in a dynamic setting and their advantages over the outlier detectors and the LS-based detectors are demonstrated. Further, in [29], a nonparametric CUSUM detector is proposed that do not assume any attack model and only evaluates the deviation of meter measurements from the baseline statistics, i.e., normal system operation. In [30], a window-based CUSUM detector is proposed for detection of FDI attacks where the attack parameters of interest are estimated based on the most recent sliding window of measurements. B. Contributions In this paper, we propose robust mechanisms for timely detection of potentially combined and stealthily designed FDI and jamming attacks. The proposed mechanisms are tightly connected to an estimation mechanism, which makes both the detection and state estimation schemes robust against unknown and time-varying attack variables. In particular, online maximum likelihood estimates (MLEs) of the attack types, set of attacked meters, and the attack magnitudes are used in attack detection. Moreover, recovered state estimates are computed based on the online MLE estimates of the attack variables. No restrictive assumptions are made about an attacker’s strategy, i.e., an attacker can design and perform arbitrarily combined FDI and jamming attacks, targeting any subset of meters in any magnitude and can also change its attack parameters over time. Further, considering the 3 possibility of smarter and more capable attackers, additional countermeasures are proposed against stealthily designed cyber- attacks. These make the proposed detection schemes highly robust against a signiﬁcantly wide range of potential cyber-attacks targeting the smart grid. Since the smart grid is a highly complex network, any anomaly/failure in a part of the system can quickly spread over the network and lead to new unpredicted failures. Hence, timely attack detection and mitigation is crucial. In this paper, for timely detection, we present real-time detection mechanisms. Moreover, to help for timely attack mitigation and quick system recovery, we provide online estimates of the attack types, set of attacked meters and attack magnitudes. Note that having an estimate for the attack type can be useful since different countermeasures may need to be employed against different types of attacks. Further, considering that the real power grid is a huge network consisting of many meters, an estimate of the attacked meters can be critical for a timely and effective attack mitigation, e.g., via isolating the attacked meters during the recovery procedure. Moreover, estimates of attack magnitudes are needed to recover attack-free states. We list our main contributions as follows: • A novel low-complexity online detection and estimation algorithm is proposed against (possibly) combined FDI and jamming attacks. The proposed algorithm is robust to unknown and time-varying attack types, magnitudes, and set of attacked meters. Further, recovered state estimates and closed-form online MLE estimates of the attack variables are presented. • Stealthy attacks against CUSUM-based detectors and particularly against the proposed algorithm are introduced and analyzed. • Several countermeasures are proposed against the considered stealthy attacks. C. Organization The remainder of the paper is organized as follows. In Sec. II, the system model, attack models, state estimation mechanism, and the problem formulation are presented. In Sec. III, an online cyber-attack detection and estimation algorithm is presented. In Sec. IV, stealthy attacks against CUSUM-based detectors are introduced and analyzed. Also, countermeasures against the considered stealthy attacks are presented. In Sec. V, the proposed detection schemes are evaluated extensively via simulations. Finally, the paper is concluded in Sec. VI. Boldface letters denote vectors and matrices, and all vectors are column vectors. II. SYSTEM MODEL AND PROBLEM FORMULATION A. System Model The actual power grid is regulated based on a nonlinear AC power ﬂow model [2]. On the other hand, the approximate linearized (around an operating point) DC power ﬂow model is a good approximation that is widely used in the literature to describe the operation of the power grid [10], [16], [31]. Furthermore, static system model and consequently conventional static (LS) state estimation are not effective in capturing the dynamics of a power system due to time-varying load and power generation [11]. In addition, attack detection mechanisms based on static estimators are not effective in detecting time-varying 4 cyber-attacks and structured “stealth” FDI attacks [10], for which dynamic state estimator-based detectors are known to be effective [28], [32]. We then model the power grid, consisting of N + 1 buses and K meters, as a discrete-time linear dynamic system based on the commonly employed linear DC model [10], [16], [31] as follows: xt = Axt−1 + vt, (1) yt = Hxt + wt, (2) where xt = [x1,t, x2,t, . . . , xN,t]T is the state vector denoting the phase angles of N buses (one of the buses is considered as a reference bus), A ∈RN×N is the state transition matrix, vt = [v1,t, v2,t, . . . , vN,t]T ∼N(0, σ2 v IN) is the process noise vector, IN is an N × N identity matrix, and ·T is the transpose operator. Further, yt = [yT 1,t, yT 2,t, . . . , yT K,t]T is the vector consisting of meter measurements, yk,t = [yk,t,1, yk,t,2, . . . , yk,t,λ]T is the measurement vector for meter k, H ∈RKλ×N is the measurement matrix, wt = [wT 1,t, wT 2,t, . . . , wT K,t]T ∼N(0, σ2 w IKλ) is the measurement noise vector, and wk,t = [wk,t,1, wk,t,2, . . . , wk,t,λ]T is the measurement noise vector for meter k. Note that in each time interval between t −1 and t, λ ∈{1, 2, 3, . . . } measurements are taken at each meter, where λ is usually small, and the collected measurements between t −1 and t are processed at time t. To increase the measurement redundancy against noise and also to estimate the unknown attack parameters more reliably in case of a cyber-attack, λ needs to be chosen higher. In general, the state transition and measurement matrices can also be dynamic. For instance, due to changes in network topology, i.e., on and off states of the switches and line breakers in the power grid, the measurement matrix may vary over time. In that case, instead of modeling the smart grid as a linear time-invariant system as in (1) and (2), we can model it as a linear time-varying system where we can replace A and H by At and Ht, respectively. The results presented in this study can be generalized to the case of linear time-varying system model as long as At and Ht are known by the system controller at each time t. B. Attack Models We assume that at an unknown time τ, a cyber-attack is launched to the system, where we particularly consider FDI attacks, jamming attacks, and their combination. The attack types, attack magnitudes, and the set of attacked meters can be time-varying. But, during a time interval, i.e., between t −1 and t, we assume that the attack parameters stay constant. Next, we explain the attack models under consideration. 1) FDI Attack: In case of an FDI attack, additive malicious data are injected into the measurements of a subset of meters. In practice, an FDI attack can be performed by manipulating the network communication channels or hacking meters and/or control centers in the smart grid [2], [8]. The measurement model in case of an FDI attack takes the following form: yt = Hxt + at + wt, t ≥τ, (3) where at = [aT 1,t, aT 2,t, . . . , aT K,t]T denotes the injected false data at time t. Since the attack magnitudes are assumed to be constant between t −1 and t, for meter k, ak,t = 1λ×1 ak,t, where 1λ×1 is a λ × 1 vector consisting of 1s. Note that if meter 5 k is not under an FDI attack at time t, then ak,t = 0, otherwise ak,t ̸= 0. 2) Jamming Attack: In case of a jamming attack, we assume that the attacker constantly emits additive white Gaussian noise (AWGN) to the network communication channels to compromise a subset of meter measurements. We consider jamming with AWGN since (i) it is a commonly employed jamming model in the literature [33], [34], (ii) it is a simple attacking strategy to perform, and (iii) in an additive noise channel with Gaussian input, for a given mean and variance, among all noise distributions, the Gaussian noise maximizes the mean squared error of estimating the channel input given the channel output [34], [35]. Hence, an attacker can jam the communication channels with AWGN to maximize its damage on the state estimation mechanism. In case of a jamming attack, the measurement model can be written as follows: yt = Hxt + wt + nt, t ≥τ, (4) where nt = [nT 1,t, nT 2,t, . . . , nT K,t]T ∼N(0, diag(σt)) denotes the jamming noise, σt = [σT 1,t,σT 2,t, . . . ,σT K,t]T, and σk,t = 1λ×1 σ2 k,t where σ2 k,t is the variance of the jamming noise targeting meter k at time t. If meter k is not under a jamming attack at time t, then σ2 k,t = 0, otherwise σ2 k,t > 0. 3) Hybrid Attack: In case of a hybrid (combined) attack, FDI and jamming attacks are simultaneously launched to the system and hence the measurement model takes the following form: yt = Hxt + at + wt + nt, t ≥τ. (5) For meter k under both FDI and jamming attacks at time t, ak,t ̸= 0 and σ2 k,t > 0. Since the FDI and jamming attacks can be considered as special cases of hybrid attacks, we consider (5) as the measurement model under the attacking regime, i.e., for t ≥τ. Remark 1: If the noise terms in the normal system operation are AWGN (as in (1) and (2)) and the jamming noise terms are mutually independent over the meters, then the considered hybrid FDI/jamming attacks span all possible data attacks. This is due to the fact that a Gaussian random variable is deﬁned by its mean and variance, and through the hybrid attacks, mean and variance of the density of meter measurements can be arbitrarily changed (cf. (5)). For instance, in case of a DoS attack, meter measurements are blocked and only a random or zero signal is received at the control center [9], [13], [14]. Hence, the DoS attack can be considered as a special case of the hybrid cyber-attacks, i.e., a DoS attack can either be equivalent to an FDI attack with false data being in the same magnitude of the actual signal but with an opposite sign or a jamming attack with high level noise variances such that the actual signal can be neglected compared to the noise signal [28]. On the other hand, if the jamming noise is correlated over the meters or it is not normally distributed, then such an attack does not comply with the considered jamming attack model in (4) and nor with (5). For such cases, we consider a non-parametric goodness-of-ﬁt test as a countermeasure (see Sec. IV-C.2). 6 C. Pre- and Post-Attack Measurement Densities Let H = [HT 1 , HT 2 , . . . , HT K]T where Hk ∈Rλ×N is the measurement matrix for meter k. Since the measurement matrix is determined based on the system topology, the rows of Hk are identical, i.e., Hk = 1λ×1 hT k , where hT k is a row of Hk. Based on the considered post-attack model in (5), a measurement obtained at meter k during the time interval between t −1 and t, i.e., yk,t,i, k ∈{1, 2, . . . , K}, i ∈{1, 2, . . . , λ} can be written as yk,t,i =                        hT k xt + wk,t,i, if k ∈S0 t hT k xt + ak,t + wk,t,i, if k ∈Sf t hT k xt + wk,t,i + nk,t,i, if k ∈Sj t hT k xt + ak,t + wk,t,i + nk,t,i, if k ∈Sf,j t , t ≥τ, (6) where S0 t is the set of non-attacked meters, Sf t is the set of meters under only FDI attack, Sj t is the set of meters under only jamming attack, and Sf,j t is the set of meters under both FDI and jamming attacks at time t ≥τ. Note that S0 t , Sf t , Sj t , and Sf,j t are disjoint sets and S0 t ∪Sf t ∪Sj t ∪Sf,j t = {1, 2, . . . , K}. Then, the probability density functions (pdfs) of the measurements in the pre- and post-attack regimes take respectively the following forms ∀i ∈{1, 2, . . . , λ}: yk,t,i ∼N(hT k xt, σ2 w), ∀k ∈{1, 2, . . . , K}, t < τ, (7) and yk,t,i ∼                        N(hT k xt, σ2 w), ∀k ∈S0 t N(hT k xt + ak,t, σ2 w), ∀k ∈Sf t N(hT k xt, σ2 w + σ2 k,t), ∀k ∈Sj t N(hT k xt + ak,t, σ2 w + σ2 k,t), ∀k ∈Sf,j t , t ≥τ. (8) D. State Estimation Since the smart grid is modeled as a discrete-time linear dynamic system with the Gaussian noise terms (cf. (1) and (2)), the Kalman ﬁlter is the optimal linear estimator in minimizing the mean squared state estimation error [36]. Further, since the measurement models for the pre- and post-attack periods are different (cf. (7) and (8)), two Kalman ﬁlters need to be simultaneously employed: one for assuming no attack occurs at all and one for assuming an attack occurs at an unknown time τ. Since the latter involves the unknown change-point τ and the unknown attack parameters at and σt, estimates of these unknowns are needed to employ the corresponding Kalman ﬁlter. As we will explain later, τ is estimated by the detection algorithm, at and σt are estimated via the maximum likelihood (ML) estimation. The Kalman ﬁlter is an iterative real-time estimator composed of prediction and measurement update steps at each iteration. Let the Kalman ﬁlter estimates for the pre- and post-attack cases be denoted with ˆx0 t|t′ and ˆx1 t|t′, respectively where t′ = t −1 7 and t′ = t for the prediction and measurement update steps at time t, respectively. The Kalman ﬁlter equations at time t are then given as follows: Pre-attack – Prediction: ˆx0 t|t−1 = Aˆx0 t−1|t−1, P0 t|t−1 = AP0 t−1|t−1AT + σ2 v IN, (9) Pre-attack – Measurement update: G0 t = P0 t|t−1HT(HP0 t|t−1HT + σ2 w IKλ)−1, ˆx0 t|t = ˆx0 t|t−1 + G0 t(yt −Hˆx0 t|t−1), P0 t|t = P0 t|t−1 −G0 tHP0 t|t−1, (10) Post-attack – Prediction: ˆx1 t|t−1 = Aˆx1 t−1|t−1, P1 t|t−1 = AP1 t−1|t−1AT + σ2 v IN, (11) Post-attack – Measurement update: G1 t = P1 t|t−1HT(HP1 t|t−1HT + σ2 w IKλ + diag(ˆσt))−1, ˆx1 t|t = ˆx1 t|t−1 + G1 t(yt −Hˆx1 t|t−1 −ˆat), P1 t|t = P1 t|t−1 −G1 tHP1 t|t−1, (12) where P0 t|t′ and P1 t|t′ denote the estimates of the state covariance matrix at time t, and G0 t and G1 t denote the Kalman gain matrices at time t for the pre- and post-attack cases, respectively. Note that the MLE estimates of the attack parameters are used in the measurement update step of the Kalman ﬁlter for the post-attack case, where ˆat is the MLE of at (cf. (26)) and ˆσt is the MLE of σt (cf. (27)). Hence, ˆx1 t|t−1 and ˆx1 t|t are, in fact, recovered state estimates in case of a cyber-attack. Note, however, that ML estimation errors may lead to errors in computing the recovered state estimates. E. Problem Formulation Our objective is detecting cyber-attacks in a timely and reliable manner and the quickest detection theory [37]–[39] is well suited to this objective. In the quickest change detection problems, measurements become available sequentially over time and at each time, either a change is declared or further measurements are taken in the next time interval, where the aim is to optimally balance the detection delay and the false alarm rate. There are two main approaches in the quickest detection theory, namely Bayesian and non-Bayesian. In a Bayesian setting, the change point τ is considered as a random variable with a known a priori distribution whereas in a non-Bayesian setting, the change point is considered as non-random and unknown. Our problem better ﬁts to the non-Bayesian setting since we do not assume any a priori knowledge about the change-point τ. 8 Then, we consider the following objective function, proposed by Lorden [40]: d(T) = sup τ ess sup Fτ Eτ  (T −τ)+ |Fτ  , (13) where T is the stopping time at which an attack is declared, Fτ denotes all measurements obtained up to time τ, and Ej is the expectation under Pj, that is the probability measure if the change occurs at time j. Note that d(T) is called the worst- case average detection delay since it is maximized over the change point and also over all measurements obtained up to the change-point. We then consider the following minimax optimization problem: inf T d(T) subject to E∞[T] ≥α, (14) where E∞[T] is called the average false alarm period, i.e., average stopping time when no change occurs at all (τ = ∞), and α is a prespeciﬁed lower bound for E∞[T]. Let the pre- and post-attack measurement pdfs given in (7) and (8) be denoted with p0(yt|xt) and p1(yt|xt, at,σt), respectively. Since the dynamic system state xt is not directly observed and the attack parameters at and σt are completely determined by an attacker and hence unknown, both pdfs are unknown and time-varying. If the pre- and post-attack pdfs would be exactly known, then the well-known CUSUM algorithm would be the optimal solution to (14) [41]. Nonetheless, the system state can be inferred using the Kalman ﬁlters and the MLEs of the unknown attack parameters can be computed. Then, following a generalized likelihood ratio approach [38, Sec. 5.3], [26], [28] and replacing the unknowns with their estimates, a generalized CUSUM algorithm can be used as a solution to (14). In this paper, in addition to early attack detection, we also aim to recover the attack-free system states. Notice that in case of no attack, i.e., for t < τ, the Kalman ﬁlter for the pre-attack case (assuming no attack at all) is the optimal state estimator. However, after an attack occurs, the measurement model assumed in the pre-attack period (cf. (2)) is no longer true. Hence, the state estimates for the pre-attack case, i.e., ˆx0 t|t−1 and ˆx0 t|t, deviate from the actual system state xt for t ≥τ. Recalling that an attack occurs at an unknown time τ and the measurements follow the post-attack measurement model (cf. (5)) for t ≥τ, if the attack launch time τ and the attack magnitudes at and σt would be exactly known, then the system state would be perfectly recovered for t ≥τ. Nonetheless, as we will explain more clearly in the next section, the (generalized) CUSUM algorithm always keeps a change-point estimate ˆτ in its memory and updates this estimate as the measurements become sequentially available over time [38, Sec. 2.2]. When an attack is declared at the stopping time T, ˆτ becomes the ﬁnal change-point estimate of the (generalized) CUSUM algorithm. Furthermore, the MLEs of the attack magnitudes, i.e., ˆat and ˆσt, can be computed at each time t. Then, employing a Kalman ﬁlter for the post-attack case (cf. (11) and (12)) and computing the state estimates using the MLEs of the attack parameters in the measurement update step, recovered state estimates, i.e., ˆx1 t|t−1 and ˆx1 t|t, can be obtained for ˆτ ≤t ≤T. III. ONLINE ATTACK DETECTION AND ESTIMATION Since it is hard to distinguish noise from FDI/jamming attacks with small magnitudes, some minimum levels for the attack magnitudes need to be deﬁned in order to control the false alarm level of a detection algorithm. We then deﬁne the change 9 event of interest as follows: |ak,t| ≥γ, ∀k ∈Sf t , t ≥τ, σ2 k,t ≥σ2, ∀k ∈Sj t , t ≥τ, |ak,t| ≥γ & σ2 k,t ≥σ2, ∀k ∈Sf,j t , t ≥τ, (15) where γ and σ2 are the smallest attack magnitudes of interest for |ak,t| and σ2 k,t, respectively. Note that, in general, an attacker can arbitrarily choose its attack parameters, i.e., γ and σ2 do not restrict an attacker’s strategy. In fact, attackers usually do not know such parameters. On the other hand, smarter attackers may exploit such lower bounds on the attack magnitudes in order to perform stealthy attacks with small attack magnitudes (see Sec. IV-B). The generalized CUSUM algorithm can then be written as follows: T = inf  m ∈N : max 1≤j≤m m X t=j sup S0 t ,Sf t ,Sj t ,Sf,j t log sup|ak,t|≥γ, k ∈Sf t ∪Sf,j t supσ2 k,t≥σ2, k ∈Sj t ∪Sf,j t p1(yt | ˆx1 t, at,σt) p0(yt|ˆx0 t) | {z } βt | {z } gm ≥h  , (16) where ˆx0 t and ˆx1 t denote the state estimates for the pre- and post-attack cases, respectively, gm is the decision statistic at time m, h is the test threshold, and βt is the generalized log-likelihood ratio (GLLR) calculated at time t. Based on (16), the decision statistic can be recursively updated at each time t as gt ←max{0, gt−1 + βt}, where g0 = 0 [38, Sec. 2.2]. Note that whenever gt reaches zero, the (generalized) CUSUM algorithm updates its change-point estimate ˆτ to the current time t, where the initial change-point estimate is ˆτ = 1 [38, Sec. 2.2]. That is, when gt ←0, we have ˆτ ←t. Recall that the Kalman ﬁlter for the post-attack case is employed assuming the normal measurement model (cf. (2)) up to the unknown change-point τ. We then propose to employ the Kalman ﬁlter for the post-attack case based on the estimated change-point ˆτ. Hence, whenever the change-point estimate is updated, the Kalman ﬁlter for the post-attack case needs also to be updated. Recall further that the Kalman ﬁlter for the pre-attack case is always employed based on the normal measurement model. Hence, whenever gt ←0, the Kalman ﬁlter estimates for the post-attack case are updated by setting them to the Kalman ﬁlter estimates for the pre-attack case, i.e., P1 t|t ←P0 t|t and ˆx1 t|t ←ˆx0 t|t. Assuming no attack, ˆx0 t|t is the optimal state estimate at time t. Thus, we estimate xt by ˆx0 t|t for the pre-attack case, i.e., ˆx0 t ≜ˆx0 t|t. On the other hand, we estimate xt by ˆx1 t|t−1 for the post-attack case, i.e., ˆx1 t ≜ˆx1 t|t−1. This is because the measurement update step of the Kalman ﬁlter for the post-attack case and hence ˆx1 t|t depends on estimates of the unknown attack variables (cf. (12)), and effects of the attack parameters at and σt at time t on ˆx1 t need to be blocked to be able to compute the MLEs of the attack parameters in closed form (cf. numerator in (16)). Note that ˆx1 t|t−1 is computed based on the measurements up to time t −1, thus ˆx1 t|t−1 is independent of the attack parameters at time t. At ﬁrst, it may seem unfair that we use the state estimate of the measurement update step, i.e., ˆx0 t|t, for the pre-attack case, and the state prediction, i.e., ˆx1 t|t−1, for the post-attack case. However, it essentially improves the performance of the proposed detection scheme due to the following reasons: (i) in case of no attack, we favor p0(yt|ˆx0 t) over p1(yt | ˆx1 t, at,σt) and hence 10 decrease the false alarm level of the proposed detection scheme, (ii) in case of an attack, since the state estimates for the post-attack case are recovered whereas the state estimates for the pre-attack case do not have a recovery mechanism, detection delays are not expected to increase. Furthermore, based on (16), the following proposition presents the GLLR at time t and the MLEs of the attack variables for the time interval between t −1 and t. Proposition 1: Let ek,t,i ≜yk,t,i −hT k ˆx1 t and ek,t ≜[ek,t,1, ek,t,2, . . . , ek,t,λ]T. Moreover, let δk,t ≜Pλ i=1 ek,t,i, ζk,t ≜ Pλ i=1 e2 k,t,i, ϱk,t ≜Pλ i=1(ek,t,i + γ)2, and ϖk,t ≜Pλ i=1(ek,t,i −γ)2, ∀k ∈{1, 2, . . . , K}, ∀t > 0. The most likely subset of meters under no attack, under only FDI attack, under only jamming attack, and under both FDI and jamming attacks during the time interval between t −1 and t are classiﬁed, respectively as ˆS0 t = n k : u0(ek,t) ≤uf(ek,t), u0(ek,t) ≤uj(ek,t), u0(ek,t) ≤uf,j(ek,t), k = 1, 2, . . . , K o , (17) ˆSf t = n k : uf(ek,t) < u0(ek,t), uf(ek,t) ≤uj(ek,t), uf(ek,t) ≤uf,j(ek,t), k = 1, 2, . . . , K o , (18) ˆSj t = n k : uj(ek,t) < u0(ek,t), uj(ek,t) < uf(ek,t), uj(ek,t) ≤uf,j(ek,t), k = 1, 2, . . . , K o , (19) ˆSf,j t = n k : uf,j(ek,t) < u0(ek,t), uf,j(ek,t) < uf(ek,t), uf,j(ek,t) < uj(ek,t), k = 1, 2, . . . , K o , (20) and the GLLR at time t is computed as βt = Kλ 2 log(σ2 w) + 1 2σ2w K X k=1 λ X i=1 (yk,t,i −hT k ˆx0 t)2 −1 2  X k∈ˆ S0 t u0(ek,t) + X k∈ˆ Sf t uf(ek,t) + X k∈ˆ Sj t uj(ek,t) + X k∈ˆ Sf,j t uf,j(ek,t)  , (21) where u0(ek,t) ≜λ log(σ2 w) + ζk,t σ2w , (22) uf(ek,t) ≜                λ log(σ2 w) + 1 σ2w Pλ i=1(ek,t,i −δk,t λ )2, if | δk,t λ | ≥γ λ log(σ2 w) + ϖk,t σ2 w , if 0 ≤δk,t λ < γ λ log(σ2 w) + ϱk,t σ2 w , if −γ < δk,t λ < 0, (23) uj(ek,t) ≜        λ log( ζk,t λ ) + λ, if ζk,t λ ≥σ2 w + σ2 λ log(σ2 w + σ2) + ζk,t σ2w+σ2 , if ζk,t λ < σ2 w + σ2, (24) 11 and uf,j(ek,t) ≜                                        λ log( 1 λ Pλ i=1(ek,t,i −δk,t λ )2) + λ, if | δk,t λ | ≥γ and 1 λ Pλ i=1(ek,t,i −δk,t λ )2 ≥σ2 w + σ2 λ log(σ2 w + σ2) + 1 σ2w+σ2 Pλ i=1(ek,t,i −δk,t λ )2, if | δk,t λ | ≥γ and 1 λ Pλ i=1(ek,t,i −δk,t λ )2 < σ2 w + σ2 λ log( ϖk,t λ ) + λ, if 0 ≤δk,t λ < γ and ϖk,t λ ≥σ2 w + σ2 λ log(σ2 w + σ2) + ϖk,t σ2w+σ2 , if 0 ≤δk,t λ < γ and ϖk,t λ < σ2 w + σ2 λ log( ϱk,t λ ) + λ, if −γ < δk,t λ < 0 and ϱk,t λ ≥σ2 w + σ2 λ log(σ2 w + σ2) + ϱk,t σ2w+σ2 , if −γ < δk,t λ < 0 and ϱk,t λ < σ2 w + σ2. (25) Furthermore, the MLEs of the attack magnitudes for meter k ∈{1, 2, . . . , K} and for the interval between t −1 and t are determined as follows: ˆak,t =                        δk,t λ , if | δk,t λ | ≥γ and k ∈ˆSf t ∪ˆSf,j t γ, if 0 ≤δk,t λ < γ and k ∈ˆSf t ∪ˆSf,j t −γ, if −γ < δk,t λ < 0 and k ∈ˆSf t ∪ˆSf,j t 0, if k ∈ˆS0 t ∪ˆSj t (26) and ˆσ2 k,t =                                                                −σ2 w + ζk,t λ , if ζk,t λ ≥σ2 w + σ2 and k ∈ˆSj t σ2, if ζk,t λ < σ2 w + σ2 and k ∈ˆSj t −σ2 w + 1 λ Pλ i=1(ek,t,i −δk,t λ )2, if | δk,t λ | ≥γ and 1 λ Pλ i=1(ek,t,i −δk,t λ )2 ≥σ2 w + σ2 and k ∈ˆSf,j t σ2, if | δk,t λ | ≥γ and 1 λ Pλ i=1(ek,t,i −δk,t λ )2 < σ2 w + σ2 and k ∈ˆSf,j t −σ2 w + ϖk,t λ , if 0 ≤δk,t λ < γ and ϖk,t λ ≥σ2 w + σ2 and k ∈ˆSf,j t σ2, if 0 ≤δk,t λ < γ and ϖk,t λ < σ2 w + σ2 and k ∈ˆSf,j t −σ2 w + ϱk,t λ , if −γ < δk,t λ < 0 and ϱk,t λ ≥σ2 w + σ2 and k ∈ˆSf,j t σ2, if −γ < δk,t λ < 0 and ϱk,t λ < σ2 w + σ2 and k ∈ˆSf,j t 0, if k ∈ˆS0 t ∪ˆSf t . (27) Proof: See Appendix A. The proposed online detection and estimation algorithm is summarized in Algorithm 1. At each time t, ﬁrstly the prediction step of the Kalman ﬁlters is implemented. Then, the most likely attack type (or no attack) and the attack parameters for each meter are determined. Based on the estimates of the attack variables, the measurement update step of the Kalman ﬁlters is implemented. Then, the GLLR is computed and the decision statistic is updated. If the decision statistic crosses the predetermined test threshold, then an attack is declared. Otherwise, it proceeds to the next time interval and further measurements are collected. Moreover, if the decision statistic reaches zero, the Kalman ﬁlter estimates for the post-attack 12 Algorithm 1 Real-time attack detection and estimation 1: Initialization: t ←0, g0 ←0, ˆτ ←1 2: while gt < h do 3: t ←t + 1 4: Implement the prediction step of the Kalman ﬁlters using (9) and (11). 5: Compute u0(ek,t), uf(ek,t), uj(ek,t), and uf,j(ek,t), ∀k ∈{1, 2, . . . , K} using (22), (23), (24), and (25), respectively. 6: Classiﬁcation: compute ˆS0 t , ˆSf t , ˆSj t , and ˆSf,j t using (17), (18), (19), and (20), respectively. 7: Compute ˆat and ˆσt using (26) and (27), respectively. 8: Implement the measurement update step of the Kalman ﬁlters using (10) and (12). 9: Compute βt using (21). 10: Update the decision statistic: gt ←max{0, gt−1 + βt} 11: if gt = 0 then 12: ˆτ ←t 13: ˆx1 t|t ←ˆx0 t|t 14: P1 t|t ←P0 t|t 15: end if 16: end while 17: T ←t, declare a cyber-attack. case are updated before proceeding to the next time interval. Recall that Algorithm 1 keeps a change point estimate ˆτ. Hence, after an attack is declared at time T, to help for a quick system recovery, {ˆx1 t|t : ˆτ ≤t ≤T} can be reported as the recovered state estimates and further, estimates of the attack types and the set of attacked meters can be reported for the time interval between ˆτ and T. Remark 2: The detector parameters γ and σ2 can be determined by the system designer based on the system requirements, i.e., the desired level of false alarm rate. The system designer ﬁrstly determines the desired minimum level of average false alarm period, i.e., α. If the frequency of false alarms needs to be decreased, then α is chosen higher. After choosing α, the system designer chooses the values of γ, σ2, and the test threshold h in order to achieve an average false alarm period that is larger than or equal to α. For a higher level of α, higher values of γ, σ2, and h need to be chosen. On the other hand, higher values of γ, σ2, and h lead to larger detection delays. Hence, the system designer can choose such parameters to strike a desired balance between false alarm rate and the detection delays. IV. STEALTHY ATTACKS AND COUNTERMEASURES We ﬁrstly discuss stealthy attacks against a CUSUM detector, which can be employed in a simple case where the pre- and post-attack pdfs are known. Discussion on the stealthy attacks against a CUSUM detector is useful since similar forms of stealthy attacks can be performed against all CUSUM-based detectors. We then particularly discuss stealthy attacks against the proposed detector, i.e., Algorithm 1, where the pre- and post-attack pdfs are unknown and time-varying, as explained in Sec. III. Finally, we present some countermeasures against the considered stealthy attacks. A. Stealthy Attacks Against a CUSUM Detector Suppose the pre- and post-attack measurement pdfs are known and denoted with f0 and f1, respectively such that yt ∼f0 for t < τ and yt ∼f1 for t ≥τ. In this case, the CUSUM algorithm is the optimum solution to (14) [41], given by TCUSUM = inf{t : gt ≥h}, gt = max{0, gt−1 + ℓt}, (28) 13 where TCUSUM denotes the stopping time, h is the test threshold, gt is the decision statistic at time t, and ℓt ≜log   f1(yt) f0(yt)  is the log-likelihood ratio (LLR) at time t. 1) Non-persistent attacks: The CUSUM algorithm is mainly designed for detecting persistent changes, i.e., it is assumed that an attack is launched at an unknown time τ and continued thereafter. It accumulates evidence (LLR) over time and declares a change (attack/anomaly) only if the accumulated evidence is reliably high (cf. (28)). Hence, with the purpose of increasing the detection delay of the CUSUM algorithm, a smart attacker can design an on-off attacking strategy to perform an intermittent (non-persistent) attack. That is, it can attack for a period of time, then wait for a period of time and repeat this procedure over its attacking period with the aim of keeping the decision statistic of the CUSUM algorithm, i.e., gt, below the decision threshold h for t ≥τ so that the attack can be continued without being noticed. Since the measurements yt are essentially random variables, an attacker cannot control the decision statistic deterministically; it can control it only on average. Note that attackers usually need simple and effective attacking strategies that require the minimum possible knowledge. Let KL(f1, f0) ≜ R f1(y) log( f1(y) f0(y))dy denote the Kullback-Leibler (KL) divergence between f1 and f0. The following proposition presents a simple necessary condition for an attacker, having the knowledge of f0 and f1, to determine the on and off periods of a non-persistent stealthy attack against the CUSUM detector. Proposition 2: Let h′ ≥KL(f1, f0) be a threshold chosen by the attacker. The on and off periods have to be chosen as Ton ≤ h′ KL(f1, f0) and Toff > h′ KL(f0, f1) in order to satisfy E[gt] ≤h′ for t ≥τ, where Ton and Toff are positive integers denoting the on and off periods, respectively. Proof. We have E[gt] = E[max{0, gt−1 + ℓt}] ≥max{0, E[gt−1 + ℓt]} = max{0, E[gt−1] + E[ℓt]}, (29) where the inequality is due to the fact that gt−1 + ℓt can take negative values in general (−∞< ℓt < ∞). If yt ∼f1, then E[ℓt] = Z f1(y) log(f1(y) f0(y))dy = KL(f1, f0) > 0, and if yt ∼f0, then E[ℓt] = Z f0(y) log(f1(y) f0(y))dy = −KL(f0, f1) < 0. Let ρt ≜max{0, E[gt−1] + E[ℓt]} (30) be a lower bound on E[gt] (cf. (29)). Since (i) gt = 0 at t = 0 (hence, E[g0] = 0) and (ii) for t ≤τ−1, E[ℓt] = −KL(f0, f1) < 0, based on (30), we have ρt = 0 for t ≤τ −1. Further, based on (30), with an on period of Ton = h′/KL(f1, f0) (when yt ∼f1) 14 and an off period of Toff = h′/KL(f0, f1) (when yt ∼f0), we have 0 ≤ρt ≤h′ for t ≥τ. Since ρt is a lower bound for E[gt] for t > 0, in order to satisfy E[gt] ≤h′ for t ≥τ, the on period needs to be chosen smaller than h′/KL(f1, f0) and/or the off period needs to be chosen larger than h′/KL(f0, f1). For a stealthy attack, the attacker needs to choose h′ such that h′ < h. Further, ∆≜h −h′ can be considered as a margin for non-detectability. That is, as ∆increases, gt, t ≥τ takes smaller values on average, that increases the average detection delay of the CUSUM algorithm. Based on Proposition 2, the average on (attacking) period is upper bounded with ¯Ton ≜ Ton Ton + Toff < KL(f0, f1) KL(f1, f0) + KL(f0, f1). Note that the upper bound on ¯Ton is independent of h′ and hence of ∆. However, for a higher ¯Ton, either Ton needs to be increased or Toff needs to be decreased, that both increases E[gt], t ≥τ and hence decreases the average detection delay. Further, note that a stealthy attack can especially be effective if the system has strict false alarm constraints, i.e., requiring high level of false alarm periods and equivalently a high threshold h. 2) Persistent attacks: The CUSUM algorithm may not be effective in attack detection if the attack does not comply with the presumed attack model. If an attacker knows that the CUSUM detector is employed based on the post-attack pdf f1, then it can perform a stealthy persistent attack with a post-attack density f ′ 1 ̸= f1. The design goal can be keeping f ′ 1 as closest as possible to the post-attack pdf f1 for a strong attack while limiting the risk of being detected. Since the attack is of persistent nature, f ′ 1 needs to be designed such that the decision statistic of the CUSUM algorithm does not increase on average over time. Since the CUSUM algorithm accumulates the LLRs over time (cf. (28)), the LLR can be designed such that it takes non-positive values on the average, i.e., E[ℓt] ≤0, t > 0. Then, since E[ℓt] = −KL(f0, f1) < 0 for t ≤τ −1, the condition E[ℓt] ≤0, t ≥τ needs to be satisﬁed. Considering the KL divergence KL(f ′ 1, f1) as the information distance between f ′ 1 and f1, the following optimization problem can be considered: min f ′ 1 KL(f ′ 1, f1) subject to E[ℓt] ≤0, t ≥τ, (31) where the solution is presented in the following proposition. Proposition 3: The solution of (31) is given by {f ′ 1 : KL(f ′ 1, f0) = KL(f ′ 1, f1)}. (32) 15 Proof. Let yt ∼f ′ 1 for t ≥τ. Then, E[ℓt] = Z f ′ 1(y) log f1(y) f0(y)  dy = Z f ′ 1(y) log(f1(y))dy − Z f ′ 1(y) log(f0(y))dy = Z f ′ 1(y) log(f1(y))dy − Z f ′ 1(y) log(f ′ 1(y))dy + Z f ′ 1(y) log(f ′ 1(y))dy − Z f ′ 1(y) log(f0(y))dy = Z f ′ 1(y) log f1(y) f ′ 1(y)  dy + Z f ′ 1(y) log f ′ 1(y) f0(y)  dy = −KL(f ′ 1, f1) + KL(f ′ 1, f0). Then, the constraint in (31), i.e., E[ℓt] ≤0, implies that −KL(f ′ 1, f1) + KL(f ′ 1, f0) ≤0, which is equivalent to KL(f ′ 1, f1) ≥ KL(f ′ 1, f0). Hence, the minimum value of KL(f ′ 1, f1) is KL(f ′ 1, f0). Proposition 3 presents a simple strategy for an attacker to perform a persistent stealthy attack against a CUSUM detector. As an example, let f0 ∼N([µ0 µ0]T, σ2 I2) and f1 ∼N([µ1 µ1]T, σ2 I2). If f ′ 1 ∼N h 1 2 (µ0+µ1) 1 2 (µ0+µ1) i , h σ2 ϕ ϕ σ2 i , then it can be checked that KL(f ′ 1, f0) = KL(f ′ 1, f1) = 1 4σ2 (µ1 −µ0)2 + 1 2 log  σ4 σ4 −ϕ2  , where the correlation term ϕ can be chosen such that σ4 −ϕ2 > 0. B. Stealthy Attacks Against Algorithm 1 In the actual problem under consideration, the pre- and post-attack measurement pdfs, i.e., p0(yt|xt) and p1(yt|xt, at,σt), are based on some unknown and time-varying variables and hence the results in the previous subsection do not directly apply. The proposed algorithm estimates the pre- and post-attack pdfs at time t as p0(yt|ˆx0 t) and p1(yt|ˆx1 t, ˆat, ˆσt), respectively where ˆx0 t and ˆx1 t are computed via the Kalman ﬁlters, ˆat is given in (26), and ˆσt is given in (27). Then, the GLLR at time t is computed as follows (cf. (16)): βt = log p1(yt|ˆx1 t, ˆat, ˆσt) p0(yt|ˆx0 t)  . (33) Note that computing ˆx0 t and ˆx1 t requires the knowledge of all previously taken measurements, i.e., {yj, j ≤t}. Hence, for an attacker, estimating the pre- and post-attack pdfs and hence computing βt and gt requires monitoring all the system-wide measurements at all times, which is practically infeasible. Although determining the online attack parameters for a stealthy attack is difﬁcult in general, we provide below a brief analysis of the proposed algorithm and discuss possible stealthy attacks against it based on this analysis and the intuitions gained in Sec. IV-A. As before, since the measurements are random, an attacker can control the decision statistic only on the average. 16 Firstly, based on (33), βt depends on how close (relatively) the state estimates ˆx0 t and ˆx1 t to the actual system state xt and how accurate the MLEs of the attack magnitudes ˆat and ˆσt compared to the actual attack magnitudes at and σt are. During the pre-attack period, the measurements yt follow the normal measurement model (2) and hence at = 0 and σt = 0. Since ˆx0 t is computed assuming no attack, for t ≤τ −1, ˆx0 t is usually a better estimate of the actual system state xt compared to ˆx1 t due to the possible ML estimation errors in computing ˆat, ˆσt, and ˆx1 t (recall that (cf. (12)) ˆx1 t is computed based on ˆat and ˆσt). Then, p0(yt|ˆx0 t) is expected to ﬁt better to yt compared to p1(yt|ˆx1 t, ˆat, ˆσt), i.e., we usually have p0(yt|ˆx0 t) ≥p1(yt|ˆx1 t, ˆat, ˆσt) for t ≤τ −1. Then, based on (33), βt is expected to take nonpositive values in general, that makes gt ≈0 a good approximation for t ≤τ −1. The main aim of an attacker against the smart grid is deviating the state estimates from the actual system state as much as possible without being detected. Hence, it needs to keep gt below the level of h as long as possible for t ≥τ (cf. (16)). Similar to the stealthy attacks against the CUSUM algorithm discussed in Sec. IV-A, an attacker can either follow an on-off attacking strategy or perform persistent attacks that do not comply with the presumed attack magnitudes (cf. (15)). Note that in case of an attack, i.e., for t ≥τ, ˆx0 t deviates from xt since it is computed assuming no attack. On the other hand, ˆx1 t is a recovered state estimate, but it is subject to possible ML estimation errors. 1) Non-persistent attacks: Since Algorithm 1 is a CUSUM-based detector, stealthy intermittent (on-off) attacking can be performed against it. Speciﬁcally, during the on periods, an attacker can choose its attack magnitudes comparable to or larger than the presumed lower bounds on the attack magnitudes, i.e., γ and σ2, with the purpose of a strong attack. However, as explained before, analytically deriving the on-off periods and the online attack magnitudes seems infeasible for an attacker. Hence, a smart attacker, having the knowledge of system and detector parameters, can determine its attack parameters based on an ofﬂine simulation. When the attack complies with the presumed attack magnitudes, during an on period, ˆx0 t usually deviates from the actual system state more than ˆx1 t due to the recovery mechanism in computing ˆx1 t (cf. (12)). That makes p1(yt|ˆx1 t, ˆat, ˆσt) a better ﬁt to yt compared to p0(yt|ˆx0 t) on the average. Then, if an on-off attack is performed, during the on periods, based on (33), usually βt takes non-negative values and gt increases. Further, at the beginning of an off period after an on period, although the attack magnitudes are zero, i.e., at = σt = 0, since ˆx1 t is still a better (recovered) state estimate compared to ˆx0 t, p1(yt|ˆx1 t, ˆat, ˆσt) can still be a better ﬁt to yt and gt may further increase. Note that during an off period, ˆx0 t is not expected to deviate further since yt now follows the normal measurement model. On the other hand, ˆat, ˆσt, and ˆx1 t are still subject to possible ML estimation errors. That may make p0(yt|ˆx0 t) a better ﬁt to yt over time and as the off period is continued, βt may start to take nonpositive values on the average. Since gt is expected to increase in an on period as well as in the beginning of an off period, the level of attack magnitudes during the on periods needs to be carefully chosen in accordance with the aim of keeping the highest value of gt below the decision threshold h, for t ≥τ. 2) Persistent attacks: Since Algorithm 1 relies on the lower bounds γ and σ2 deﬁned on the attack magnitudes (cf. (15)), an attacker can perform persistent stealthy attacks using signiﬁcantly small attack magnitudes compared to γ and σ2 so that Algorithm 1 becomes ineffective to detect such attacks. In case of such small-magnitude stealthy attacks, the attack magnitudes at and σt are close to zero for t ≥τ and due to the possible ML estimation errors in computing ˆat and ˆσt, ˆx1 t usually 17 deviates more compared to ˆx0 t, similarly to the pre-attack period discussed before. Then, p0(yt|ˆx0 t) ﬁts better to yt compared to p1(yt|ˆx1 t, ˆat, ˆσt) on the average. Hence, in case of a persistent small-magnitude attack, based on (33), βt usually takes nonpositive values and the approximation gt ≈0 can still be valid. Note that even if an attacker has an incomplete knowledge about the system and detector parameters, it can still perform stealthy attacks with small attack magnitudes. Although such small-magnitude attacks have minimal effects on the system performance in the short run, they can be effective over long periods of time. Hence, they need to be detected with reasonable detection delays. C. Countermeasures Against Stealthy Attacks We ﬁrstly discuss countermeasures against the on-off attacking strategy, i.e., the non-persistent stealthy attacks. We then discuss a countermeasure against the persistent stealthy attacks where the attacks may not comply with the presumed attack model/magnitudes. Finally, we propose a new detection scheme, i.e., Algorithm 2, that simultaneously employs Algorithm 1 and the proposed countermeasures with the aim of being effective against a diverse range of potential cyber-attacks. 1) Countermeasures against the non-persistent stealthy attacks: Timely detection of cyber-attacks against the smart grid is crucial since any failure may quickly spread over the network. Hence, in practice, detection delays cannot be allowed to be arbitrarily large. Note that the optimization problem stated in (14) does not impose any constraints on the maximum tolerable detection delay. In an alternative quickest detection problem considered in [42], the objective is maximizing the probability of detection in at most η time units after an attack occurs, where τ ≤T < τ + η needs to be satisﬁed for a successful detection. In the extreme case of the considered non-persistent stealthy attacks, the attacker can choose its on period as Ton = 1. In such a case, the attack needs to be detected using the measurements obtained during a single time interval in the attacking regime and hence η = 1 needs to be chosen. Then, we consider the following optimization problem, proposed in [42]: sup T p(T) subject to E∞[T] ≥α, (34) where p(T) = inf τ ess inf Fτ Pτ  T = τ |Fτ, T ≥τ  is the worst-case (in the Lorden’s sense) detection probability after obtaining the ﬁrst measurements in the attacking regime. Shewhart Test: In case the pre- and post-attack pdfs are known as in Sec. IV-A, the optimum solution to (34) is the Shewhart test [42, Theorem 2.3], given by TS = inf{t : ℓt ≥ν}, (35) where TS denotes the stopping time and the threshold ν is determined such that P∞(ℓ1 ≥ν) = 1/α. Note that the Shewhart test in (35) is, in fact, the repeated log-likelihood ratio test (LLRT), i.e., at each time, the LLR is compared with a certain threshold and an alarm is triggered at the ﬁrst time the LLR crosses the threshold. We then propose the Shewhart test as a countermeasure to the non-persistent stealthy attacks against the CUSUM detector. Note that ν needs to be chosen sufﬁciently high to prevent frequent false alarms. 18 Generalized Shewhart Test: In case the pre- and post-attack pdfs are unknown and time-varying, we can only compute the GLLR βt. Hence, as a countermeasure, we propose to employ the generalized Shewhart test, i.e., the repeated generalized LLRT (GLLRT), given by T ′ = inf{t : βt ≥φ}, (36) where T ′ is the stopping time and φ is the test threshold. Again, a sufﬁciently high threshold needs to be chosen to prevent frequent false alarms. Moreover, similar to Algorithm 1, by choosing higher γ and/or σ2, false alarm rate of the generalized Shewhart test can be reduced (see Remark 2). Note that the generalized Shewhart test is expected to be mainly effective in detecting signiﬁcant instantaneous increases in the level of GLLR and hence in detecting non-persistent stealthy attacks during the on periods. That is, even if an attack may be missed by Algorithm 1 since the decision statistic gt may not achieve reliably high values for t ≥τ due to the subsequent off period after an on period, the generalized Shewhart test can detect such non-persistent increases during the on periods. 2) A countermeasure against the persistent stealthy attacks: Non-parametric detection techniques do not assume any attack models and only evaluate the deviation of measurement statistics from the baseline (no attack) statistics. However, they are usually less effective if the attacks comply with the presumed attack models. As explained before, a persistent stealthy attack can be performed if an attack does not match the considered attack models or magnitudes. For such cases, parametric detectors such as Algorithm 1 and the generalized Shewhart test become ineffective and the non-parametric detection techniques become more appropriate. In case of no attack, i.e., for t < τ, ct ≜rtT Qt −1rt is a chi-square random variable with Kλ degrees of freedom [18], where rt denotes the measurement innovation signal at time t, given as rt ≜yt −Hˆx0 t|t−1, and Qt is the measurement prediction covariance matrix at time t, calculated as follows: Qt ≜HPt|t−1HT + σ2 w IKλ. Notice that although the distribution of the measurements yt is time-varying and unknown due to the dynamic system state xt, the distribution of ct is time-invariant and known in case of no attack, i.e., for t < τ. Hence, whether the sequence {ct} ﬁts to the chi-squared distribution or not can be evaluated via a goodness-of-ﬁt test and if not, an attack/anomaly is declared. Sliding-Window Chi-Squared Test: We partition the range of ct, i.e., [0, ∞), into M mutually exclusive and disjoint intervals Ij, j = 1, 2, . . . , M such that p1 = P(ct ∈I1), p2 = P(ct ∈I2), ..., pM = P(ct ∈IM). Hence, p1, p2, . . . , pM denote the probabilities that ct belongs to the intervals I1, I2, . . . , IM, respectively for t < τ, where PM j=1 pj = 1. The intervals I1, I2, . . . , IM can be determined using the cumulative distribution function (cdf) of a chi-squared random variable with Kλ degrees of freedom. Then, the null hypothesis is that ct belongs to the intervals I1, I2, . . . , IM with probabilities p1, p2, . . . , pM, respectively. 19 We propose to employ an online test to evaluate whether the most recent sliding window of ct’s ﬁts to the null hypothesis. Let the size of the sliding window be L. Then, the sliding window at time t, denoted with Wt, consists of {cj : t−L+1 ≤j ≤t}. Let the number of samples in Wt belonging to the predetermined disjoint intervals be denoted with N1,t, N2,t, . . . , NM,t, respectively where PM i=1 Ni,t = L, ∀t. Since we have a multinomial distribution where the expected number of samples in the disjoint intervals are Lp1, Lp2, . . . , LpM, respectively, the Pearson’s chi-squared test can be used to evaluate the goodness of ﬁt, that can be written as T ′′ = inf{t : χt ≥ϕ}, (37) where χt = M X i=1 (Ni,t −Lpi)2 Lpi (38) is the asymptotically (as L →∞) chi-squared distributed test statistic with M −1 degrees of freedom under the null hypothesis, ϕ is the test threshold that can be determined using the cdf of a chi-squared random variable for a desired signiﬁcance level, and T ′′ denotes the stopping time. To improve the accuracy of the detector, M can be chosen higher. Note, however, that as M is increased, the window size L needs also to be increased to improve the reliability of the goodness-of-ﬁt test, that will cause larger detection delays. The chi-squared test does not assume any attack model a priori and it only evaluates deviation of observed measurements from the baseline statistics corresponding to the normal system operation. We propose to use the chi-squared test to have a detection scheme that is robust against (i) low-magnitude stealthy attacks that corresponds to small deviations from the baseline for which our proposed parametric detectors (Algorithm 1 and the generalized Shewhart test) become ineffective to detect, and (ii) attacks that do not comply with the presumed hybrid attack model, e.g., non-Gaussian or correlated jamming noise. Remark 3: The proposed chi-squared test is a sequential version of the Pearson’s chi-squared test since the most recent sliding window of samples is used in the test. Furthermore, the proposed test is different from the outlier detector in [18], that makes sample by sample decisions, i.e., it declares a single sample as either normal and anomalous. The proposed test is thus more reliable and more sensitive to small deviations from the baseline since it considers long-term deviations by evaluating a sliding window of samples. 3) Proposed ﬁnal detection scheme: Our aim is to obtain a detection mechanism that is effective against a signiﬁcantly wide range of cyber-attacks. Hence, we propose to simultaneously employ Algorithm 1, the generalized Shewhart test, and the sliding-window chi-squared test and declare an attack at the ﬁrst time instant one of the detectors declares an attack (if any). Hence, ˜T = inf{T, T ′, T ′′} is the proposed stopping time. We summarize the proposed detector in Algorithm 2. Note that the average false alarm period of Algorithm 2 is less than the minimum of the (individual) average false alarm periods of Algorithm 1, the generalized Shewhart 20 Algorithm 2 Real-time detection of hybrid and stealthy attacks 1: Initialization: t ←0, g0 ←0, ˆτ ←1, choose the entries of the initial sliding window of the chi-squared test, i.e., W0, as realizations of a chi-squared random variable with Kλ degrees of freedom. 2: while gt < h and βt < φ and χt < ϕ do 3: t ←t + 1 4: Implement the lines 4–15 in Algorithm 1. 5: rt ←yt −Hˆx0 t|t−1 6: Qt ←HPt|t−1HT + σ2 w IKλ 7: ct ←rt T Qt −1rt 8: Update Wt with the most recent entry ct. 9: Update N1,t, N2,t, . . . , NM,t and compute χt using (38). 10: end while 11: ˜T ←t, declare a cyber-attack. test, and the sliding-window chi-squared test. Hence, sufﬁciently high thresholds, i.e., h, φ and ϕ, need to be chosen to prevent frequent false alarms. Furthermore, to have the same average false alarm periods α for Algorithms 1 and 2, the threshold h needs to be chosen higher in Algorithm 2 and the thresholds φ and ϕ need to be chosen such that the individual average false alarm periods of the generalized Shewhart test and the sliding-window chi-squared tests are greater than α. V. SIMULATION RESULTS In this section, we evaluate the performance of the proposed detection schemes via simple case studies in an IEEE-14 bus power system, where K = 23 and N = 13. The system matrix A is chosen to be an identity matrix, the measurement matrix H is determined based on the IEEE-14 bus power system, and λ = 5 is chosen. The initial state variables are obtained through the DC optimal power ﬂow algorithm for case-14 in MATPOWER [43]. The system noise variances are chosen as σ2 v = σ2 w = 10−4. Furthermore, the parameters of Algorithm 1 are chosen as γ = 0.022 and σ2 = 10−2. In Algorithm 2, the threshold of the generalized Shewhart test is chosen as φ = 10. Moreover, for the chi-squared test, the window size is chosen as L = 80, number of disjoint intervals are chosen as M = 5, the probabilities are chosen as p1 = p2 = · · · = p5 = 0.2, and the intervals I1, I2, . . . , I5 are determined accordingly as I1 = [0, 102.081), I2 = [102.081, 110.5475), I3 = [110.5475, 118.2061), I4 = [118.2061, 127.531), and I5 = [127.531, ∞) based on the cdf of a chi-squared random variable with Kλ = 115 degrees of freedom. The threshold of the Pearson’s chi-squared test, i.e., ϕ = 25.0133, is chosen based on the signiﬁcance level of 5 × 10−5 for a chi-squared random variable with M −1 = 4 degrees of freedom. The thresholds of the generalized Shewhart and the chi-squared tests are chosen such that the (individual) average false alarm periods of these tests are in the order of 104. The cyber-attacks are launched at t = 100. Firstly, we evaluate the performance of the proposed schemes in case of an FDI-only attack, a jamming-only attack, and a hybrid attack. We then evaluate the performance in case of stealthy hybrid attacks. Particularly, we consider a non-persistent stealthy attack and a small-magnitude persistent stealthy attack, and illustrate the performance improvement obtained with the proposed countermeasures against such stealthy attacks. Next, we illustrate the mean squared error (MSE) vs. time plot for the recovered and non-recovered state estimates in case of a hybrid cyber-attack. Finally, we evaluate the performance of the proposed schemes in case of a network topology attack/failure. 21 A. Case 1: FDI Attack We ﬁrstly consider a random and time-varying persistent FDI attack where at each time the attacker chooses the magnitudes of the injected false data and the set of attacked meters randomly. In particular, at each time, the attacker compromises the measurements of each meter with probability 0.5 and injects the realizations of the uniform random variable U[−0.02, 0.02] to the attacked meters. Fig. 1 illustrates the tradeoff between the average detection delay and the average false alarm period for the proposed algorithms and also three benchmark tests, namely the nonparametric CUSUM test in [29], the Euclidean detector [17] and the cosine-similarity metric based detector [19] that both check the dissimilarity between the actual and the predicted measurements (by the Kalman ﬁlter) and declare an anomaly if the dissimilarity metric is greater than certain thresholds. Since a nonlinear power system model is studied in [29] and we use a linear system model, we include a modiﬁed version of the nonparametric CUSUM detector for the linear case. The stopping time and the update of the decision statistic over time for the modiﬁed nonparametric CUSUM detector are given as follows: ¯T ≜inf {t : St ≥q} , St = St−1 + δt, δt ≜∥yt −Hˆx0 t|t−1∥−E0  ∥yt −Hˆx0 t|t−1∥  , where ¯T denotes the corresponding stopping time, St is the decision statistic at time t where S0 = 0, q is the test threshold that controls the false alarm rate of the detector, and E0[∥yt −Hˆx0 t|t−1∥] denotes the expectation of the L2 norm of the measurement innovation signal in the pre-change case, computed via a Monte Carlo simulation. The nonparametric CUSUM detector accumulates the difference between magnitude of the measurement innovation signal and its expected value in the pre-change case (normal system operation). We observe that the proposed algorithms signiﬁcantly outperform the benchmark tests. Moreover, Algorithm 1 slightly outperforms Algorithm 2. This is because the countermeasures introduced in Algorithm 2 slightly increase the false alarm rate of Algorithm 2. Note that in obtaining the tradeoff curve for Algorithm 2, we keep the thresholds φ and ϕ constant and only vary h. We then illustrate the performance of the proposed algorithms as the magnitude of the injected false data varies while keeping the false alarm rate constant. We again consider the random and time-varying persistent FDI attack described above, but this time the magnitudes of the injected data are realizations of U[−θ, θ], where θ varies between 0.009 and 0.03. Through Fig. 2, we see the advantage of the proposed countermeasures as the magnitude of the false data takes very small values. For instance, when θ = 0.009, the average detection delays of Algorithm 1 and Algorithm 2 are 48.02 and 39.45, respectively. B. Case 2: Jamming Attack Next, we consider a random and time-varying persistent jamming attack. At each time, an attacker jams the measurements of each meter with probability 0.5 where the variances of the jamming noise are the realizations of the uniform random variable U[2 × 10−4, 4 × 10−4]. Fig. 3 presents the delay to false alarm curve for the proposed algorithms and the benchmark tests. Further, we evaluate the performance as the magnitude of the jamming noise variance varies by keeping the false alarm rate 22 0 0.5 1 1.5 2 2.5 Average False Alarm Period 104 0 50 100 150 200 250 Average Detection Delay Algorithm 1 Algorithm 2 Euclidean Detector Cos-Sim Detector Nonpar. CUSUM 0.5 1 1.5 2 104 1 1.2 1.4 Fig. 1: Average detection delay vs. average false alarm period for the proposed detectors and the benchmark tests in case of a random FDI attack. 0.005 0.01 0.015 0.02 0.025 0.03 0 5 10 15 20 25 30 35 40 45 50 Average Detection Delay Algorithm 1 Algorithm 2 Fig. 2: Average detection delay vs. magnitude of the injected false data for the proposed detectors in case of a random FDI attack, where the average false alarm period is approximately 1.5 × 104. constant. In particular, jamming noise variances are chosen as realizations of U[ϑ, 2ϑ], where ϑ is varied between 0.75σ2 w and 3σ2 w. Through Fig. 4, we again observe smaller detection delays in Algorithm 2 compared to Algorithm 1 in case of very small attack magnitudes. C. Case 3: Hybrid FDI/Jamming Attack Next, we consider a random and time-varying persistent hybrid attack. The attack is combined over the system and it may also be combined over a subset of meters. In particular, we consider the attacks described in Sec. V-A and Sec. V-B altogether. Hence, the attacker chooses a random subset of meters for FDI attack and another random subset of meters for jamming attack, where these subsets might overlap with each other. The attack magnitudes for FDI and jamming attacks are realizations of U[−0.02, 0.02] and U[2 × 10−4, 4 × 10−4], respectively. In Fig. 5, for the same levels of false alarm rate, we observe smaller detection delays compared to Figures 1 and 3, as expected. 23 0 0.5 1 1.5 2 2.5 Average False Alarm Period 104 0 50 100 150 200 250 300 Average Detection Delay Algorithm 1 Algorithm 2 Euclidean Detector Cos-Sim Detector Nonpar. CUSUM 0.5 1 1.5 2 104 0.6 0.7 0.8 0.9 1 Fig. 3: Average detection delay vs. average false alarm period for the proposed detectors and the benchmark tests in case of a random jamming attack. 0.5 1 1.5 2 2.5 3 0 10 20 30 40 50 60 Average Detection Delay Algorithm 1 Algorithm 2 Fig. 4: Average detection delay vs. variance of the jamming noise for the proposed detectors in case of a random jamming attack, where the average false alarm period is approximately 1.5 × 104. 0 0.5 1 1.5 2 2.5 Average False Alarm Period 104 0 50 100 150 200 250 Average Detection Delay Algorithm 1 Algorithm 2 Euclidean Detector Cos-Sim Detector Nonpar. CUSUM 0.5 1 1.5 2 104 0.1 0.15 0.2 Fig. 5: Average detection delay vs. average false alarm period for the proposed detectors and the benchmark tests in case of a hybrid attack. 24 0 0.5 1 1.5 2 2.5 Average False Alarm Period 104 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Missed Detection Ratio Algorithm 1 Algorithm 2 Euclidean Detector Cos-Sim Detector Nonpar. CUSUM Fig. 6: Missed detection ratio vs. average false alarm period for the proposed detectors and the benchmark tests in case of a stealthy non-persistent attack, where the attack is assumed to be missed if it is not detected within 50 time units. D. Case 4: Non-persistent Stealthy Attack Next, we consider a stealthily designed on-off attack. Particularly, after the attack is launched at t = 100, the attacker performs a hybrid attack as described in Sec. V-C where the magnitudes of the FDI and jamming attacks are realizations of U[−0.01, 0.01] and U[10−4, 2 × 10−4], respectively and the on and off periods are Ton = 1 and Toff = 3, respectively. As an example, we choose the maximum tolerable detection delay as 50 time units and if the attack cannot be detected within this period, we assume that the attack is missed. In Fig. 6, we present the missed detection ratio versus average false alarm period for the proposed algorithms and the benchmark tests. As discussed in Sec. IV-C.1, against the non-persistent attacks, mainly the generalized Shewhart test is expected to perform well. That is, due to the off periods, even though the accumulated evidence supporting change may not become reliably high to declare an attack in Algorithm 1, the GLLR may take high values during the on periods. On the other hand, since the threshold of the generalized Shewhart test is chosen very high (φ = 10) to reduce the false alarm level of Algorithm 2, the missed detection ratios in Algorithms 1 and 2 are almost the same for the small levels of average false alarm period, i.e., for the small test thresholds. However, for higher levels of average false alarm period, the missed detection ratio of Algorithm 2 signiﬁcantly decreases compared to Algorithm 1 and the advantage of introducing the generalized Shewhart test in Algorithm 2 becomes visible in detecting the non-persistent stealthy attacks. E. Case 5: Persistent Stealthy Attack Although the considered lower bounds γ and σ2 on the attack magnitudes are already very small, an attacker may still perform a persistent stealthy attack using even lower attack magnitudes. Recall that we have previously showed in Figures 2 and 4 the advantage of Algorithm 2 over Algorithm 1 as the attack magnitudes get smaller for the FDI and jamming attacks, respectively. This time, we consider a hybrid attack with even smaller attack magnitudes where the magnitudes of FDI and jamming attacks are chosen as realizations of U[−0.005, 0.005] and U[0.5 × 10−4, 10−4], respectively. We present the missed detection ratio versus the average false alarm period curve for the proposed algorithms and the benchmark tests in Fig. 7. We observe that Algorithm 2 signiﬁcantly outperforms Algorithm 1 due to the introduced non-parametric chi-squared test in Algorithm 2. Since the attack magnitudes are very small, the proposed parametric tests become ineffective to detect 25 0 0.5 1 1.5 2 2.5 Average False Alarm Period 104 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Missed Detection Ratio Algorithm 1 Algorithm 2 Euclidean Detector Cos-Sim Detector Nonpar. CUSUM Fig. 7: Missed detection ratio vs. average false alarm period for the proposed detectors and the benchmark tests in case of a stealthy small-magnitude persistent attack, where the attack is assumed to be missed if it is not detected within 50 time units. such stealthy attacks. Note that although the non-parametric goodness-of-ﬁt tests such as the chi-squared test becomes more successful in detecting such small-magnitude stealthy attacks, they in general lead to longer detection delays compared to the considered parametric tests since they usually require more samples for a reliable decision, mainly because they ignore all the prior knowledge about the post-attack case. F. Algorithm 1 vs. Countermeasures Against Stealthy Attacks With the purpose of illustrating the advantages of additional countermeasures employed in Algorithm 2 more clearly, Fig. 8 shows a comparison between Algorithm 1 and the countermeasures in case of stealthy attacks described in Sec. V-D and Sec. V-E. Here, the individual average false alarm periods of Algorithm 1, the generalized Shewhart test, and the sliding- window chi-squared test are nearly equal to each other and for the non-persistent and persistent stealthy attacks, the ﬁgure shows the ratios over all trials at which each algorithm detects the attack ﬁrst (with the minimum delay), where more than one test may simultaneously declare an attack with the minimum delay. Through the ﬁgure, we observe that the generalized Shewhart and the sliding-window chi-squared tests outperform Algorithm 1 in case of non-persistent and persistent stealthy attacks, respectively. Hence, together with the results obtained through Figures 6 and 7, we can conclude that in case of stealthy attacks, the countermeasures improve the detection performance of Algorithm 2 compared to Algorithm 1. G. Recovered State Estimates Fig. 9 presents the MSE versus time curve for the recovered, i.e., ˆx1 t|t, and the non-recovered, i.e., ˆx0 t|t, state estimates during the pre-change period, i.e., for t < 100, and the ﬁrst 50 time units after a hybrid FDI/jamming attack is launched to the system at τ = 100. The FDI and jamming attacks are both of persistent nature as described in Sec. V-C and the attack magnitudes are realizations of U[−0.1, 0.1] and U[1, 2], respectively. Through the ﬁgure, we observe that the MSE of the recovered state estimates is signiﬁcantly smaller than the MSE of the non-recovered state estimates. Further, we observe that the recovered state estimates slightly deviate from the actual system state xt over the attacking period. This is due to the fact that the MLEs of the attack variables are computed based on the recovered state estimates (cf. (26) and (27)) and also the 26 Non-Persistent Attack Persistent Attack 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 Alg. 1 G. Shewhart Chi-Squared Fig. 8: Ratio of trials at which Algorithm 1, the generalized Shewhart test, and the sliding-window chi-squared test detect the stealthy attacks ﬁrst (with the minimum delay), where the individual average false alarm periods of the algorithms are approximately 1.5 × 104. 0 50 100 150 0 0.2 0.4 0.6 0.8 1 1.2 1.4 Fig. 9: MSE vs. time for the recovered (ˆx1 t|t) and non-recovered (ˆx0 t|t) state estimates in case of a hybrid attack. recovered state estimates are computed based on the MLEs of the attack variables (cf. (12)). Hence, the ML estimation errors accumulate over time during the attacking period. However, since the attacks can be quickly detected with the proposed real- time detection schemes, the deviation of the recovered state estimates is not expected to be signiﬁcantly high at the detection time. Furthermore, recall that during the pre-attack period, whenever the decision statistic of Algorithm 1 reaches zero, the state estimates for the post-attack case are updated as being equal to the state estimates for the pre-attack case. Since the decision statistic frequently reaches zero during the pre-attack period, the ML estimation errors in computing the recovered state estimates do not accumulate in the pre-attack period. H. Case 6: Topology Attack/Fault Except the proposed nonparametric chi-squared test, the proposed methods are prone to the errors in the measurement matrix H due to either cyber-attacks or faults. This is because Algorithm 1 and the generalized Shewhart test are designed for a given H (see the hybrid attack model in (5)), whereas the chi-squared test does not depend on attack model assumptions. On the other hand, the speciﬁc version of topology attack/failure in which some rows of H seem zero to the control center (although they are not) corresponds to DoS attacks, which is covered by the considered hybrid attack model (see Remark 1). For 27 0 0.5 1 1.5 2 2.5 Average False Alarm Period 104 0 2 4 6 8 10 12 Average Detection Delay Algorithm 1 Algorithm 2 Euclidean Detector Cos-Sim Detector Nonpar. CUSUM Fig. 10: Average detection delay vs. average false alarm period for the proposed detectors and the benchmark tests in case of a network topology attack/fault. instance, if the link between two buses in a power grid breaks down due to an attack or fault, then the row in H corresponding to the power-ﬂow measurement between these buses is changed accordingly such that the corresponding measurement signal becomes unavailable to the control center. Since the hybrid attack model covers DoS attacks as a special case, such topology attacks/faults can be detected by the proposed detectors. In Fig. 10, we illustrate the performance of the proposed and the benchmark algorithms in detecting a line break between buses 9 and 10 in the IEEE-14 bus power system. VI. CONCLUSIONS In this paper, we have studied the real-time detection of hybrid FDI/jamming attacks in the smart grid. For a given network topology, we have modeled the smart grid as a linear dynamic system and employed Kalman ﬁlters for state estimation. We have proposed an online CUSUM-based attack detection and estimation algorithm that is robust to unknown and time-varying attack parameters. We have also presented online estimates of the attack parameters in closed form and recovered state estimates in case of a cyber-attack. Furthermore, we have introduced and analyzed stealthy attacks against CUSUM-based detectors and speciﬁcally against the proposed algorithm, where the main aim of stealthy attacks is to prevent the detection or at least to increase the detection delays. We have presented the generalized Shewhart test and the sliding-window chi-squared test as countermeasures against non-persistent and persistent stealthy attacks, respectively. Through extensive simulations, we have illustrated that the proposed algorithms can timely and reliably detect hybrid FDI/jamming attacks and stealthy attacks against CUSUM-based detectors, that correspond to a signiﬁcantly diverse range of potential cyber-attacks targeting the smart grid. Moreover, the simulations illustrate the effectiveness of the proposed state recovery mechanism to mitigate the effects of cyber-attacks on the state estimation mechanism. The proposed hybrid attack model does not cover network topology attacks as a special case. As a future work, the generalized state estimation mechanism [44] can be considered where both the system state and the network topology are estimated based on power ﬂow/injection measurements and measurements regarding the status of network switches and line breakers, and countermeasures can be developed against advanced topology attacks where attackers simultaneously perform hybrid FDI/jamming and network topology attacks. 28 APPENDIX A. Proof of Proposition 1 Based on (7) and (8), βt in (16) can be written as follows: βt = Kλ 2 log(σ2 w) + 1 2σ2w K X k=1 λ X i=1 (yk,t,i −hT k ˆx0 t)2 + sup S0 t ,Sf t ,Sj t ,Sf,j t ( sup |ak,t|≥γ, k ∈Sf t ∪Sf,j t sup σ2 k,t≥σ2, k ∈Sj t ∪Sf,j t  X k∈S0 t λ X i=1 −1 2 log(σ2 w) − 1 2σ2w (yk,t,i −hT k ˆx1 t)2 + X k∈Sf t λ X i=1 −1 2 log(σ2 w) − 1 2σ2w (yk,t,i −hT k ˆx1 t −ak,t)2 + X k∈Sj t λ X i=1 −1 2 log(σ2 w + σ2 k,t) − 1 2(σ2w + σ2 k,t)(yk,t,i −hT k ˆx1 t)2 + X k∈Sf,j t λ X i=1 −1 2 log(σ2 w + σ2 k,t) − 1 2(σ2w + σ2 k,t)(yk,t,i −hT k ˆx1 t −ak,t)2 ) . (39) Let ek,t,i ≜yk,t,i −hT k ˆx1 t and ek,t ≜[ek,t,1, ek,t,2, . . . , ek,t,λ]T. Using the fact that taking supremum of a quantity is equivalent to taking inﬁmum of the negative of the quantity, (39) can be rewritten as βt = Kλ 2 log(σ2 w) + 1 2σ2w K X k=1 λ X i=1 (yk,t,i −hT k ˆx0 t)2 −1 2 inf S0 t ,Sf t ,Sj t ,Sf,j t  X k∈S0 t λ log(σ2 w) + Pλ i=1 e2 k,t,i σ2w | {z } u0(ek,t) + X k∈Sf t λ log(σ2 w) + inf|ak,t|≥γ  Pλ i=1(ek,t,i −ak,t)2 σ2w | {z } uf (ek,t) + X k∈Sj t inf σ2 k,t≥σ2 n λ log(σ2 w + σ2 k,t) + Pλ i=1 e2 k,t,i (σ2w + σ2 k,t) o | {z } uj(ek,t) + X k∈Sf,j t inf σ2 k,t≥σ2 inf |ak,t|≥γ n λ log(σ2 w + σ2 k,t) + Pλ i=1(ek,t,i −ak,t)2 (σ2w + σ2 k,t) o | {z } uf,j(ek,t) ! (40) = Kλ 2 log(σ2 w) + 1 2σ2w K X k=1 λ X i=1 (yk,t,i −hT k ˆx0 t)2 −1 2 inf S0 t ,Sf t ,Sj t ,Sf,j t  X k∈S0 t u0(ek,t) + X k∈Sf t uf(ek,t) + X k∈Sj t uj(ek,t) + X k∈Sf,j t uf,j(ek,t) ! . The MLE estimates of S0 t , Sf t , Sj t , and Sf,j t are then determined as follows: ˆS0 t = n k : u0(ek,t) ≤uf(ek,t), u0(ek,t) ≤uj(ek,t), u0(ek,t) ≤uf,j(ek,t), k = 1, 2, . . . , K o ˆSf t = n k : uf(ek,t) < u0(ek,t), uf(ek,t) ≤uj(ek,t), uf(ek,t) ≤uf,j(ek,t), k = 1, 2, . . . , K o ˆSj t = n k : uj(ek,t) < u0(ek,t), uj(ek,t) < uf(ek,t), uj(ek,t) ≤uf,j(ek,t), k = 1, 2, . . . , K o ˆSf,j t = n k : uf,j(ek,t) < u0(ek,t), uf,j(ek,t) < uf(ek,t), uf,j(ek,t) < uj(ek,t), k = 1, 2, . . . , K o . 29 Then, βt can be computed as βt = Kλ 2 log(σ2 w) + 1 2σ2w K X k=1 λ X i=1 (yk,t,i −hT k ˆx0 t)2 −1 2  X k∈ˆ S0 t u0(ek,t) + X k∈ˆ Sf t uf(ek,t) + X k∈ˆ Sj t uj(ek,t) + X k∈ˆ Sf,j t uf,j(ek,t)  , where u0(ek,t) is given by (cf. (40)) u0(ek,t) = λ log(σ2 w) + Pλ i=1 e2 k,t,i σ2w . Next, we determine uf(ek,t), uj(ek,t), uf,j(ek,t), respectively and the MLEs of ak,t and σ2 k,t. Firstly, uf(ek,t) = λ log(σ2 w) + inf|ak,t|≥γ  Pλ i=1(ek,t,i −ak,t)2 σ2w =                λ log(σ2 w) + 1 σ2w Pλ i=1(ek,t,i −1 λ Pλ i=1 ek,t,i)2, if | 1 λ Pλ i=1 ek,t,i| ≥γ λ log(σ2 w) + 1 σ2w Pλ i=1(ek,t,i −γ)2, if 0 ≤1 λ Pλ i=1 ek,t,i < γ λ log(σ2 w) + 1 σ2w Pλ i=1(ek,t,i + γ)2, if −γ < 1 λ Pλ i=1 ek,t,i < 0, where the MLE of ak,t, k ∈Sf t is obtained as follows: ˆak,t =                1 λ Pλ i=1 ek,t,i, if | 1 λ Pλ i=1 ek,t,i| ≥γ, k ∈Sf t γ, if 0 ≤1 λ Pλ i=1 ek,t,i < γ, k ∈Sf t −γ, if −γ < 1 λ Pλ i=1 ek,t,i < 0, k ∈Sf t . (41) Secondly, uj(ek,t) = inf σ2 k,t≥σ2 n λ log(σ2 w + σ2 k,t) + Pλ i=1 e2 k,t,i σ2w + σ2 k,t o . We have ∂uj(ek,t) ∂σ2 k,t = λ σ2w+σ2 k,t − Pλ i=1 e2 k,t,i (σ2w+σ2 k,t)2 = 0 if σ2 k,t = −σ2 w + 1 λ Pλ i=1 e2 k,t,i. Moreover, for σ2 k,t < −σ2 w + 1 λ Pλ i=1 e2 k,t,i, ∂uj(ek,t) ∂σ2 k,t < 0 and for σ2 k,t > −σ2 w + 1 λ Pλ i=1 e2 k,t,i, ∂uj(ek,t) ∂σ2 k,t > 0. Hence, if 1 λ Pλ i=1 e2 k,t,i ≥σ2 w + σ2, uj(ek,t) takes it minimum at σ2 k,t = −σ2 w + 1 λ Pλ i=1 e2 k,t,i. On the other hand, if 1 λ Pλ i=1 e2 k,t,i < σ2 w + σ2, uj(ek,t) is monotone increasing function of σ2 k,t in the range of σ2 k,t ≥σ2. Hence, uj(ek,t) takes its minimum at σ2 k,t = σ2. Then, uj(ek,t) =        λ log( 1 λ Pλ i=1 e2 k,t,i) + λ, if 1 λ Pλ i=1 e2 k,t,i ≥σ2 w + σ2 λ log(σ2 w + σ2) + 1 σ2w+σ2 Pλ i=1 e2 k,t,i, if 1 λ Pλ i=1 e2 k,t,i < σ2 w + σ2, where the MLE of σ2 k,t, k ∈Sj t is obtained as follows: ˆσ2 k,t =        −σ2 w + 1 λ Pλ i=1 e2 k,t,i, if 1 λ Pλ i=1 e2 k,t,i ≥σ2 w + σ2, k ∈Sj t σ2, if 1 λ Pλ i=1 e2 k,t,i < σ2 w + σ2, k ∈Sj t . (42) 30 Further, uf,j(ek,t) = inf σ2 k,t≥σ2 inf |ak,t|≥γ n λ log(σ2 w + σ2 k,t) + Pλ i=1(ek,t,i −ak,t)2 (σ2w + σ2 k,t) o = inf σ2 k,t≥σ2 n λ log(σ2 w + σ2 k,t) + inf|ak,t|≥γ  Pλ i=1(ek,t,i −ak,t)2 (σ2w + σ2 k,t) o =                infσ2 k,t≥σ2 n λ log(σ2 w + σ2 k,t) + 1 (σ2w+σ2 k,t) Pλ i=1(ek,t,i −1 λ Pλ i=1 ek,t,i)2o , if | 1 λ Pλ i=1 ek,t,i| ≥γ infσ2 k,t≥σ2 n λ log(σ2 w + σ2 k,t) + 1 (σ2w+σ2 k,t) Pλ i=1(ek,t,i −γ)2o , if 0 ≤1 λ Pλ i=1 ek,t,i < γ infσ2 k,t≥σ2 n λ log(σ2 w + σ2 k,t) + 1 (σ2w+σ2 k,t) Pλ i=1(ek,t,i + γ)2o , if −γ < 1 λ Pλ i=1 ek,t,i < 0 =                                        λ log( 1 λ Pλ i=1(ek,t,i −1 λ Pλ i=1 ek,t,i)2) + λ, if | 1 λ Pλ i=1 ek,t,i| ≥γ and 1 λ Pλ i=1(ek,t,i −1 λ Pλ i=1 ek,t,i)2 ≥σ2 w + σ2 λ log(σ2 w + σ2) + 1 σ2w+σ2 Pλ i=1(ek,t,i −1 λ Pλ i=1 ek,t,i)2, if | 1 λ Pλ i=1 ek,t,i| ≥γ and 1 λ Pλ i=1(ek,t,i −1 λ Pλ i=1 ek,t,i)2 < σ2 w + σ2 λ log( 1 λ Pλ i=1(ek,t,i −γ)2) + λ, if 0 ≤1 λ Pλ i=1 ek,t,i < γ and 1 λ Pλ i=1(ek,t,i −γ)2 ≥σ2 w + σ2 λ log(σ2 w + σ2) + 1 σ2w+σ2 Pλ i=1(ek,t,i −γ)2, if 0 ≤1 λ Pλ i=1 ek,t,i < γ and 1 λ Pλ i=1(ek,t,i −γ)2 < σ2 w + σ2 λ log( 1 λ Pλ i=1(ek,t,i + γ)2) + λ, if −γ < 1 λ Pλ i=1 ek,t,i < 0 and 1 λ Pλ i=1(ek,t,i + γ)2 ≥σ2 w + σ2 λ log(σ2 w + σ2) + 1 σ2w+σ2 Pλ i=1(ek,t,i + γ)2, if −γ < 1 λ Pλ i=1 ek,t,i < 0 and 1 λ Pλ i=1(ek,t,i + γ)2 < σ2 w + σ2, where the MLE of ak,t, k ∈Sf,j t is obtained as ˆak,t =                1 λ Pλ i=1 ek,t,i, if | 1 λ Pλ i=1 ek,t,i| ≥γ, k ∈Sf,j t γ, if 0 ≤1 λ Pλ i=1 ek,t,i < γ, k ∈Sf,j t −γ, if −γ < 1 λ Pλ i=1 ek,t,i < 0, k ∈Sf,j t , (43) and the MLE of σ2 k,t, k ∈Sf,j t is obtained as follows: ˆσ2 k,t =                                        −σ2 w + 1 λ Pλ i=1(ek,t,i −1 λ Pλ i=1 ek,t,i)2, if | 1 λ Pλ i=1 ek,t,i| ≥γ and 1 λ Pλ i=1(ek,t,i −1 λ Pλ i=1 ek,t,i)2 ≥σ2 w + σ2 σ2, if | 1 λ Pλ i=1 ek,t,i| ≥γ and 1 λ Pλ i=1(ek,t,i −1 λ Pλ i=1 ek,t,i)2 < σ2 w + σ2 −σ2 w + 1 λ Pλ i=1(ek,t,i −γ)2, if 0 ≤1 λ Pλ i=1 ek,t,i < γ and 1 λ Pλ i=1(ek,t,i −γ)2 ≥σ2 w + σ2 σ2, if 0 ≤1 λ Pλ i=1 ek,t,i < γ and 1 λ Pλ i=1(ek,t,i −γ)2 < σ2 w + σ2 −σ2 w + 1 λ Pλ i=1(ek,t,i + γ)2, if −γ < 1 λ Pλ i=1 ek,t,i < 0 and 1 λ Pλ i=1(ek,t,i + γ)2 ≥σ2 w + σ2 σ2, if −γ < 1 λ Pλ i=1 ek,t,i < 0 and 1 λ Pλ i=1(ek,t,i + γ)2 < σ2 w + σ2. (44) 31 Using (41), (43), and the MLEs of S0 t , Sf t , Sj t , and Sf,j t , the MLE of ak,t, k ∈{1, 2, . . . , K} is then determined as follows: ˆak,t =                        1 λ Pλ i=1 ek,t,i, if | 1 λ Pλ i=1 ek,t,i| ≥γ and k ∈ˆSf t ∪ˆSf,j t γ, if 0 ≤1 λ Pλ i=1 ek,t,i < γ and k ∈ˆSf t ∪ˆSf,j t −γ, if −γ < 1 λ Pλ i=1 ek,t,i < 0 and k ∈ˆSf t ∪ˆSf,j t 0, if k ∈ˆS0 t ∪ˆSj t . Furthermore, using (42), (44), and the MLEs of S0 t , Sf t , Sj t , and Sf,j t , the MLE of σ2 k,t, k ∈{1, 2, . . . , K} is obtained as follows: ˆσ2 k,t =                                                                −σ2 w + 1 λ Pλ i=1 e2 k,t,i, if 1 λ Pλ i=1 e2 k,t,i ≥σ2 w + σ2 and k ∈ˆSj t σ2, if 1 λ Pλ i=1 e2 k,t,i < σ2 w + σ2 and k ∈ˆSj t −σ2 w + 1 λ Pλ i=1(ek,t,i −1 λ Pλ i=1 ek,t,i)2, if | 1 λ Pλ i=1 ek,t,i| ≥γ and 1 λ Pλ i=1(ek,t,i −1 λ Pλ i=1 ek,t,i)2 ≥σ2 w + σ2 and k ∈ˆSf,j t σ2, if | 1 λ Pλ i=1 ek,t,i| ≥γ and 1 λ Pλ i=1(ek,t,i −1 λ Pλ i=1 ek,t,i)2 < σ2 w + σ2 and k ∈ˆSf,j t −σ2 w + 1 λ Pλ i=1(ek,t,i −γ)2, if 0 ≤1 λ Pλ i=1 ek,t,i < γ and 1 λ Pλ i=1(ek,t,i −γ)2 ≥σ2 w + σ2 and k ∈ˆSf,j t σ2, if 0 ≤1 λ Pλ i=1 ek,t,i < γ and 1 λ Pλ i=1(ek,t,i −γ)2 < σ2 w + σ2 and k ∈ˆSf,j t −σ2 w + 1 λ Pλ i=1(ek,t,i + γ)2, if −γ < 1 λ Pλ i=1 ek,t,i < 0 and 1 λ Pλ i=1(ek,t,i + γ)2 ≥σ2 w + σ2 and k ∈ˆSf,j t σ2, if −γ < 1 λ Pλ i=1 ek,t,i < 0 and 1 λ Pλ i=1(ek,t,i + γ)2 < σ2 w + σ2 and k ∈ˆSf,j t 0, if k ∈ˆS0 t ∪ˆSf t . Finally, deﬁning δk,t ≜Pλ i=1 ek,t,i, ζk,t ≜Pλ i=1 e2 k,t,i, ϱk,t ≜Pλ i=1(ek,t,i + γ)2, and ϖk,t ≜Pλ i=1(ek,t,i −γ)2, ∀k ∈ {1, 2, . . . , K} and ∀t > 0, we obtain the simpliﬁed expressions as given in Proposition 1. REFERENCES [1] H. He and J. Yan, “Cyber-physical attacks and defences in the smart grid: a survey,” IET Cyber-Physical Systems: Theory Applications, vol. 1, no. 1, pp. 13–27, 2016. [2] G. Liang, J. Zhao, F. Luo, S. Weller, and Z. Y. Dong, “A review of false data injection attacks against modern power systems,” IEEE Transactions on Smart Grid, vol. PP, no. 99, pp. 1–1, 2016. [3] W. Wang and Z. Lu, “Cyber security in the smart grid: Survey and challenges,” Computer Networks, vol. 57, no. 5, pp. 1344–1371, 2013. [4] Y. Yan, Y. Qian, H. Sharif, and D. Tipper, “A survey on cyber security for smart grid communications,” IEEE Communications Surveys & Tutorials, 2012. [5] L. Xie, Y. Mo, and B. Sinopoli, “False data injection attacks in electricity markets,” in 2010 First IEEE International Conference on Smart Grid Communications, Oct 2010, pp. 226–231. [6] R. Moslemi, A. Mesbahi, and J. Mohammadpour, “Design of robust proﬁtable false data injection attacks in multi-settlement electricity markets,” IET Generation, Transmission & Distribution, 2017. 32 [7] M. Ayar, S. Obuz, R. D. Trevizan, A. S. Bretas, and H. A. Latchman, “A distributed control approach for enhancing smart grid transient stability and resilience,” IEEE Transactions on Smart Grid, vol. 8, no. 6, pp. 3035–3044, 2017. [8] G. Liang, S. R. Weller, J. Zhao, F. Luo, and Z. Y. Dong, “The 2015 ukraine blackout: Implications for false data injection attacks,” IEEE Transactions on Power Systems, vol. 32, no. 4, pp. 3317–3318, July 2017. [9] S. Amin, A. A. Cárdenas, and S. S. Sastry, Safe and Secure Networked Control Systems under Denial-of-Service Attacks. Berlin, Heidelberg: Springer Berlin Heidelberg, 2009, pp. 31–45. [10] Y. Liu, P. Ning, and M. K. Reiter, “False data injection attacks against state estimation in electric power grids,” in Proceedings of the 16th ACM Conference on Computer and Communications Security, ser. CCS ’09. New York, NY, USA: ACM, 2009, pp. 21–32. [11] S. Tan, D. De, W. Z. Song, J. Yang, and S. K. Das, “Survey of security advances in smart grid: A data driven approach,” IEEE Communications Surveys Tutorials, vol. 19, no. 1, pp. 397–422, Firstquarter 2017. [12] R. Moslemi, A. Mesbahi, and J. M. Velni, “A fast, decentralized covariance selection-based approach to detect cyber attacks in smart grids,” IEEE Transactions on Smart Grid, 2017. [13] A. Sargolzaei, K. Yen, M. Abdelghani, A. Abbaspour, and S. Sargolzaei, “Generalized attack model for networked control systems, evaluation of control methods,” Intelligent Control and Automation, vol. 08, pp. 164–174, 2017. [14] Y. Li, L. Shi, P. Cheng, J. Chen, and D. E. Quevedo, “Jamming attacks on remote state estimation in cyber-physical systems: A game-theoretic approach,” IEEE Transactions on Automatic Control, vol. 60, no. 10, pp. 2831–2836, Oct 2015. [15] D. Deka, R. Baldick, and S. Vishwanath, “Optimal data attacks on power grids: Leveraging detection measurement jamming,” in 2015 IEEE International Conference on Smart Grid Communications (SmartGridComm), Nov 2015, pp. 392–397. [16] A. Abur and A. Gomez-Exposito, Power System State Estimation: Theory and Implementation, 01 2004, vol. 24. [17] K. Manandhar, X. Cao, F. Hu, and Y. Liu, “Detection of faults and attacks including false data injection attack in smart grid using kalman ﬁlter,” IEEE Transactions on Control of Network Systems, vol. 1, no. 4, pp. 370–379, Dec 2014. [18] B. Brumback and M. Srinath, “A chi-square test for fault-detection in kalman ﬁlters,” IEEE Transactions on Automatic Control, vol. 32, no. 6, pp. 552–554, Jun 1987. [19] D. B. Rawat and C. Bajracharya, “Detection of false data injection attacks in smart grid communication systems,” IEEE Signal Processing Letters, vol. 22, no. 10, pp. 1652–1656, Oct 2015. [20] M. Esmalifalak, L. Liu, N. Nguyen, R. Zheng, and Z. Han, “Detecting stealthy false data injection using machine learning in smart grid,” IEEE Systems Journal, vol. 11, no. 3, pp. 1644–1652, Sept 2017. [21] M. Ozay, I. Esnaola, F. T. Y. Vural, S. R. Kulkarni, and H. V. Poor, “Machine learning methods for attack detection in the smart grid,” IEEE Transactions on Neural Networks and Learning Systems, vol. 27, no. 8, pp. 1773–1786, Aug 2016. [22] A. S. Bretas, N. G. Bretas, B. Carvalho, E. Baeyens, and P. P. Khargonekar, “Smart grids cyber-physical security as a malicious data attack: An innovation approach,” Electric Power Systems Research, vol. 149, pp. 210–219, 2017. [23] J. Zhao, M. Netto, and L. Mili, “A robust iterated extended kalman ﬁlter for power system dynamic state estimation,” IEEE Transactions on Power Systems, vol. 32, no. 4, pp. 3205–3216, 2017. [24] J. Zhao, L. Mili, and A. Abdelhadi, “Robust dynamic state estimator to outliers and cyber attacks,” in Power & Energy Society General Meeting, 2017 IEEE. IEEE, 2017, pp. 1–5. [25] M. A. Gandhi and L. Mili, “Robust kalman ﬁlter based on a generalized maximum-likelihood-type estimator,” IEEE Transactions on Signal Processing, vol. 58, no. 5, pp. 2509–2520, 2010. [26] S. Li, Y. Yilmaz, and X. Wang, “Quickest detection of false data injection attack in wide-area smart grids,” IEEE Transactions on Smart Grid, vol. 6, no. 6, pp. 2725–2735, Nov 2015. [27] Y. Huang, J. Tang, Y. Cheng, H. Li, K. A. Campbell, and Z. Han, “Real-time detection of false data injection in smart grid networks: An adaptive cusum method and analysis,” IEEE Systems Journal, vol. 10, no. 2, pp. 532–543, June 2016. [28] M. N. Kurt, Y. Yilmaz, and X. Wang, “Distributed quickest detection of cyber-attacks in smart grid,” IEEE Transactions on Information Forensics and Security, vol. 13, no. 8, pp. 2015–2030, Aug 2018. [29] Q. Yang, L. Chang, and W. Yu, “On false data injection attacks against kalman ﬁltering in power system dynamic state estimation,” Security and Communication Networks, vol. 9, no. 9, pp. 833–849, 2016. 33 [30] B. Sun, X. Shan, K. Wu, and Y. Xiao, “Anomaly detection based secure in-network aggregation for wireless sensor networks,” IEEE Systems Journal, vol. 7, no. 1, pp. 13–25, 2013. [31] S. Cui, Z. Han, S. Kar, T. T. Kim, H. V. Poor, and A. Tajer, “Coordinated data-injection attack and detection in the smart grid: A detailed look at enriching detection solutions,” IEEE Signal Processing Magazine, vol. 29, no. 5, pp. 106–115, Sept 2012. [32] J. Zhao, G. Zhang, M. L. Scala, Z. Y. Dong, C. Chen, and J. Wang, “Short-term state forecasting-aided method for detection of smart grid general false data injection attacks,” IEEE Transactions on Smart Grid, vol. 8, no. 4, pp. 1580–1590, July 2017. [33] J. Gao, S. A. Vorobyov, H. Jiang, and H. V. Poor, “Worst-case jamming on mimo gaussian channels,” IEEE Transactions on Signal Processing, vol. 63, no. 21, pp. 5821–5836, Nov 2015. [34] S. Gezici, S. Bayram, M. N. Kurt, and M. R. Gholami, “Optimal jammer placement in wireless localization systems,” IEEE Transactions on Signal Processing, vol. 64, no. 17, pp. 4534–4549, Sept 2016. [35] S. M. Kay, Fundamentals of Statistical Signal Processing: Estimation Theory. Upper Saddle River, NJ, USA: Prentice-Hall, Inc., 1993. [36] R. E. Kalman, “A new approach to linear ﬁltering and prediction problems,” Transactions of the ASME–Journal of Basic Engineering, vol. 82, no. Series D, pp. 35–45, 1960. [37] H. V. Poor and O. Hadjiliadis, Quickest Detection. Cambridge University Press, 2008. [38] M. Basseville and I. V. Nikiforov, Detection of Abrupt Changes: Theory and Application. Upper Saddle River, NJ, USA: Prentice-Hall, Inc., 1993. [39] V. V. Veeravalli and T. Banerjee, “Chapter 6 - quickest change detection,” in Academic Press Library in Signal Processing: Volume 3 Array and Statistical Signal Processing, ser. Academic Press Library in Signal Processing, R. C. Abdelhak M. Zoubir, Mats Viberg and S. Theodoridis, Eds. Elsevier, 2014, vol. 3, pp. 209 – 255. [40] G. Lorden, “Procedures for reacting to a change in distribution,” Ann. Math. Statist., vol. 42, no. 6, pp. 1897–1908, 1971. [41] G. V. Moustakides, “Optimal stopping times for detecting changes in distributions,” Ann. Statist., vol. 14, no. 4, pp. 1379–1387, 1986. [42] ——, “Multiple optimality properties of the shewhart test,” Sequential Analysis, vol. 33, no. 3, pp. 318–344, 2014. [43] R. Zimmerman, C. Murillo-Sanchez, and R. Thomas, “Matpower: Steady-state operations, planning, and analysis tools for power systems research and education,” IEEE Transactions on Power Systems, vol. 26, no. 1, pp. 12–19, Feb 2011. [44] O. Alsac, N. Vempati, B. Stott, and A. Monticelli, “Generalized state estimation,” IEEE Transactions on power systems, vol. 13, no. 3, pp. 1069–1075, 1998.