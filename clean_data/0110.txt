1 Cyber-Physical Security and Safety of Autonomous Connected Vehicles: Optimal Control Meets Multi-Armed Bandit Learning Aidin Ferdowsi, Student Member, IEEE, Samad Ali, Student Member, IEEE, Walid Saad, Fellow, IEEE, and Narayan B. Mandayam, Fellow, IEEE Abstract Autonomous connected vehicles (ACVs) rely on intra-vehicle sensors such as camera and radar as well as inter-vehicle communication to operate effectively. This reliance on cyber components exposes ACVs to cyber and physical attacks in which an adversary can manipulate sensor readings and physically take control of an ACV. In this paper, a comprehensive framework is proposed to thwart cyber and physical attacks on ACV networks. First, an optimal safe controller for ACVs is derived to maximize the street trafﬁc ﬂow while minimizing the risk of accidents by optimizing ACV speed and inter-ACV spacing. It is proven that the proposed controller is robust to physical attacks which aim at making ACV systems instable. To improve the cyber-physical security of ACV systems, next, data injection attack (DIA) detection approaches are proposed to address cyber attacks on sensors and their physical impact on the ACV system. To comprehensively design the DIA detection approaches, ACV sensors are characterized in two subsets based on the availability of a-priori information about their data. For sensors having a prior information, a DIA detection approach is proposed and an optimal threshold level is derived for the difference between the actual and estimated values of sensors data which enables ACV to stay robust against cyber attacks. For sensors having no prior information, a novel multi-armed bandit (MAB) algorithm is proposed to enable ACV to securely control its motion. Collectively, the proposed DIA detection approaches minimize the vulnerability of ACV sensors against cyber attacks while maximizing the ACV system’s physical robustness. Simulation results show that the proposed optimal safe controller outperforms current state of the art controllers by maximizing the robustness of ACVs to physical attacks. The results also show that the proposed DIA detection approaches, compared to Kalman ﬁltering, can improve the security of ACV sensors against cyber attacks and ultimately improve the physical robustness of an ACV system. This research was supported by the U.S. National Science Foundation under Grants OAC-1541105 and IIS-1633363. Aidin Ferdowsi and Walid Saad are with Wireless@VT, Bradley Department of Electrical and Computer Engineering, Virginia Tech, Blacksburg, VA, USA, {aidin, walids}@vt.edu. Samad Ali is with Centre for Wireless Communications (CWC), University of Oulu, Finland, samad.ali@oulu.fi. Narayan B. Mandayam is with WINLAB, Dept. of ECE, Rutgers University, New Brunswick, NJ, USA, narayan@winlab.rutgers.edu arXiv:1812.05298v1 [cs.SY] 13 Dec 2018 2 I. INTRODUCTION Intelligent transportation systems (ITS) will encompass autonomous connected vehicles (ACVs), roadside smart sensors (RSSs), vehicular communications, and even drones [1]–[4]. To operate autonomously in future ITS, ACVs must process a large volume of data collected via sensors and communication links. Maintaining reliability of this data is crucial for road safety and smooth trafﬁc ﬂow [5]–[8]. However, this reliance on communications and data processing renders ACVs highly susceptible to cyber-physical attacks. In particular, an attacker can possibly interject the ACV data processing stage, inject faulty data, and ultimately induce accidents or compromise the road trafﬁc ﬂow [9]. As demonstrated in a real-world experiment on a Jeep Cherokee in [10], ACVs are largely vulnerable to cyber attacks that can control their critical systems, including braking and acceleration. Naturally, by taking control of ACVs, an adversary can not only impact the compromised ACV, but it can also reduce the ﬂow of other vehicles and cause a non-optimal ITS operation. This, in turn, motivates a holistic study for joint cyber and physical impacts of attacks on ACV systems. Recently, a number of security solutions have been proposed for addressing intra-vehicle network and vehicular communication cyber security problems [11]–[19]. In [11], the authors showed that long-range wireless attacks on the current security protocols of ACVs can disrupt their controller area network (CAN). Furthermore, the work in [12], proposed a data analytics approach for the intrusion detection problem by applying a hidden Markov model. In [13], the security vulnerabilities of current vehicular communication architectures are identiﬁed. The work in [14] proposed the use of multi-source ﬁlters to secure a vehicular network against data injection attacks (DIAs). Furthermore, the authors in [15] introduced a new framework to improve the trustworthiness of beacons by combining two physical measurements (angle of arrival and Doppler effect) from received wireless signals. In [16], the authors designed a multi-antenna technique for improving the physical layer security of vehicular millimeter-wave communications. Moreover, in [17], the authors proposed a collaborative control strategy for vehicular platooning to address spooﬁng and denial of service attacks. The work in [18] developed a deep learning algorithm for authenticating sensor signals. Finally, an overview of current research on advanced intra-vehicle networks and the smart components of ITS is presented in [19]. In addition to cyber security in ITSs, physical safety and optimal control of ACVs have been 3 studied in [20]–[26]. In [20], the authors identiﬁed the key vulnerabilities of a vehicle’s controller and secured them using intrusion detection algorithms. The work in [21] analyzed the ACVs as cyber-physical systems and developed an optimal controller for their motion. The authors in [22] studied the safe operation of ACV networks in presence of an adversary that tries to estimate the dynamics of ACVs by its own observations. The authors in [23] proposed centralized and decentralized safe cruise control approaches for ACV platoons. A learning-based approach is proposed in [24] to control the velocity of ACVs. Furthermore, in [25], the authors have proposed a robust deep reinforcement learning (RL) algorithm which mitigates cyber attacks on ACV sensors and maintains the safety of ACV system. In [26], the authors studied the essence of secure and safe codesign for ACV systems. However, despite their importance, the architecture and solutions in [11]–[26] do not take into account the interdependence between the cyber and physical layers of ACVs while designing their security solutions. Moreover, the prior art in [11]–[26], does not provide solutions that can enhance the robustness of ACV motion control to malicious attacks. Nevertheless, designing an optimal and safe ITS requires robustness to attacks on intra-vehicle sensors as well as inter- vehicle communication. In addition, these existing works do not properly model the attacker’s action space and goal (physical disruption in ITS) while providing their security solutions. In this context, the cyber-physical interdependence of the attacker’s actions and goals will help providing better security solutions. Finally, the existing literature lacks a fundamental analysis of physical attacks as in the Jeep hijacking scenario [10] in which the attacker aims at disrupting the ITS operation by causing non-optimality in a compromised ACV’s speed. The main contribution of this paper is, thus, a comprehensive study of joint cyber-physical security challenges and solutions in ACV networks which can be summarized as follows: • To address both safety and optimality of an ACV system, ﬁrst an optimal safe controller is proposed so as to maximize the trafﬁc ﬂow and minimize the risk of accidents by optimizing the speed and spacing of ACVs. To the best of our knowledge, this work will be the ﬁrst to analyze the physical attack on a ACV network and to prove that the proposed controller can maximize the stability and robustness of ACV systems against physical attacks such as in the Jeep hijacking scenario [10]. • To improve the cyber-physical security study of ACV systems, next, new DIA detection approaches are proposed to address cyber attacks on ACV sensors and to analyze the physical impact of DIAs on an ACV system. To efﬁciently design the DIA detection 4 approaches, ACV sensors are characterized in two subsets based on the availability of a priori information about their readings. • For the ﬁrst subset of sensors which have a priori information, a DIA detection approach is proposed derive an optimal threshold level for sensor errors which enables ACV to detect DIAs. For the second subset of sensors that lack a priori information, a novel multi-armed bandit (MAB) algorithm is proposed to learn which sensors are attacked. The proposed MAB algorithm uses the so-called Mahalanobis distance between the sensor data and an a-posteriori prediction to calculate a regret value and optimize the ACV’s sensor fusion process by applying an upper conﬁdence bound (UCB) algorithm. The proposed detection approaches maximize both the cyber security and physical robustness of ACV systems against DIAs. Simulation results show that the proposed optimal safe controller has higher safety, optimality, and robustness against physical attacks compared to other state-of-the-art approaches. In addition, our results show that the proposed DIA detection approaches yield an improved performance compared to Kalman ﬁltering in mitigating the cyber attacks. Therefore, the proposed solutions improve the stability of ACV networks against DIAs. The rest of the paper is organized as follows. Section II introduces our system model while Section III derives the optimal safe controller. Section IV proves that the proposed optimal safe controller is robust against physical attacks. Section V proposes approaches to mitigate cyber attacks on ACV while reducing the risk of accidents. Finally, simulation results are shown in Section VI and conclusions are drawn in Section VII. II. SYSTEM MODEL A. ACV Physical Model Consider an ACV, f, that follows a leading ACV, l and tries to maintain a spacing from ACV l as shown in Fig. 1. Maintaining a spacing between ACVs is important to maximize the trafﬁc ﬂow and minimize the risk of accidents [9]. Let vf be ACV f’s speed in m/s. Then, ACV f’s speed deviation can be written as ˙vf(t) = Ff(t) mf ≜uf(t), where Ff(t) is f’s engine force in Newtons (N), mf is f’s mass in kilograms (kg), and uf(t) is f’s physical controller input in N/kg . Moreover, letting vl be l’s speed, the spacing d(t) between f and l can be written as ˙d(t) = vl(t) −vf(t). Note that this model can be easily generalized to multiple ACVs by repeating the same set of equations for every pair of ACVs to capture any ACV network as 5 Roadside sensor V2V V2I Leading vehicle with speed Spacing  sensors measuring  sensors measuring  sensors measuring Vulnerable to cyber attacks Vulnerable to physical attacks Under study vehicle with speed Camera & LiDAR Radar Fig. 1: Illustration of the considered ACV system model. shown in Fig. 1. Due to discrete time sensor readings in ACVs, we convert the aforementioned continuous system model to a discrete one using a linear transformation as follows [27]: vf(t + 1) = vf(t) + Tuf(t), d(t + 1) = d(t) + Tvl(t) −Tvf(t), (1) where T is the sampling period of the sensors in seconds. The model can be summarized as: x(t + 1) = Ax(t) + Buf(t) + F vl(t), (2) where x(t)=   vf(t) d(t)  , A=   1 0 −T 1  , B=   T 0  , F =   0 T  . (3) To validate the practicality of the proposed system model, we need to show that uf(t) can control the speed and spacing of f , i.e., uf can take state vector x(t0) to any desired state x(t1). The following remark shows that uf can control system (2). Remark 1. If T > 0, then the system in (2) is controllable. To illustrate the reason, we know that the system (2) is controllable if the rank of controllability matrix C = h B AB i is 2 (number of state variables) [27]. Thus, we have: C=   T 0   1 0 −T 1  .  T 0    =   T T 0 −T 2  . (4) Therefore, for any T > 0 the columns of C are linearly independent which implies that the rank of C will be 2. B. ACV cyber model In order to navigate, as shown in Fig. 1, ACV f relies on nf, nl, and nd sensors which measure vf(t), d(t), and vl(t), respectively. For instance, multiple intra-vehicle inertial measurement units 6 (IMUs) measure vf(t), multiple cameras, radars, and LiDAR can measure d(t), and roadside sensors and ACV l measure vl(t) and transmit the measurements to ACV f using vehicle-to- vehicle (V2V) and vehicle-to-infrastructure (V2I) communication links. Thus, we model the sensor readings as follows: zf(t) = hfvf(t) + ef(t), zl(t) = hlvl(t) + el(t), zd(t) = hdd(t) + ed(t), (5) where zf(t), zl(t), and zd(t) are sensor vectors with nf, nl, and nd elements which measure vf(t), vl(t), and d(t), respectively. Also, hf, hl, and hd are vectors with nf, nl, and nd elements equal to 1. Moreover as assumed in [27] and [28], ef(t), el(t), and ed(t) are noise vectors that follow a white Gaussian distribution with zero mean and variance vectors σ2 f = h σ2 f1, . . . , σ2 fnf iT , σ2 l = h σ2 l1, . . . , σ2 lnl iT , and σ2 d = h σ2 d1, . . . , σ2 dnd iT . Since the sensor readings in (5) are noisy, we need to optimally estimate vf(t), vl(t) and d(t) from zf(t), zl(t), and zd(t) by minimizing the estimation error. To ﬁnd the optimal estimations ˆvf(t), ˆvl(t), and ˆd(t) (the estimations of vf(t), vl(t), and d(t)), we use two types of estimators. A static estimator to estimate the variables at the initial state, t0, (the time step that f starts following l) and a dynamic estimator to estimate ˆvf(t) and ˆd(t) using the state equations in (1). We use a static estimator at the initial state because ACV f does not follow the speed of ACV l using (1) before t0 and, hence, a dynamic estimator cannot be used due to lack of information about the dynamics of f before t0. Moreover, for ˆvl(t), we always use a static estimator since we do not have any information on the dynamics of vl(t). For the static estimator, we deﬁne a least-square (LS) cost function for each variable as follows: Jf(ˆvf(t)) = 1 2 ∞ X t=0 (zf(t) −hf ˆvf(t))T R−1 f (zf(t) −hf ˆvf(t)) , (6) Jl(ˆvd(t)) = 1 2 ∞ X t=0 (zl(t) −hlˆvl(t))T R−1 l (zl(t) −hlˆvl(t)) , (7) Jd( ˆd(t)) = 1 2 ∞ X t=0  zd(t) −hd ˆd(t) T R−1 d  zd(t) −hf ˆd(t)  , (8) where Rf, Rl, and Rd are the measurement covariance matrices associated with sensors measure vf(t), vl(t), and d(t), respectively. Moreover, since the sensors independently measuring the three variables, they will not have any noise covariance and Rf, Rl, and Rd will be diagonal. Therefore, explicit solution for the optimal estimation can be derived as: ˆvf(t)=  hT f R−1 f hf −1 hT f R−1 f zf(t) = nf X i=1 1 σ2 fi Pnf i=1 1 σ2 fi | {z } wfi zfi(t) = vf(t) + nf X i=1 wfiefi(t), (9) 7 ˆvl(t)=  hT l R−1 l hl −1 hT l R−1 l zl(t) = nl X i=1 1 σ2 li Pnl i=1 1 σ2 li | {z } wli zli(t) = vl(t) + nl X i=1 wlieli(t), (10) ˆd(t)=  hT d R−1 d hd −1 hT d R−1 f zd(t) = nd X i=1 1 σ2 di Pnd i=1 1 σ2 di | {z } wdi zdi(t) = d(t) + nd X i=1 wdiedi(t). (11) For the dynamic estimator, we use a Kalman ﬁlter which uses the state equation in the estimation process. To this end, we deﬁne an output equation as follows: z(t) = Hx(t)+e(t), s.t. H =   hf 0nf×1 0nd×1 hd  , z(t) =  zf(t) zd(t)  , e(t) =  ef(t) ed(t)  . (12) Note that we cannot apply the dynamic estimator on ˆvl(t) since we do not have a-priori information about the dynamics of l. To dynamically estimate ˆd(t) and ˆvf(t), we use an a priori estimation derived from the state equations as well as a weighted residual of output error to correct the a priori estimation as follows [29]: ˆx(t) |{z} estimation = ˆx(−)(t) | {z } a priori estimation + K(t) residual z }| { h z(t) −H ˆx(−)(t) i | {z } correction , (13) where K(t) is the Kalman gain. By deﬁning an a posteriori error covariance matrix P (t) = E  r(t)rT(t)  , where r(t) = x(t) −ˆx(t), we can ﬁnd a K(t) to minimize trace [P (t)] = E  rT(t)r(t)  . The solution for such K(t) can be given by [29]: ˆx(−)(t) = Aˆx(t −1) + Buf(t −1) + F ˆvl(t −1), (14) P (−)(t) ≜AP (t −1)AT , (15) K(t) = P (−)(t)HT h HP (−)(t)HT + R i−1 , (16) ˆx(t) = [I −K(t)H] ˆx(−)(t) + K(t)z(t), (17) P (t) = [I −K(t)H] P (−)(t). (18) where R =   Rf 0nf ×nd 0nd×nf Rd  is a block diagonal matrix. As can be seen from (15), (16), and (18), the update processes for P (t) and K(t) are independent of the states and controller. Thus, P (t) and K(t) will converge to constant matrices, ˜P and ˜K. For the studied system, we now deﬁne the cyber-physical security problems for ACV systems that we will study next. We will address three main problems: 1) What is the optimal safe ACV controller for the system in (2) that minimizes the risk of accidents while maximizing the trafﬁc ﬂow on the roads? 2) Is the proposed optimal safe controller for ACV systems robust 8 and stable against physical attacks? and 3) How to securely fuse the sensor readings to mitigate DIAs on ACVs and minimize the impact of such attacks on the control of ACVs? Addressing these problems is particularly important because the model in (2) identiﬁes the microscopic characteristics of an ACV network and, thus, to achieve large-scale security and safety in ACV networks we must secure every ACV against cyber-physical attacks. Addressing these three problem requires a comprehensive study of the interdependencies between the cyber and physical characteristics of ACV systems. Such interdependent cyber- physical study helps to ﬁnd the vulnerabilities of the ACV systems against both cyber and physical attacks. Thus, we can derive an optimal controller that minimizes the risk of accidents and we can design cyber attack detection approaches that not only take into account the cyber characteristics of the ACV system, but also aims at minimizing the likelihood of collisions in ACV networks. Unlike the works in [11]–[19], we consider the physical characteristics of ACV systems while developing DIA detection approaches. Moreover, the combined optimal and safe ACV controller design has not been studied previously in [20]–[26]. III. OPTIMAL SAFE ACV CONTROLLER Our ﬁrst task is thus to derive an optimal safe controller for ACV systems. To analyze ACV f’s optimal control input uf(t), we deﬁne an optimal safe spacing value as o(vf(t)) ≜ v2 f(t) 2bfT , where bf is ACV f’s maximum braking deceleration. This value is deﬁned so as to guarantee that if the leading ACV l stops suddenly, the following ACV f will stop completely before hitting ACV l as long as f starts braking immediately after observing l’s braking process. This can be captured by the following energy equivalence condition: mf 2 (v2 f(t) −0) | {z } Kinetic Energy = mfbfd(t) | {z } Potential Energy ⇒o(vf(t)) = v2 f(t) 2bf . (19) Our goal here is to maintain an optimal safe spacing between ACVs f and l. Thus, we deﬁne a physical regret R(t) as the square of difference between the optimal safe spacing and the actual spacing. This regret quantiﬁes the safety and optimality of ACV motion by preventing any collisions and minimizing the spacing between the ACVs and can be written as follows: R(t) = (o(vf(t + 1)) −d(t + 1))2 = v2 f(t + 1) 2bf −d(t + 1) 2 = (vf(t) + Tuf(t))2 2bf −d(t) −Tvl(t) + Tvf(t) 2 (20) 9 In addition, each ACV only have access to estimation of vf(t), vl(t), and d(t). Thus, ACV f must design an input uf(t) to minimize an estimation of physical regret which is deﬁned as follows: ˆR(t) = (ˆvf(t) + Tuf(t))2 2bf −ˆd(t) −T ˆvl(t) + T ˆvf(t) 2 . (21) This problem is challenging to solve because ˆvl(t) is an independent parameter and ACV f cannot be sure about the future values of ˆvl(t). To solve this problem, we consider two scenarios: a) ACV f has no prediction about ACV l’s future speed values (One-step ahead controller) and b) ACV f has a predictor which can predict ACV l’s future speed value for N time steps (N-step ahead controller)(such predictors have attracted recent attention in the transportation literature, e.g., see [30] and [31]). Next, we propose an optimal controller for these two cases. A. One-step ahead controller To solve the one-step ahead controller problem, we consider some physical limitations on the speed and the control input. We prohibit the speed from being greater than the free-ﬂow speed of a road, ˜v. Moreover, due to the physical capabilities of the vehicle and for maintaining passengers’ comfort, we must have a limitation on the control input and speed deviation. Thus, the optimization problem of the ACV f can be written as follows: u∗ f(t) = arg min uf(t) ˆR(t) (22) s.t. umin f ≤uf(t) ≤umax f , (23) 0 ≤vf(t + 1) ≤˜v, (24) |uf(t) −uf(t −1)| ≤∆u, (25) where umin f < 0 and umax f > 0 are the minimum and maximum allowable control input and ∆u is the maximum allowable change in the controller to yield a comfortable ride. Theorem 1. The one-step ahead optimal controller is: u∗ f(t) = min ( max ( u1(t), 1 T r 2bf  ˆd(t) + T ˆvl(t) −T ˆvf(t)  −ˆvf(t) !) , u1(t) ) (26) where u1(t) ≜max n −ˆvf(t) T ,umin f ,uf(t −1)−∆u o and u1(t) ≜min n ˜v−ˆvf(t) T , umax f , uf(t−1)+∆u o . Proof. See Appendix A. ■ 10 Theorem 1 derives the optimal controller for the ACV f when it only optimizes its action for the next step without considering future actions. In the next subsection, we derive the ACV f’s optimal controller when it considers minimizing the regret for N step ahead. B. N-step ahead controller To ﬁnd the N-step ahead controller, ﬁrst we deﬁne a discount factor 0 ≤γ ≤1 which speciﬁes the level of future physical regret for the decision taken at each time step. Thus, by deﬁning the N-step ahead total discounted physical regret R(t, N) ≜Pt+N−1 τ=t γτ−t ˆR(τ), the controller optimization problem can be written as follows: u∗ f(t) = [1, 0, . . . , 0 | {z } N−1 ] ( arg min uN f (t) R(t, N) ) , (27) where the conditions in (23), (24), and (25) hold true. Moreover uN f (t) = [uf(t), . . . , uf(t + N −1)]T, N is the number of future steps which is taken into account in ﬁnding the optimal controller, and u∗ f(t) is the optimal controller at time step t. Theorem 2. The solution of N-step ahead controller is equivalent to the one-step ahead con- troller. Proof. To solve the problem in (27), we use a so called indirect method. To this end, we start by deﬁning an augmented physical regret using the following state equation: R′(t, N) = R(t, N) + t+N−1 X τ=t λT(τ + 1)  Aˆx(τ) + Buf(τ) + F vl(τ) | {z } g(τ) −ˆx(τ + 1)   = t+N−1 X τ=t h γτ−t ˆR(τ) + λT(τ + 1) [g(τ) −ˆx(τ + 1)] i , (28) where λ(τ) = [λ1(τ), λ2(τ)]T. Then, let Hamiltonian function deﬁned as H(τ) ≜γτ−t ˆR(τ) + λT(τ + 1)g(τ). Thus, we can write (28) as follows: R′(t, N) = λT(t + N)ˆx(t + N) | {z } terminal time + H(t) |{z} initial time + t+N−1 X τ=t+1  H(τ) −λT(τ)ˆx(τ)  | {z } running time . (29) Thus, to ﬁnd critical points (candidate minima) we must solve ∇R′(t, N) = 0. First, we start by ﬁnding the differential dR′(t, N) and then we identify the derivatives as follows: dR′(t, N) = λT(t + N)dˆx(t + N) +  ∇ˆx(t)H(t) T dˆx(t) + t+N−1 X τ=t+1  ∇x(τ)H(τ) −λ(τ) T dˆx(τ) 11 + t+N−1 X τ=t  ∇u(τ)H(τ) T du(τ) + t+N X τ=t+1  ∇λ(τ)H(τ −1) −ˆx(τ) T dλ(τ). (30) Thus, to have dR′(t) = 0 each of the terms in brackets must be equal to zero: λ(t + N) = 0, (31) ∇ˆx(t)H(t) = 0, ⇒ˆx(t) = h ˆvf(t), ˆd(t) iT , (32) λ(τ) = ∇ˆx(τ)H(τ) = ∇ˆx(τ)γt−τ ˆR(τ) + ∇ˆx(τ)g(τ)λ(t + 1), ∀τ = t + 1, . . . , t + N −1, (33) 0 = ∇u(τ)H(τ) = ∇u(τ)γt−τ ˆR(τ) + ∇u(τ)g(τ)λ(t + 1), ∀τ = t, . . . , t + N −1, (34) ∇λ(τ+1)H(τ) = ˆx(τ + 1) ⇒ˆx(τ + 1) = g(τ), ∀τ = t, . . . , t + N −1. (35) Now, using (33) we will have: λ(τ) =   ˆvf(τ)+Tuf(τ) bf + T −1  γt−τ  (ˆvf(τ)+Tuf(τ))2 2bf −ˆd(τ) −T ˆvl(τ) + T ˆvf(τ)  + ATλ(τ + 1). (36) Moreover, from (34) we will have: 0 = γt−τ (ˆvf(τ) + Tuf(τ))2 2bf −ˆd(τ) −T ˆvl(τ) + T ˆvf(τ)  T(ˆvf(τ) + Tuf(τ)) bf + BTλ(τ + 1). (37) Since λ(t + N) = 0, then from (37), we derive: uf(t + N −1) = 1 T " ± r 2bf  ˆd(t+N −1)+T ˆvl(t + N −1)−T ˆvf(t + N −1)  −ˆvf(t + N −1) # . (38) By substituting uf(t+N −1) in (36), we obtain λ(t+N −1) = 0. This process can continue until τ = t where we obtain λ(t+1) = 0 and uf(t) = 1 T " ± r 2bf  ˆd(t) + T ˆvl(t) −T ˆvf(t)  −ˆvf(t) # . Moreover, considering the constraints (23), (24), and (25), we will end up having the optimal controller as deﬁned in Theorem 1. Thus, we prove that the N-step ahead optimal controller is equivalent to 1-step ahead optimal controller. ■ From Theorem 2, we can observe that, if the ACV f minimizes its immediate physical regret, it will also minimize its long-term physical regret. This result shows that the proposed optimal safe controller does not require any information from future dynamics of ACV l as done in [30] and [31]. 12 IV. PHYSICAL ATTACK ON ACV SYSTEMS As derived in the previous section, the proposed optimal controller is a function of ˆvl(t). This makes ACV f vulnerable against a physical attack on ACV l. Thus, we now analyze whether an attacker can cause instable dynamics at ACV f by controlling l. Consider an adversary who takes the control of ACV l and tries to cause instability in ACV f’s speed, vf(t), and spacing d(t). Using our derived optimal controller, by ensuring uf(t) is not saturated (u1(t) ≤uf(t) ≤u1(t)), and considering the estimated values to be close to the real values we will have: vf(t + 1) = q 2bf(d(t) + Tvl(t) −Tvf(t) | {z } g1(x(t),vl(t)) , d(t + 1) = d(t) + Tvl(t) −Tvf(t) | {z } g2(x(t),vl(t)) .              ⇒x(t + 1) = g(x(t), vl(t)), (39) where g = [g1(x(t), vl(t)), g2(x(t), vl(t))]T. (39) is designed such that ACV f will always maintain an optimal safe spacing with l. However, from (39) we can see that the behavior of the system is a function of vl. Thus, next, we will analyze the physical attack scenario that is analogous to the Jeep hijacking case in [10]. A. Stability Analysis To analyze the stability of (39), ﬁrst, we deﬁne some useful concepts. Deﬁnition 1. [28] ¯x(vl) is said to be an equilibrium point for the system in (39) and a constant input vl, if g(¯x(vl), vl) = ¯x(vl). An equilibrium indicates a point at which the states will not change. From Deﬁnition 1 we can derive the equilibrium point for (39) by considering a constant input vl and solving the following set of equations: ¯vf(vl) = q 2bf( ¯d(vl) + Tvl −T ¯vf(vl), ¯d(vl) = ¯d(vl) + Tvl −T ¯vf(vl), (40) which results in: ¯x(vl) = h vl, vl 2bf iT . The derived value for ¯x(vl) shows that in order to reach an equilibrium, ACV f must maintain the optimal safe spacing from ACV l and its speed must equal to vl. Thus, next, we show that our derived optimal controller is robust, i.e., under our controller if an adversary hijacks ACV l, it cannot cause instability in vf(t) and d(t). Deﬁnition 2. A system is called asymptotically stable around its equilibrium point if it satisﬁes the following two conditions [28]: 1) Given any vl > 0 and ε > 0, ∃δ1 > 0 such that if 13 |x(ts)−¯x(vl)|, then |x(t)−¯x(vl)| < ϵ, ∀t > ts and 2) ∃δ2 > 0 such that if |x(ts)−¯x(vl)| < δ2, then x(t) →¯x(vl) as t →∞. The ﬁrst condition requires the state trajectory to be conﬁned to an arbitrarily small “ball” centered at the equilibrium point and of radius ε, when released from an arbitrary initial condition in a ball of sufﬁciently small (but positive) radius δ1. This is called stability in the Lyapunov sense [28], [32]. It is possible to have Lyapunov stability without having asymptotic stability. Next, we show how a Lyapunov function can help to analyze the stability of system (39) [28]. From [28], we know that if there exists a Lyapunov function for system (39), then x(t) = ¯x(vl) is a stable equilibrium point in the sense of Lyapunov. In addition, if L(g(x(t), vl))−L(x(t)) < 0 then x(t) = ¯x(vl) is an asymptotically stable equilibrium point. We can prove that the system in (39) is asymptotically stable for the equilibrium point ¯x(vl), as follows. Proposition 1. x(t) = ¯x(vl) is a stable equilibrium point in the Lyapunov sense. Proof. Let L(x(t)) =  v2 f(t) 2bf −d(t) 2 . Then we will have L(¯x(vl)) = 0. Moreover, we can show that L(x(t)) ≥0, ∀x(t). Now, to check if L is a Lyapunov function we have: L(g(x(t), vl)) −L(x(t)) = 1 2bf q 2bf(d(t) + Tvl −Tvf(t) 2 −d(t) + Tvl −Tvf(t) !2 − v2 f(t) 2bf −d(t) 2 = − v2 f(t) 2bf −d(t) 2 ≤0. (41) Thus, x(t) = ¯x(vl) is a stable equilibrium point in the sense of Lyapunov. ■ From Proposition 1, we can see that, as long as f follows l using our proposed controller, its speed and spacing from l will stay stable and will not be affected by the physical attack on l. This shows that, not only our proposed controller maximizes the safety and optimality in ITS roads, but also it is robust to physical attacks such as in the Jeep scenario [10]. However, as can be seen from Theorems 1 and 2, even though it is robust to physical attacks, the derived optimal controller is largely dependent on the estimated values ˆvf(t), ˆvl(t), and ˆd. Thus, an adversary can manipulate the sensor data to inject error in the estimation and ultimately increase the ACV f’s physical regret. Analyzing such attacks require a cyber-physical study of the ACV system to derive approaches that mitigate attacks on sensors and minimize the effect of such attacks on the physical regret. Thus, next, we analyze the cyber attack on the ACV system. 14 V. CYBER ATTACK ON ACV SYSTEMS We now consider a cyber attacker that injects faulty data to sensor readings (cameras, LiDARs, radars, IMUs, and roadside sensors) such that the attacked sensor vector can be written as:   ¯z(t) ≜  ¯zf(t) ¯zd(t)   ¯zl(t)  ≜   zf(t) zd(t) zl(t)  +   af(t) ≜[af1, . . . , afnf ]T ad(t) ≜[ad1, . . . , adnd]T al(t) ≜[al1, . . . , alnl]T  , (42) where af(t), ad(t), and al(t) are data injection vectors on sensors and ¯zf(t), ¯zd(t), and ¯zl(t) are compromised sensor readings from vf(t), d(t), and vl(t), respectively. As we discussed in the state estimation section, we have a-priory information about sensors which measure vf(t) or d(t), but such information is lacking for sensors that collect data from vl(t). Thus, next, we consider cyber attacks on sensors a) with a-priori information and b) without a-priori information. A. Attack on sensors with a-priori information As discussed in Subsection II-B, we use Kalman ﬁltering to estimate ˆvf(t) and ˆd(t). However, Kalman ﬁltering is not robust to DIAs [33]. Thus, we propose a ﬁltering mechanism that can limit the effect of the DIA on ˆvf(t) or ˆd(t). To this end, we use the a priori estimation ˆx(−)(t) at each time step to ﬁnd an a priori sensor reading z(−)(t) ≜H ˆx(−)(t). Then, the attack detection ﬁlter checks the absolute value of the residual |µ(t)| ≜ " |µf1(t)|, . . . , |µfnf (t)|, |µd1(t)|, . . . , |µdnd(t)| #T ≜ z(t) −z(−)(t) < η, where η is the threshold vector. Any sensor which violates this inequality will be considered as a compromised sensor and will not be involved in Kalman ﬁlter update procedure. To ﬁnd an optimal value for the threshold η, we next characterize the stochastic behavior of residual µ(t) when the ACV is not under attack. Theorem 3. The residual µ(t) follows a Gaussian distribution with zero mean and covariance matrix as follows: Cµ = HCrHT + R −R ˜K TQTHT −HQ ˜KR, (43) and Cr is the solution of following discrete Ricatti equation Cr = QACrATQT + Cρ, where Cρ = QF σ2 l F TQT + Q ˜KR ˜K TQT, and Q =  I + h I −˜KH i−1 ˜KH −1 . Proof. See Appendix B. ■ Theorem 3 derives the distribution of µ(t) which we will use next to ﬁnd an optimal value for the threshold level η. Fig. 2 and Fig. 3 show a comparison between simulation and analytical 15 0 1 5 2 4 6 1010 8 0 10-3 10 10-3 0 12 -5 -1 2 0 0.05 0 -0.05 1 2 3 105 4 10-3 5 0 6 -2 Fig. 2: Analytical and simulation result for cumulative density function of ρ(t) and r(t). 1 0 2 1 3 1 2 4 3 2 5 4 3 5 6 6 7 7 8 8 1 2 3 4 5 6 7 8 -0.07 -0.06 -0.05 -0.04 -0.03 -0.02 -0.01 0 0.01 Fig. 3: Analytical and simulation result for the mean and variance of µ(t). results derived for the mean and covariance matrix of r(t), ρ(t), and µ(t). From Figs. 2 and 3 we can that the analytical results match the simulation results which validates Theorem 3. We can now ﬁnd the probability with which µi(t) (element i of µ(t)) remains below the threshold value ηi as Pr (|µi| ≤ηi) = Pr (−ηi ≤µi ≤ηi) = Φµi(ηi) −Φµi(−ηi), where Φµi(.) is the cumulative density function of µi which follows a Gaussian distribution with zero mean and variance Cµ(i, i) (element in i-th row and i-th column of Cµ). Thus, we can derive the optimal value for eta by deﬁning Pr (|µi| ≤ηi) for every sensor. For instance, choosing values ηi = Cµ(i, i), 2Cµ(i, i), or 3Cµ(i, i) will result in Pr (|µi| ≤ηi) = 0.68, 0.95, or 0.997. Even by deﬁning the threshold value, the attacker might stay stealthy in some cases if it controls the amount of injected data to the sensors. Next, we ﬁnd a relationship between the maximum value of DIA and the probability of staying stealthy. Proposition 2. The probability with which an attack vector ˜a ≜[af, ad]T will not trigger the i-th element of attack detection ﬁlter, µi, (stealthy attack) will be given by: pi(˜a) ≜Pr (|µi| ≤ηi|˜a) = Φµi(Ψ i˜a + ηi) −Φµi(Ψ i˜a −ηi), (44) 16 where Ψ i is the i-th row of Ψ = h I −H [I −QA]−1 Q ˜K i . Proof. Suppose that the attacker initiates attack after the Kalman ﬁlter converges. Thus, from (14) and (17) we have: ˆx(t) = h I −˜KH i ˆx(−)(t) + ˜K z(t) |{z} [Hx(t)+e(t)] + ˜K  af ad   | {z } ˜a = h I −˜KH i h Aˆx(t −1) + Buf(t −1) + F ˆvl(t −1) i + ˜KH [ˆx(t) + r(t)] + ˜K [e(t) + ˜a] . (45) Thus, by simpliﬁcations analogous to the proof of Theorem 3, we can ﬁnd r(t) = QAr(t−1)− Q ˜K˜a+ρ(t). The expectation of r(t) will be E {r(t)} = QA E {r(t −1)}−Q ˜K E {˜a} . Since the attack vector is constant, ˜a, and E {r(t)} = E {r(t −1)} for t →∞we will have the steady state expected estimation error as E {r(t)} ≜¯r = −[I −QA]−1 Q ˜K˜a. Thus, considering such steady state expected estimation error, ¯r, we can derive the mean of µ(t): E {µ(t)} = E  z(t) −z(−)(t) = E {Hr(t) + ˜a + e(t)} = h I −H [I −QA]−1 Q ˜K i | {z } Ψ ˜a. Since ad is constant, then σµ will not change. Therefore, we can ﬁnd the probability of not triggering the attack detection ﬁlter for µi as in (44). ■ Proposition 2 derives the probability of staying stealthy for any particular DIA vector. Next we will ﬁnd how much our deﬁned attack detection ﬁlter is robust against a particular DIA. To this end, ﬁrst we deﬁne a stealthy attack probability vector as p(˜a) =  p1(˜a), . . . , pnf+nd(˜a) T, which is a vector that shows the probability of staying stealthy by initiating ˜a on all of the vf and d type sensors. The attacker has to ﬁnd the optimal value of ˜a which maximizes the physical regret while staying stealthy with probability below a deﬁned value, p, i.e., attack vector must be chosen such that the physical regret is maximized and every sensor i stays stealthy with the probability below the i-th element of p. Corollary 1. The attacker’s optimal attack vector a∗which maximizes the steady state physical regret by attacking vf or d type sensors is the solution of following optimization problem: arg max ˜a ˜θ2 ≜ ¯rTΘ¯r + cT ¯r 2 , (46) s.t. ¯r = −[I −QA]−1 Q ˜K˜a, (47) 17 Θ ≜   1 2bf 0 0 0  , c =   √ ˜d bf + T −1  , (48) p(˜a) ≥p, (49) where ˜d is the average spacing between the ACVs. Proof. From the deﬁnition of physical regret we have: R(t) u∗ f(t) =  vf(t) + Tu∗ f(t) 2 2bf −d(t) −Tvl(t) + Tvf(t) !2 (50) =         r2 f(t) 2bf + rf(t) bf s ˆd(t) + T ˆvl(t) −T ˆvf(t) | {z } ≃˜d −rd(t) −Trl(t) + Trf(t) | {z } θ(t)         2 , Moreover, the steady state value of θ(t) can be derived by using the steady state expected value of ¯r as ¯θ = ¯rTΘ¯r + cT ¯r. Also, the attacker must choose ad to satisfy (44). Thus, the attacker must solve the optimization problems in (46). ■ Corollary 1 derives a robustness level for our proposed attack detection ﬁlter. It allows us to ﬁnd the maximum regret which is caused by any stealthy attack vector. This allows us to design a secure cyber-physical ACV system since we take into account the physical regret of DIAs on sensors. However, the proposed attack detection ﬁlter works for sensors with a-priori information only. For ACV f’s other sensors which measure vl(t) we do not have a-priori information. Thus, we next address this case using MAB. B. Multi-armed bandit learning for attack detection in sensors without a-priori information To detect the attack on vl type sensors, we cannot use any a priori estimation for vl(t) as done for vf and d type sensors because ACV f cannot have any information about evaluation of vl(t) since it does not know how ACV l is being controlled. Such lack of a priori information makes the attack detection challenging. To overcome this challenge, we propose to use a MAB learning approach because such approach does not require a-priori information and ﬁnds the optimal action (detecting attacked sensors) only by interacting with the sensors and ACV’s dynamics. Before applying the MAB algorithm, we deﬁne an a posteriori estimation for vl(t): v(+) l (t) = ˆd(t + 1) −ˆd(t) T + ˆvf(t). (51) 18 Here, we also deﬁne an a posteriori residual as µ(+) l (t) ≜ h |µ(+) l1 (t)|, . . . , |µ(+) lnl (t)| iT ≜ hlv(+) l (t)− zl(t) . Next, we analyze the distribution of µ(+) l (t) to use it to design an attack detection ﬁlter. Theorem 4. µ(+) l (t) follows a Gaussian distribution with zero mean and covariance matrix Cµl: Cµl = Υ RlΥ T + hlJ h HACrATHT −R ˜K TQTATHT −HAQ ˜KR + R i J ThT l , (52) where Υ =  −s1 T hlwT l −I  and J = h 0 1 i ˜K. Proof. See Appendix C. ■ Theorem 4 derives the covariance matrix for µ(+) l (t) which we will use to detect anomaly in the vl(t) type sensors. To this end, ﬁrst, we deﬁne the squared Mahalanobis (SM) distance, a measure which quantiﬁes the distance between the a posteriori residual of sensors in a subset L of vl type sensors, µ(+) l (t, L), and the distribution of a posteriori residuals which is derived in Theorem 4. SM will help us ﬁnd how much every subset L deviates from its distribution. Deﬁnition 3. The squared Mahalanobis distance between subset L’s a posteriori residual at time t and its distribution is deﬁned as DL(t) = µ(+) l T(t, L)C−1 µl (L)µ(+) l (t, L), where DL(t) is the subset L’s SM and Cµl(L) is the covariance matrix associated with L. Next, we derive the expected value and variance of DL(t). We know from [34, (378)] that E {DL(t)} = E n µ(+) l T(t, L)C−1 µl (L)µ(+) l (t, L) o = Tr  C−1 µl (L)Cµl(L)  = Tr (I) = |L|, where |L| is the number of sensors in L. In addition, for a subset L of vl type sensors and an attack vector al(t), we will have: E {DL(t)} = E n µ(+) l T(t, L)C−1 µl (L)µ(+) l (t, L) + aT l (t)C−1 µl al(t) o (53) = |L| + E  aT l (t, L)C−1 µl (L)al(t, L) , where al(t, L) consists of only elements of al(t) which are in L. Since Cµ(L) is positive semi deﬁnite then C−1 µ (L) is also positive semi deﬁnite. Thus, we will have E n aT l (t, L)C−1 µl (L)al(t, L) o ≥0. Therefore, if there exists a subset L such that E {DL(t)} ≥|L|, then there is at least one sensor under attack in L. Hence, at each time step, to estimate ˆvl(t), ACV f must choose a subset L which has the least divergence from |L|. To capture the security level of a subset, we deﬁne a security divergence (SD) metric for a subset L as ςL(t) ≜E{DL(t)} |L| ≥1. Therefore, a subset L with a lower ςL(t) value has a higher security level. Moreover, any subset L of vl type sensors have a cost based on the estimation error induced 19 to ˆvl(t). Thus, we deﬁne the cost of L, as νL = E  (vl(t) −ˆvl(t, L))2 , where ˆvl(t, L) is the estimation of vl using the subset L. Thus, to ﬁnd νL we have: E{(vl(t)−ˆvl(t,L))2}=E n ( P i∈L wlieli) 2o =E         P i∈L 1 σ2 li eli P i∈L 1 σ2 li    2     = P i∈L 1 σ4 li E ( el2 i )  P i∈L 1 σ2 li   2 = P i∈L 1 σ2 li  P i∈L 1 σ2 li   2 = 1 P i∈L 1 σ2 li . Therefore, we have νL = 1 P i∈L 1 σ2 li . Clearly, a subset L with a higher P i∈L 1 σ2 li has a lower cost. While DL represents a security measure for a subset L, νL can be considered as an estimation performance metric. Thus, at each time step, ACV f must choose a subset L which has the minimum SD as well as the minimum cost. Thus, we have to ﬁnd the secure high performance subset L∗(t) which is a subset that is secure and has the lowest estimation cost. To this end, a minimization problem that ﬁnds the secure high performance subset can be deﬁned as L∗(t) = arg minL ξL(t), where, ξL(t) = νLςL(t). Although νL is known for f, ςL(t) might change due to an attack on vl type sensors. Thus, we propose an MAB learning algorithm which learns the secure high performance subset L∗(t) [35], [36]. Our goal here is to choose a safe subset of sensors out of all available sensors by efﬁciently exploring different subsets and effectively exploiting the optimal subset, thus, we can apply an MAB framework to solve our problem. In an MAB problem, a decision maker (ACV f), pulls an arm from a set of available arms (selects a subset L from vl type sensors). Each arm generates a cost after being played, based on a distribution that is not known to the decision maker. The aim of ACV f is to minimize a cumulative cyber regret. This regret is deﬁned as the difference between the reward of the best possible arm at each step, and the generated reward of the arm that is played [35]–[37]. Let ξ∗(t) = ξL∗(t)(t) be the lowest cost that could be achieved at time t from vl type sensors. Thus, the cyber regret from t = t0 up to a time t = te is deﬁned as: Rc(t0, te) ≜E " te X t=t0 ξL(t) − te X t=t0 ξ∗(t) # , (54) where the expectation is taken over the random choices of the L. Cyber regret implies choosing non-optimal and non-secure subset of sensors. Thus, having a high cyber regret implies choosing a subset of sensors with higher error and possibly higher injected data which can lead to an estimation error for ˆvl(t). Since our proposed optimal controller which minimizes the physical regret is a function of estimated value, ˆvl(t), thus, higher cyber regret results in a higher estimation error and can introduce physical regret to ACV f. This clearly shows the cyber- physical aspects of ACV security. One of the most recognized methods for the MAB problem is to use the concept of UCB 20 [35]. In this method, the MAB algorithm at each time t chooses L such that: I(t) = arg max L −νL |L| 1 nL nL X i=1 DL(tL,i) + r 2 ln t nL (55) where nL is the number of times that arm L was played before and tL,i is the time step when L is selected for i-th time. Also, note that nL →∞, 1 nL PnL i=1 DL(tL,i) →E {DL(t)} [35], [36]. The UCB algorithm has an expected cumulative regret of: E {Rc(t0, te)} = 8 X L|ξL<ξ∗ ln(te −t0 + 1) E [ξL] −E [ξ∗] +  1 + π2 3  X L|ξL<ξ∗ E [ξL] −E [ξ∗] . (56) We use UCB algorithm because it has a logarithmic cyber regret and has been shown that there exists no algorithm that can have a better cyber regret [36]. Thus, using the UCB algorithm and the deﬁned cyber regret we can address the DIA detection problem for sensors which lack a priori information. VI. SIMULATION RESULTS AND ANALYSIS For our simulations, we assume that ACV l has a sinusoidal speed pattern and ACV f’s initial speed and spacing from the ACV l are vf(0) = 90 km/h and d(0) = 100 m. We set nf = nd = nl = 4, T = 0.1 s, bf = 2.5 m/s2, and umax f = −umin f = 0.25 N/kg, which are chosen based on practical ACV characteristics [13]. A. Optimal Safe Controller Fig. 4a shows an ACV which uses the proposed optimal controller. From Fig. 4a, we make three observations: 1) The physical regret converges to zero and the actual spacing converges to the optimal safe spacing after approximately 20 seconds which shows that the proposed controller works properly, 2) The speed of ACV f, vf(t), exhibits, approximately, a 5 seconds delay compared to the ACV l’s speed vehicle vl(t). This is because ACV f should ﬁrst observe ACV l and then control its own speed, and 3) The estimated states match with the actual state values which shows that applied state estimation estimation processes have an error close to zero. Fig. 4b shows a comparison between our proposed controller with Gipps [38] and the intelli- gent driver model (IDM) [39] controllers, two of the well-known controllers for ACV leading- following scenarios. From Fig. 4b, we can observe three key points: 1) Our proposed controller can follow the speed of ACV l better compared to IDM as we can see that IDM converges to an almost constant speed while our proposed controller can track vl(t), 2) The proposed controller converges to the optimal safe spacing. However, the IDM model has a positive offset from the optimal safe spacing and the Gipps controller always has a smaller spacing than the 21 70 75 80 85 90 -0.2 -0.1 0 0.1 0.2 60 80 100 120 140 0 20 40 60 80 100 120 140 160 180 0 500 1000 1500 (a) The proposed controller, physical regret, speed and spacing. 65 70 75 80 85 90 0 50 100 150 0 20 40 60 80 100 120 140 160 180 200 0 2 4 6 107 150 160 170 180 190 200 0 50 100 (b) Comparison of proposed controller, Gipps, and IDM. Fig. 4: The proposed optimal controller’s effect on the physical regret. optimal safe spacing. This shows that the Gipps model does not take into consideration the safety as we can see from Fig. 4b that the spacing can admit small values close to 0 meters which increases the risk of collision. On the other hand, the IDM model does not consider the optimality of trafﬁc ﬂow as it always yields a higher spacing than the optimal spacing, and 3) The cumulative physical regret for our proposed optimal safe controller outperforms the other two models thus demonstrating that the proposed controller can jointly yield optimality and safety in ACV systems. B. Robustness Against Physical Attacks Next, we simulate an attacker which takes control of ACV l and after 100 seconds suddenly drops the speed of ACV l from 75 km/h to 5 km/h. Fig. 5 shows the effect of this attack on the ACV f’s speed, spacing and physical regret. Fig. 5 shows that our proposed controller always maintains the optimal safe spacing even in presence of an attack. In contrast, the Gipps and IDM controllers always have an offset from the optimal safe spacing. Hence, our proposed controller is more robust against physical attacks. Note that, although Gipps can track the speed faster than our proposed method, however, it does not optimize the spacing. In addition, we can see from Fig. 5 that the proposed controller has a physical regret closed to zero while the cumulative regret of IDM and Gipps grow linearly since they have a constant offset from the optimal safe spacing in this attack scenario. 22 20 40 60 80 test test test test test test test test 0 50 100 150 0 20 40 60 80 100 120 140 160 180 200 0 1 2 3 107 test 150 160 170 180 190 200 0 50 100 150 160 170 180 190 200 2 4 6 8 Fig. 5: A comparison of the proposed controller, Gipps, and IDM when ACV system is physical attacked. C. Cyber Security of ACV Systems To illustrate the effectiveness of our proposed attack detection approaches, in Fig. 6, we analyze the impact of DIA on physical regret and estimation errors. Fig. 6a shows the relationship between the stealthy attack probability and maximum DIA when we apply our proposed attack detection ﬁlter on the sensors with a priori information. Fig 6a shows that as the stealthy attack probability increases the domain of the attack reduces. Moreover the DIA has higher value for the sensors with higher noise variance. To stay stealthy with higher probability, the attacker must reduce the domain of its injected faulty data to the sensors. In addition, Figs. 6b, 6c, and 6d show how the physical regret and steady state errors are affected by the probability of staying stealthy. From these ﬁgures, we can see that as the stealthy attack probability increases the regret and the absolute value of steady state errors decrease because the attacker’s maximum DIA decreases. Fig. 7 shows the estimation error after applying our proposed attack detection ﬁlter on sensors with apriori estimation. From Fig. 7, we can see that, while the attack on vf(t) type sensor does not affect signiﬁcantly the estimation, an attack on a d(t) type sensor can cause an estimation error on ˆd(t). In addition, Fig. 7 shows that the designed attack detection mechanism for sensors with a priori information mitigates DIAs and keeps the estimation error close to zero. Fig. 8 shows how the increase on the number of under attack vl type sensors affects the cyber regret. In this simulation, we use the same settings as for Fig. 4. From Fig. 8, we can ﬁrst observe that irrespective of the number of under attack sensors, the attack can be detected in under 4 seconds as the cyber regret goes to zero after 4 second which is acceptable for this scenario as in 4 seconds ACV f travels for 80 meters while the optimal safe spacing is also 80 23 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 0 0.5 1 1.5 2 2.5 3 (a) Attack detection ﬁlter applied on the cyber attacks on ˆvf(t) and ˆd(t). 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 2 4 6 8 10 12 14 16 18 10-3 (b) Attack detection ﬁlter applied on the cyber attacks on ˆvf(t) and ˆd(t). 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 -2 -1.5 -1 -0.5 0 0.5 1 1.5 10-8 (c) Attack detection ﬁlter applied on the cyber attacks on ˆvf(t) and ˆd(t). 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 -0.15 -0.1 -0.05 0 0.05 0.1 0.15 (d) Attack detection ﬁlter applied on the cyber attacks on ˆvf(t) and ˆd(t). Fig. 6: Attack detection ﬁlter applied on the cyber attacks on ˆvf(t) and ˆd(t). -2 0 2 4 6 8 -2 -1 0 1 2 3 0 20 40 60 80 100 120 140 160 180 0 1 2 3 0 20 40 60 80 100 120 140 160 180 Fig. 7: Attack detection ﬁlter applied on the cyber attacks on ˆvf(t) and ˆd(t). meters, thus, there will be no collision even if ACV l stops suddenly , while ACV f’s sensors are attacked. Moreover, the growth rate of cyber regret for the three attacks is approximately equal regardless of the number of attacked sensors. Furthermore, Fig. 8 shows that, as the number of attacked sensors increases, the cumulative cyber regret increases faster thus the attack can be detected earlier. This shows that having access to more sensors is not essentially beneﬁcial for the attacker and thus, the attacker must also optimize its set of attacked sensors to stay stealthy for a longer time. Fig. 9 shows how the domain of attack can affect the cyber regret. We can see from Fig. 9 that, as the domain of injected data to the vl type sensor increases, the MAB algorithm can chooses the optimal subset more efﬁciently. This means that injecting higher values to the sensor increases the chance of detectability and thus, reduces the impact of the attack on the sensors. In addition, we can see that the cumulative cyber regret for the highest DIA (2.5 m/s data injection) 24 0 50 100 150 200 250 300 350 400 450 500 0 5 10 15 20 25 0 50 100 150 200 250 300 350 400 450 500 0 20 40 60 80 100 120 140 160 0 5 10 -5 0 5 10 15 20 25 30 Fig. 8: The cyber regret in MAB algorithm applied to vl type sensors. 0 50 100 150 200 250 300 350 400 450 500 0 10 20 30 40 50 60 70 80 90 100 0 50 100 150 200 250 300 350 400 450 500 0 500 1000 1500 2000 2500 3000 3500 4000 4500 5000 Fig. 9: The best subset selection in MAB algorithm applied to vl type sensors. is greater than other cases, at the beginning of the simulation. However, after almost 350 seconds, the cumulative cyber regret of the highest DIA becomes the least compared to the other DIAs. This is due to the fact that a larger DIA leads to a higher cyber regret at the beginning of the attack which leads the MAB algorithm to detect it earlier than other DIA cases. Fig. 10 shows a scenario in which the attacker attacks only the third sensor when nl = 4. Note that, b4b3b2b1 shows the state of the sensors such that for i = 1, . . . , 4 if bi = 1 then sensor i is under attack and otherwise, it is not. Obviously, when the attacker attacks the third sensor, the ACV must only rely on the other sensors. The b4b3b2b1 on the x-axis indicates the chosen subset by the MAB algorithm to use for estimation. Fig. 10 shows that using the MAB algorithm, percentage of the times that subset {1011} is chosen by MAB is higher than other cases, which means that the MAB algorithm can detect the attack on the vl type sensors. Finally, to show that our proposed DIA detection approaches can reduce the physical regret signiﬁcantly, in Fig. 11, we consider that the attacker attacks only one sensor of each type with the lowest noise error variance (most valuable sensor) after 1000 seconds (after ensuring that Kalman ﬁlter converged). Then, we compare the cumulative physical regret of the ACV 25 0001 0010 0011 0100 0101 0110 0111 1000 1001 1010 1011 1100 1101 1110 1111 0 10 20 30 40 50 60 70 80 Fig. 10: Attack detection with MAB algorithm applied to vl type sensors. 950 1000 1050 1100 0 0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 (a) DIA on vf(t) type. 950 1000 1050 1100 0 20 40 60 80 100 120 140 160 180 (b) DIA on d(t) type. 950 1000 1050 1100 0 1 2 3 4 5 6 7 8 105 (c) DIA on vl(t) type. Fig. 11: Comparison of the proposed DIA detection approaches with Kalman ﬁltering. system for a case in which the ACV only uses a Kalman ﬁlter for estimation and another case in which the ACV applies both of our proposed DIA detection ﬁlters. Moreover, in this attack, we consider that the attacker increases the sensor readings by a factor of 50%. As can be seen from Fig. 11, the proposed attack detection ﬁlter has lower physical regret compared to a simple Kalman ﬁltering. We can see that while the physical regret increases linearly for Kalman ﬁlter, our proposed DIA detection approach keeps the physical regret close to zero. This shows that, our proposed DIA detection approach can successfully detect the attack, mitigate it, and keep the ACV system safe and secure, however the Kalman ﬁlter fails to stay robust against the DIA. VII. CONCLUSION In this paper, we have comprehensively studied the cyber-physical security and safety of ACV systems. We have proposed an optimal safe controller that maximizes the trafﬁc ﬂow and minimizes the risk of accidents on the roads by optimizing the speed and spacing of ACVs. In addition, the proposed optimal safe controller maximizes the stability of ACV systems and improves their robustness against physical attacks. Moreover, we have improved cyber- physical security of ACV systems by proposing two novel DIA detection approaches. The ﬁrst approach detects DIAs using a priori information about the sensors. In the second approach, 26 we have proposed an MAB algorithm to learn secure subset of sensors when there exists no a priori information about sensors. Simulation results have shown that the proposed optimal safe controller yields better stability and robustness compared to current state of the art controllers. In addition, the DIA detection approaches improve the security of the sensors and robustness of the ACV system compared to Kalman ﬁltering. APPENDIX A. Proof of Theorem 1 First, using (1) and (24) we can ﬁnd that: max −vf(t) T ,umin f ,uf(t −1) −∆u  ≤uf(t) ≤min ˜v −vf(t) T , umax f , uf(t −1) + ∆u  , (57) and since ACV f only has an estimation of vf(t), then we can rewrite (57) as follows: max −ˆvf(t) T , umin f , uf(t −1) −∆u  | {z } u1(t) ≤uf(t) ≤min ˜v −ˆvf(t) T , umax f , uf(t −1) + ∆u  | {z } u1(t) . (58) Now, we can deﬁne Lagrangian multipliers and apply the Karush Kuhn Tucker (KKT) conditions to solve the optimization problem in (22). Then, we will have: g(uf(t), λ1, λ2) = (ˆvf(t) + Tuf(t))2 2bf −ˆd(t) −T ˆvl(t) + T ˆvf(t) 2 + λ1(uf(t) −u1(t) + λ2(u1(t) −uf(t)), (59) with the ﬁrst order necessary conditions given by: ∂g ∂uf = 0, ∂g ∂λ1 = 0, and ∂g ∂λ2 = 0. When λ1 and λ2 are not active (λ1 = 0 and λ2 = 0), we will have: ∂g ∂uf = 4T 2bf (ˆvf(t) + Tuf(t))2 2bf −ˆd(t) −T ˆvl(t) + T ˆvf(t)  (ˆvf(t) + Tuf(t)) = 0 ⇒u∗ f(t) = 1 T ± r 2bf  ˆd(t) + T ˆvl(t) −T ˆvf(t)  −ˆvf(t) ! , −1 T ˆvf(t). (60) However, 1 T  − r 2bf  ˆd(t) + T ˆvl(t) −T ˆvf(t)  −ˆvf(t)  and −1 T ˆvf(t) are not acceptable solu- tions since they result in vf(t + 1) ≤0. The next step is to show that the third solution in (60) is the global minimum. Thus, we apply the second-order condition on ˆR(t) as follows: d2 ˆR(t) du2 f(t) = 4T 2bf T(ˆvf(t) + Tuf(t))2 bf  + T (ˆvf(t) + Tuf(t))2 2bf −ˆd(t) −T ˆvl(t) + T ˆvf(t)  d2 ˆR(t) du2 f(t) u∗ f(t) = 4T 2bf T(ˆvf(t) + Tu∗ f(t))2 bf  > 0. (61) Thus, u∗ f(t) = 1 T r 2bf  ˆd(t) + T ˆvl(t) −T ˆvf(t)  −ˆvf(t)  is a global maximizer of ˆR(t). Now, to consider the constraints in (57), if we activate λ1 or λ2 the ﬁrst order condition will 27 result in having u∗ f(t) = u1(t) or u1(t). Therefore, the optimal 1-step ahead controller can be given by (26). B. Proof of Theorem 3 We know that the Kalman gain converges to ˜K. Thus, from (14) and (17) we can ﬁnd the state estimation ˆx(t) as a process which depends on estimation error r(t) as follows: ˆx(t) = h I −˜KH i ˆx(−)(t) + ˜K z(t) |{z} [Hx(t)+e(t)] = h I −˜KH i [Aˆx(t −1) + Buf(t −1) + F ˆvl(t −1)] + ˜KH [ˆx(t) + r(t)] + ˜Ke(t), ⇒ h I −˜KH i ˆx(t) = h I −˜KH i [Aˆx(t −1) + Buf(t −1) + F ˆvl(t −1)] + ˜K [Hr(t) + e(t)] , ⇒ˆx(t) = Aˆx(t −1)+Buf(t −1)+F ˆvl(t −1)+ h I −˜KH i−1 ˜K[Hr(t)+e(t)]. (62) Now, by subtracting (62) from the system model deﬁned in (2), we will have: r(t) = Ar(t −1) + F rl(t) − h I −˜KH i−1 ˜K [Hr(t) + e(t)] , r(t) =  I + h I −˜KH i−1 ˜KH −1 | {z } Q Ar(t −1) +  I + h I −˜KH i−1 ˜KH −1h F rl(t) −˜Ke(t) i | {z } ρ(t) Moreover, we can see that ρ(t) is a linear combination of independent white Gaussian process with zero mean. To ﬁnd the covariance matrix Cρ of ρ(t) we will have: Cρ = E  ρ(t)ρT(t) = E nh QF rl(t) −Q ˜Ke(t) i h rT l (t)F TQT −eT(t) ˜K TQTio = E n QF rl(t)rT l (t)F TQT −Q ˜K e(t)rT l (t) | {z } 0 F TQT −QF rl(t)eT(t) | {z } 0 ˜K TQT + Q ˜Ke(t)eT(t) ˜K TQTo = QF σ2 l F TQT + Q ˜KR ˜K TQT. (63) Note that the fact that e(t) and rl(t) are independent leads to having e(t)rT l (t) = 0 . Next, we write the dynamic model for the estimation error as follows: r(t) = QAr(t −1) + ρ(t) = [QA]t−t0 r(tc) + t−t0−1 X k=0 [QA]t−t0−k−1 ρ(tc + k), (64) where t0 is the time step where the Kalman ﬁlter converges. Thus, for t ≫t0 and if QA is asymptotically stable then we will have r(t) as a Gaussian process due to the central limit theorem. Now, to ﬁnd the mean of r(t) we can write: E {r(t)} = QA E {r(t −1)} + E {ρ(t)} = QA E {r(t)} , ⇒E {r(t)} = 0. (65) 28 Next, since the mean is zero, then the covariance matrix of r(t), Cr = E{r(t)rT(t)}. To ﬁnd Cr, we have: E  r(t)rT (t) = E n [QAr(t −1) + ρ(t)] h r(t −1)AT QT + ρT (t) io = E n QAr(t −1)rT (t −1)AT QT + QA r(t −1)ρT (t) | {z } 0 + ρ(t)rT (t −1) | {z } 0 AT QT + ρ(t)ρT (t) o . Note that since r(t −1) and ρ(t) are independent ρ(t)rT(t −1) = 0. In addition, we know that after convergence we will have E  r(t)rT(t) = E  r(t −1)rT(t −1) = Cr then, we will need to solve the following discrete Ricatti equation Cr = QACrATQT + Cρ. Now, the ﬁnal step is to ﬁnd the covariance matrix of the residual Cµ. Since after Kalman ﬁlter convergence we will have ˆx(−)(t) = ˆx(t) then: z(t) −z(−)(t) = Hx(t) + e(t) −Hx(−)(t) = Hx(t) + e(t) −H ˆx(t) = Hr(t) + e(t). (66) Thus, we will have: E  µ(t)µT(t) = E  [Hr(t) + e(t)]  rT(t)HT + eT(t)  = E  Hr(t)rT(t)HT + e(t)rT(t)HT + Hr(t)eT(t) + e(t)eT(t) = HCrHT + R + E  e(t)rT(t)HT + Hr(t)eT(t) . (67) Now, we have: E n e(t)rT (t)HT o = E      e(t)rT (t −1) | {z } 0 AT QT HT + e(t)  rl(t) | {z } 0 F T −eT (t) ˜K T  QT HT      = −R ˜K T QT HT , E  Hr(t)eT (t) = E      HQA r(t −1)eT (t) | {z } 0 +HQ  −˜Ke(t) +F rl(t)  eT (t) | {z } 0      = −HQ ˜KR. Thus, the covariance matrix can be given by (43). C. Proof of Theorem 4 From (17), after Kalman ﬁlter convergence we obtain: ˆx(t + 1) = h I −˜KH i x(−)(t) + ˜K [Hx(t + 1) + e(t)] = h I −˜KH i [Aˆx(t) + Buf(t) + F ˆvl(t)] + ˜K [H [Ax(t) + Buf(t) + F vl(t)] + e(t)] =Aˆx(t) + Buf(t) + h I −˜KH i F ˆvl(t) + ˜KHF vl(t) + ˜K [HAr(t) + e(t)] . (68) Due to the deﬁnition ofF = h 0 T iT , h I −˜KH i F and ˜KHF are vectors with two elements where the ﬁrst elements are zero. We deﬁne two parameters s1 and s2 as h I −˜KH i F =  0 s1   and ˜KHF =  0 s2  , and we will have s1 + s2 = T. Then using (51) and (68) the a posteriori 29 estimation will be v(+) l (t) = s1 T ˆvl(t) + s2 T vl(t) + h 0 1 i ˜K | {z } J [HAr(t) + e(t)] .Thus, we will have: µ(+) l (t) = hlv(+) l (t) −hlvl(t) −el(t) = hl hs1 T (ˆvl(t) −vl(t)) i −el(t) + hlJ [HAr(t) + e(t)] = −hl " s1 T nl X i=1 wlieli # −el(t) | {z } Υ el(t) +hlJ [HAr(t) + e(t)] . (69) First, we derive the mean of a posteriori residual: E n µ(+) l (t) o = −hl " s1 T nl X i=1 wli E {eli} # −E {el(t)} + hlJ [HA E {r(t)} + E {e(t)}] = 0. (70) Since the mean is zero the covariance matrix of µ(+) l (t), Cµl, can be derived as follows: Cµl = E n µ(+) l (t)µ(+) l T(t) o = E ( [Υ el(t) + hlJ [HAr(t) + e(t)]] ×  eT l (t)Υ T +  rT(t)ATHT + eT(t)  J ThT l  ) = E ( Υ el(t)eT l (t)Υ T + Υ el(t)  rT(t)ATHT + eT(t)  | {z } 0 +hlJ [HAr(t) + e(t)] eT l (t) | {z } 0 Υ T +hlJ  HAr(t)rT(t)ATHT + e(t)rT(t)ATHT + HAr(t)eT(t) + e(t)eT(t)  J ThT l ) =Υ RlΥ T + hlJ h HACrATHT −R ˜K TQTATHT −HAQ ˜KR + R i J ThT l . (71) REFERENCES [1] A. Ferdowsi, U. Challita, and W. Saad, “Deep learning for reliable mobile edge analytics in intelligent transportation systems,” IEEE Vehicular Technology Magazine, Accepted and to Appear, 2018. [2] M. Mozaffari, W. Saad, M. Bennis, and M. Debbah, “Unmanned aerial vehicle with underlaid device-to-device communi- cations: Performance and tradeoffs,” IEEE Transactions on Wireless Communications, vol. 15, no. 6, pp. 3949–3963, June 2016. [3] T. Zeng, O. Semiari, W. Saad, and M. Bennis, “Joint communication and control for wireless autonomous vehicular platoon systems,” arXiv preprint arXiv:1804.05290, 2018. [4] U. Challita, A. Ferdowsi, M. Chen, and W. Saad, “Artiﬁcial intelligence for wireless connectivity and security of cellular- connected UAVs,” IEEE Wireless Communications Magazine, Accepted and to Appear, 2018. [5] M. Amoozadeh, A. Raghuramu, C. n. Chuah, D. Ghosal, H. M. Zhang, J. Rowe, and K. Levitt, “Security vulnerabilities of connected vehicle streams and their impact on cooperative driving,” IEEE Communications Magazine, vol. 53, no. 6, pp. 126–132, June 2015. [6] I. Parvez, A. Rahmati, I. Guvenc, A. I. Sarwat, and H. Dai, “A survey on low latency towards 5g: Ran, core network and caching solutions,” IEEE Communications Surveys Tutorials, pp. 1–1, May 2018. [7] M. Hus´ak, N. Neshenko, M. Safaei Pour, E. Bou-Harb, and P. ˇCeleda, “Assessing internet-wide cyber situational awareness of critical sectors,” in Proceedings of the 13th International Conference on Availability, Reliability and Security. Hamburg, Germany: ACM, August 2018, pp. 29:1–29:6. [8] A. Ferdowsi, W. Saad, B. Maham, and N. B. Mandayam, “A Colonel Blotto game for interdependence-aware cyber-physical systems security in smart cities,” in Proceedings of the 2Nd International Workshop on Science of Smart City Operations and Platforms Engineering, ser. SCOPE ’17. New York, NY, USA: ACM, 2017, pp. 7–12. [9] F. Kargl, P. Papadimitratos, L. Buttyan, M. Mter, E. Schoch, B. Wiedersheim, T. V. Thong, G. Calandriello, A. Held, A. Kung, and J. P. Hubaux, “Secure vehicular communication systems: implementation, performance, and research challenges,” IEEE Communications Magazine, vol. 46, no. 11, pp. 110–118, November 2008. 30 [10] A. Greenberg. Hackers remotely kill a jeep on the highway. [Online]. Available: https://www.wired.com/2015/07/ hackers-remotely-kill-jeep-highway/ [11] S. Woo, H. J. Jo, and D. H. Lee, “A practical wireless attack on the connected car and security protocol for in-vehicle can,” IEEE Transactions on Intelligent Transportation Systems, vol. 16, no. 2, April 2015. [12] S. N. Narayanan, S. Mittal, and A. Joshi, “OBD securealert: An anomaly detection system for vehicles,” in Proc. of IEEE International Conference on Smart Computing (SMARTCOMP), May 2016, pp. 1–6. [13] G. Calandriello, P. Papadimitratos, J. P. Hubaux, and A. Lioy, “On the performance of secure vehicular communication systems,” IEEE Transactions on Dependable and Secure Computing, vol. 8, no. 6, pp. 898–912, Nov 2011. [14] T. Kim, A. Studer, R. Dubey, X. Zhang, A. Perrig, F. Bai, B. Bellur, and A. Iyer, “Vanet alert endorsement using multi- source ﬁlters,” in Proceedings of the Seventh ACM International Workshop on VehiculAr InterNETworking, Chicago, IL, USA, September 2010, pp. 51–60. [15] M. Sun, M. Li, and R. Gerdes, “A data trust framework for vanets enabling false data detection and secure vehicle tracking,” in Proc. of IEEE Conference on Communications and Network Security (CNS), Las Vegas, NV, USA, Oct 2017, pp. 1–9. [16] M. E. Eltayeb, J. Choi, T. Y. Al-Naffouri, and R. W. Heath, “Enhancing secrecy with multiantenna transmission in millimeter wave vehicular communication systems,” IEEE Transactions on Vehicular Technology, vol. 66, no. 9, pp. 8139–8151, Sept 2017. [17] A. Petrillo, A. Pescap, and S. Santini, “A collaborative approach for improving the security of vehicular scenarios: The case of platooning,” Computer Communications, vol. 122, pp. 59 – 75, 2018. [18] A. Ferdowsi and W. Saad, “Deep learning for signal authentication and security in massive Internet of Things systems,” IEEE Transactions on Communications, October 2018. [19] S. Tuohy, M. Glavin, C. Hughes, E. Jones, M. Trivedi, and L. Kilmartin, “Intra-vehicle networks: A review,” IEEE Transactions on Intelligent Transportation Systems, vol. 16, no. 2, pp. 534–545, April 2015. [20] P. Kleberger, T. Olovsson, and E. Jonsson, “Security aspects of the in-vehicle network in the connected car,” in Proc. of IEEE Intelligent Vehicles Symposium (IV), Baden-Baden, Germany, June 2011, pp. 528–533. [21] J. M. Bradley and E. M. Atkins, “Optimization and control of cyber-physical vehicle systems,” Sensors, vol. 15, no. 9, pp. 23 020–23 049, September 2015. [22] M. Xue, W. Wang, and S. Roy, “Security concepts for the dynamics of autonomous vehicle networks,” Automatica, vol. 50, no. 3, pp. 852 – 857, 2014. [23] S. Sadraddini, S. Sivaranjani, V. Gupta, and C. Belta, “Provably safe cruise control of vehicular platoons,” IEEE Control Systems Letters, vol. 1, no. 2, pp. 262–267, Oct 2017. [24] S. Lefvre, A. Carvalho, and F. Borrelli, “A learning-based framework for velocity control in autonomous driving,” IEEE Transactions on Automation Science and Engineering, vol. 13, no. 1, pp. 32–42, Jan 2016. [25] A. Ferdowsi, U. Challita, W. Saad, and N. B. Mandayam, “Robust deep reinforcement learning for security and safety in autonomous vehicle systems,” in Proc. of IEEE International Conference on Intelligent Transportation Systems, Maui, HI, November 2018. [26] E. Schoitsch, C. Schmittner, Z. Ma, and T. Gruber, “The need for safety and cyber-security co-engineering and standardization for highly automated automotive vehicles,” in Advanced Microsystems for Automotive Applications 2015, T. Schulze, B. M¨uller, and G. Meyer, Eds. Cham: Springer International Publishing, 2016, pp. 251–261. [27] R. L. Williams, D. A. Lawrence et al., Linear state-space control systems. John Wiley & Sons, 2007. [28] H. K. Khalil, Nonlinear systems. Upper Saddle River, NJ : Prentice-Hall, 2002. [29] T. Kailath, Linear systems. Prentice-Hall Englewood Cliffs, NJ, 1980, vol. 156. [30] Y. Tian and L. Pan, “Predicting short-term trafﬁc ﬂow by long short-term memory recurrent neural network,” in Proc. IEEE International Conference on Smart City/SocialCom/SustainCom (SmartCity), Dec 2015, pp. 153–158. [31] X. Ma, Z. Tao, Y. Wang, H. Yu, and Y. Wang, “Long short-term memory neural network for trafﬁc speed prediction using remote microwave sensor data,” Transportation Research Part C: Emerging Technologies, vol. 54, pp. 187 – 197, 2015. [32] A. Taleb Zadeh Kasgari and W. Saad, “Stochastic optimization and control framework for 5G network slicing with effective isolation,” in Proc. 52nd Annual Conference on Information Sciences and Systems (CISS) (CISS 2018), Princeton, NJ, USA, Mar. 2018. [33] Q. Yang, L. Chang, and W. Yu, “On false data injection attacks against Kalman ﬁltering in power system dynamic state estimation,” Security and Communication Networks, vol. 9, no. 9, pp. 833–849, August 2013. [34] K. B. Petersen and M. S. Pedersen, The Matrix Cookbook. Technical University of Denmark, 2012. [35] P. Auer, N. Cesa-Bianchi, and P. Fischer, “Finite-time analysis of the multiarmed bandit problem,” Machine Learning, vol. 47, no. 2, pp. 235–256, May 2002. [36] R. Kleinberg, A. Niculescu-Mizil, and Y. Sharma, “Regret bounds for sleeping experts and bandits,” Machine Learning, vol. 80, no. 2, pp. 245–272, Sep 2010. [37] S. Ali, A. Ferdowsi, W. Saad, N. Rajatheva, and J. Haapola, “Sleeping multi-armed bandit learning for fast uplink grant allocation in machine type communications,” arXiv preprint arXiv:1810.12983, 2018. [38] P. G. Gipps, “A behavioural car-following model for computer simulation,” Transportation Research Part B: Methodolog- ical, vol. 15, no. 2, pp. 105–111, 1981. [39] A. Kesting, M. Treiber, and D. Helbing, “Enhanced intelligent driver model to access the impact of driving strategies on trafﬁc capacity,” Philosophical Transactions of the Royal Society of London A: Mathematical, Physical and Engineering Sciences, vol. 368, no. 1928, pp. 4585–4605, 2010.