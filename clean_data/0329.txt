Let’s Talk Through Physics! Covert Cyber-Physical Data Exﬁltration on Air-Gapped Edge Devices Matthew Chan Rutgers University matthew.chan@rutgers.edu Nathaniel Snyder University of California, Los Angeles natsnyder1@g.ucla.edu Marcus Lucas University of California, Los Angeles maluc@g.ucla.edu Luis Garcia University of California, Los Angeles lgarcia@isi.edu Oleg Sokolsky University of Pennsylvania sokolsky@cis.upenn.edu James Weimer Vanderbilt University weimerj@seas.upenn.edu Insup Lee University of Pennsylvania lee@cis.upenn.edu Paulo Tabuada University of California, Los Angeles tabuada@ee.ucla.edu Saman Zonouz Georgia Institute of Technology saman.zonouz@gatech.edu Mani Srivastava University of California, Los Angeles mbs@ucla.edu Abstract— Although organizations are continuously making concerted efforts to harden their systems against network attacks by air-gapping critical systems, attackers continuously adapt and uncover covert channels to exﬁltrate data from air-gapped systems. For instance, attackers have demonstrated the feasibility of exﬁltrating data from a computer sitting in a Faraday cage by exﬁltrating data using magnetic ﬁelds. Although a large body of work has recently emerged highlighting various physical covert channels, these attacks have mostly targeted open-loop cyber- physical systems where the covert channels exist on physical channels that are not being monitored by the victim. Network architectures such as fog computing push sensitive data to cyber- physical edge devices–whose physical side channels are typically monitored via state estimation. In this paper, we formalize covert data exﬁltration that uses existing cyber-physical models and infrastructure of individual devices to exﬁltrate data in a stealthy manner, i.e., we propose a method to circumvent cyber-physical state estimation intrusion detection techniques while exﬁltrating sensitive data from the network. We propose a generalized model for encoding and decoding sensitive data within cyber-physical control loops. We evaluate our approach on a distributed IoT network that includes com- putation nodes residing on physical drones as well as on an industrial control system for the control of a robotic arm. Unlike prior works, we formalize the constraints of covert cyber-physical channel exﬁltration in the presence of a defender performing state estimation. Keywords—Cyber-physical systems, covert channel, side chan- nel, data exﬁltration I. INTRODUCTION The practice of air-gapping critical systems–i.e., physically isolating a computer from an unsecured network–provides assurances against standard network vulnerabilties and signif- icantly reduces the associated attack surface. These defenses typically only break down in the face of insider or physical attacks as in the Stuxnet malware [8]. However, recent attacks have overcome air-gap defenses to exﬁltrate data via covert channels that exploit device peripherals, including electro- magnetic emanations [20], [19], [21], magnetic ﬁelds [27], [18], power consumption [26], acoustic noise [24], [23], [35], [25], observable characteristics [16], [28], [17], and thermal emissions [22]. The countermeasures proposed for such attacks typically discuss procedural countermeasures such as secure practices in the work environment or technological approaches that attempt to conceal or shield the physical covert channels. Mitigating the physical covert channels is feasible for static scenarios, e.g., data centers for a distributed cloud computing architecture. However, distributed computation architectures such as fog computation have evolved to perform computation on much more dynamic and adaptive edge network devices. Edge devices in the wild that are sensing and actuating in the physical environment with distributed state estimation introduce physical covert channels that exhibit much more complexities than the aforementioned channels. There have been several driving factors that have pushed the cloud computation paradigm to distributed computing on the edge. In particular, the explosion of the internet of things (IoT) has called for an increased emphasis on the collateral attributes of distributed edge networks, e.g., mobility, wide- spread geographical location, low-latency, and heterogene- ity [6]. In parallel, recent works [38], [7] have shown the feasibility of driving computation to edge devices in an attempt to facilitate advancements that target these attributes. Yet as applications are driven further from cloud computing towards the edge, there exists a tradeoff in utility versus physical security guarantees. In particular, emerging scenarios that rely on deployable and/or mobile infrastructures such as emergency response necessitate a means of distributed edge computation on devices that are cyber-physically insecure. As opposed to cloud data centers, these low-level devices are physically ex- posed and may not be able to deploy any of the aforementioned procedural countermeasures while providing cyber-physical runtime guarantees. However, unlike the aforementioned covert channels, these cyber-physical systems are typically monitored via supervisory controller state estimation to ensure the sys- tem is behaving correctly. Therefore, an attacker’s encoding mechanism for data exﬁltration would need to be designed so as not to have the state estimator raise any ﬂags. Because arXiv:2210.07531v1 [cs.CR] 14 Oct 2022 fog architectures are running inferencing closer to or on the edge devices, an attacker may have access to higher-level information inferred from the data and, as such, has to encode less bits into an attack since more information can be encoded into each bit. For instance, a drone that is monitoring a group of soldiers may have an inference algorithm that detects how many soldiers are in its view. An attacker would only have to encode the number of soldiers into the data exﬁltration as opposed to sending the raw data. In this paper, we show how an edge device’s physical actuation can be used as a covert channel to exﬁltrate sensitive data. In particular, we introduce a cyber-physical encoding technique that maintains stealthiness against an entity who is monitoring the cyber-physical system via state estimation techniques. We begin by characterizing control system models for both an attacker and a defender in the same cyber- physical context. We empirically demonstrate how an attacker would maximize the rate of transmission while maintaining stealthiness with respect to the physical covert channel. This also implies that our approach maintains the utility of the cyber-physical application. For instance, to encode data into the actuation of a drone, our approach would encode data into the movement of the drone while ensuring that the drone completes its waypoint navigation correctly. This approach is analogous to prior attacks that focused on the semantic models of autonomous systems, e.g., cyber-physical attacks that target state-estimation techniques or adversarial machine learning techniques that target learned models. We evaluate our attack on two exemplary cyber-physical systems: a robotic arm in the context of an industrial control system as well as a drone surveilling an area of interest. For each system, we encode the data across a variety of applications and evaluate the efﬁcacy of each attack. We use computer vision techniques to observe the physical actuation and decode the encoded bits. We also evaluate each attack against defenders with varying levels of probabilistic certainty about the estimated system states, including a “perfect" de- fender that has access to the precise attacker model. We optimize our attacks against state-of-the-art state estimation techniques and show how we would maximize transmission rate for each case with respect to the state estimation noise. We further enumerate countermeasures that can be embedded into state estimation techniques as well as the associated control mechanisms. Our contributions are summarized as follows: • We characterize the state-of-the-art of cyber-physical data exﬁlration techniques (Section II and introduce a generalized cyber-physical covert channel attack model for data exﬁltration that is optimized against state estimation techniques to maximize the transmis- sion rate while maintaining stealthiness (Sections III and IV). • We evaluate our approach on a variety of applica- tions across two exemplary cyber-physical systems and show the efﬁcacy of such an attack (Section V). • We discuss future directions of such attacks and enu- merate countermeasures (Sections VI and VIII). The source code and datasets of our system are available online at: [repository]1 II. BACKGROUND In this section we provide a background on air-gapped covert data exﬁltration. We then discuss the recent advance- ments in edge computation that have driven sensitive data and applications to the edge. to establish a preliminary foundation for generalizing a system model and its associated threat model. A. Air-Gapped Covert Data Exﬁltration Currently, covert data exﬁltration works have shown how physical side channels may be enabled across different modal- ities for air-gapped systems such as electromagnetic radi- ation [20], [19], [21], magnetic ﬁelds [27], [18], power consumption [26], acoustic channel [9], [24], [25], optical ﬁeld [16], [28], [17], as well as thermal emissions [22]. In all cases, these systems typically propose a cyber-physical air-gapped covert channel followed by an associated coun- termeasure to prevent such channels from being exploited. Subsequent works will then continue this attacker-defender game where a new covert channel is proposed to attack the hardened system. For instance, to provide a defense against the aforementioned attacks where data was exﬁltrated via electro- magnetic radiation [20], [19], [21], technical countermeasures are proposed such as physical insulation and software-based reductions of information-bearing emissions. Subsequent at- tacks then proposed a means of circumventing the physical insulation of electromagnetic radiation by exﬁltrating via the magnetic ﬁeld emissions of the targeted device [27], [18]. The procedural and technical countermeasures presented the aforementioned attacks generally propose insulation of the physical channels in which data can be exﬁltrated that are subsequently exploited. For both attacks and defenses, these approaches fail to encapsulate the physical model of these channels that stem from the memory-mapped inputs and outputs of the system. Such physical models can be used to perform cyber-physical state estimation to understand what will be the physical impact of a particular action in the cyber space. Further, state estimation allows for providing an under- standing of the mutual dependency between physical channels, e.g., the correlation between a computer’s fan operation and the acoustic channel. From a defender’s perspective, state estima- tion not only enables the cyber-physical noise models that may need to be insulated, but also can perform intrusion detection if an attacker is explicitly encoding data into a particular channel that deviates from the estimated state of the channel. From an attacker’s perspective, state estimation techniques can be used to craft complex cyber-physical attacks on neglected physical channels. In both cases, the respective problems are exacerbated when moving from the static, immobile systems considered in these works–e.g., data center computers that are easier to physically insulate–to mobile and autonomous edge devices that are difﬁcult to physically insulate and expose even more cyber-physical channels. In this paper, we aim to formalize the notion of securing all physical covert channels, 1The source code and datasets will be available after the paper is published to respect the double-blind policy. 2 particularly in the context of mobile and autonomous edge devices. B. Computation on Autonomous Edge Devices Although edge and fog computation can be alluded to interchangeably [34], we refer to edge computation as the enabling technologies that perform data processing on devices that reside a single “hop" away from sensors and actuators, i.e., directly interfacing with sensors and actuators. This implies that the edge devices will need to perform local processing of data in addition to maintaining any cyber-physical functions. The need for such edge computation stems from several factors, including the bottleneck and insecurity of networking, the inefﬁciency of cloud computation for real-time systems, as well as the fact that edge devices now produce data instead of just consuming data [34]. With the increasing demand for such frameworks, the industry has been quick to provide IoT edge services that excel in different domains. Platforms such as Microsoft Azure IoT Edge [15], AWS IoT Greegrass [32], and Watson IoT [2] have enabled previous cloud services to be migrated to the edge devices in collaboration with cloud services. Google IoT Edge [1] has similarly enabled and facilitated machine learning on the edge. GE Predix [3] has enabled distributed edge services for Industrial IoT (IIoT) applications. The increasing ubiquity of such technologies has spilled into privacy-sensitive edge applications that call for increased security and privacy measures. Privacy-sensitive edge applications. Prior works have shown that computation on the edge can signiﬁcantly reduce the latency for invasive applications such as facial recognition [39] or cognitive assistance [30]. Such local processing reduces security and privacy concerns for sensitive contexts such as emergency response scenarios where IoT devices may provide supportive services for humans [36], as shown in Figure 1. However, enabling such inference abstractions on the edge now exposes the higher level logic that can be inferred from the raw data that is being processed. In distributed cloud computation models, the raw data (e.g., an image) was sent over the network to be processed on the cloud. Exﬁltrating raw data through physical side channels is more challenging as each bit represents a very small fraction of the larger signal. However, raised abstractions and inference applications enable more information to be encoded into each bit that is exﬁltrated. We now characterize the models and assumptions for physical covert channels from both an attacker’s perspective as well as a defender of the system. III. MODELS AND ASSUMPTIONS In this section we will provide a precise system model considered in this paper for physical covert channels. We then deﬁne the threat model along with the adversarial assumptions. In particular, we categorize the different attack scenarios that arise in this context. A. System Model The system model we consider in this paper is depicted in Figure 2, where the visible IoT/CPS Edge device is monitoring a sensitive application in the context of an edge computation system model as depicted in Figure 1. A supervisory controller is monitoring the system state of the edge device and sending high-level control commands accordingly, e.g., an air trafﬁc controller sending a coordinate setpoint for a drone. The supervisory controller is also using the state information to ensure that the system state is consistent with previously sent control commands, e.g., a drone’s previous state has been updated according to the physical dynamics. We assume that the edge device has local control loops that convert the high-level commands from the supervisory controller to local actuation with respect to its internally maintained state estimation, e.g., a drone’s stability and waypoint navigation control loops. Finally, we assume that there may be one or more humans in the same vicinity that can observe the physical characteristics of the device from a distance. The notion of a human’s perception is an analog to a human’s perception with respect to distortion models in the context of adversarial machine learning [33]. We now discuss the threat model with respect to this system model. B. Threat model The threat model has two components: the compromised edge device that is encoding sensitive information into physical actuation, and an adversarial observer that is decoding the encoded actuation. Compromised software model. We assume that an attacker has compromised the edge device in such a way in which the attacker has full control of one or more physical actuators of the device. We also assume that the attacker has access to the physical dynamics of the edge device such that an attacker can model the state estimator along with an estimated noise model for the device. Such assumptions have been in used in prior cyber-physical state estimation attacks as these models can be practically obtained [11]. However, unlike previous cyber- physical system attacks, we do not assume that the attacker can report false system states to the supervisory controller as the mechanism that reports the sensed system state may be located on a different chip than the exploited software module, e.g., an attacker who has compromised the GPIO microcontroller may not be able to compromise the reported values of a separate GPS chip that is reporting the location. Enhanced adversarial observer model. For our enhanced adversarial observer, we simply assume that an adversary may be able to “zoom" in on the edge device to observe ﬁne- grained observable physical characteristics that would not be observable to a normal human observer. To formalize the adversary model, we place both the attacker and the defender in a control systems context. C. A Control Systems Summarization We formalize a control-theoretic, systems-oriented model of our proposed attacker and defender models. This systems- view summarizes the aforementioned attack vectors and elab- orates on how an attacker/defender would begin to model the physical variables and their cyber-physical dependencies. To start, we can choose to describe the cyber-physical system as a set of discrete-time, non-linear stochastic equations repre- senting the dynamics of the system as: x(t + 1) = f(x(t), u(t)) + g(w(t)) (1) 3 Privacy-Sensitive Applications Cloud Services IoT Edge Devices Distributed Logic Sensors/Actuators State Estimator Edge Application Big Data Figure 1: Edge computation system model. @ !" # + 1 CPS State Estimation Supervisory Control Visible IoT/CPS Edge Device Compromised Firmware System State Control Commands Fine-grained Observable Physical Characteristics Control + Stealthy Encoding X Decoding via State Estimation …11011000100… Enhanced Observer Normal Observer Figure 2: Data exﬁltration attack overview. With x(t) ∈Rn as the state vector, u(t) ∈Rp as the control input, f(x(t), u(t)) as a deterministic propagation function and g(w(t)) being a potentially non-linear function of the system’s process noise w(t) ∈Rr, described by an underlying probability density function [29]. The CPS can also access information from its available set of sensing instruments. We can model a set of sensors using a stochastic transformation over the system state vector as: z(t) = h(x(t)) + v(t) (2) With z(t) ∈Rq as the sensor measurement vector received from the sensing instruments and v(t) ∈Rq representing a stochastic noise term, commonly regarded to be independent of the process noise w(t). Such a set of non-linear system equations can be linearized about a known system equilibrium-point (or the system’s current state ˆx(t)) as: δx(t) = x(t) −xeq(t), with δx(t) ∈Rn and expressed linearly as: δx(t + 1) = A(t)δx(t) + B(t)δu(t) + G(t)w(t) (3) With A(t), B(t), G(t) possibly time varying (or time- invariant). We consider A ∈Rn×n to represent the state dynamics matrix, B ∈Rn×p, as the control input matrix, and G ∈Rn×r as a process-noise propagation matrix, respectively. Using the dynamics models and on board measurement equipment, we can develop control structures and state es- timators, possibly linear or non-linear in nature, to describe the attack or defense strategy of an adversary or defender. In constraining the system dynamics to a set of linearized propagation equations, when necessary, well-known estimators and controllers such as Kalman Filters and Linear Regulators can be applied to model simple and descriptive representations of the respective adversary and defender strategies in consid- eration. By subjecting the defender and attacker models to a control-theoretic perspective, we can provide provable mea- sures, when necessary, over the various “blocks" of the system, i.e., the adversary, the defender, and the model dynamics which is referred to as the plant. Figure 3 depicts a general system structure in which the aforementioned blocks are connected into a system repre- sentation. The goal of an attacker is to encode data into a physical covert channel while maintaining stealthiness. To deﬁne stealthiness, we ﬁrst formalize the plant, adversary, and defender models as follows. Attacker systems model. An attacker is formalized to take the plant’s estimator output ˆx and the controller’s output uk as inputs to its system. In contrast, the defender attempts to monitor (and identify) deviations to the expected control inputs and state. To deviate a system’s response, an attacker will add an attack vector to the process noise, ωk to the actuators and/or sensor noise, vk to the measurement, respectively. In doing so, the attacker can break multiple independence assumptions the 4 Plant (System Model) 𝒙 𝒚 𝝊 Observer (Defender) 𝒖 ref Controller (Defender) Attacker (Targets 𝝎k, 𝝊k) 𝝊attack &𝒙 𝝎 𝒖𝒌 𝝎𝒂𝒕𝒕𝒂𝒄𝒌 ref &𝒙 𝒖 𝝊 𝒖 Figure 3: Control system representation of the threat model. Add chi-squared detector to this model system state estimator may rely upon for its estimation model. Therefore, the system state, i.e., xk can now be correlated to the process or measurement noise by the attacker’s choosing. The choice and encoding scheme of the attacker will be domain speciﬁc and described in the subsequent section. But ﬁrst, we brieﬂy discuss the defender model in this context. Defender systems model. The defender differs from the system’s state estimator, in that the defender uses the output of the state estimate and its policy to detect whether a state deviates from its intended path. The goal of the defender will be to distinguish whether a perturbation is due to an attack or merely a random perturbation. This formalization allows us to model the encoding and decoding of data into covert channels, and subject them to systems-theory, when necessary. We now use our control-theoretic representation of attacker and defender in the context of covert data exﬁltration. We deﬁne what an attacker’s stealthiness and imperceptibility is with respect to this systems model. Deﬁnition III.1 (Stealthiness). We deﬁne stealthiness as the attacker’s ability to deviate the CPS’s state such that any threshold levels of the system are not crossed as a result of the attack, the attacked state(s) do not strongly correlate with non-attacked state variables, and the attack is conducted on a state which does not utilize a ’colored-noise’ state estimator, i.e., if the measurement noise is correlated, then computing an ensemble average for the auto-correlation of the measurement noise (empirically) would differ from the known correlation signal. This basic structure provides an outline for our domain- speciﬁc design of both an attack and defense strategy for cyber- physical data exﬁltration. IV. CYBER-PHYSICAL DATA EXFILTRATION In this section we formalize the design of a cyber-physical data exﬁltration attack over a physical covert channel given the aforementioned system models. The goal of the attacker is to encode data into a physical channel while maintaining stealthiness. The choice of the physical channel and all of the associated parameters will be domain-speciﬁc and dependent on the defender model. We will therefore categorize the different attacker-defender scenarios with varying levels of quality for the defender’s state estimator. In all cases, the attacker needs an enhanced sensing modality that can decode the bits at a sufﬁcient granularity. To illustrate each component of the attack design, we present a motivating example of a simpliﬁed robotic arm. A. Motivating Example: Simpliﬁed Industrial Control System Figure 4 shows an example of a simpliﬁed industrial control system (ICS) where a robotic arm is controlled by a programmable logic controller (PLC). The PLC receives higher-level setpoint commands from a supervisory control and data acquisition (SCADA) entity, which may consist of human- machine interfaces, PLC workstations, as well as historians for data logging. The robot arm is composed of two segments that are controlled by stepper motors. In this simpliﬁed example, each arm is equipped with an inertial measurement unit (IMU) that is used to close the loop for the arm’s controller. For simplicity, we restrict each arm to move along the X-Y plane. In this case, we assume that the PLC takes a an XY-coordinate setpoint from the SCADA entity and its internal control loop calculates the associated actuation commands necessary to arrive at the desired waypoint for both arm segments. For this simpliﬁed case, we will demonstrate how an attacker may choose a particular attack vector along with the associated parameters. We implemented this industrial control system with a Dobot robotic arm controlled by a Siemens S7 1200 PLC. The robotic arm has a swappable end attachment that can stand in for several example applications, such as 3D printing, laser etching, and a gripper for industrial automation. The PLC controls the arm in a closed feedback loop, reading in sensor data from the arm’s two accelerometers and actuating its stepper motors to control the arm’s movement. For simplicity, we limit the motion of the arm to a two-dimensional plane. We emulate the SCADA components through an API that sends motion commands to the PLC, which calculates the appropriate actuation commands for the arm’s stepper motors. Given this system, we now describe how a defender would model a state estimator to detect anomalies in the sensor data. ICS defender model design. The typical goal of a defender, e.g., the SCADA entity in this context, is to develop an appropriate state estimator that will detect any anomalies. Theoretically, a perfectly tuned state estimator model for all memory-mapped physical I/O and it’s associated physical covert channels of a CPS would detect any cyber-physical data exﬁltration attack[5]. In practice, it is difﬁcult to develop a perfectly robust state estimation model for real-world applications as the state dynamics and measurements can be far from ideal. Further, a defender can only develop a state estimation model for the observable set of physical variables–including the phys- ical channels and associated noise models that depend on a particular variable. This means that the state estimation model is heavily dependent on not only the availability and quality of sensors instrumentation, but also the associated level of process noise for the system model. For instance, if the robotic arm is making inferences about it’s own pose and reporting just the XY-coordinates of the robots end effector 5 y 1 x1 Start End “0” “0” “1” “0” “1” “0” “1” Estimation-Free Trajectory x1 End “0” “0” “1” “0” “1” “0” “1” With Trajectory Estimation Start y 1 Error Bounds Expected Trajectory y 1 x1 y2 x2 IMU Arm 1 Encoding Arm 1 Arm 2 SCADA Workstation Historian HMI PLC Attack Trajectory Figure 4: Simpliﬁed industrial control system to illustrate cyber-physical data exﬁltration. An attacker may encode data into the movement of the robotic arm that is not being estimated or into the noise model associated with movement that is being estimated. before and after a movement command, then a state estimator is only able to report the posterior ˆxt then prior ¯xt+1 state estimates and associated covariances of the end effector. An anomaly could be detected using a distance metric such as a Euclidean distance to see if the current XY-coordinates, {(x1, y1), (x2, y2)} are close enough to the ˆx and ˆy estimates within a certain error ϵ, i.e., p ( ˆy1 −y1)2 + ( ˆx1 −x1)2 + ( ˆy2 −y2)2 + ( ˆx2 −x2)2 < ϵ. (4) However, because our system model assumes it is a remote defender, augmenting a defender’s state estimator necessitates sending more sensor data over the network, which is contra- dictory to the edge computation paradigm. In any case, we will detail the design of an attacker’s encoding and decoding schemes for varying levels of state estimation. B. Encoding Data into Physical Channels As discussed, an attacker’s encoding scheme into a par- ticular physical channel will depend on the quality of the defender’s state estimation model–which is assumed to be known by the attacker. As such, we consider three different defender models: (1) an attacker encoding data into a physical channel that is independent from any of the defender’s state estimator models, i.e., the control process for that state variable is locally autonomous; (2) an attacker encoding data into the "noise" of a channel that is being directly estimated by the system’s state estimator; and (3) the "perfect" defender that is fully aware of an attacker’s encoding scheme and is as powerful as the attacker in terms of sensing capabilities. For the latter case, the roles are essentially reversed and the attacker’s stealthiness goals will be focused on maintaining conﬁdentiality of the data being encoded. We discuss each case in detail. Case 1: Local autonomy and estimation. If a state vari- able’s associated control loop is locally autonomous to the edge device, i.e., there is no feedback control or estimation mechanism from a higher ﬁdelity external entity, then an attacker essentially has little to no inhibitions with respect to stealthiness and can manipulate any aspect of the system as long as the utility of the application is maintained. For instance, in Figure 4, the estimation-free trajectory scenario shows how an attacker may encode data into the path from a starting ("Start") XY-coordinate to an ending ("End") XY- coordinate. Such an attack would need to ensure that the utility of the function is maintained, e.g., that the encoding will have a mean noise of zero while ensuring that it reaches a distance within an error bound before the next sample. This also implies that the associated perturbations will not cause any collateral threshold violations for other states being estimated. And although this example shows the path trajectory between two sampled points as the physical channel of choice, any other cyber-physical channel that depends on the associated physical variables can also be utilized by an attacker, e.g., the acoustic noise of the stepper motors during the path trajectory. In any case, the attacker may engineer an encoding scheme that will transmit the data while ensuring the utility function’s integrity is maintained. However, encoding data becomes more difﬁcult for subsequent cases where the state variable is being estimated. Case 2: Remote external feedback control. If a state vari- able’s associated control loop relies on external state estimation and feedback control, the attacked state variable is being monitored with ﬁne granularity –which complicates the design of the attacker’s encoding scheme. However, it is infeasible for a defender to have a perfect state estimator model for real world systems due to environmental and systematic noise. Such an encoding mechanism requires an accurate noise model that is at least as granular as the noise model of the defender. The plot on the right of Figure 4 shows an attacker encoding bits into the trajectory of the end effector while staying within an error bounds. In this case, the attacker is much more restricted in terms of how much noise can be introduced in the encoding scheme due to the fact that the bits are being encoded into an estimated variable. However, up until now, we have assumed the attacker is more powerful than the defender. 6 Case 3: An omniscient perfect defender. The ﬁnal defender model is an ideal "perfect" defender that not only has much more sensing capabilities than the attacker with perfect state estimation, but also knows the attacker model, i.e., the asso- ciated encoding and decoding schemes and modalities. In this case, the roles are reversed as an attacker has been exposed and needs to maintain conﬁdentiality of the exﬁltrated data. Obviously, a defender could simply take the system ofﬂine if the utility of the system is not critical and if it has a means to remotely control the device, i.e., only a subset of the device’s remotely controlled variables have been compromised. But in a honeypot scenario–i.e., where a defender is attempting to discover more information about the attack–the exﬁltrated data can reveal the intent of the attacker along with other sensitive semantic information. From a cryptographic perspective, an attacker can leverage two "secrets": (1) standard cryptographic techniques embedded in the encoding software payload and (2) the location and sampling parameters of the decoding sensor. In this paper, we focus on the latter solution in which the location of a sensor can hide the semantic meaning of data being encoded. Although the design of a cryptographic mechanism within the software payload is outside of the scope of this paper, such an approach has several security and en- gineering challenges to ensure the semantic information being encoded into the physical actuation is sufﬁciently secured. If a defender can recover the device, static and dynamic analysis techniques can be used to reverse engineer some of the semantic information, e.g., combining static binary analysis with the dynamic behavioral analysis of the encoder when given certain inputs or environmental conditions [37]. We now present a generalized decoding mechanism for these encoding schemes. C. Decoding Cyber-physical Encoded Data Figure 5: System state tracking using colored markers. In order to decode data that has been encoded with any of these encoding schemes, the attacker simply needs to mirror Figure 6: Camera-tracked system state trace. Each segment encodes a single bit based on the change in angle. Bit Rate FPS Bit Error Rate 5 bit/sec 30 0% 10 bit/sec 30 0% 15 bit/sec 30 15.6% Table I: Bit error rates (BERs) for various encoding rates. the modality and granularity of the encoding scheme. For instance, in the estimation-free trajectory attack of the ICS example, an attacker would need access to the ﬁner-grained path trajectory between movement commands. Having access to either a faster sampling rate or even the IMU data would be ideal, but it is not realistic for a remote attacker–especially if we are assuming the defender does not have access to these results. A more realistic approach is that an attacker may infer the cyber-physical encoding utilizing an air-gapped physical channel such as a microphone monitoring the noise of the device or by visually monitoring the movements of each component from a distance with a camera. For instance, we im- plemented malicious motion command on the aforementioned PLC that encodes a bit string in the actuation of the arm’s motors during a benign motion command. An attacker may focus a camera on the arm to observe speciﬁc markers on the arm as shown in Figure 5. We applied color markers to the arm to simplify the tracking algorithm2. For tracking the markers we utilized OpenCV–an open-source computer vision library. The resulting output of an encoded movement is shown in Figure 6. We now discuss the design considerations for a communication protocol given an encoding and decoding scheme. D. Communication Protocol There are several domain-speciﬁc design parameters that need to be tuned for particular CPS. Regardless of whether an attacker is using cryptographic mechanisms or not, the goal should be to maximize both the rate of transmission as well as the signal-to-noise ratio (SNR). 2A more sophisticated algorithm could perform position tracking without external markers speciﬁc to the CPS 7 Channel Capacity and Bit Error Rate. There are several factors that determine the channel capacity of data exﬁltration. • Physical system constraints. The rate of encoding into a physical system is limited by the actuation speed of the system, which is determined by the system’s kinematics. Faster encoding speeds require greater forces which the system may not support. Addition- ally, physical systems may have a minimum precision with which motions can be made consistently (eg. a single motor step is 1.8 for the robotic arm°). • The observer’s frame rate and resolution. The channel capacity is also limited by the capabilities of the observer. For a camera, the frame rate is analogous to the sampling rate, and we found that for the robotic arm, at least 3 frames were necessary to identify an encoded motion consistently. Additionally, the resolu- tion of the observer is correlated with the encoding: a higher resolution means that smaller motions can be detected reliably, allowing a greater encoding rate within the constraints of the physical system. • Maintaining stealth. In a scenario with a defender performing state estimation on the system, a faster encoding produces more noticeable actuations, in- creasing the likelihood of revealing the exﬁltration process to the defender. Table I shows the bit error rates for decoding in the robotic arm scenario. As we approached the limits of the encoding rate we found that the decoding accuracy decreases signiﬁcantly due to increased system vibration coupled with fewer frames per encoded bit. We now brieﬂy discuss design considerations for error checking. We now brieﬂy discuss mechanisms that can be utilized to maintain the integrity of the data. Error checking and redundancy. Since the transmission channel is a one-way communication link, re-transmission can not be requested in case of a transmission error. Forward error correction such as cyclic-redundancy checks (CRC) [10], can be used to correct errors at the receiver at the cost of reducing transmission bandwidth for redundancy. Alternatively, if the same variables are being transmitted repeatedly (data values), then the values have a short "lifetime" and we can forgo error correction altogether, ﬁltering out outliers at the receiver. The ﬁnal design piece focuses on an attacker’s means of maintaining imperceptibility from a defender. E. Maintaining Imperceptibility The ﬁnal notion of the aforementioned attacks is main- taining imperceptibility in the face of a “human observer"– or an observer that may be monitoring the CPS through a particular modality or set of modalities from sensors equivalent to a human’s “sensors". This problem is analogous to the problem of adversarial machine learning where an attacker is introducing perturbations to a model’s input data while minimizing some loss function such that the system will misclassify the data sample while maintaining imperceptibility of the perturbations [33]. In this context, the perfect model of perceptibly is the associated decoding mechanism itself. In addition to maintaining stealthiness with respect to the state estimation model, an attacker will also minimize the encoded movements such that the decoding function will only work with a decoder that has a sufﬁcient sensing granularity, e.g., a camera equipped with an appropriate focal length to pickup tiny movements of the robotic arm. We propose the following simple scheme for maintaining imperceptibility. For a given attacker strength, it is desirable to encode information at the lowest SNR that the attacker can still decode reliably (eg. with an acceptable bit error rate). By deﬁnition, this minimizes the differentiation between signal and noise for any observer and results in the least conspicuous encoding. Additionally, the frequency and choice of encoding should be chosen carefully to closely mirror normal operating characteristics. That being said, determining these parameters may be impractical in certain situations. We now evaluate each of the aforementioned attacker-defender scenarios on a much more complex autonomous edge device. V. EVALUATION ON AN AUTONOMOUS EDGE DEVICE We now evaluate both the attacker and defender models presented from the previous section in the context of a more complex edge computation scenario: a surveillance drone. We are emulating the aforementioned scenario depicted in Figure 1 where a drone is part of an IoT coalition supporting a group of ﬁrst responders or soldiers. In particular, the drone is tasked to surveil an area, e.g., to search for particular objects of interest. Any inferences made by the drone will be reported by back to a supervisory entity that is interacting with the drone. We describe our experimental setup in detail. A. Experimental Setup To evaluate the drone surveillance application, we formal- ize our defense models on both position and orientation state estimates of a Crazyﬂie quadcopter [14]. For our scenario, we abstract the speciﬁc task and focus on the trajectory of the drone since the Crazyﬂie cannot support such a large computation load3. Throughout the trajectory, the ideal attacker can choose to deviate any physical degree of freedom of the system such as position, speed, or orientation. For simplicity, we show the effect a defender can have when an attacker is physically exﬁltrating data through the drone’s yaw variable. We use an Optitrack motion capture system to provide the drone with external location estimates of its 3D position and orientation in space. The Crazyﬂie was ﬁtted with four Optitrack markers to precisely localize the drone during its ﬂight. Our Optitrack setup utilizes 12 cameras to obtain sub- millimeter positioning accuracy. This state of the art level of accuracy allows us to provide the defender with a very precise and accurate state estimator for the drone–more precise than outdoor localization schemes4. The drone with the markers as well as its representation in the Optitrack software can be seen in Figure 7. We use the Robotic Operating System (ROS) as the software package to communicate between the drone, motion capture system, and host computer in real time. 3Although the Crazyﬂie cannot support such large computation, neural accelerators have already shown such inferencing can be run on the edge. It is a safe assumption that this computation is already or will be soon enabled on larger outdoor drones. 4The Crazyﬂie quadcopter was chosen because it can be ﬂown indoors and the motion capture system needs to be calibrated in a static indoor environment. 8 Cam. 1 Cam. 3 Cam. 5 Cam. 7 Figure 7: Drone evaluation setup using the Optitrack motion capture system. The system consists of 12 Optitrack motion capture cameras. The circled cameras were the four different perspectives selected in our evaluation. Figure 8: Optitrack replays used to simulate an enhanced observer: 1. Normal, 2. Enhanced, 3. Tracking example. We evaluate a defender model under the three aforemen- tioned attack cases for our experimental setup. For the ﬁrst case, the drone is tasked to execute a constant hover at 0.5 meters. The attacker encodes the data into the yaw variable about a ﬁxed position. For the second case, we allow the defender to monitor both the position and yaw variable of the drone. Because the defender would be able to easily detect a change in yaw for a stationary hovering case, the drone is tasked to ﬂy in a circle approximately 1 meter radius at 0.5 meters from ground level. In the third case, the drone is tasked to hover again, but now the attacker exﬁltrates data with an asynchronous and more challenging encoding scheme to highlight alternative means of stealthiness in the face of a perfect defender. The attacker generally uses two encoding schemes: The ﬁrst scheme is used in scenarios one and two. • Encoded Bit 1 Attacker yaws drone approximately 5 degrees counter-clockwise from start. Attacker yaws back to reference to complete the transmission. • Encoded Bit 0 Attacker yaws drone approximately 5 degrees clockwise. Attacker yaws back to reference to complete the transmission. To evaluate the feasibility of decoding the cyber-physical encoded data, we utilized video recordings of replays from the Optitrack system. The recordings were taken at 30 frames per second, and zoomed-in simulates an enhanced observer as shown in Figure 8. Similar to the ICS scenario, relative angles were established between the markers to track the system state for data exﬁltration. Baselines with no attacker perturbation were ﬁrst found for both the hover and circle scenarios. For the hover scenario, ambient noise levels were seen to be small. For the circle (surveillance) scenario, the drone conducted ten circles with no attacker perturbation for ground truth. Figure 10 depicts the surveillance loop of the drone, and Figure 9 shows the baseline position error and yaw of the drone as it completes 10 circles with no attacker perturbation. Furthermore, Figure 9 details ﬁve segments per each subplot, depicting the respective amount of position error or yaw as the drone navigates two full circle paths, resets and starts again. We observe the XYZ position error variances are .00123, .00101, and .0001 m2, for the case of no attacker, respectively. B. Evaluating Across Different Defense Schemes We now provide an evaluation of different attacks across the aforementioned defender models. Case 1: Local autonomy and estimation. For case 1, the attacker is encoding into the yaw variable that is not being estimated by the defender. The attacker exﬁltrates using the ﬁrst bit encoding scheme. We repeat this process for encoding speeds of 1 bit/s, 2 bit/s and 5 bit/s. Figure 11 illustrates the hovering sequences of the drone. The data presented in Figure 11 furthermore shows the yaw of the drone does not undergo signiﬁcant drift as the attacker perturbs the system. Simple threshold values are sufﬁcient for the defender to detect an attacker in this experimental setup. Table II summarizes these results. From the attacker’s perspective, observing the drone’s motion from afar provides a reconstruction shown in Figure 12. Noisy artifacts are present due to ﬂickering markers and temporary occlusions. Isolating a single channel in Figure 13 reveals a signal with acceptable signal-to-noise ratios (dB) 9 20 40 60 80 100 120 0.00 0.05 0.10 Error Pos X (m) Baseline Error for Drone Surveillance Path 20 40 60 80 100 120 0.00 0.05 0.10 Error Pos Y (m) 20 40 60 80 100 120 0.000 0.025 0.050 Error Pos Z (m) 20 40 60 80 100 120 Time (seconds) 0.2 0.0 Yaw (rad) Figure 9: Baseline errors for drone surveillance path. 1.0 0.5 0.0 0.5 1.0 1.0 0.5 0.0 0.5 1.0 0.1 0.2 0.3 0.4 0.5 Surveillance Path of Drone Figure 10: Baseline surveillance loop of drone. Freq Mean Thresh Low Thresh High Accuracy 1Hz 0 -.025 .025 100% 2Hz -.125 -.035 .035 93.75% 5Hz -0.14 -.030 0.30 93.75 % Table II: Defender Results for Case 1. Defender has knowl- edge of attacker encoding strategy. Defender uses threshold detection levels to detect attack 0 10 20 30 40 0.075 0.050 0.025 0.000 0.025 0.050 0.075 yaw (rad) Drone Hover Encoding 1hz 10 15 20 25 30 0.20 0.15 0.10 0.05 yaw (rad) Drone Hover Encoding 2hz 8 10 12 14 16 Time (sec) 0.200 0.175 0.150 0.125 0.100 yaw (rad) Drone Hover Encoding 5hz Figure 11: From Top: Drone yaw (radians) vs ﬂight time (seconds) for exﬁltrating a 1 and 0 at about 1hz, 2hz and 5hz, respectively 0 5 10 15 20 25 30 Time (sec) -90 -60 -30 0 30 60 90 Relative Tracker Angles Hover Encoding 1 Hz - Camera 7 (Raw) 0 2 4 6 8 10 12 14 16 18 20 Time (sec) -90 -60 -30 0 30 60 90 Relative Tracker Angles Hover Encoding 2.5 Hz - Camera 7 (Raw) 0 2 4 6 8 10 12 14 16 Time (sec) -90 -60 -30 0 30 60 90 Relative Tracker Angles Hover Encoding 5 Hz - Camera 7 (Raw) Figure 12: Visually reconstructed drone encoding trace. 10 0 5 10 15 20 25 30 Time (sec) -90 -75 -60 -45 -30 Relative Tracker Angles Hover Encoding 1 Hz - Camera 7 (Isolated) SNR = 6.8 0 2 4 6 8 10 12 14 16 18 20 Time (sec) -90 -75 -60 -45 -30 Relative Tracker Angles Hover Encoding 2.5 Hz - Camera 7 (Isolated) SNR = 8.8 0 2 4 6 8 10 12 14 16 Time (sec) -90 -75 -60 -45 -30 Relative Tracker Angles Hover Encoding 5 Hz - Camera 7 (Isolated) SNR = 5.7 Figure 13: Isolated encoding trace for decoding. for decoding (with sufﬁcient signal processing). Of note in Figure 13, as the encoding frequency approaches the channel capacity, physical system constraints become apparent, as the drone must either endure greater accelerations or make smaller rotations (observed) to maintain the 5 Hz bitrate. Case 2: Remote external feedback control. For case two, the attacker is encoding into the yaw variable as the drone ﬂies along its circular surveillance path. Figure 14 shows the 3D position error of the CPS under encoding scheme 1. The attacker’s encoding begins at each vertical red line, respectively. In this example, we ﬁrst give the defender the sub-task of monitoring the position of the drone. Figure 14 shows the position error traces as the drone follows the circular reference path. One key importance of Figure 14 is the fact that the start of the attacker’s encoding signal does not inﬂuence error in 3D position. This is further evident when comparing the associated xyz position error variance levels from the attacker case (.00116, .00098, .000118) m2, respectively. Thus, we observe the yaw-attack has no effect on the position error variance levels and the attack is unobservable. Figure 15 depicts the yaw error about the reference path of the drone as the attacker performs encoding scheme one again. In this case, the defender solely monitors the yaw variable, while the attacker perturbs this channel. The start of each attacker encoding is represented by a vertical red line. We see that maximums and minimums of yaw directly align with the attacker’s encoding frequency over this channel. As seen from Figure 15, the drone’s yaw slightly drifts as the attacker perturbs the drone’s heading during its circular ﬂight. We see implementing a simple thresholding technique here will not be as robust when compared to the hover case, since the ﬂight data is clearly non-stationary in this example. Given the defender is monitoring the yaw state variable, and 20 25 30 35 40 45 50 55 0.00 0.05 0.10 Error Pos X (m) Drone Circular Path, with Position Detector (XYZ) and Attacker 20 25 30 35 40 45 50 55 0.00 0.05 0.10 Error Pos Y (m) 20 25 30 35 40 45 50 55 Time (seconds) 0.00 0.02 0.04 Error Pos Z (m) Figure 14: Error in XYZ Position as attacker encodes bit sequence through yaw. Encoding is unobservable when moni- toring just position. Start of attacker’s bit encoding represented in red. knows the attacker’s bit encoding scheme, a simple local min/max extrema search would detect the attacker’s presence and encoded bit sequence. Table III displays the defender’s accuracy in correctly detecting the exﬁltrated data through thresholding and local extrema ﬁnding. 20 25 30 35 40 45 50 55 Time (seconds) 0.00 0.05 0.10 0.15 0.20 0.25 0.30 0.35 Error Yaw (rad) Drone Circular Path, with Yaw-Detector & Attacker Figure 15: Error in yaw (radians) vs ﬂight time (seconds). Error in yaw is in sync with the start of each attacker perturbation command (red lines) For the circular ﬂight scenario, it is again possible for an attacker to reconstruct and decode encoded data as the yaw is independent of the XYZ position. In this situation the attacker faces challenges similar to the defender when decoding (such as non-stationary data), as both parties are estimating the yaw. However, an unencoded ﬂight can help establish a baseline Technique Accuracy Local Extrema 90.6% Thresholding 53.1% Table III: Defender Results for Case 2: Defender has knowl- edge of attacker encoding strategy. Comparison of threshold detection and local extrema accuracy. 11 for decoding. Figure 16 shows the adversarial observer’s reconstruction of the circular motion. Although the defender in this case would also be able to read and decode encoded data, we discuss in following sections ways to protect an attacker and their communication. 0 2 4 6 8 10 12 14 16 18 20 Time (sec) -80 -60 -40 -20 0 20 40 60 80 Relative Tracker Angles Circular Motion (no encoding) 0 2 4 6 8 10 12 14 16 18 20 Time (sec) -80 -60 -40 -20 0 20 40 60 80 Relative Tracker Angles Circular Motion (with encoding) Figure 16: Visually reconstructed circular motion trace. Case 3: An omniscient perfect defender. In the case of a perfect defender, who knows both the attacker’s covert physical channel and encoding scheme, there are two main secrets for the attacker to protect: • The communication contents. In the case of an ideal defender, the roles effectively swap – the defender wants to ﬁnd out what information is being exﬁltrated, whilst the attacker must defend this secret. To prevent a defender with knowledge of the system from ﬁguring out what data the attacker is exﬁltrating, encryption (based on some shared secret between the compro- mised device and the attacker) can be used, which is outside of the scope of the paper. • The location of the decoding sensor. Depending on the encoding channel and scheme, it is possible that data exﬁltration is only feasible from certain perspec- tives (eg. the 2D robotic arm scenario). When the defender has this information, it may compromise the stealth of the attacker by giving away their location. Given the rotational symmetry of the yaw in the drone case, we hypothesize that this encoding channel gives little information on where the attacker is observing the system from. Figure 17 shows that this is indeed true; the encoding is visible from multiple camera angles. It is important to note though that certain angles are still "better" than others, whether due to occlusion or a observation angle depth leading to a larger SNR. However, given a capable attacker all of these angles are sufﬁcient for data exﬁltration without giving information to a knowledgeable defender. 0 2 4 6 8 10 12 14 16 18 20 Time (sec) -90 -60 -30 0 30 60 90 Relative Tracker Angles Hover Encoding 2.5 Hz - Camera 1 0 2 4 6 8 10 12 14 16 18 20 Time (sec) -90 -60 -30 0 30 60 90 Relative Tracker Angles Hover Encoding 2.5 Hz - Camera 3 0 2 4 6 8 10 12 14 16 18 20 Time (sec) -90 -60 -30 0 30 60 90 Relative Tracker Angles Hover Encoding 2.5 Hz - Camera 5 0 2 4 6 8 10 12 14 16 18 20 Time (sec) -90 -60 -30 0 30 60 90 Relative Tracker Angles Hover Encoding 2.5 Hz - Camera 7 Figure 17: Decoding as seen from various angles (see Figure 7 for camera locations). Obfuscated Encodings: We now consider the case when the attacker exﬁltrates a meaningful byte of data from the drone. A second, more challenging encoding scheme is now used: • Encoded Bit 1 Attacker yaws drone approximately 5 degrees counter-clockwise. Attacker holds this orien- tation for 0.75 seconds to transmit another encoded bit 1. • Encoded Bit 0 Attacker yaws drone approximately 5 degrees clockwise. Attacker holds this orientation for 0.75 seconds to transmit another encoded bit 0. Figure 18 depicts a byte of data being physically exﬁltrated through the drone’s yaw using the encoding scheme above. The byte is transmitted twice, to show reproducibility of the transmission. In this case, the attacker’s exﬁltration strategy is dependent on both direction of physical perturbation and the duration of the perturbation. If the defender chooses to implement either of the two formerly proposed techniques (thresholding, local-extrema search), the attacker will have successfully fooled the defender in recovering the wrong bit- string. For example, the byte exﬁltrated from ﬁgure 18 is 10110110, however, the defender would guess 101010 if they only had knowledge of the attacker’s perturbation rule and not 12 the time delay rule. This demonstrates the attacker can fool the defender by encoding bits over both the system’s degrees of freedom and time. This situation is further exacerbated by the fact the attacker may be using cryptographic mechanisms to communicate the exﬁltrated bit string to a third party observer. We hypothesize combining secure state estimation models to estimate the current attack vector and possibly time-series machine learning models to infer the exﬁltrated bits from the attack sequence could provide a solution for the asynchronous exﬁltration scenario described here, and will be part of future work. 12 14 16 18 20 22 24 0.10 0.05 0.00 0.05 0.10 yaw (rad) Encoded Bit Pattern during Drone Hover, Byte 1 Figure 18: Attacker exﬁltrates a byte of data by yawing the drone with precise timing to exﬁltrate bits covertly. Byte 1 is: 10110110 VI. RELATED WORK In this section we will discuss some of the related work on data exﬁltration via covert channels as well as the formalization of side channels. Air-gapped covert data exﬁltration. There is a large body of research on the topic of physical covert channel data exﬁltration across air-gapped systems. Multiple works have shown that electromagnetic signals emitted from devices, e.g., signals from video displays [20], GSM frequencies emitted from workstations [19], or USB generated electromagnetic emissions [21], can be picked up by mobile phones to establish a physical covert channel. It was shown that even if these channels were physically insulated to conceal any emissions via a Faraday cage, magnetic ﬁelds emitted from a CPU can act as a transmitter of data to mobile phones [27], [18]. Power consumption has also been utilized as a transmitter of data by modulating the CPU utilization [26]. Similarly (but at a larger scale), it was shown that two PLCs in the context of industrial power grid can communicate covertly with each other by modulating their associated actuators in a stealthy manner [12]. However, these systems are not necessarily air- gapped as they have direct access to the cyber-physical sensors. Thermal emissions between two PCs have also been utilized to establish bi-directional communication [22]. Acoustic covert channels have been utilized to exﬁltrate data from physical hard drive noises [24], commodity desktop speakers [25], or desktop fans [23]. It has even been shown propietary information of 3D printed models can be divulged from the noise of the motors [9]. There has also been several works that have shown a similar approach to optically encode and decode information by utilizing LEDs [28], [16], [17]. In all of these cases, these attacks were presented informally and, to the best of our knowledge, our work is the ﬁrst to formalize a control- theoretic model of covert physical channel exﬁltration while maintaining stealthiness as well as the utility of the respective cyber-physical application. Amost all of these related works actually do not implement these attacks in the context of cyber- physical applications and the associated proposed countermea- sures discuss physical isolation or procedural security that are not applicable to cyber-physical edge devices in the wild. It is important to note that there have been attempts to formalize the notion of side-channels. Formalizing cyber-physical side channel attacks. The notion of an information-theoretic model for side-channels has been discussed to describe what an attacker may derive from other types of side channels. In these attacks, an attacker can query a system to observe its characteristics and infer characteristics about a secret key given a limited number of queries [31]. Note that the analysis of side-channels are subsumed by our physical covert channel analysis as side-channels are cyber- physical dependencies stemming from the memory-mapped I/O of the system. An attacker or a defender can utilize our approach to analyze the cyber-physical dependencies of memory-mapped I/O and uncover possible side-channels that may leak information. The major difference is that our model assumes an attacker can compromise the CPS binary to encode information and instrument side-channels as covert channels. VII. DISCUSSION We brieﬂy discuss the practicality of such attacks as well as the practical design of defensive countermeasures. Practicality and efﬁcacy of attacks. The attacks presented in this paper are signiﬁcantly more complicated than the previous air-gapped attacks, e.g., encoding data into LEDs is much easier than encoding into the movement of a drone while maintaining the utility of the application. However, such attacks are also easier to mitigate as one can simply physically disable such unnecessary actuators to harden the systems, e.g., by removing any LEDs from the system. It is much less feasible to constrain particular movements of a CPS. Further, the attacks presented in this paper were very simple movements. For more complex systems with more physical degrees of freedom, e.g., a swarm of drones or a factory automation ﬂoor with several robotic arms, more sophisticated encoding and decoding mechanisms can be instrumented to both increase the rate of data transmission as well as to further obfuscate the encoding scheme. Practical defensive measures. The state estimators utilized by the defenders in this paper were idealistic as we used the Optitrack motion capture system that has sub-millimeter accuracy and typically requires signiﬁcant calibration for a small and limited space. In reality, localization and state estimation of drones in the wild is much more noisier and less predictable. In such cases, state estimation may not be reliable enough to detect an attacker and a defender may need to rely on a means of attesting the software that is running on 13 the CPS. Recent works have made strides towards attesting the behavioral integrity [4] as well as the integrity of controller software [13] in the context of industrial control systems. However, these have yet to be generalized to more complex CPS such as drones. VIII. CONCLUSION In this paper, we characterized covert data exﬁltration over air-gapped cyber-physical channels in the context of edge device applications. In particular, we formalized how an attacker may maintain the stealthiness and utility of a cyber- physical application while maximizing the rate of transmission. We detailed how to practically model attackers and defenders in this context using real-world examples of an industrial control system as well as an autonomous drone surveilling an area. We ﬁnally discuss the limitation of current defensive measures and discuss appropriate countermeasures. REFERENCES [1] Cloud iot edge - extending google cloud’s ai & ml | iot edge | google cloud. [2] Explore the internet of things (iot). [3] Predix edge computing | edge computing platform | ge digital. [4] ADEPU, S., BRASSER, F., GARCIA, L., RODLER, M., DAVI, L., SADEGHI, A.-R., AND ZONOUZ, S. Control behavior integrity for distributed cyber-physical systems. arXiv preprint arXiv:1812.08310 (2018). [5] BERTSEKAS, D. P., BERTSEKAS, D. P., BERTSEKAS, D. P., AND BERTSEKAS, D. P. Dynamic programming and optimal control, vol. 1. Athena scientiﬁc Belmont, MA, 1995. [6] BONOMI, F., MILITO, R., ZHU, J., AND ADDEPALLI, S. Fog com- puting and its role in the internet of things. In Proceedings of the ﬁrst edition of the MCC workshop on Mobile cloud computing (2012), ACM, pp. 13–16. [7] ESMAEILZADEH, H., SAMPSON, A., CEZE, L., AND BURGER, D. Neural acceleration for general-purpose approximate programs. In Proceedings of the 2012 45th Annual IEEE/ACM International Symposium on Microarchitecture (2012), IEEE Computer Society, pp. 449–460. [8] FALLIERE, N., MURCHU, L. O., AND CHIEN, E. W32. stuxnet dossier. White paper, Symantec Corp., Security Response 5, 6 (2011), 29. [9] FARUQUE, A., ABDULLAH, M., CHHETRI, S. R., CANEDO, A., AND WAN, J. Acoustic side-channel attacks on additive manufacturing systems. In Proceedings of the 7th International Conference on Cyber-Physical Systems (2016), IEEE Press, p. 19. [10] FREIVALD, M. P., RICHARDS, M. S., AND NOBLE, A. C. Change- detection tool indicating degree and location of change of internet documents by comparison of cyclic-redundancy-check (crc) signatures, Apr. 27 1999. US Patent 5,898,836. [11] GARCIA, L., BRASSER, F., CINTUGLU, M. H., SADEGHI, A.-R., MOHAMMED, O. A., AND ZONOUZ, S. A. Hey, my malware knows physics! attacking plcs with physical model aware rootkit. In NDSS (2017). [12] GARCIA, L., SENYONDO, H., MCLAUGHLIN, S., AND ZONOUZ, S. Covert channel communication through physical interdependencies in cyber-physical infrastructures. In Smart Grid Communications (SmartGridComm), 2014 IEEE International Conference on (2014), IEEE, pp. 952–957. [13] GHAEINI, H. R., CHAN, M., BAHMANI, R., BRASSER, F., GARCIA, L., ZHOU, J., SADEGHI, A.-R., AND ZONOUZ, S. Patt: Physics-based attestation of control systems. In International Symposium on Research in Attacks, Intrusions, and Defenses (2019), Springer. [14] GIERNACKI, W., SKWIERCZY ´NSKI, M., WITWICKI, W., WRO ´NSKI, P., AND KOZIERSKI, P. Crazyﬂie 2.0 quadrotor as a platform for research and education in robotics and control engineering. In 2017 22nd International Conference on Methods and Models in Automation and Robotics (MMAR) (2017), IEEE, pp. 37–42. [15] GREMBAN, K. What is azure iot edge. [16] GUR, M., ZADOV, B., DAIDAKULOV, A., AND ELOVICI, Y. xled: Covert data exﬁltration from air-gapped networks via switch and router leds. In 2018 16th Annual Conference on Privacy, Security and Trust (PST) (2018), IEEE, pp. 1–12. [17] GURI, M., AND BYKHOVSKY, D. air-jumper: Covert air-gap exﬁl- tration/inﬁltration via security cameras & infrared (ir). Computers & Security 82 (2019), 15–29. [18] GURI, M., DAIDAKULOV, A., AND ELOVICI, Y. Magneto: Covert channel between air-gapped systems and nearby smartphones via cpu- generated magnetic ﬁelds. arXiv preprint arXiv:1802.02317 (2018). [19] GURI, M., KACHLON, A., HASSON, O., KEDMA, G., MIRSKY, Y., AND ELOVICI, Y. Gsmem: Data exﬁltration from air-gapped computers over gsm frequencies. In USENIX Security Symposium (2015), pp. 849–864. [20] GURI, M., KEDMA, G., KACHLON, A., AND ELOVICI, Y. Airhopper: Bridging the air-gap between isolated networks and mobile phones using radio frequencies. In Malicious and Unwanted Software: The Americas (MALWARE), 2014 9th International Conference on (2014), IEEE, pp. 58–67. [21] GURI, M., MONITZ, M., AND ELOVICI, Y. Usbee: Air-gap covert- channel via electromagnetic emission from usb. In Privacy, Security and Trust (PST), 2016 14th Annual Conference on (2016), IEEE, pp. 264– 268. [22] GURI, M., MONITZ, M., MIRSKI, Y., AND ELOVICI, Y. Bitwhisper: Covert signaling channel between air-gapped computers using thermal manipulations. In Computer Security Foundations Symposium (CSF), 2015 IEEE 28th (2015), IEEE, pp. 276–289. [23] GURI, M., SOLEWICZ, Y., DAIDAKULOV, A., AND ELOVICI, Y. Fansmitter: Acoustic data exﬁltration from (speakerless) air-gapped computers. arXiv preprint arXiv:1606.05915 (2016). [24] GURI, M., SOLEWICZ, Y., DAIDAKULOV, A., AND ELOVICI, Y. Acoustic data exﬁltration from speakerless air-gapped computers via covert hard-drive noise (‘diskﬁltration’). In European Symposium on Research in Computer Security (2017), Springer, pp. 98–115. [25] GURI, M., SOLWICZ, Y., DAIDAKULOV, A., AND ELOVICI, Y. Mosquito: Covert ultrasonic transmissions between two air-gapped computers using speaker-to-speaker communication. arXiv preprint arXiv:1803.03422 (2018). [26] GURI, M., ZADOV, B., BYKHOVSKY, D., AND ELOVICI, Y. Power- hammer: Exﬁltrating data from air-gapped computers through power lines. arXiv preprint arXiv:1804.04014 (2018). [27] GURI, M., ZADOV, B., DAIDAKULOV, A., AND ELOVICI, Y. Odini: Escaping sensitive data from faraday-caged, air-gapped computers via magnetic ﬁelds. arXiv preprint arXiv:1802.02700 (2018). [28] GURI, M., ZADOV, B., AND ELOVICI, Y. Led-it-go: Leaking (a lot of) data from air-gapped computers via the (small) hard drive led. In International Conference on Detection of Intrusions and Malware, and Vulnerability Assessment (2017), Springer, pp. 161–184. [29] GUSTAFSON, D. E., AND SPEYER, J. L. Design of linear regulators for nonlinear stochastic systems. Journal of Spacecraft and Rockets 12, 6 (1975), 351–358. [30] HA, K., CHEN, Z., HU, W., RICHTER, W., PILLAI, P., AND SATYA- NARAYANAN, M. Towards wearable cognitive assistance. In Proceedings of the 12th annual international conference on Mobile systems, applications, and services (2014), ACM, pp. 68–81. [31] KÖPF, B., AND BASIN, D. An information-theoretic model for adaptive side-channel attacks. In Proceedings of the 14th ACM conference on Computer and communications security (2007), ACM, pp. 286–296. [32] KURNIAWAN, A. Learning AWS IoT: Effectively manage connected devices on the AWS cloud using services such as AWS Greengrass, AWS button, predictive analytics and machine learning. Packt Publish- ing Ltd, 2018. [33] PAPERNOT, N., MCDANIEL, P., JHA, S., FREDRIKSON, M., CELIK, Z. B., AND SWAMI, A. The limitations of deep learning in adversarial settings. In 2016 IEEE European Symposium on Security and Privacy (EuroS&P) (2016), IEEE, pp. 372–387. [34] SHI, W., CAO, J., ZHANG, Q., LI, Y., AND XU, L. Edge computing: Vision and challenges. IEEE Internet of Things Journal 3, 5 (2016), 637–646. 14 [35] SONG, C., LIN, F., BA, Z., REN, K., ZHOU, C., AND XU, W. My smartphone knows what you print: Exploring smartphone-based side- channel attacks against 3d printers. In Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security (2016), ACM, pp. 895–907. [36] SRINIVASAN, R., MOHAN, A., AND SRINIVASAN, P. Privacy con- scious architecture for improving emergency response in smart cities. In 2016 Smart City Security and Privacy Workshop (SCSP-W) (2016), IEEE, pp. 1–5. [37] SUN, P., GARCIA, L., AND ZONOUZ, S. Tell me more than just assembly! reversing cyber-physical execution semantics of embedded iot controller software binaries. In 2019 49th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN) (2019), IEEE. [38] YAO, S., ZHAO, Y., SHAO, H., LIU, S., LIU, D., SU, L., AND ABDELZAHER, T. Fastdeepiot: Towards understanding and optimizing neural network execution time on mobile and embedded devices. In Proceedings of the 16th ACM Conference on Embedded Networked Sensor Systems (2018), ACM, pp. 278–291. [39] YI, S., HAO, Z., QIN, Z., AND LI, Q. Fog computing: Platform and applications. In 2015 Third IEEE Workshop on Hot Topics in Web Systems and Technologies (HotWeb) (2015), IEEE, pp. 73–78. 15