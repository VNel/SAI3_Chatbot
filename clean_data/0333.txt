arXiv:2211.04762v3 [cs.CR] 7 Sep 2023 Building Resilience in Cybersecurity – An Artiﬁcial Lab Approach Kerstin Awiszusb, Yannick Bella, Jan L¨uttringhausa, Gregor Svindlanda, Alexander Voßa, and Stefan Webera aHouse of Insurance, Leibniz Universit¨at Hannover bUniversity of Applied Sciences and Arts, Hannover September 8, 2023 Based on classical contagion models we introduce an artiﬁcial cyber lab: the digital twin of a complex cyber system in which possible cyber resilience measures may be implemented and tested. Using the lab, in numerical case studies, we identify two classes of measures to control systemic cyber risks: security- and topology-based interventions. We discuss the implications of our ﬁndings on selected real-world cybersecurity measures currently applied in the insurance and regulation practice or under discussion for future cyber risk control. To this end, we provide a brief overview of the current cybersecurity regulation and emphasize the role of insurance companies as private regulators. Moreover, from an insurance point of view, we provide ﬁrst attempts to design systemic cyber risk obligations and to measure the systemic risk contribution of individual policyholders. Keywords: Systemic Cyber Risks; Cyber Insurance; Cybersecurity; Cyber Resilience; Eco- nomics of Networks; Complexity Economics; Complex Systems. 1. Introduction Cyber risks pose a major threat to societies, governments, businesses and individuals world- wide. For example, the annually published Allianz Risk Barometer, see Allianz (2022), recently identiﬁed cyber incidents as the most important global business risks, ahead of business in- terruptions, natural disasters and pandemic outbreaks. In addition, cyber risk continues to increase, ﬁrstly due to the continued digitization of business processes, and secondly due to the COVID-19 pandemic and the associated increase in teleworking, see e.g. Lallie et al. (2021), and thirdly in the context of current political conﬂicts and wars. Regulatory and macro-prudential leaders are increasingly aware of the potentially catastrophic consequences of cyber risks. In particular, the systemic relevance of certain types of cyber threats, so-called systemic cyber risks, is highlighted, see e.g. Lagarde (2021). Two illustrative systemic cyber incidents from the past are the WannaCry and NotPetya attacks1: 1An in-depth risk analysis of these two incidents can be found, for example, in ESRB (2020). 1 • In May 2017, the WannaCry ransomware infected around 230,000 computer devices in more than 150 countries. It encrypted data on the infected systems and demanded a ransom payment of USD 300. The encryption resulted in data loss and rendered IT systems unusable in healthcare services and in industry. It is estimated that the damage caused ranges from hundreds of millions to four billion US dollars. The discovery of a “kill switch” helped contain the incident. • In June 2017, the NotPetya malware was used for a global cyberattack that mainly tar- geted Ukraine. This version of the Petya malware was disguised as ransomware, but with the intention of causing maximum damage by encrypting data and disrupting IT systems. The encryption of data resulted in a permanent loss of its availability with immediate im- pact on institutions such as the Ukrainian Central Bank and a disruption of the country’s major stock markets. In addition, the malware was able to infect other organizations out- side the Ukrainian ﬁnancial sector with oﬃces in Ukraine, compromising machines also elsewhere. For example, the global shipping company Maersk experienced widespread business disruptions at other locations around the world, which nearly destroyed the com- pany. This paper, in view of the previous examples, focuses on systemic cyber risks which are charac- terized by contagion eﬀects in interconnected systems. Other instances of cyber accumulation scenarios are attacks based on a common risk factor such as the dependence on joint IT archi- tecture or service providers, see for instance the infamous SolarWinds attack.2 For insurance stress testing of accumulation scenarios which may not follow a contagion pattern, like DoS attacks or cloud outage, see the discussion in EIOPA (2022). In light of the rapidly growing and evolving cyber threat landscape, cybersecurity approaches that focus solely on preventing attacks may be insuﬃcient to manage and mitigate this class of systemic cyber risks. Therefore, building cyber resilience requires taking a more expansive approach that targets the “ability to anticipate, withstand, recover from, and adapt to adverse conditions, stresses, attacks, or compromises on systems that use or are enabled by cyber resources”3. Legislators and regulators have enacted a variety of laws and policies governing cybersecurity and identiﬁed the need to enhance the resilience of cyber systems. In addition, private actors may also take a leading role in shaping and guiding cybersecurity standards. In particular, the idea of (re)insurance companies acting as private regulators to ﬁll existing regulatory gaps and mitigate residual risks has emerged. But how can private and government regulators ensure an adequate level of protection against cyber threats and implement appropriate measures to build cyber resilience? What character- istics of networked cyber systems are critical to managing and controlling cyber threats and, in particular, to preventing, managing, and responding to the onset of a systemic cyber risk event? And is regulatory intervention even necessary to build eﬀective levels of cyber resilience? In this paper, we address these questions. Our key contributions are: 1. We design the artiﬁcial cyber lab, the digital twin of a complex cyber system, to evaluate diﬀerent types of cyber resilience measures. Digital twins consist of a ”physical entity, a virtual counterpart, and the data links between them,” cf. Jones et al. (2020). The virtual counterpart of interconnected cyber-physical systems is based on network conta- gion models and is therefore tailored to the analysis of systemic cyber risks such as the aforementioned WannaCry and NotPetya attacks. 2Awiszus et al. (2023) propose to classify aggregate cyber risks which depend on a common risk factor as systematic while reserving the notion systemic for cyber risks caused by local or global contagion eﬀects. 3See the deﬁnition of “cyber resiliency” in NIST (2022). 2 2. In two exemplary case studies, we leverage the lab to generate artiﬁcial data from vir- tual counterparts of real-world cyber systems to analyze speciﬁc types of cyber resilience interventions. a) Security-related interventions: Interconnected actors in a cyber network use security investments to protect themselves from cyber risk contagion. We • study a security investment game modeling network interaction and interdepen- dence eﬀects related to IT security standards; unlike the vast majority of game- theoretic models in the cyber insurance literature, our game is based on the underlying dynamic contagion captured by stochastic Monte-Carlo simulations, • rigorously prove that there exists a steady state (Nash equilibrium) of security investment decisions which, however, generally does not minimize the overall cyber risk losses of the network, • develop and evaluate diﬀerent regulatory allocation strategies to further improve the overall system security in a steady state of security investment choices, • and analyze centrality measures to identify systemically relevant nodes for the targeted allocation of cybersecurity obligations. b) Topology-based interventions: Network topology is important for both network func- tionality and the risk of cyber epidemic contagion. Therefore, we • characterize the cyber contagion risk exposure of large-scale networks, • study the eﬀect of network heterogeneity on risk ampliﬁcation, • discuss possible eﬃcient intervention strategies that minimize the negative im- pact on network functionality, • present a novel approach to quantify contagious cyber risks and eﬀectively allo- cate associated surcharges or insurance premiums based on the identiﬁcation of critical network connections. Our digital twin approach provides an experimental framework for testing and evaluating diﬀerent regulatory intervention strategies. This is particularly important due to the lack of data on historical cyber incidents and the non-stationarity of the cyber environment. Our results clearly indicate a need for regulation in order to build an appropriate level of cyber resilience. 3. Based on the ﬁndings from the case studies, selected regulatory measures that are currently in use or under debate to strengthen resilience in real-world networked cyber systems are discussed. 4. To this end, we provide a brief overview of the current regulatory framework for cyberse- curity in the European Union and the United States. In addition, we also discuss the role of private actors, particularly cyber insurance companies, in shaping security standards. Literature In the following, we will only brieﬂy review the relevant literature. For a com- prehensive overview of the various modeling and pricing approaches in the ﬁeld of cyber risk and insurance, we refer the interested reader to the most recent survey Awiszus et al. (2023). Dacorogna and Kratz (2023) provides another recent discussion on characteristics, models, and the management of cyber risks. In the actuarial literature, cyber loss models are often based on classical frequency-severity approaches; see, e.g., Zeller and Scherer (2022) for an exemplary loss model and a comprehensive literature overview, and Eling (2020) for a recent review of research in business and actuarial science. While at ﬁrst glance such approaches appear to be the most feasible from an insurer’s 3 perspective, they suﬀer from insuﬃcient or inadequate data, see also Zeller and Scherer (2023). Furthermore, in the case of systemic cyber risks such as WannaCry or NotPetya, the struc- tural importance of network eﬀects for risk emergence and ampliﬁcation cannot be adequately captured by these classical approaches. The dynamics of incidents are similar to feedback mechanisms in ﬁnancial systems such as the propagation of economic distress in a network of creditors or business partners. Interaction mechanisms of this type were, for example, studied in Giesecke and Weber (2004) and Giesecke and Weber (2006) using results from the theory of interacting particle systems. A similar approach was ﬁrst introduced in microeconomics in the seminal work F¨ollmer (1974) in which actors interact on a grid. Regulatory aspects are also not considered in frequency-severity models for cyber claims. In a game-theoretic framework, by contrast, regulatory issues as well as network interdependence of policyholders can be taken into consideration. The existing literature on strategic interactions in cyber networks has focused mainly on the impact of cyber insurance on the self-protection eﬀorts of interconnected actors, see, e.g. Ogut, Menon, and Raghunathan (2005), Bolot and Lelarge (2009), Schwartz and Sastry (2014), and Yang and Lui (2014). In most cases, market in- eﬃciencies are observed and cyber insurance is not found to provide incentives for self-protection. However, in the absence of information asymmetries between insureds and insurer(s), simpliﬁed regulatory corrective actions and measures such as ﬁnes, rebates, or mandatory cyber insur- ance may increase incentives for self-protection, see, e.g. Pal et al. (2014) and Naghizadeh and Liu (2014). For a detailed summary and comparative analysis of this literature, see Marotta et al. (2017); see also B¨ohme and Schwartz (2010), and B¨ohme, Laube, and Riek (2018). How- ever, the modeling framework adopted for risk contagion is often extremely simple and static, excluding risk ampliﬁcation and the possibility of very high loss events. In contrast, dynamic models of contagion processes provide a more realistic framework. Orig- inally, such models were developed in the ﬁeld of mathematical biology and epidemiology since the seminal work of Kermack and McKendrick (1927). In the last two decades, extensive eﬀorts have been made to incorporate the underlying contact structure within populations into the modeling framework: Epidemic processes have been generalized to networks; see, for example, Pastor-Satorras et al. (2015) and Kiss, Miller, and Simon (2017) for detailed reviews. Because of their ability to capture interconnectedness, approaches to modeling epidemics in the context of cyber risk have also appeared recently. For example, models of network contagion are utilized in Fahrenwaldt, Weber, and Weske (2018), Xu and Hua (2019), Jevti´c and Lanchier (2020), An- tonio, Indratno, and Simanjuntak (2021), and Chiaradonna, Jevti´c, and Lanchier (2023) for the purpose of pricing cyber insurance policies. Furthermore, the impact of cyber risk contagion on insurance portfolios has been analyzed in Hillairet and Lopez (2021), and more recently the network structure of interconnected industry sectors has been considered, see Hillairet et al. (2022). A dynamic contagion game was introduced in Hayel et al. (2014) using the Markov- SIS model (but based on the easily tractable, albeit rough, NIMFA approximation). However, to our knowledge, the regulation, management, and control of contagious cyber risks have not yet been studied in a modeling framework based on dynamic contagion. Beyond the ﬁeld of cyber risk, applications of network models to insurance-related problems are less common in the literature. Existing works focus, for example, on the implementation of data science methods such as fraud detection techniques, see Tumminello et al. (2023), or study the systemic risk in ﬁnancial networks where insurance companies themselves are present as interdependent ﬁnancial actors, such as in Chen et al. (2020) and Chen and Sun (2020). Studies of network resilience and robustness can be found in the engineering and computer science literature. However, much of the work focuses exclusively on measurements of network topology properties (see Freitas et al. (2022) for a recent overview) or is based on models of lateral network movements that do not capture the infection and recovery dynamics of risk contagion (see Chen, Tong, and Ying (2018) or Freitas et al. (2020)). Moreover, resilience building is studied only from a network perspective and not in a regulatory framework. A 4 speciﬁc attempt to build network resilience against self-propagating malware, and in particular the WannaCry worm, was recently presented in Chernikova et al. (2022). The authors use synthetic WannaCry data to derive an adequate contagion model, similar to the classic SIR model, and appropriate parameter estimates. However, this model follows a deterministic top- down population-based approach, whereas our study is based on a stochastic bottom-up model of node-level interactions. Again, resilience is considered from an engineering perspective rather than a regulatory one, and issues of network economics and risk management are also not considered. Outline The paper is organized as follows. In Section 2, we provide a brief overview of current cybersecurity legislation in the European Union (EU) and the United States of America (US), and also mention the regulatory role of private actors and insurance companies. Based on this, we present a selection of current approaches from the ﬁeld to strengthen cybersecurity. In Section 3, we introduce the artiﬁcial cyber lab, and in the following two sections, we conduct the aforementioned illustrative case studies to analyze security- and topology-based cyber resilience measures. In light of these ﬁndings, we also revisit the selected real-world approaches from Section 2. Section 6 concludes. 2. The Real World: The Current State of Cybersecurity Regulation In what follows, we brieﬂy discuss the main characteristics of current cybersecurity legislation in the EU and the US, as well as the role of private actors such as insurance companies in shaping cybersecurity standards. This discussion will serve to identify and classify a set of real-world measures for improving resilience to cyberattacks, which we will then discuss in light of our ﬁndings from simulations conducted in the artiﬁcial cyber lab. 2.1. Current Government Regulations for Cybersecurity Due to the enormously increasing importance of cybersecurity to the functioning of modern so- cieties, lawmakers have enacted several regulations, including a variety of legal norms. However, given the non-stationary nature of cyberspace, policymakers tend to future-proof their regula- tions by using indeterminate legal terms when formulating security requirements. Examples of such phrases include “adequate security measures” or “adequate technical and organizational measures,” see below. On the one hand, this can guarantee a high level of cybersecurity, even if a new technology or vulnerability is found. On the other hand, the indeterminacy of the legal terms introduces a signiﬁcant degree of uncertainty as to the “correct” cybersecurity mea- sures to be taken. In light of the latter problem, a growing number of technical standards and guidelines published by organizations such as the Cybersecurity & Infrastructure Security Agency (CISA) and the National Institute of Standards and Technology (NIST) in the U.S., the International Organization for Standardization (ISO), the European Network and Information Security Agency (ENISA), or TeleTrusT - IT Security Association Germany and the Bunde- samt f¨ur Sicherheit in der Informationstechnik (BSI) in Germany provide speciﬁc guidance, see for example TeleTrusT (2021) and BSI (2022). While some of these standards actually serve as guidelines for government institutions, they are not legally binding for private companies, and furthermore they are usually characterized by a high degree of complexity, see for example BSI (2022). Both the non-legally binding nature and the complexity may prevent companies from implementing these standards in practice. Cyber Security Legislation in the EU and the US Protection of Critical Infrastructure 5 • The EU sets minimum standards for cybersecurity of critical infrastructure in the 2020 NIS Directive.4 The requirements include organizational provisions such as risk analysis and policies for information systems security, incident handling, business continuity and crisis management, supply chain security, and IT-related technical safeguards. In this context, critical infrastructure operators are required to implement “appropriate security measures.” However, the speciﬁc design of these measures is not speciﬁed in the directive. • In the US, the Cybersecurity and Infrastructure Security Agency Act of 2018 entailed the establishment of the Cybersecurity & Infrastructure Security Agency (CISA) by the Department of Homeland Security. The CISA regularly publishes Binding Operational Directives in which explicit actions improving the cybersecurity of federal civilian agencies are stated. For example, the recently published Directive BOD 22-01 requires all federal civilian agencies to remediate newly discovered exploits within a period of two weeks since disclosure, based on a regularly updated catalogue of known exploited vulnerabilities. Thereby, CISA sets a ﬁxed threshold for software and service providers to roll out patches and updates for their respective end users. Although the BOD 22-01 targets federal civilian agencies only, CISA itself strongly recommends that private businesses review and monitor the catalogue to strengthen their cybersecurity. Data Protection • The General Data Protection Regulation (GDPR) is the centerpiece of data protection legislation in the EU. It has been in force since May 25, 2018 and regulates the handling of personal data. The central provision of data protection is addressed in Art. 32 GDPR, which requires the implementation of “appropriate technical and organizational measures”, taking into account the “state of the art, the implementation costs, and the nature, scope, circumstances, and purposes of data processing”. However, these terms are not further speciﬁed. • In the US, many federal states have introduced legislation on data protection. Again, in- determinate legal terms are used to deﬁne legislative requirements. For example, Section 1798.81.5 (b) and Section 1798.81.5 (e) of the California Consumer Privacy Act (CCPA) state that “a business that collects a consumer’s personal information shall implement reasonable security procedures and practices appropriate to the nature of the personal information to protect the personal information from unauthorized or illegal access, de- struction, use, modiﬁcation, or disclosure” – without specifying which measures may be considered “reasonable security procedures”. 2.2. Regulation by Private Actors and the Role of Insurance Companies Against the backdrop of legal uncertainty associated with the presence of indeterminate terms under current legislation and the fact that recommended technical standards are typically not legally binding for business corporations, private actors may play an essential role in cyberse- curity governance by implementing and shaping security standards. For example, Hurel and Lobato (2018) discuss the role of private companies as entrepreneurs of cyber standards, with particular attention to Microsoft’s eﬀorts to inﬂuence global security standards and policies. 4See the “Directive (EU) 2016/1148 of the European Parliament and of the Council of 6 July 2016 concerning measures for a high common level of security of network and information systems across the Union”. Later, we will also discuss the newly proposed NIS2 Directive which is set to replace the existing regulatory framework for critical infrastructures in the EU. 6 For insurance companies and ﬁnancial institutions, cyber security is an increasingly important issue because of their signiﬁcance to society and the sensitive data they hold. An empirical study on this issue and its growing relevance within the US banking and insurance industry has been presented in Gatzert and Schubert (2022). Also, Sweetman (2022) provides a ﬁrst history of computer security and network protection within major institutions from the UK banking sector. In this paper, in contrast, we will focus to a greater extent on the particular role that cyber in- surance companies can play in promoting security standards among their policyholders. This role has also been studied in, for instance, Trang (2017), Talesh (2018), Woods and Moore (2020), Herr (2021), and Lemnitzer (2021). There, it is found that insurers may act as private regulators in cybersecurity governance: Cyber insurance is an eﬃcient way for companies to manage their cyber risk and seek assistance in implementing appropriate security measures. Hence, insurance companies can promote cybersecurity and resilience for their policyholders by setting certain standards in their contractual obligations. 2.3. Selected Measures of Cyber Resilience In the previous sections, we discussed the current framework of cybersecurity regulation and emphasized the role of both governments and private actors such as insurance companies in implementing cyber security standards and strengthening resilience. In this section, we present a selection of concrete measures to improve cyber resilience focusing on systemic cyber risks that are either already part of current practice or currently under discussion. In particular, we include some measures which appear in the European Commission’s proposal for replacing the existing NIS legislation by a new NIS2 Directive5. Consistent with the previous discussion, we will distinguish between government regulation (GOV) and private regulation, particularly insurance-based regulation (INS). In addition, we will distinguish between measures targeting the IT-security (security-related interventions) and those aiming at the structure of the net- work (topology-based interventions). To understand why we consider both, recall the infamous WannaCry and NotPetya attacks mentioned in the introduction, which can serve as models for studying systemic cyber risk. In both of these incidents, the risk propagation was due to the spread of malware across a network of interconnected actors and was characterized by the following two key aspects: • Both attacks resulted from an initial vulnerability of Windows-based computer systems: devices that had not applied the latest patches from Microsoft or were running outdated systems were aﬀected. Improved IT-security – in this case: regular software updates – may have prevented these attacks. • Both cyber epidemics spread through IT networks and aﬀect many interconnected com- puters across diﬀerent institutions at a global scale. Controlling the topology, especially the connections to critical parts of the network, might have reduced the damage caused. Security-Related Interventions We consider the following security-related interventions: GOV ⋄Size-cap rule: Instead of covering all, the proposal for the new NIS2 Directive suggests limiting the scope of the Directive to medium-sized and large compa- nies operating in the targeted sectors or providing services covered by the NIS2 5See the “Proposal for a Directive of the European Parliament and of the Council on measures for a high common level of cybersecurity across the Union, repealing Directive (EU) 2016/1148—EU-doc. COM (2020) 823 ﬁnal, dated 16 December 2020”. A discussion on the proposal is provided in Sievers (2021). 7 Directive. In general, micro or small enterprises from critical infrastructure sec- tors should not be aﬀected by the directive while exceptional cases are listed in Article 2, §2. ⋄Supply chain protection: Article 18, §2 of the NIS2 proposal contains a new catalog of cybersecurity risk management measures that are intended to reﬂect the state of the art. Speciﬁcally, supply chain security measures must be im- plemented by addressing “security-related aspects concerning the relationships between each entity and its suppliers or service providers such as providers of data storage and processing services or managed security services”. Note the use of the indeterminate legal term “state of the art”. Nonetheless, we adopt the idea of supply chain protection as a concrete measure that can be analyzed. INS ⋄Assistance services: Depending on the policyholder’s own (lack of) expertise, the policyholder’s level of security can be signiﬁcantly increased by providing or requiring investment in cyber assistance services. Cyber assistance services include implementation services, staﬀtraining, and external security testing for policyholders. Some insurers also oﬀer a 24/7 hotline with direct contact to tech- nical experts, as well as public relations and legal experts at their own expense to minimize the potential damage from an ongoing cyberattack. Insurers could potentially mandate additional services for certain policyholders. ⋄Patch management and backup: The use of a patch management procedure and the application of a backup process are already part of the current cyber insurance practice, see, for instance, Section A1-16 in GDV (2017). However, eﬃciently tailoring these obligations to the characteristics of the policyholder can further improve their eﬀectiveness. Intuitively, the requirements for individual cybersecurity investments should contribute to a higher level of security for the overall system. However, increasing the level of security comes at a cost. There is, of course, a trade-oﬀbetween the cost of maintaining a high level of cybersecurity and potential losses from cyberattacks. The situation becomes particularly complex when one considers that networked actors imply interdependent levels of IT security. The question naturally arises whether individually rational security investment decisions by network actors already provide a sound level of security for the system as a whole, or whether interdependence calls for additional security commitments? And if such extra commitments are necessary, how should they be implemented within a cyber network? Topology-Based Interventions The topological arrangement of the interconnected agents is critical to the extent of resulting cyber risk. We will consider the following topology-based arrangements: GOV ⋄Incident response and reporting: Computer security incident response teams (CSIRTs) shall be designated by each EU member state according to Article 9 of the NIS2 proposal. Speciﬁc requirements and tasks for CSIRTs are deﬁned in Article 10, including the monitoring of cyber threats, the implementation of an early warning system, and the provision of proactive network scanning upon request of an entity. In addition, Article 20 obliges “essential and important entities” to report incidents with a signiﬁcant impact on their functioning or the 8 provision of their services to regulatory authorities or the CSIRT without undue delay. ⋄Critical supply chains: In addition to IT-security aspects, also the underlying pattern of connections between business partners (and their partners) and along production chains may play an important role in securing supply chains. There- fore, the risk assessment of network characteristics may help protect highly inter- connected industries and infrastructures. Article 19 of the NIS2 proposal allows for EU coordinated assessments of critical supply chains, identiﬁed by the Com- mission in consultation with ENISA. INS ⋄Contact liability premiums: A major concern are existing contagion channels for risk spreading and ampliﬁcation. For instance, policyholders might have to pro- vide so-called need-to-access information when signing cyber insurance contracts, see for instance Kategorie B.4 in GDV (2019). The idea is to monitor the num- ber and type of access to a given IT facility and thus control potential contagion channels. To counteract possible accumulation scenarios, it might even be sensi- ble to introduce additional risk premiums for systemic cyber events that depend on the existing contagion channels. ⋄Insurance backstop mechanism: Lemnitzer (2021) argues for the necessity of a state-funded backstop mechanism for systemic cyber incidents to cover the losses of catastrophic events, similar to the Terrorism Risk Insurance Act (TRIA) which was established in the United States after 9/11. Here, a federal guarantee could be given to the insurance industry; after the occurrence of a systemic cyber event, mandatory surcharges could be imposed to the policyholders for the settlement of the costs incurred. Similar to the allocation of contact liability premiums, the size of these surcharges could correspond to the policyholders’ individual contribution to the overall systemic risk. Here too, of course, a trade-oﬀexists between viewing the network links as contagion chan- nels and providing an eﬀective infrastructure for data distribution. Obligations should be im- plemented in a way that minimizes any negative impact on network functionality. But how can the exposure to large cyber risk be assessed in complex network arrangements? What net- work characteristics do signiﬁcantly increase the risk of large-scale cyber events? And how can eﬀective topology-based measures be designed and implemented? 3. The Artiﬁcial Cyber Lab - the Digital Twin of a Complex Cyber System Important characteristics of cyber risk are the scarcity of data and the non-stationarity of the cyber environment due to the rapidly evolving IT-infrastructure. However, since classical statistical and actuarial models follow a frequency-severity approach and thus heavily rely on a suﬃcient amount of meaningful data, these standard methods are insuﬃcient to evaluate the impact of cyber resilience interventions. To explore the questions from the previous section and assess the quality of proposed measures, we follow the digital twin paradigm and propose a novel approach based on models from network science and contagion theory; an experimental setup where cyber resilience measures can be implemented and tested through analysis and simulation - the artiﬁcial cyber lab. To build the virtual counterparts of real-world cyber systems, a certain degree of abstraction 9 is necessary to provide a suﬃciently complex but still tractable modeling framework. In general, network models for cyber risk contagion consist of three key components which we will sketch subsequently: (i) A network representing interaction channels between agents or entities, (ii) a model for the spread of a certain cyber threat through these interaction channels, (iii) and a loss model determining the (monetary) losses occurring at the diﬀerent agents due to the spread of the considered cyber threat. 3.1. Networks Systems of interconnected agents, like companies with data exchange, computer systems, or single devices, can mathematically be interpreted as networks. Agents are represented as nodes, and the interaction channels (potential infection channels) between them as edges. Exemplary network structures are depicted in Figure 1. 1 2 3 4 5 6 7 8 (a) fully connected 1 2 3 4 5 6 7 8 (b) star-shaped 1 2 3 4 5 6 7 8 (c) branching tree Figure 1: Exemplary network structures with N = 8 nodes. A simple (unweighted) network connecting N diﬀerent agents can be represented by its ad- jacency matrix A = (aij)i,j∈{1,...,N} with aij ∈{0, 1}: here, aij = 1 indicates that nodes i and j are directly connected, aij = 0 indicates no direct connection.6 For example, in the case of the tree network depicted in Figure 1 (c), A is given by A =         0 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 1 0 0 1 1 0 0 0 1 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0         . 3.1.1. Random Network Models In applied network analysis, the exact network structure is often unknown. In this case, random network models enable sampling from a class of networks with given ﬁxed topological charac- teristics (such as the overall number of nodes). In a random network, each possible edge in the network is present (or absent) with a given ﬁxed probability. We consider the following two standard classes of undirected random networks:7 6Alternatively, weighted networks could be considered. Here, aij > 0 represents the strength of the connection between nodes i and j. 7Pseudocode for both random network models is provided in Appendix C. 10 • Erd˝os-R´enyi networks: The simplest random network model was introduced by Erd¨os and R´enyi (1959): The Erd˝os-R´enyi network Gp(N) is constructed from a set of N nodes in which each of the possible N(N −1)/2 edges is independently present with the same probability p, i.e., the expected number of edges is given by (N(N −1)p)/2 ≈(N 2p)/2 for large N. • Barab´asi-Albert networks: A phenomenon widely observed in the empirical analysis of networks, including the world wide web, IT networks, and social networks, is that newly formed connections tend to emerge at nodes with an already large degree. For example, newly created websites are more likely to link to an already existing popular website than to other websites. This principle is called preferential attachment. Hence, real-world net- works are usually more heterogeneous in terms of their topology than the Erd˝os-R´enyi model would suggest. Often, a hierarchy of nodes is observable—with a few nodes of high degree (called hubs), and a vast majority of less connected nodes. A ﬁrst model, motivated by the study of citation networks of academic papers, was introduced and dis- cussed in Price (1965) and Price (1976). The most commonly applied random graph model for networks which follow a preferential attachment principle is the one from Barab´asi and Albert (1999). Diﬀerent from the Erd˝os-R´enyi model, a Barab´asi-Albert network BA(N; m) with N nodes is generated by a growing network algorithm: Starting from an initial core with n0 nodes, m ≤n0, and ǫ0 edges, a new node i is added to the graph in each simulation step and m edges for i are randomly generated following a preferential attachment rule. The number of edges for the resulting network is given by m(N −n0)+ǫ0, which, neglecting the initial core, can be approximated by mN. 3.1.2. Measuring Centrality In network science, the structural importance of single nodes or edges within the network can be characterized using centrality measures C. However, centrality is not a rigorously deﬁned term and a large variety of diﬀerent concepts has been proposed. 1. For a network edge e, a common way to measure centrality is to consider the fraction of shortest paths between any two nodes i and j that pass through e. The corresponding measure is then called edge (betweenness) centrality,8 and, can be written as Cedge(e) = X i,j σij(e) σij , (1) where σij denotes the number of shortest paths between nodes i and j, and σij(e) is the total number of these paths that go through edge e. 2. For a network node i, two of the most frequently used measures are9 • Degree centrality: Here nodes are simply ranked by their number of network neigh- bors, i.e., Cdeg(i) = N X j=1 aij = N X j=1 aji, i = 1, . . . , N, (2) for an undirected graph. It accounts for immediate network eﬀects. • Betweenness centrality: In contrast to degree-based approaches, betweenness central- ity focuses on the role nodes may play as connections or “bridges” between diﬀerent 8This centrality measure was introduced in Girvan and Newman (2002). 9For an extensive overview we refer to Chapter 7 in Newman (2018). 11 network regions. In analogy to the concept of edge betweenness centrality, the cor- responding deﬁnition on the node level is given by Cbet(i) = X j,h σjh(i) σjh , i = 1, . . . , N, (3) where σjh denotes the total number of shortest paths between nodes j and h, and σjh(i) is the particular number of these paths that go through node i. 3.2. Modeling Contagious Cyber Risks Through the interaction channels described by the chosen network, a contagious cyber risk may spread. Mathematical models describing the spread of cyber epidemics on networks ﬁrst divide the set of agents into distinct categories varying over time: e.g., individuals that are susceptible to an infection, infected, and recovered individuals. The SIS (Susceptible-Infected- Susceptible) and SIR (Susceptible-Infected-Recovered) Markov models constitute frequently used epidemic spreading models on networks. The diﬀerence between them is the presence (SIR) or absence (SIS) of immunity: While reinfection events are possible in the SIS framework, in the SIR framework, recovered individuals gain permanent immunity. A rigorous discussion of the mathematical aspects is provided in Appendix A. The possible transitions in these two models as well as their two key parameters, the infection rate τ and the recovery rate γ, are illustrated in Figure 2.10 I S I I τ I S γ (a) SIS Model I S I I τ I R γ (b) SIR Model Figure 2: Infection and recovery for the SIS and SIR model in a network: A susceptible node is infected by its contagious neighbor with rate τ. Independent from the state of its neighbors, an infected node recovers at rate γ. SIS and SIR diﬀer in terms of immunity: In the SIS model, a recovered node is susceptible again such that multiple infections for the same node are possible. In contrast, recovery in the SIR model means that the node is immune and cannot be infected again. 3.3. Cyber Loss Models Finally, agents, i.e., nodes in the network, may experience losses due to a cyber infection. Depending on the modeling purpose, the cyber loss model may emphasize diﬀerent aspects of an ongoing cyber incident, like the total number of aﬀected network components, aggregate losses of network nodes, and the monetary losses of single entities. Typically, an adequate model should reﬂect on the stochastic nature of risk scenarios and capture key statistical aspects of cyber loss distributions, including loss expectations and tail risk properties. 3.4. Artiﬁcial Cyber Lab Setup For our design of the artiﬁcial cyber lab, a fundamental choice has to be made in terms of the contagious spread model, namely between an SIR and SIS approach (see Figure 2). Since we 10There also exist more nuanced models, e.g., containing only a limited immunity (SIRS) or an additional category of exposed individuals, i.e., individuals that are infected but not yet contagious (SEIR). For more details, see, e.g., Pastor-Satorras et al. (2015) and Kiss, Miller, and Simon (2017). 12 consider attacks similar to the WannaCry and NotPetya attacks, which were both based on the EternalBlue exploit, we assume that reinfections are rather unlikely because—once detected— the underlying security issues are easily solvable through the installation of the latest patches. Therefore, we will use the SIR model.11 The key in- and output parameters can be summarized as follows: • Input: – Network: ∗network size N (number of agents) ∗topological structure A = (aij)i,j=1,...,N, i.e., the connectivity pattern between nodes (see Figure 1 for examples) ∗number and position of initially infected nodes – Epidemic Dynamics: ∗infection rate τ = 0.1 (determines the speed of the infection), assumed to be equal for all connections12 ∗individual recovery rates γi for nodes i = 1, . . . , N (inﬂuence the time needed for recovery—interpreted as IT security level, see Section 4) – Loss Distribution: ∗stochastic modeling framework for loss formation • Output: – Epidemic Dynamics: ∗spread of cyber infection over time, total number of aﬀected nodes, probability of infection for each node – Loss Distribution: ∗aggregate losses for single nodes or the entire network In the following, we use the lab to generate artiﬁcial data from our virtual model and evalu- ate two diﬀerent types of cyber resilience interventions. Based on the results, we discuss the implications of our ﬁndings on the implementation of concrete cyber resilience measures for real-world cyber systems. 4. Case Study I: Security-Related Interventions under Strategic Interaction For both the WannaCry and NotPetya attacks, the vulnerability of systems was crucially depen- dent on the security eﬀorts taken by individual network users. Therefore, we ﬁrstly introduce a suitable model for security levels, beneﬁts and costs within the framework of our artiﬁcial cyber lab. However, due to the interconnectedness of entities in cyber systems, the individual risk exposure is also inﬂuenced by the security choices of other network participants: Interde- pendence and strategic interaction of diﬀerent actors constitute a key characteristic of systemic 11A similar choice has also been made in Hillairet and Lopez (2021) for modelling the WannaCry attack. Here, the authors use the population-based ODE system from Kermack and McKendrick (1927) instead of a stochastic network model. 12Reasonable estimates of the infection speed in contagious cyber incidents cannot be derived due to insuﬃcient data. We assume τ = 0.1, which in a Markovian setting corresponds to the expected waiting time of 10 units of time for infectious transmission over a network edge. Our results can easily be adapted to a speciﬁc infection speed scenario by adequate interpretation of the time unit. 13 cyber risks. Therefore, we develop a security investment game in order to study interdependence eﬀects within the cyber network. Finally, we evaluate if, and how, security-related interventions in the form of additional security obligations can eﬃciently be allocated among network nodes to improve the overall safety of the cyber system. 4.1. Security Investments and Strategic Interaction In our SIR model, the cyber risk exposure of network nodes depends on the epidemic infection and recovery rates. For tractability reasons, we assume a ﬁxed homogeneous infection rate τ (see Section 3.4) and vary the individual recovery rate γi of node i = 1, . . . , N which we will interpret as security level: The lower the security level γi, the longer it takes for ﬁrm i to detect a cyber infection or an existing security gap. Consequently, this also aﬀects the risk exposure of the ﬁrm’s direct network neighbors, see Figure 3. I S S γi (a) Low Security Level I S S γi (b) High Security Level Figure 3: Contagious spreading for initially infected nodes with low and high recovery rates γi. The value of γi reﬂects the IT security level and protection eﬀorts of company i. From the perspective of the individual node i, the choice of security level γi results from the trade-oﬀbetween the following two functions: 1. The cyber loss function Li(γ1, γ2, . . . , γN) describes the losses of node i – as a function of all nodes’ security levels due to the interconnectedness of network agents. In general, a loss model may capture a variety of aspects, see the discussion in the previous section. Clearly, the amount of cyber losses should be related to the duration of a cyber attack, which, for instance, may correspond to downtime of services13 and business interruption costs. We choose a simple and tractable loss model by setting Li := Li(γ1, . . . , γN) := E h Z ∞ 0 Ii(t)dt i which represents the expected amount of time node i will spend in the infectious state I, given the security levels γ1, . . . , γN. In particular, Li can be reduced by increasing the security level γi. For details, see Appendix D. SIR infection dynamics are described by an ordered system of equations; see Appendix A for details. Note that the order of SIR equations increases up to the network size N. Hence, solving the exact system is intractable for complex networks due to the large number of system equations. We thus follow a stochastic simulation approach.14 Further details are given in Appendix E. 2. The cost function Ci(γi) describes the cost of the implementation of security level γi for node i. For simplicity, we let Ci = C for all i = 1, . . . , N. Typically, such a cost function should be strictly convex, representing a rapidly increasing cost with increasing targeted 13For example, this idea has been proposed in the loss model from Xu and Hua (2019). 14Trajectories of the SIR dynamics can be generated using the well-known Gillespie algorithm, cf. Gillespie (1976) and Gillespie (1977). Pseudocode is provided in Appendix B. 14 security level. Further, C should satisfy C(0) = 0. For simplicity and tractability, we choose an exponential function C(γi) = ekγi −1, k > 0, with growth constant k. In the following, we set k = 1/3. A rational network agent i will try to minimize her total expenses Ei(γ1, . . . , γN) = Ci(γi) + Li(γ1, . . . , γN), i.e., the competing sums of security costs and cyber losses, as a function of γi. As noted in Section 3.4, we choose the ﬁxed homogeneous rate τ = 0.1 for the infection dynamics. The contagion process is initialized at time t = 0 by the random infection of a single node. We remark that there are, of course, many reasonable choices for the loss and cost function and thus the total expenses, and also the infection dynamics. However, since our studies are of a qualitative and not a quantitative nature, we believe that our choices are suited to gain a basic understanding of the problem. 4.1.1. Individually Optimal Security Level Under the assumption that for all nodes j ̸= i the security level γj remains unchanged, a security level γi is individually optimal for node i, if it minimizes the total expenses Ei, i.e., a rational agent will choose the individually optimal security level γind i (γ−i) := arg min γi∈[0,∞) Ei(γ1, . . . , γN) where γ−i := (γ1, . . . , γi−1, γi+1, . . . , γN). An example for node 3 from the branching tree in Figure 1 is shown in Figure 4. 0 0.5 1 1.5 2 Security investment 3 0 0.5 1 1.5 2 Figure 4: Cyber losses, security costs, and total expenses of node 3 in the branching tree from Figure 1 as a function of the security level γ3. Infection rates are assumed to be homogeneous, τ = 0.1, and security levels are set to γj = 0.1 for j ̸= 3. The value γind 3 = 0.943 is individually optimal. Cyber losses are calculated using the decom- position scheme from Appendix D: T = 10, 000, 000 trajectories of the SIR process were generated to determine the probability P(A3) where A3 is the event that node 3 becomes infected. For each simulation, the initially infected node was randomly chosen. 15 4.1.2. Strategic Interaction of Interdependent Actors The security level choices of network agents do not only aﬀect their individual expenses Ei but also the cyber losses Lj, j ̸= i, of other network nodes. Therefore, these nodes will in turn react to the new threat situation, initializing a cascade of strategic interactions. We will call this the security investment game. A steady state of individually optimal security levels is a choice of security levels γ ∈(0, ∞)N such that ∀i = 1, . . . , N : γind i (γ−i) = γi. In other words, a steady state is a Nash equilibrium of the security investment game. The following theorem asserts the existence of steady states of individually optimal security levels. The proof of Theorem 4.1 is provided in Appendix F. Theorem 4.1. Steady states of individually optimal security levels exist. Note that the theorem holds for basically any reasonable choices of cost functions Ci and loss functions Li as long as the total expenses Ei remain strictly convex in γi and admit a minimum point. In that case the proof would make use of Berge’s maximum principle. We implement the security investment game as a dynamical game with several rounds r = 0, 1, . . . , M where every round r starts with a ﬁxed vector of security levels γ(r) = (γ1(r), γ2(r), . . . , γN(r)). Algorithm 4.2 (The Security Investment Game). Input: Initial conﬁguration γ(0) ∈(0, ∞)N, number of rounds M ∈N>0. 1. (Initialization) Set r →0. 2. For every node i, i = 1, . . . , N, calculate γi(r + 1) = arg min γi∈[0,∞) Ei(γ1(r), . . . , γi−1(r), γi, γi+1(r), . . . , γN(r)). More details are given in Appendix E. Set γ(r + 1) = (γ1(r + 1), γ2(r + 1), . . . , γN(r + 1)). 3. If r < M, set r →r + 1, and return to Step 2; otherwise end. Output: Security conﬁguration γ(M) after M rounds 4.1.3. Complex Network Interactions We study the strategic interaction in two particular ﬁxed networks: one generated from the Erd˝os-R´enyi class with parameters N = 50 and p = 0.16, and another one drawn from the Barab´asi-Albert class with N = 50 and m = 4. Note that these two exemplary networks are comparable with respect to their number of network connections, cf. Section 3.1.1. Visualiza- tions are provided in Figure 5. On both networks, we conduct the security investment game (Algorithm 4.2) with M = 50 rounds and initial security level γi(0) = 0.1 for all nodes i. To generate values for the cyber losses Li, in each round of the game, T = 10, 000, 000 trajectories of the SIR epidemic process are simulated; see Appendix E for details. The results of the security investment game in the steady state, γstead = (γstead 1 , . . . , γstead N ), are represented by node colors in Figure 5. For both network arrangements, we observe that 16 Figure 5: Visualization of the considered exemplary networks drawn from the Erd˝os-R´enyi (left) and Barab´asi-Albert (right) classes. Nodes are colored according to their chosen level of security after round 50 of the security investment game (Algorithm 4.2): the darker the color, the higher the chosen security level (for Erd˝os-R´enyi: minimum: 0.3780, maximum: 0.6526; for Barab´asi-Albert: minimum: 0.4719, maximum: 0.7598). Data is based on T = 10, 000, 000 trajectories of the SIR epidemic process for each round of the security investment game. more central nodes choose higher security levels than nodes in the periphery. The accumulated total expenses E(γstead) := N X i=1 Ei(γstead 1 , . . . , γstead N ) are given by E(γstead) ≈21.66 for the Erd˝os-R´enyi-type, and E(γstead) ≈21.92 for the Barab´asi- Albert-type network, respectively. 4.2. Demand for Regulation: Allocating Additional Security Investments In this section we address the question whether the individually optimal security choices given by a steady state γstead are also favorable from an overall network perspective, i.e., do they minimize the accumulated total expenses E(γ), or can additional security investments further improve the situation? In fact, the individually optimal security choices will in general not lead to a minimization of the overall network expenses, see Appendix G for a simple example. Indeed, it is well-known that Nash equilibria (steady states) do not in general minimize the social welfare function which in this case is the total expenses. In our case, a profound systematic characterization of the latter observation is, however, still an open challenge due to the lack of suﬃcient analytical tractability of the network dynamics, f.e., see Section 3.5.3 in Kiss, Miller, and Simon (2017) for a similar problem. As indicated by the distribution of steady state security investments shown in Figure 5, a key role in identifying good allocations of additional security investments may be played by the individual nodes’ centrality. To this end, recall the degree and betweenness centrality of network nodes introduced in Section 3.1.2. Note that these standard centrality measures from the literature are solely based on the underlying network topology. The security investment game, however, suggests yet another way of measuring centrality, namely by ﬁxing a steady state γstead and deﬁning the centrality of node i to be the individually optimal investment Cinv(i) = γstead i . In the following, we will refer to this latter centrality measure as the investment-based centrality. 4.2.1. Allocation Strategies In view of the previous discussion, in this section we proceed as follows: 17 1. We start from a steady state γstead of individually optimal security levels. Moreover, we ﬁx an additional security budget β > 0. 2. This extra amount of security is allocated amongst the nodes according to one of the following strategies: a) Untargeted allocation: β is uniformly distributed among all network nodes, provid- ing an additional security investment γall i = β/N for each node i. b) Targeted allocation: we choose a centrality measure C and determine the allocation weights wi := C(i) PN j=1 C(j), i = 1, . . . , N. Based on these allocation weights we consider two opposing procedures: i) The upper allocation strategy allocates β proportionally γall i := β · wi. Here a higher amount of β is assigned to nodes with a higher degree of centrality. ii) The lower allocation strategy does the opposite. To this end, we calculate the inverse allocation weights ˆwi := ( w−1 i if wi ̸= 0 0 else. In this case the additional security investment γall i = β · ( ˆwi/ PN j=1 ˆwj) for node i assigns a higher amount of β to nodes with a lower, yet positive, degree of centrality. The proposed allocation procedures yield a new vector of security levels ˜γ with entries ˜γi = γstead i + γall i , i = 1, . . . , N. 3. Finally, we calculate the accumulated total network expenses E(˜γ) under the new security conﬁguration. 4.2.2. Allocation for Complex Networks We compare the diﬀerent allocation strategies and centrality measures for the Erd˝os-R´enyi- and Barab´asi-Albert-type networks from Figure 5 by allocating an additional budget of β = 5. The strategies are visualized in Figure 6 and the resulting reductions of total network expenses are shown in Table 1 on a percentage basis. cdeg cbet cinv upper 10.6% 11.3% 10.8% 12.3% 10.2% 9.6% lower 8.2% 6.7% 0.5% 3.4% 9.5% 8.3% untargeted 9.9% 9.0% Table 1: Percental reduction of accumulated total expenses E after the allocation of the addi- tional budget β = 5 among all network nodes. The three proposed allocation strategies are evaluated for each of the suggested centrality measures. Entries for the Erd˝os- R´enyi network are colored in blue (left entries), and for the Barab´asi-Albert network in salmon (right entries), respectively. For each entry, cyber losses were generated from T = 10, 000, 000 simulations of the SIR epidemic process. Full data is given in Appendix H. 18 Weights − Betweenness 0.05% (rank 50 (Min.)) 0.74% (rank 40) 1.57% (rank 30) 2.23% (rank 20) 2.88% (rank 10) 4.97% (rank 1 (Max.)) (a) Weights − Degree 0.53% (rank 50 (Min.)) 1.32% (rank 40) 1.85% (rank 30) 2.12% (rank 20) 2.65% (rank 10) 3.17% (rank 1 (Max.)) (b) Weights − Investment 1.34% (rank 50 (Min.)) 1.81% (rank 40) 1.98% (rank 30) 2.09% (rank 20) 2.17% (rank 10) 2.32% (rank 1 (Max.)) (c) Weights − Betweenness 0.06% (rank 50 (Min.)) 0.24% (rank 40) 0.42% (rank 30) 1.32% (rank 20) 3.51% (rank 10) 13.76% (rank 1 (Max.)) (a) Weights − Degree 1.05% (rank 50 (Min.)) 1.05% (rank 40) 1.32% (rank 30) 1.84% (rank 20) 2.89% (rank 10) 6.05% (rank 1 (Max.)) (b) Weights − Investment 1.66% (rank 50 (Min.)) 1.75% (rank 40) 1.84% (rank 30) 2.03% (rank 20) 2.30% (rank 10) 2.68% (rank 1 (Max.)) (c) Figure 6: Exemplary visualization of centrality weights wi in the Erd˝os-R´enyi (top) and Barab´asi-Albert-type (bottom) network for (a) betweenness, (b) degree, and (c) in- vestment centrality. In any case, we observe that the injection of additional network security clearly reduces the accumulated total expenses. Comparing the diﬀerent allocation procedures, we see that the upper allocation strategy leads to lower overall losses than both the untargeted and lower allocation strategies – regardless of the centrality measure chosen. Moreover, for both types of networks, we observe that the upper allocation strategy combined with topology-based centrality measures outperforms the investment-based approach. In par- ticular, the upper allocation strategy based on betweenness centrality yields the best outcome. A possible reason for this is that the proportion of budget which is allocated to periphery nodes is too large in both the untargeted and investment-based case: e.g., for the graph from the Erd˝os-R´enyi class, the investment-based centrality of periphery nodes is more than half the size of the maximum node centrality, see Figure 6 (c). In contrast, the betweenness centrality of the most isolated nodes is close to zero, and therefore, almost no additional security investment is allocated to these nodes, see Figure 6 (a). 4.2.3. Further Centralization of Upper Allocations Our previous observations suggest that additional security investments should not be distributed equally among nodes, but in accordance with their centrality following an upper allocation strategy. Introducing speciﬁc requirements for every network entity may be diﬃcult or even im- possible from a regulatory point of view. For example, the upcoming NIS2 Directive introduces a speciﬁc size-cap rule which solely targets medium-sized and large entities in sectors of critical infrastructure, see the discussion in Section 2.3. But does the exclusion of low-centrality nodes from the allocation procedure substantially reduce the beneﬁcial eﬀect of additional network security? Or can we even improve the eﬀectiveness of security obligations if only a certain fraction of highest-centrality nodes is considered? To answer these questions, the upper allocation procedure is slightly modiﬁed: Suppose we 19 want to restrict the budget allocation to a certain fraction p of nodes with the highest centrality, and let I denote the set of corresponding node indices. Then, the amount of budget which is allocated to node i is chosen as γall i = ( β · (C(i)/ P j∈I C(j)), if i ∈I, 0, else. Note that for p = 100%, this coincides with the previously studied upper allocation strategy on the full network. Results of the modiﬁed procedure for diﬀerent percentages of targeted nodes are depicted in Figure 7. 20 30 40 50 60 70 80 90 100 % of targeted nodes 7 8 9 10 11 Total expense reduction in % Degree Betweenness Investment Erd˝os-R´enyi 20 30 40 50 60 70 80 90 100 % of targeted nodes 9 10 11 12 13 Total expense reduction in % Degree Betweenness Investment Barab´asi-Albert Figure 7: Reﬁnement of the upper allocation strategy for diﬀerent percentages of targeted nodes. Again, the total additional security budget is β = 5. For each data point, T = 10, 000, 000 simulations of the epidemic process were generated. Full data is given in Appendix H. For the Erd˝os-R´enyi network no substantial change of expenses is found when excluding the most decentralized nodes from the allocation of the additional security budget. In contrast, for the Barab´asi-Albert network and allocations based on investment and degree centrality, only targeting nodes with a medium to high degree of centrality is even beneﬁcial. No substantial change, however, is observed in case of the betweenness-centrality based allocation. As noted before, this may be due to the fact that in the betweenness-centrality case, the allocation weights of periphery nodes are anyway close to zero. In sum, our observations provide evidence that budget allocations to periphery nodes are rather ineﬀective. Nevertheless, for all centrality measures and both types of networks under consideration, solely allocating the budget to a small fraction of nodes with the highest centrality does not prove to be optimal. A reason for that might be the trade-oﬀbetween costs and eﬃciency: Additional security investments for highly central nodes come with substantially increasing costs, since these nodes already invest a high amount in the individually optimal steady state (see Figure 5) and the cost function Ci(γi) is strictly convex. For both types of networks, the overall best results are found for betweenness-based allo- cations. However, the corresponding optimal total expenses are only slightly below the total expenses corresponding to adequately targeted degree-based allocations. Determining the be- tweenness centrality of nodes requires information on the full network topology, and this in- formation may not be available in practice. In contrast, node degrees, i.e., the number of IT contacts of an agent in the cyber network, are local quantities, and thus, they can more easily be determined, e.g., using questionnaires. Therefore, in view of the information gathering issue and given the comparable performance in our simulations, degree-based allocations targeting the upper 50% of most central nodes may constitute a reasonable compromise. 20 4.3. Evaluation of Security-Related Interventions We ﬁnd that mandatory security investments as a regulatory obligation can actually increase the overall cybersecurity in a system of interconnected agents. More precisely, our simulations suggest the following: (i) The strategic interaction of nodes in the cyber network leads to a steady state of security investments as proven in Theorem 4.1. However, the self-regulation of interdependent actors does in general not lead to an eﬀective state of security conﬁgurations from an overall network perspective: A substantial improvement of this state is possible by the injection of additional security budget. Therefore, a need for regulation is found, and introducing adequate security-related obligations might be reasonable. (ii) Severe security requirements for weakly connected entities like private households or com- panies with a very small number of business partners do not seem to have any notable eﬀect on reducing network vulnerability. However, solely focusing on the most central nodes does not produce the best results either. Provided that these central nodes at least make the signiﬁcant investments given by some steady state of the security investment game, additional investments come with massively increasing costs. Therefore, regula- tion should also focus on agents and companies with a medium to large number of IT or business contacts. (iii) Centrality is not a rigorously deﬁned concept. However, for both degree- and betweeness- based security allocations, good results are obtained. For practical reasons, degree-based allocations may be easier to implement: information on immediate network contacts can directly be obtained from agents, e.g., using questionnaires. As regards the selected cybersecurity measures given in Section 2 we ﬁnd that: GOV ⋄Size-cap rule: Remarkably, the approach proposed by the European Commission is in very good agreement with our ﬁndings: Security obligations for micro and small enterprises are ineﬀective, but both medium-sized entities as well as large businesses should be targeted. Therefore, our results strongly suggest that the size-cap rule is an eﬃcient tool for improving resilience in cyber systems. ⋄Supply chain protection: The observation that eﬃcient security allocations can- not solely be restricted to a small fraction of nodes with the highest centrality illustrates the need for a strengthening of security levels further down along pos- sible paths of contagious transmission. Therefore, similar to the size-cap rule, our study supports the implementation of security enhancing measures along supply chains. INS ⋄Assistance services: Our study may help to identify companies for which as- sistance should be made mandatory in insurance contracts, and also give an estimate of the amount of services that should be made available to the speciﬁc policyholder. Further, in the case of an ongoing WannaCry- or NotPetya-type incident, the amount of resources for those assistance services may only be lim- ited, see also the discussion in Hillairet and Lopez (2021). Thus, our results may also be useful for an eﬀective resource allocation in such situations. ⋄Patch management and backup: Our observations suggest that the eﬀectiveness of mandatory obligations strongly depends on the systemic importance of the examined entity measured by a reasonable centrality criterion. Medium-sized as 21 well as large businesses with respect to centrality should not only invest more in cybersecurity, and thus in particular in their back-up and patching procedures, than smaller entities, but they should even invest more than an individually optimal assessment would suggest. 5. Case Study II: Topology-Based Interventions and Cyber Pandemic Risk Due to the interconnectedness of modern IT systems, both the WannaCry and NotPetya in- cidents aﬀected systems at a global scale, triggering large amounts of cyber losses. Clearly, a major regulatory concern is the prevention of such cyber pandemic incidents. Moreover, since risk pooling does not apply to systemic incidents, it is also important for insurance companies to reduce the risk of potential cyber accumulation scenarios within their portfolios. Digital information and technology networks often come at a size of several thousand nodes15, see the reference network data from Table 2.1 in Barab´asi and P´osfai (2016) and Table 10.1 in Newman (2018). In this section we study the cyber pandemic risk exposure, ﬁrst for ho- mogeneous Erd˝os-R´enyi-type networks, and then for heterogeneous—probably more realistic— Barab´asi-Albert-type networks of large size. We will observe that in order to control the cyber pandemic risk, regulatory approaches which solely focus on the improvement of individual cy- ber security are insuﬃcient: interventions need to target the underlying topological network structure. Thus a clear demand for the regulation of the network topology in large-scale cyber systems is found. We will also observe that network heterogeneity massively ampliﬁes the cyber pandemic risk. 5.1. Demand for Regulation: Network Topology and Cyber Pandemic Risk In large-scale networks, the frequency distribution of epidemic outbreak sizes in the SIR model can typically be characterized by the presence of two peaks,16 namely • small outbreaks, aﬀecting only a very small fraction of network nodes, and • proper epidemic outbreaks or pandemics, where a large number of nodes becomes infected. To assess the risk of cyber pandemics, simulation studies are conducted. Again, for all networks, we choose a global infection rate of τ = 0.1. In contrast to the previous study, recovery rates are assumed to be ﬁxed and homogeneous for all nodes, i.e., γi = γ = 1 for all i = 1, . . . , N. This parameter choice implies that detection of cyber incidents is expected to be 10 times faster than infectious transmission, i.e., we assume an overall high standard of IT security for the full network. 5.1.1. Cyber Pandemic Risk in Homogeneous Networks We ﬁrstly analyze the cyber epidemic risk exposure of homogeneous large networks drawn from the Erd˝os-R´enyi random graph model with a ﬁxed size of N = 1, 000. The beneﬁt of this model class is that the resulting networks are easily tractable due to the fact that their topology is entirely determined by the parameters p and N. In particular, p can be interpreted as the control parameter of network connectivity. Each simulation is performed in the following way: 15 The possibly largest existing network is the WWW with approximately N = 1012 nodes. 16Mathematical details are extensively discussed in Chapter 6 of Kiss, Miller, and Simon (2017). 22 1. Randomly draw a network Gp(1, 000) from the Erd˝os-R´enyi class. 2. Randomly choose a single node which is initially infected. 3. Randomly generate an infection trajectory from our SIR model. We are interested in the total number of infected nodes, i.e., the outbreak size. 50 100 150 200 250 300 350 400 450 500 550 Number infected 2 4 6 8 10 12 Probability / Relative frequency 10-4 p1 p2 p3 p4 p5 Figure 8: Final outbreak size frequencies given an initial infection of a single network node, over 100,000 simulations for increasing values of p; values are p1 = 0.01 < p2 = 0.011 < pc < p3 = 0.012 < p4 = 0.013 < p5 = 0.014. Exact data points from the simulation and appropriate regression curves (power law for p1 and p2, polynomial of degree 8 for p3, p4, p5) are plotted. The resulting frequency distribution of outbreak sizes is depicted in Figure 8. The following phase transition can be observed: • For low connectivity probabilities p, only small outbreaks occur; the outbreak size fre- quency is exponentially decaying. • Tipping point behavior: If a certain critical edge probability pc is exceeded, the frequency distribution is characterized by a second peak around a characteristic large outbreak size. The apparent strong dependence between network connectivity and outbreak sizes suggest that a supervision and regulation of the network is beneﬁcial to avoid large systemic outbreaks. Naively speaking, in a homogeneous network, the regulator should aim at keeping the network connectivity below the critical threshold pc. 5.1.2. The Heterogenous Case: Cyber Pandemic Risk in Scale-Free Networks On a larger scale, many real-world networks are characterized by a preferential attachment principle, see Chapter 4 in Barab´asi and P´osfai (2016), and therefore, a more heterogeneous topology is often observed: Let K be a random variable which represents the degree ki of a randomly chosen network node i. Then • the degree distribution of the Erd˝os-R´enyi random graph Gp(N) is given by a binomial form, i.e., we have P(K = k) = N −1 k ! pk(1 −p)N−1−k, k = 0, · · · , N −1, 23 • whereas under preferential attachment, the distribution of node degrees typically follows a power-law, i.e., P(K = k) ∼k−α, with degree exponent α ∈R+.17 Node arrangements with α = 3 can be modeled using the Barab´asi-Albert class intro- duced in Section 3.1.1. These so-called scale-free networks provide a hierarchy of nodes, with heavily connected high-degree hubs in their center and less connected nodes in their periphery. Figure 9 shows representative networks from both the Erd˝os-R´enyi and Barab´asi-Albert class, highlighting the diﬀerent degree distributions. Figure 9: Erd˝os-R´enyi G0.01(1, 000) (left) and Barab´asi-Albert BA(1, 000; 5) (right). In both cases the node size of node i is given by 100 · q ki/ P1000 j=1 kj, an increasing function of the node’s relative degree ki/ P1000 j=1 kj . This diﬀerence in the network topology has a strong impact on the epidemic vulnerability. Focusing on connectivity in terms of the sole number of edges, for networks of size N = 1, 000, the class of Barab´asi-Albert networks with m = 5 is comparable to Erd˝os-R´enyi graphs with p = 0.01, since the resulting numbers of edges in both networks approximately coincide.18 However, there exists a strong diﬀerence regarding their vulnerability to epidemic outbreaks, as shown by Figure 10: In contrast to the Erd˝os-R´enyi graph, a clear second peak in the frequency distribution of outbreak sizes is observed for the Barab´asi-Albert network. Hence, the heterogeneity in the topology of Barab´asi-Albert networks remarkably lowers the critical connectivity threshold for cyber pandemics, i.e., it ampliﬁes the epidemic spread and triggers the emergence of large-scale outbreaks. A profound characterization of this behavior in relation to the distribution of node degrees can be obtained in the limit of inﬁnite network size N →∞: Neglecting additional correlation eﬀects19 it is known that large-scale pandemic outbreaks are possible if and only if the threshold condition τ τ + γ E[K2 −K] E[K] > 1 (4) is satisﬁed, see Equation 6.4 on p.221 in Kiss, Miller, and Simon (2017)20. Note: 17For details and empirical examples, we refer to Chapters 3 and 4 in Barab´asi and P´osfai (2016). 18Approximately 5,000 edges should be present in both networks, see the discussion in Section 3.1.1. 19 The eﬀect of degree correlations and clustering on the dynamics of spreading phenomena is diﬃcult to quantify analytically due to the dimensionality of the system, see also the discussion in Appendix A. Findings on their impact on the epidemic threshold are surveyed in Sections B.1 and B.2 of Pastor-Satorras et al. (2015). 20See also Equation 62 in Pastor-Satorras et al. (2015) for an equivalent expression of the threshold. 24 50 100 150 200 250 300 350 400 Number infected 0 0.2 0.4 0.6 0.8 1 1.2 Probability / Relative frequency 10-3 Barabási-Albert Figure 10: Final outbreak size frequencies given an infection of a single network node for the Barab´asi-Albert BA(1, 000; 5) and Erd˝os-R´enyi networks G0.01(1, 000) from Figure 9 over 100,000 simulations. Exact data points from the simulation and a regression curve (power law for Erd˝os-R´enyi, polynomial of degree 8 for Barab´asi-Albert) are plotted. • For Erd˝os-R´enyi random graphs, in the limit the degree distribution is Poisson with pa- rameter λ denoting the average degree, see Section 3.4 in Barab´asi and P´osfai (2016). Therefore, from (4), it follows that cyber pandemics can be prevented in the inﬁnite limit if the network security/recovery rate γ, satisﬁes γ ≥τ(λ −1). • In contrast, for scale-free networks with α ∈(2, 3] and a suﬃciently high number of nodes, it may be diﬃcult or even impossible to prevent cyber pandemics by solely improving the network security or reducing the overall network connectivity. The reason for this is that in the inﬁnite size limit, the second moment E[K2] of the degree distribution diverges to ∞while the ﬁrst moment E[K] stays ﬁnite, see Section 10.4.2 in Newman (2018) for more details. Hence, in view of (4), with growing N, the security parameter γ must be substantially increased to prevent the occurrence of cyber pandemics. This comes with massively increasing costs. In the limiting case N →∞, (4) is always satisﬁed, regardless of the infection and recovery parameters chosen, so cyber pandemics may always occur. In scale-free networks with a degree exponent α in the range of (2, 3] and a large number of entities, cyber pandemics are thus an inherent risk of the underlying network topology. The risk of cyber pandemic outbreaks cannot be controlled by security-related interventions, i.e., by increasing the recovery rate γ, only, but requires a manipulation of the degree distribution, that is the topological network arrangement. This behavior is clearly relevant in the risk assessment of cyberspace, which consists of a very large number of entities and is characterized by a heterogeneous, possibly scale-free, structure of interconnections.21 5.2. Implementing Suitable Interventions In the previous subsection, we have seen how a network’s vulnerability to large-scale cyber pandemic outbreaks depends on the topology of the underlying cyber network. The following approaches may be considered to limit or control critical network connections and nodes: • Edge removal: Edge deletion comprises – physical deletion of connections, such as any unnecessary access to servers, or if not possible, 21For example, the Internet’s degree distribution is estimated to be scale-free with degree exponent α ≈2.5 in Table 10.1 of Newman (2018). 25 – edge hardening, which corresponds to strong protection of network connections via ﬁrewalls, the closing of open ports, or the monitoring of data ﬂows using speciﬁc detection systems, see Chernikova et al. (2022). • Node splitting to separate critical contagion channels and let them pass through two diﬀerent nodes with the same operational task. Since manipulating the network topology comes at a cost, probably reducing network function- ality, the aim in the following is to identify critical network connections and nodes in a way which reduces negative eﬀects on the network functionality to a minimum. A classical measure for network functionality is the average shortest path length ⟨l⟩: For nodes i and j, lij is the minimum number of edges connecting i and j. The average shortest path length is the average over all these distances, i.e., ⟨l⟩= X i,j,i̸=j 1 N(N −1)lij in case of a connected network. A small value of ⟨l⟩is a measure for fast and eﬃcient data ﬂow, and hence, corresponds to a high network functionality. If a network consists of more than one component, then lij is not well deﬁned for any two nodes i and j which come from two diﬀerent components. In this case, we follow Newman (2018), p. 311 and adopt the deﬁnition by only taking the average over those node pairs which are connected by an existing path.22 5.2.1. Edge Removal and Node Splitting Edge Removal To identify epidemically critical edges, we utilize the edge centrality given in (1) in Section 3.1.2 and propose the following procedure: 1. Consider a network G. Determine the centrality of G’s edges. 2. Consecutively delete the most central network edges. Stop the deletion process, if the resulting network does not exhibit a cyber pandemic outbreak any more. The procedure thus ends when pandemic outbreaks are not any longer observed in the result- ing network Gc. Let Ec denote the set of edges which are deleted from G to obtain Gc, and let |Ec| be its number. To illustrate the eﬀectiveness of the proposed procedure, we determine the value |Ec| and the average shortest path length ⟨lc⟩of the resulting network Gc for the Barab´asi-Albert network depicted in Figure 9 with initial functionality of ⟨l⟩≈2.96 and outbreak size frequencies as shown in Figure 10. The results after edge deletion are depicted in Figure 11. In comparison to random edge removals, it is clearly observable that the number of necessary edge deletions |Ec| can be signiﬁcantly reduced by following the edge centrality deletion proce- dure. Moreover, the remaining network possesses a higher functionality represented by a lower average shortest path length ⟨lc⟩than in the case of random edge removals. Node Splitting In the following, we propose a splitting procedure which is based on the suitable choice of a node centrality measure C.23 Nodes with highest centrality are splitted in an iterative manner, i.e., centralities are re-evaluated after each split. Hence, nodes resulting from a split can be splitted again if they still exceed the rest of the network in terms of centrality. Algorithm 5.1 (Node Splitting). Input: Initial network of N nodes, number n of node splits, node centrality measure C 22In particular, this modiﬁcation is relevant for the random edge deletions in Figure 11, where larger amounts of links are removed. The networks in Figures 11, 12, and 13 which are generated by targeted edge deletions and node splittings are not fragmented into disconnected components. 23A similar algorithm was introduced in Chernikova et al. (2022). 26 50 100 150 200 250 300 350 Number infected 1 2 3 4 5 6 7 8 Probability / Relative frequency 10-4 6 %, <l> = 3.13 10 %, <l> = 3.22 12 %, <l> = 3.26 14 %, <l> = 3.30 edge centrality 50 100 150 200 250 300 350 Number infected 1 2 3 4 5 6 7 8 Probability / Relative frequency 10-4 20 %, <l> = 3.20 25 %, <l> = 3.28 30 %, <l> = 3.37 35 %, <l> = 3.47 random Figure 11: Final outbreak size frequencies given an initial infection of a single network node, over 100,000 simulations for diﬀerent percentages of deleted edges. Exact data points from the simulations and regression curves (polynomial of degree 8) are plotted. The results for edge centrality-based removals are depicted in the left ﬁgure, and the percentage of critical links is found to be about 14 %. In contrast, random edge removals are shown in the right ﬁgure, and this procedure is clearly less eﬀective: Approximately 30-35% of edges need to be removed here to eliminate the risk of cyber pandemics. The randomized edge removals are newly conducted for each of the 100,000 simulations. 1. Determine the centrality of all network nodes. 2. Find the node i with highest centrality. 3. Split node i in the following way: i) Add a new node j to the existing network. ii) Create an order of node i’s network neighbors where nodes are sorted according to their centrality. iii) For nodes l with an even order rank, delete the edge between i and l and create a new edge between l and j. 4. Repeat steps 1) - 3) until n node splits are conducted. Output: Resulting network Gc of N + n nodes In analogy to the previously conducted analysis of edge removals, we study the eﬀect of node splitting on the epidemic outbreak size distribution and functionality of the Barab´asi-Albert network from Figure 9 with initial outbreak size frequencies as shown in Figure 10. The results for degree- and betweenness-based node splitting are depicted in Figure 12, yielding almost identical results. In comparison to edge removals, we ﬁnd that node splitting is even more eﬀective: Only about 6% of the most central nodes need to be splitted in order to control the risk of cyber pandemics. Further, the functionality of ⟨l⟩≈3.24 of the resulting network is better than in the case of edge removals (⟨l⟩≈3.30). In step 3, iii) of the algorithm, rewiring of edges is conducted with the aim of separating critical contagion channels from each other. To study the eﬀectiveness of the procedure, we may modify this step of the algorithm in the following way: Let ki denote the degree of node i. Then, the ⌈ki/2⌉neighbors with highest degree remain connected to i, and only edges between the ⌊ki/2⌋lowest degree nodes and i are rewired from node i to j. From the outcomes in Figure 13, we clearly observe that the eﬀectiveness of the node splitting procedure is now remarkably 27 50 100 150 200 250 300 Number infected 1 2 3 4 5 6 7 8 Probability / Relative frequency 10-4 n = 30, <l> = 3.146 n = 40, <l> = 3.179 n = 50, <l> = 3.211 n = 60, <l> = 3.240 degree-based 50 100 150 200 250 300 350 Number infected 1 2 3 4 5 6 7 8 Probability /Relative frequency 10-4 n = 30, <l> = 3.146 n = 40, <l> = 3.180 n = 50, <l> = 3.211 n = 60, <l> = 3.241 betweenness-based Figure 12: Final outbreak size frequencies given an initial infection of a single network node, over 100,000 simulations for diﬀerent numbers of splitted nodes. Exact data points from the simulations and regression curves (polynomial of degree 8) are plotted. The results for degree-based splittings are depicted in the left ﬁgure, the number of critical splits is found to be about n = 60 which corresponds to 6% of the nodes. Very similar results are found when splitting nodes according to their betweenness centrality, as is shown in the right ﬁgure. lowered, both in terms of necessary node splits for the prevention of cyber pandemics and network functionality. Hence, the separation of critical contagion channels is essential for the eﬀective implementation of node splitting. 50 100 150 200 250 300 Number infected 1 2 3 4 5 6 7 8 Probability / Relative frequency 10-4 n = 50, <l> = 3.27 n = 60, <l> = 3.31 n = 70, <l> = 3.33 n = 80, <l> = 3.36 Figure 13: Final outbreak size frequencies given an initial infection of a single network node, over 100,000 simulations for diﬀerent numbers of split nodes under the modiﬁed procedure. Exact data points from the simulations and regression curves (polynomial of degree 8) are plotted. In comparison to the results from Figure 12, we see that the modiﬁed rewiring procedure substantially reduces the procedure’s eﬃciency. Indeed, in this case 8% of the nodes need to be splitted and the corresponding network functionality is ⟨l⟩= 3.36. 5.2.2. Risk Allocation and Design of Contractual Obligations Risk Allocation Consider an initial graph G and the graph Gc which is obtained by network interventions, either edge removals or node splitting, such that cyber pandemics are suﬃciently controlled in Gc. The network connections in Gc can be considered acceptable, i.e, they should not warrant further regulatory action. Instead, suitable risk allocation schemes and possible obligations should be derived from the set of deleted (edge removals) or rewired (node splitting) connections. To allocate the cyber pandemic risk to the individual nodes in accordance with their systemic risk contribution, we thus introduce the concept of contact coeﬃcients: 28 • Edge removals: Let ǫi = |{j | (i, j) ∈Ec}| denote the number of critical connections of node i.24 To measure the cyber pandemic risk contribution of the single node i, we deﬁne the contact coeﬃcient ci of i by ci = ǫi 2|Ec|, normalized to N X i=1 ci = 1. • Node splitting: Let I ⊆{1, . . . , N} denote the set of nodes from the initial network G which are splitted during the procedure. Then, in analogy to the centrality weights wi from Case Study I, we choose a node centrality measure C and deﬁne the contact coeﬃcient ci by ci = ( (C(i)/ P j∈I C(j)), if i ∈I, 0, else. In the following, we sketch preliminary ideas on how speciﬁc topology-based obligations for network nodes i could be established. Contractual Obligations A major problem of (private) regulators such as insurance companies is that they might not be able to directly control or limit connections within cyber networks. In that case, contractual obligations, like surcharges or insurance risk premiums, may incentivize the deletion or protection of critical contagion channels. In the following we brieﬂy discuss such insurance-related obligations. • Fixed surcharge: Given a cyber premium πi ∈R+ for node i, not yet accounting for systemic cyber risks, the contact coeﬃcient ci could serve to determine the fraction of a ﬁxed systemic risk surcharge f > 0 which has to be borne by node i. This means that node i’s total premium would equal eπi = πi + ci · f ≥πi, with equality if and only if ci = 0, i.e., if and only if node i possesses no critical network connections. For example, these surcharges could be implemented in the context of the insurance backstop mechanism that is discussed in Lemnitzer (2021). • Risk premia: Let L represent the random total loss (over all nodes) in the original network G, and let Lc represent the total loss in the new network Gc. Then Le := L −Lc may be interpreted as the cyber pandemic loss. Consider a risk measure ρ such as the Value at Risk or Expected Shortfall25 and let ρ(Le) denote the corresponding risk capital. When ρ(Le) > 0 we deﬁne a topology-based premium π(ci) for each node i by allocating the risk capital ρ(Le) among the policyholders according to their individual risk contribution. For ﬁxed networks G and Gc, the corresponding function π : [0, 1] →[0, ρ(Le)] should be non-decreasing and satisfy PN i=1 π(ci) = ρ(Le). This amounts to a classical risk allocation problem, see, e.g. Feinstein, Rudloﬀ, and Weber (2017). Obviously, the proportional allocation rule π(ci) = ci · ρ(Le) satisﬁes these constraints. 24Note that every critical edge (i, j) ∈Ec connects two nodes i and j, thus PN i=1 ǫi = 2|Ec|. 25For a rigorous introduction to monetary risk measures, we refer the interested reader to Section 4 in F¨ollmer and Schied (2016). 29 Using edge-removal interventions, we illustrate the eﬀect of these mechanisms in Figure 14 for the Barab´asi-Albert network from Figure 9. The larger the size of a node in Figure 14, the larger is its underlying contact coeﬃcient ci, and, thus, the higher would be an adequate topology-based obligation. We ﬁnd that critical network connections are mostly associated to a few central hubs. Comparing Figures 9 and 14, these few hubs are even more important than from a degree perspective, and their decisive meaning for the emergence of cyber pandemic risk within the network is clearly observed. Thus, adequate topology-based interventions should target these few central pandemic nodes. Figure 14: Visualization of contact coeﬃcients based on edge removals in the Barab´asi-Albert network introduced in Figure 9: Here, node size of node i equals 100 · q ci/ P1000 j=1 cj, an increasing function of the node’s importance with respect to its contact coeﬃcient ci. 5.3. Evaluation of Topology-Based Interventions The case study clearly demonstrates that eﬀective manipulations of the network topology can prevent cyber pandemic outbreaks while preserving a reasonable level of network functionality. We obtain the following insights: (i) In homogeneous networks of large size, connectivity, deﬁned in terms of the sole number of links, plays a major role in the emergence of cyber pandemic risk: A critical connectivity threshold pc can be identiﬁed, below which the frequency of cyber pandemics is negligi- ble. Further, it is possible to prevent cyber pandemics by increasing the overall network security. (ii) However, many real-world networks are characterized by a more heterogeneous, scale-free distribution of node degrees. Examples of networks with a scale-free topology can be modeled using the Barab´asi-Albert model. Here, we found that highly-connected network participants (hubs) may further amplify risk propagation compared to homogeneous net- works. Moreover, in the limit of inﬁnite network size, cyber pandemics cannot solely be prevented by strengthening the security of network participants but requires manipulating the degree distribution of the underlying network topology. (iii) Centrality and contact coeﬃcients are an eﬀective way to measure an agent’s relative topological importance and allocate the cyber pandemic risk of the system to its individual nodes. Regulation taking into account these parameters may signiﬁcantly reduce the cyber risk and simultaneously preserve a high level of network functionality. However, determining these coeﬃcients requires information on the full network topology. (iv) In contrast to security-related measures, which should target all large and medium scale entities, topology-based interventions only need to focus on a small group of highly cen- 30 tral nodes. Thus, while contact coeﬃcients might be diﬃcult to determine in practice, it is suﬃcient to impose obligations, like mandatory backup servers, the protection of data connections, and separation of contagion channels, on a small fraction of highly intercon- nected network entities. Due to their size and importance, these nodes are more likely to be identiﬁed. We identify the following implications for the cyber resilience measures discussed in Section 2: GOV ⋄Incident response and reporting: The implementation of early warning systems and reporting obligations for strongly connected network entities may be an ef- fective way to prevent large-scale events. Immediately disconnecting or otherwise securing these agents after risk arrival may be crucial to prevent the outbreak of a systemic incident. Further, network scanning should evaluate the risk of cyber pandemic outbreaks; in particular, contact coeﬃcients and the analysis of edge removal or node splitting procedures may help to give concrete advice for the design of a more resilient network topology. ⋄Critical supply chains: Network topology characteristics of industry supply chains should play a major role in risk assessment and resilience building. Highly interconnected entities, cloud service platforms, or frequently used software may pose a severe threat for production chains and industry sectors. INS ⋄Contact liability premiums: The systemic risk contribution of a policyholder to the insurers portfolio could be evaluated by means of contact coeﬃcients as introduced in Section 5.2.2. ⋄Insurance backstop mechanism: Our approach provides a reasonable allocation mechanism for mandatory surcharges after the appearance of a systemic cyber risk incident. Further, it may help encourage the deletion or protection of critical network connections and thereby reduce the existing risk potential. 6. Conclusion and Outlook As systemic cyber risks such as the well-known WannaCry and NotPetya incidents pose a growing threat to social and economic stability around the world, risk management and resilience building are increasingly becoming the focus of regulators and private actors. In this context, major issues arise from the limited amount of incident data available and the ever-evolving threat landscape. Following the digital twin paradigm, we tackle this issue by introducing the artiﬁcial cyber lab: Based on data from virtual counterparts of real-world cyber systems, the artiﬁcial cyber lab provides an experimental framework to analyze the impact of both security-related and topology-based interventions. We ﬁnd that both types can signiﬁcantly improve the resilience of interconnected cyber systems – if they are well-adapted to the topology of the underlying cyber network: In the context of security-related interventions, appropriate obligations can be successfully implemented if, in addition to regulating highly centralized entities, they also apply to medium-sized network players. Additionally, topology-based measures for preventing cyber pandemic outbreaks in large-scale heterogeneous networks are essential. These constitute a rather serious regulatory intervention in cyber systems compared to security-related obligations. However, these interventions may be justiﬁed because only a small portion of highly centralized nodes need to be aﬀected. Based on our analysis of a virtual counterpart of the real world, 31 digital networks might become more resilient against systemic cyber threats by implementing the discussed cyber resilience measures. Of course, our speciﬁc case studies are highly stylized, and the validity of results depends on the appropriateness of the chosen framework. Possible modiﬁcations and extensions of the lab environment may be: • Attackers and insurers as strategic actors: A limitation of our approach is that we have not yet considered in detail the reactions and objectives of the actors involved, e.g., the reaction of malicious actors to the implementation of novel measures, or the impact of information asymmetries in the relationships between insurers and policyholders. Our approach is a ﬁrst step toward combining strategic approaches and dynamic cyber risk models. Future research should seek to incorporate these strategic aspects into the modeling framework. • Data gathering and model uncertainty: Based on artiﬁcal lab data, our study is able to provide insights on critical aspects of building cyber resilience – in a qualitative sense. However, to determine what exact degree of constraints might be appropriate in reality, the input parameters of our mathematical cyber risk model need to be ﬁtted to real-world data in order to establish additional data links between the virtual and real-world components of our digital twin. Therefore, gathering data about network topologies and cyber incidents remains an important task for regulatory authorities, risk management agencies, and insurance companies.26 Additionally, considering risk management methods under model uncertainty may be necessary to robustify the lab framework. • Network size and complexity: Of course, the computational complexity of algorithms applied within the artiﬁcial cyber lab signiﬁcantly increases with the number of network nodes and edges. However, our studies indicate that an eﬀective risk assessment can be achieved by focusing on the most central parts of the network only. Hence, a possible way to overcome complexity issues could be to artiﬁcially reduce the size of the network subject to preserving important characteristics. For instance, large real-world networks could be downsized by merging the peripheral parts to a tractable number of nodes. The suitability of such approaches is part of future research. • Feedback mechanisms in dynamic and adaptive networks: Over the course of an ongoing contagious cyber incident, nodes may in turn react to the threat evolution dynamics by link activation, shift, or deletion. For example, in response to the downfall of a server, new links may be created to servers which are still operational. Models for dynamic and adaptive networks with link rewiring, activation, and deletion are extensively discussed in Masuda and Holme (2017) and Chapter 8 of Kiss, Miller, and Simon (2017). This list of future research and modeling perspectives is not exhaustive. Moreover, new as- pects of cyber risk will emerge over time as cyber technology evolves. Nevertheless, artiﬁcial cyber labs are a promising tool for analyzing and understanding threats – supporting the eval- uation of potential countermeasures when building a more resilient cyber landscape for the future. 26 A brief survey on statistical inference methods for network topologies and/or epidemic model parameters is presented in Appendix E of Awiszus et al. (2023). Further, in Hillairet et al. (2022), a macroeconomic network model with weighted edges was calibrated from OECD data on the economic ﬂow between industry sectors. 32 Appendix A Markovian SIR Dynamics Continuous-Time Markov Chains In Markovian spread models on networks of N nodes, the evolution of the state vector X(t) X(t) = (X1(t), . . . , XN(t)) ∈EN, is described by a continuous-time Markov chain on the discrete state space EN. E is the compartment set of possible single node states. We assume that the Markov chain is time- homogeneous, i.e., that the probability of changing from state x ∈EN to state y ∈EN within a time window of length t > 0 does not depend on the current time u Pxy(t) := P(X(u + t) = y | X(u) = x) = P(X(t) = y | X(0) = x), u > 0. These probabilities constitute the |E|N × |E|N transition probability matrix P(t) = (Pxy(t)) with P y∈EN Pxy(t) = 1. For t = 0, it is consistent to assume that P(0) = limtց0 P(t) equals the |E|N × |E|N-dimensional identity matrix. Then P(t) is continuous for all t ≥0 and satisﬁes the Chapman-Kolmogorov equation P(t + u) = P(u)P(t) = P(t)P(u). (5) The transition probabilities P(t) fully characterize the evolution of a continuous-time Markov chain. For practical purposes, however, they provide too much information. Hence, we will focus on inﬁnitesimal transition probabilities instead. The continuity of P(t) implies that the derivative matrix Q := P ′(0) = lim hց0 P(h) −P(0) h exists.27 Q is called the inﬁnitesimal generator of the process, and its entries qxy are called transition rates since they describe the probability per unit time of a transition from state x to state y. Using the Chapman-Kolmogorov equation (5), the evolution of the complete process (X(t))t≥0 can be described by its inﬁnitesimal generator Q via the Kolmogorov forward and backward equations P ′(t) = P(t)Q and P ′(t) = QP(t). (6) The latter matrix diﬀerential equation is solved by the matrix exponential P(t) = eQt, i.e., the transition probabilities can directly be retrieved from the inﬁnitesimal transition rates. Moreover, this solution implies that the holding time Tx, i.e., the waiting time for leaving state x ∈EN, is exponentially distributed with parameter qx := P y∈EN,y̸=x qxy = −qxx ≥0. In addition, the Markov property of (X(t))t≥0 implies the independence of holding times.28 SIR Dynamics The SIR spread process is determined by Xi(t) ∈E = {S, I, R}. A transition of X from one state in EN to another is only possible if exactly one node changes its state Xi in E. State changes can occur through infection or recovery: It is assumed that each node may be infected by its infected neighbors, but can be cured independently of all other nodes in the network. Transitions are depicted in Figure 2. Formally, the entries of the inﬁnitesimal generator Q are given by qxy =              γi, if xi = I, yi = R, and xj = yj for j ̸= i τ PN j=1 aij 1xj=I, if xi = S, yi = I, and xj = yj for j ̸= i −P z∈EN,z̸=x qxz, if x = y 0, otherwise. (7) 27see Theorem 2.1 in Br´emaud (1999) 28For details see, e.g., Chapter 10 in Mieghem (2014). We refer to this book for more in-depth reading on stochastic processes and complex networks. 33 Of particular interest are the dynamics of the state probabilities of individual nodes P(Xi(t) = xi), t ≥0. They can be derived from Kolmogorov’s forward equation and written in general form as (i = 1, . . . , N) dP(Xi(t) = xi) dt = X y:yi=xi X z̸=y [P(X(t) = z)qzy −P(X(t) = y)qyz], (8) where qzy denotes the transition rate of the entire process X from z →y. Using Bernoulli random variables Si(t) := 1{Xi(t)=S}, Ii(t) := 1{Xi(t)=I}, and Ri(t) := 1{Xi(t)=R}, the dynamics of state probabilities of individual nodes (8) can conveniently be written via moments:29 dE[Si(t)] dt = −τ N X j=1 aijE[Si(t)Ij(t)], dE[Ii(t)] dt = τ N X j=1 aijE[Si(t)Ij(t)] −γiE[Ii(t)], dE[Si(t)Ij(t)] dt = τ N X k=1,k̸=i ajkE[Si(t)Sj(t)Ik(t)] −τ N X k=1,k̸=j aikE[Ik(t)Si(t)Ij(t)] −τaijE[Si(t)Ij(t)] −γjE[Si(t)Ij(t)], dE[Si(t)Sj(t)] dt = −τ X k=1,k̸=j aikE[Ik(t)Si(t)Sj(t)] −τ N X k=1,k̸=i ajkE[Si(t)Sj(t)Ik(t)], (9) where i, j = 1, 2, . . . , N and i ̸= j. Note that system (9) is not closed: The dynamics of second order moments depend on third order moments, which, in turn, depend on fourth order moments etc. This dependence structure cascades up to network size N. Therefore, in general, solving the exact system of moment equations becomes intractable, especially for larger networks. To deal with this issue, the following two approximation approaches have been proposed: 1. Monte Carlo simulation: Monte Carlo simulation using the Gillespie algorithm from Gillespie (1976) and Gillespie (1977) constitutes a powerful tool to obtain various quantity estimates related to the evolution of the epidemic spread. Pseudocode is given in Appendix B, and further explanations of the Gillespie algorithm applied to SIR epidemic network models is, e.g., given in Appendix A.1.1 of Kiss, Miller, and Simon (2017). 2. Moment closures: If a set of nodes J is infected, this increases the probability of other nodes in the network (that are connected to the set J via an existing path) to become infected as well. Hence, node states are to some extent correlated. To break the cascade of equations and to make ODE systems tractable, the moment closure approach consists in assuming independence at a certain order k, neglecting any further correlations. This is done by considering the exact moment equations up to this order k and closing the system by approximating moments of order k + 1 in terms of products of lower-order moments using a mean-ﬁeld function. However, a major problem with moment closures is that only little is known about rigorous error estimates. 29The dynamics of the recovery Bernoulli random variable Ri(t) result from the dynamics of Ii(t) and Si(t) due to E[Ri(t)] = 1 −E[Si(t)] −E[Ii(t)]. 34 Appendix B Gillespie Algorithm Algorithm (Gillespie). Input: Initial state of the system x0 ∈EN and initial time t0 ≥0. 1. (Initialization) Set the current state x →x0, current time t →t0, and k →0. 2. (Rate Calculation) For the current state of the system x, calculate the sum of rates for all possible transitions qx = PN i=1 qxi, where qxi denotes the rate for a state change of node i according to (7). 3. (Generate Next Event Time) Sample the next event time tnew from an exponential distri- bution with parameter qx. 4. (Choose Next Event) Sample the node inew at which the next transition occurs: Each node i = 1, . . . , N is chosen with probability qxi/qx. Change the state xinew →yinew according to (7). 5. Set t →t + tnew =: tk+1, x →(x1, . . . , xinew−1, yinew, xinew+1, . . . , xN) =: xtk+1, k →k + 1, and return to Step 2 until a prespeciﬁed stopping criterion is met. Output: Trajectory [t0, tend] ∋t →X(t, ω) of the spread process, where X(t, ω) := xtk for t ∈[tk, tk+1]; tend denotes the end time of the simulation Appendix C Network Algorithms Algorithm (Erd˝os-R´enyi). Input: Number of network nodes N, connection probability p. 1. Choose a pair of nodes (i, j) with i, j ∈{1, · · · , N}, i ̸= j. 2. Simulate a uniformly distributed number ˜p between 0 and 1. 3. If ˜p < p, create an edge between node i and j. Else, no edge is created. 4. Repeat steps 1) −3) for all the other possible pairs of nodes. Output: Network G from class Gp(N) Algorithm (Barab´asi-Albert). Input: Number of network nodes N, small initial network of n0 connected nodes, number m of nodes to which every newly added node is connected. 1. Add a new node i to the small initial network. 2. Create a new edge for i in the following way: i) Uniformly generate a node number j from the existing network (i ̸= j). ii) Simulate a uniformly distributed number r between 0 and 1. iii) Let kl denote the current degree of node l, l = 1, · · · N. If r < kj/ P l kl, then the edge should be created between i and j. Else, go back to step i). 3. Repeat step 2) until m edges are created for the new node i. 4. Repeat steps 1) - 3) until a network of N nodes is formed. Output: Network G from class BA(N; m) 35 Appendix D Li as a Strictly Convex Function of γi For our cyber loss model Li := Li(γ1, . . . , γN) := E[ Z ∞ 0 Ii(t)dt], we can derive an elegant expression in terms of γi: Let Ai := {∃t ∈[0, ∞) : Ii(t) = 1} be the event that node i will be infected at some moment in time t. Then Li = E[ Z ∞ 0 Ii(t)dt 1Ai] + E[ Z ∞ 0 Ii(t)dt 1Ac i ] where R ∞ 0 Ii(t)dt 1Ac i = 0 by deﬁnition. Note that γi only aﬀects the recovery process of node i, and since reinfection events are ruled out in the SIR modeling framework, the probability of infection P(Ai) for node i does not depend on the recovery rate of node i but only on the vector γ−i of the other node’s recovery rates. Further, since the initial infections are randomly chosen, we have P(Ai) ≥1/N. Thus, by using the rules of conditional expectation, Li can be expressed as Li = E[ Z ∞ 0 Ii(t)dt 1Ai] = P(Ai) · E[ Z ∞ 0 Ii(t)dt | Ai]. By deﬁnition, R ∞ 0 Ii(t)dt is the amount of time i spends in the infectious state I. If an infection of node i actually occurs, then this is the time of transition from state I into state R. Hence, E[ R ∞ 0 Ii(t)dt | Ai] is the expected waiting time for recovery of node i. Since the SIR spread pro- cess is assumed to be Markovian, the waiting time is exponentially distributed with parameter γi. Therefore, we obtain E[ Z ∞ 0 Ii(t)dt | Ai] = 1 γi . Hence, Li(γ1, . . . , γN) = P(Ai) γi (10) where the numerator does not depend on node i’s recovery rate. Thus, Li is a strictly convex function of γi. Appendix E Modeling Cyber Losses for the Security Investment Game The decomposition of loss functions Li in Appendix D can be used for an eﬃcient stochastic simulation procedure of cyber losses in Algorithm 4.2: To ﬁnd the recovery rate γi(r + 1) for round r + 1 in step 2 of the algorithm, we need to determine the minimizer γi(r + 1) = arg min γi Ei(γi, γ−i(r)) = arg min γi [Ci(γi) + Li(γi, γ−i(r))]. Using the aforementioned representation of the loss functions, this means that for every node i, we need to determine the infection probabilities P(Ai) to describe Li as a function of γi. Now, since the infection probability of every node i is not depending on its own recovery rate, these probabilities can be determined in a joint procedure: 1. Choose a suﬃciently high number of simulation runs T to generate trajectories of the SIR process. For example, we chose T = 10, 000, 000 for simulations in Figure 5 and 7. 2. For every node i, let the recovery rate be given by γi(r). 36 3. For every simulation run, initially infect a randomly chosen single node and generate a trajectory of the SIR process on the network. For every node i, save whether i was infected during this run. 4. After the conduction of the T simulation runs, for every node i, let Ti be the number of simulation runs where node i was infected. Set P(Ai) = Ti/T . Then, for every node i the total expenses Ei are solely given as a function of γi, and it is straightforward to determine γi(r + 1) = arg min γi [Ci(γi) + P(Ai)/γi]. Appendix F Proof of Theorem 4.1 Proof. 1. Continuity of total expenses: We prove that Ei : (0, ∞)N →R is continuous. Recall that Ei(γ1, . . . , γN) = Ci(γi) + L(γ1, . . . , γN) where Ci(γi) = ekγi −130 and Li(γ1, . . . , γN) = E[ R ∞ 0 Ii(t)dt]. Obviously, Ci is continuous. As regards Li note that Li(γ1, . . . , γN) = E[ Z ∞ 0 Ii(t)dt] = Z ∞ 0 E[Ii(t)]dt = Z ∞ 0 P(Xi(t) = I)dt by the Fubini-Tonelli Theorem. Therefore, it is suﬃcient to prove the continuity of P(Xi(t) = I) in (γ1, . . . , γN) ∈(0, ∞)N. From equation (7), we see the the generator matrix of the SIR Markov process is continuous (w.r.t. the Frobenius norm), and there- fore, the same applies to the solution P(t) = eQt of the Kolmogorov backward equation. The continuity (w.r.t. the Euclidean norm) is preserved by the continuous transform P(Xi(t) = I) = X x∈EN P(X(0) = x) X y∈EN, yi=I Pxy(t) of transition probability matrix P(t). 2. Recall the representation (10) Li(γ1, . . . , γN) = P(Ai) γi . Hence, according to 1. also P(Ai) = γiLi(γ1, . . . , γN) is continuous as a function of γ−i. 3. Note that both Ci and Li, and thus Ei, are strictly convex functions of γi. Recalling that P(Ai) does not depend on γi, the ﬁrst order condition for the unique minimum is ∂ ∂γi Ei(γ1, . . . , γN) = kekγi −P(Ai) γ2 i = 0. Since P(Ai) is continuous as a function of γ−i by 2., it also follows that unique minimizer γind i (γ−i) is continuous in γ−i. On the one hand, note that ∂ ∂γi Ei(γ1, . . . , γN) = kekγi −P(Ai) γ2 i ≥kekγi −1 γ2 i and the latter expression does not depend on γ−i and is positive for, for instance, γi > 1 √ k. On the other hand, since the initial infections are randomly chosen, we have P(Ai) ≥1/N, and thus kekγi −P(Ai) γ2 i ≤kekγi − 1 Nγ2 i 30In Case Study 1, we choose k = 1 3. 37 where again the latter expression does not depend on γ−i. Now let ε(N) > 0 such that kekε(N) − 1 Nε(N)2 < 0 (which always exists depending only on N). Then it follows that for any i = 1, . . . , N and (γ1, . . . , γN) ∈(0, ∞)N we have γind i (γ−i) ∈[ε(N), 1 √ k]. 4. In 3. we showed that the function [ε(N), 1 √ k ]N →[ε(N), 1 √ k ]N, (γ1, . . . , γN) 7→(γind 1 (γ−1), . . . , γind N (γ−N)) is well-deﬁned and continuous. Hence, according to Brouwer’s ﬁxed point theorem31 it has a ﬁxed point, that is ∃γ ∈[ε(N), 1 √ k ]N ∀i = 1, . . . , N : γind i (γ−i) = γi. Appendix G Security Choices for a Network of Two Nodes Straightforward exact computations of optimal investment levels are possible for the simple case of two interconnected nodes as illustrated in Figure 15. 1 2 γ1 γ2 τ Figure 15: Line network with N = 2 nodes and the corresponding epidemic transition rates. In this special case, the infection probabilities P(Ai) from the loss model decomposition in Appendix D can be explicitly calculated from the waiting time distributions of the Markov chain: Due to the random uniform choice of the initially infected node, it is P(Xi(0) = I) = 1/2 for i = 1, 2, and thus, we obtain P(Ai) = P(Xi(0) = I) + P(Xj(0) = I) · P((Si, Ij) →(Ii, Ij)) = 1 2 · (1 + P((Si, Ij) →(Ii, Ij))), i, j ∈{1, 2}, i ̸= j. P((Si, Ij) →(Ii, Ij)) can be expressed in terms of the waiting time for recovery T recov j of node j and the infection event T infec, and we can use the fact that waiting times for Markov chains are independent and exponential, yielding P((Si, Ij) →(Ii, Ij)) = P(T recov j > T infec) = τ γj + τ . Hence, a closed expression of the cyber losses Li in terms of epidemic transition rates is given by Li(γ1, γ2) = P(Ai) γi = 1 2γi ·  1 + τ γj + τ  , i, j ∈{1, 2}, i ̸= j, and this can be inserted into the total expense functions Ei(γ1, γ2) = C(γi) + Li(γ1, γ2). Thus, the individual optimal security choice γind i (r+1) in round r+1 of the security investment game is given by γind i (r + 1) = arg min γi Ei(γi, γind j (r)), i, j ∈{1, 2}, i ̸= j. Now, in agreement with the chosen parameters in Case Study 4, we ﬁx τ = 0.1 and initialize the security investment game with recovery rates γ1(0) = γ2(0) = 0.1. From Table 2, we see 31see e.g. Corollary 17.56 in Aliprantis and Border (2006) 38 r γind i (r) 1 1.2234 2 1.0638 3 1.0681 4 1.0680 5 1.0680 Table 2: The security investment game for a line network of N = 2 nodes that the game converges to the security conﬁguration (γind 1 , γind 2 ) = (1.068, 1.068) after r = 4 rounds. However, from an overall network perspective, the best security conﬁguration (γsoc 1 , γsoc 2 ) would be the one which minimizes the accumulated total expenses E, i.e., from a social welfare perspective, the choice (γsoc 1 , γsoc 2 ) := arg min (γ1,γ2) X k=1,2 Ek(γ1, γ2) = (1.0984, 1.0984) would be beneﬁcial. Since γind i ̸= γsoc i , this simple example illustrates that, in general, indi- vidually optimal security choices will not correspond to investment levels which minimize the overall network expenses. Appendix H Allocation Data H.1 Data for Upper and Lower Allocation Strategies cdeg cbet cinv upper 19.363 (0.0030) 19.444 (0.0030) 19.323 (0.0030) 19.230 (0.0028) 19.460 (0.0031) 19.813 (0.0032) lower 19.891 (0.0033) 20.450 (0.0036) 21.551 (0.0040) 21.171 (0.0039) 19.601 (0.0032) 20.096 (0.0034) untargeted 19.516 (0.0031) 19.954 (0.0033) Table 3: Accumulated total expenses E after the allocation of the additional budget β = 5 among all network nodes. The three proposed allocation strategies are evaluated for each of the suggested centrality measures. Entries for the Erd˝os-R´enyi network are colored in blue (upper entries), and for the Barab´asi-Albert network in salmon (lower entries), respectively. Reference values without the injection of additional security are 21.66 for the Erd˝os-R´enyi, and 21.92 for the Barab´asi-Albert network. For each entry, cyber losses were generated from T = 10, 000, 000 simulations of the SIR epidemic process; standard errors are given in brackets. 39 H.2 Data for Centralized Upper Allocations targeted cdeg cbet cinv 10 % 21.129 (0.0037) 20.163 (0.0031) 21.120 (0.0036) 20.214 (0.0031) 21.130 (0.0037) 20.156 (0.0031) 20 % 20.091 (0.0033) 19.459 (0.0028) 20.152 (0.0033) 19.495 (0.0028) 20.111 (0.0033) 19.507 (0.0029) 30 % 19.702 (0.0031) 19.302 (0.0028) 19.769 (0.0031) 19.311 (0.0028) 19.769 (0.0031) 19.398 (0.0029) 40 % 19.523 (0.0030) 19.265 (0.0028) 19.554 (0.0031) 19.251 (0.0028) 19.545 (0.0030) 19.408 (0.0029) 50 % 19.406 (0.0030) 19.271 (0.0028) 19.454 (0.0030) 19.233 (0.0028) 19.454 (0.0030) 19.461 (0.0030) 60 % 19.347 (0.0030) 19.312 (0.0029) 19.367 (0.0030) 19.229 (0.0028) 19.378 (0.0030) 19.552 (0.0030) 70 % 19.328 (0.0030) 19.339 (0.0029) 19.324 (0.0030) 19.227 (0.0028) 19.364 (0.0030) 19.625 (0.0031) 80 % 19.329 (0.0030) 19.372 (0.0029) 19.319 (0.0030) 19.231 (0.0028) 19.374 (0.0030) 19.708 (0.0032) 90 % 19.345 (0.0030) 19.412 (0.0030) 19.319 (0.0030) 19.233 (0.0028) 19.405 (0.0031) 19.758 (0.0032) Table 4: Accumulated total expenses for diﬀerent percentages of targeted nodes under the upper allocation strategy for each centrality measure. Again, the total additional security budget is ﬁxed with size β = 5. Entries for the Erd˝os-R´enyi network are colored in blue (upper entries), and for the Barab´asi-Albert network in salmon (lower entries), respectively. The standard error of the stochastic simulations is given in brackets. For each entry, T = 10, 000, 000 simulations of the epidemic process were generated. 40 References Aliprantis, C. D. and K. C. Border (2006). Inﬁnite Dimensional Analysis. A Hitchhiker’s Guide. 3. ed. Springer. Allianz (2022). Allianz Risk Barometer. Tech. rep. Allianz Global Corporate & Specialty. Antonio, Y., S. W. Indratno, and R. Simanjuntak (2021). “Cyber Insurance Ratemaking: A Graph Mining Approach”. In: Risks 9(12). Awiszus, K., T. Knispel, I. Penner, G. Svindland, A. Voß, and S. Weber (2023). “Modeling and pricing cyber insurance. Idiosyncratic, systematic, and systemic risks”. In: European Actuarial Journal 13, pp. 1–53. BSI, ed. (2022). IT-Grundschutz-Kompendium. Bundesamt f¨ur Sicherheit in der Information- stechnik. Reguvis. Barab´asi, A.-L. and R. Albert (1999). “Emergence of scaling in random networks”. In: Science 286, pp. 509–512. Barab´asi, A.-L. and M. P´osfai (2016). Network Science. Cambridge University Press. B¨ohme, R., S. Laube, and M. Riek (2018). “A Fundamental Approach to Cyber Risk Analysis”. In: Variance. B¨ohme, R. and G. Schwartz (2010). “Modeling Cyber-Insurance: Towards a Unifying Frame- work”. In: WEIS. Bolot, J. and M. Lelarge (2009). “Economic incentives to increase security in the Internet: The case for insurance”. In: Proceedings of the 28th Conference on Computer Communications, Rio de Janeiro, Brazil, pp. 1494–1502. Br´emaud, P. (1999). Markov Chains. Gibbs Fields, Monte Carlo Simulation, and Queues. Vol. 31. Texts in Applied Mathematics. Springer. Chen, H., J. D. Cummins, T. Sun, and M. A. Weiss (2020). “The Reinsurance Network Among U.S. Property–Casualty Insurers: Microstructure, Insolvency Risk, and Contagion”. In: Journal of Risk and Insurance 87(2), pp. 253–284. Chen, H. and T. Sun (2020). “Tail Risk Networks of Insurers Around the Globe: An Empirical Examination of Systemic Risk for G-SIIs vs Non-G-SIIs”. In: Journal of Risk and Insurance 87(2), pp. 285–318. Chen, Z., H. Tong, and L. Ying (2018). “Realtime Robustiﬁcation of Interdependent Networks under Cascading Attacks”. In: 2018 IEEE International Conference on Big Data (Big Data), pp. 1347–1356. Chernikova, A., N. Gozzi, S. Boboila, P. Angadi, J. Loughner, M. Wilden, N. Perra, T. Eliassi- Rad, and A. Oprea (2022). “Cyber Network Resilience Against Self-Propagating Malware Attacks”. In: Computer Security – ESORICS 2022. Ed. by V. Atluri, R. Di Pietro, C. D. Jensen, and W. Meng. Springer International Publishing: Cham, pp. 531–550. Chiaradonna, S., P. Jevti´c, and N. Lanchier (2023). “Framework for cyber risk loss distribution of hospital infrastructure: Bond percolation on mixed random graphs approach”. In: Risk Analysis. Dacorogna, M. and M. Kratz (2023). “Managing cyber risk, a science in the making”. In: Scandinavian Actuarial Journal. EIOPA (2022). Discussion Paper on Methodologies of Insurance Stress Testing - Cyber compo- nent. European Insurance and Occupational Pensions Authority. ESRB, ed. (2020). Systemic Cyber Risk. European Systemic Risk Board. Eling, M. (2020). “Cyber risk research in business and actuarial science”. In: European Actuarial Journal, pp. 1–31. Erd¨os, P. and A. R´enyi (1959). “On Random Graphs I”. In: Publicationes Mathematicae De- brecen 6, pp. 290–297. Fahrenwaldt, M. A., S. Weber, and K. Weske (2018). “Pricing of cyber insurance contracts in a network model”. In: ASTIN Bulletin: The Journal of the IAA 48(3), pp. 1175–1218. 41 Feinstein, Z., B. Rudloﬀ, and S. Weber (2017). “Measures of systemic risk”. In: SIAM Journal on Financial Mathematics 8(1), pp. 672–708. F¨ollmer, H. (1974). “Random economies with many interacting agents”. In: Journal of Mathe- matical Economics 1(1), pp. 51–62. F¨ollmer, H. and A. Schied (2016). Stochastic Finance: An Introduction in Discrete Time. 4th ed. Walter de Gruyter. Freitas, S., A. Wicker, D. H. P. Chau, and J. Neil (2020). “D2M: Dynamic Defense and Modeling of Adversarial Movement in Networks”. In: Proceedings of the 2020 SIAM International Conference on Data Mining (SDM), pp. 541–549. Freitas, S., D. Yang, S. Kumar, H. Tong, and D. H. Chau (2022). “Graph Vulnerability and Robustness: A Survey”. In: IEEE Transactions on Knowledge and Data Engineering. GDV (2017). Allgemeine Versicherungsbedingungen f¨ur die Cyberrisiko-Versicherung (AVB Cy- ber), Musterbedingungen des GDV. Gesamtverband der Deutschen Versicherungswirtschaft e.V. (GDV). GDV (2019). Unverbindlicher Muster-Fragebogen zur Risikoerfassung im Rahmen von Cyber- Versicherungen f¨ur kleine und mittelst¨andische Unternehmen. Gesamtverband der Deutschen Versicherungswirtschaft e.V. (GDV). Gatzert, N. and M. Schubert (2022). “Cyber risk management in the US banking and insurance industry: A textual and empirical analysis of determinants and value”. In: Journal of Risk and Insurance 89(3), pp. 725–763. Giesecke, K. and S. Weber (2004). “Cyclical Correlations, Credit Contagion, and Portfolio Losses”. In: Journal of Banking and Finance 28(12), pp. 3009–3036. Giesecke, K. and S. Weber (2006). “Credit contagion and aggregate losses”. In: Journal of Economic Dynamics and Control 30(5), pp. 741–767. Gillespie, D. T. (1976). “A general method for numerically simulating the stochastic time evo- lution of coupled chemical reactions”. In: Journal of Computational Physics 22(4), pp. 403– 434. Gillespie, D. T. (1977). “Exact stochastic simulation of coupled chemical reactions”. In: The Journal of Physical Chemistry 81(25), pp. 2340–2361. Girvan, M. and M. E. J. Newman (2002). “Community structure in social and biological net- works”. In: Proceedings of the National Academy of Sciences of the United States of America 99(12), pp. 7821–7826. Hayel, Y., S. Trajanovski, E. Altman, H. Wang, and P. Van Mieghem (2014). “Complete game- theoretic characterization of SIS epidemics protection strategies”. In: 53rd IEEE Conference on Decision and Control, pp. 1179–1184. Herr, T. (2021). “Cyber insurance and private governance: The enforcement power of markets”. In: Regulation & Governance 15(1), pp. 98–114. Hillairet, C. and O. Lopez (2021). “Propagation of cyber incidents in an insurance portfolio: counting processes combined with compartmental epidemiological models”. In: Scandina- vian Actuarial Journal, pp. 1–24. Hillairet, C., O. Lopez, L. d’Oultremont, and B. Spoorenberg (2022). “Cyber-contagion model with network structure applied to insurance”. In: Insurance: Mathematics and Economics 107, pp. 88–101. Hurel, L. M. and L. C. Lobato (2018). “Unpacking cyber norms: private companies as norm entrepreneurs”. In: Journal of Cyber Policy 3(1), pp. 61–76. Jevti´c, P. and N. Lanchier (2020). “Dynamic structural percolation model of loss distribution for cyber risk of small and medium-sized enterprises for tree-based LAN topology”. In: Insurance: Mathematics and Economics 91, pp. 209–223. Jones, D., C. Snider, A. Nassehi, J. Yon, and B. Hicks (2020). “Characterising the Digital Twin: A systematic literature review”. In: CIRP Journal of Manufacturing Science and Technology 29, pp. 36–52. 42 Kermack, W. O. and A. G. McKendrick (1927). “A contribution to the mathematical theory of epidemics”. In: Proceedings of the Royal Society of London. Series A 115, pp. 700–721. Kiss, I. Z., J. C. Miller, and P. L. Simon (2017). Mathematics of Epidemics on Networks. From Exact to Approximate Models. Vol. 46. Interdisciplinary Applied Mathematics. Springer. Lagarde, C. (2021). Macroprudential policy in Europe – the future depends on what we do today. Welcome remarks by Christine Lagarde, President of the ECB and Chair of the European Systemic Risk Board, at the ﬁfth annual conference of the ESRB. Lallie, H. S., L. A. Shepherd, J. R. Nurse, A. Erola, G. Epiphaniou, C. Maple, and X. Bellekens (2021). “Cyber security in the age of COVID-19: A timeline and analysis of cyber-crime and cyber-attacks during the pandemic”. In: Computers & Security 105, p. 102248. Lemnitzer, J. M. (2021). “Why cybersecurity insurance should be regulated and compulsory”. In: Journal of Cyber Policy 6(2), pp. 118–136. Marotta, A., F. Martinelli, S. Nanni, A. Orlando, and A. Yautsiukhin (2017). “Cyber-insurance survey”. In: Computer Science Review. Masuda, N. and P. Holme, eds. (2017). Temporal Network Epidemiology. Theoretical Biology. Springer: Singapore. Mieghem, P. V. (2014). Performance Analysis of Complex Networks and Systems. Cambridge University Press: Cambridge. NIST (2022). Glossary of the National Institute of Standards and Technology. https://csrc.nist.gov/glossa Accessed: 2022-05-27. Naghizadeh, P. and M. Liu (2014). “Voluntary Participation in Cyber-insurance Markets”. In: Proceedings of the 2014 Annual Workshop on Economics in Information Security. Newman, M. E. J. (2018). Networks. Second Edition. Oxford University Press. Ogut, H., N. Menon, and S. Raghunathan (2005). “Cyber insurance and IT security investment”. In: Proceedings of the 4th Workshop on the Economics of Information Security. Pal, R., L. Golubchik, K. Psounis, and P. Hui (2014). “Will cyber insurance improve network security? A market analysis”. In: Proceedings of the 2014 INFOCOM, IEEE. Pastor-Satorras, R., C. Castellano, P. Van Mieghem, and A. Vespignani (2015). “Epidemic processes in complex networks”. In: Reviews of Modern Physics. Price, D. d. S. (1965). “Networks of Scientiﬁc Papers”. In: Science 149(3683), pp. 510–515. Price, D. d. S. (1976). “A general theory of bibliometric and other cumulative advantage pro- cesses”. In: Journal of the American Society for Information Science 27(5), pp. 292–306. Schwartz, G. A. and S. S. Sastry (2014). “Cyber-insurance framework for large scale interde- pendent networks”. In: Proceedings of the 3rd international conference on High conﬁdence networked systems, pp. 145–154. Sievers, T. (2021). “Proposal for a NIS directive 2.0: companies covered by the extended scope of application and their obligations”. In: International Cybersecurity Law Review 2, pp. 223– 231. Sweetman, A. (2022). Cyber and the City. Securing London’s Banks in the Computer Age. History of Computing. Springer. Talesh, S. A. (2018). “Data Breach, Privacy, and Cyber Insurance: How Insurance Companies Act as “Compliance Managers” for Businesses”. In: Law & Social Inquiry 43(2), 417–440. TeleTrusT, ed. (2021). Guideline “State of the Art”. TeleTrusT - IT Security Association Ger- many. In cooperation with ENISA. Trang, M. N. (2017). “Compulsory Corporate Cyber-Liability Insurance: Outsourcing Data Privacy Regulation to Prevent and Mitigate Data Breaches”. In: Minnesota Journal of Law, Science & Technology. Tumminello, M., A. Consiglio, P. Vassallo, R. Cesari, and F. Farabullini (2023). “Insurance fraud detection: A statistically validated network approach”. In: Journal of Risk and Insurance 90(2), pp. 381–419. 43 Woods, D. W. and T. Moore (2020). “Does Insurance Have a Future in Governing Cybersecu- rity?” In: IEEE Security & Privacy 18(1), pp. 21–27. Xu, M. and L. Hua (2019). “Cybersecurity insurance: Modeling and pricing”. In: North American Actuarial Journal 23(2), pp. 220–249. Yang, Z. and J. Lui (2014). “Security adoption and inﬂuence of cyber-insurance markets in heterogeneous networks”. In: Performance Evaluation 74, pp. 1–17. Zeller, G. and M. Scherer (2022). “A comprehensive model for cyber risk based on marked point processes and its application to insurance”. In: European Actuarial Journal 12, pp. 33–85. Zeller, G. and M. Scherer (2023). “Is Accumulation Risk In Cyber Systematically Underesti- mated?” In: SSRN. 44