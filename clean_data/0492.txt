CyberAlly: Leveraging LLMs and Knowledge Graphs to Empower Cyber Defenders Minjune Kim∗ CSIRO’s Data61 Sydney, NSW, Australia minjune.kim@data61.csiro.au Jeff Wang CSIRO’s Data61 Sydney, NSW, Australia jeff.wang@data61.csiro.au Kristen Moore CSIRO’s Data61 Melbourne, VIC, Australia kristen.moore@data61.csiro.au Diksha Goel CSIRO’s Data61 Melbourne, VIC, Australia diksha.goel@data61.csiro.au Derui Wang CSIRO’s Data61 Melbourne, VIC, Australia derek.wang@data61.csiro.au Ahmad Mohsin Edith Cowan University Perth, WA, Australia a.mohsin@ecu.edu.au Ahmed Ibrahim Edith Cowan University Perth, WA, Australia ahmed.ibrahim@ecu.edu.au Robin Doss Deakin University Melbourne, VIC, Australia robin.doss@deakin.edu.au Seyit Camtepe CSIRO’s Data61 Sydney, NSW, Australia seyit.camtepe@data61.csiro.au Helge Janicke Edith Cowan University Perth, WA, Australia h.janicke@ecu.edu.au Abstract The increasing frequency and sophistication of cyberattacks de- mand innovative approaches to strengthen defense capabilities. Training on live infrastructure poses significant risks to organiza- tions, making secure, isolated cyber ranges an essential tool for conducting Red vs. Blue Team training events. These events enable security teams to refine their skills without impacting operational environments. While such training provides a strong foundation, the ever-evolving nature of cyber threats necessitates additional support for effective defense. To address this challenge, we intro- duce CyberAlly, a knowledge graph-enhanced AI assistant designed to enhance the efficiency and effectiveness of Blue Teams during incident response. Integrated into our cyber range alongside an open-source SIEM platform, CyberAlly monitors alerts, tracks Blue Team actions, and suggests tailored mitigation recommendations based on insights from prior Red vs. Blue Team exercises. This demonstration highlights the feasibility and impact of CyberAlly in augmenting incident response and equipping defenders to tackle evolving threats with greater precision and confidence. CCS Concepts • Security and privacy →Security services. Keywords Augmenting Cyber Defence, Human AI Teaming, Cyber Incident Response 1 Introduction The increasing complexity and frequency of cyberattacks present significant challenges for cybersecurity practitioners. Modern Secu- rity Operation Centers (SOCs) must process vast volumes of system logs and alerts, the majority of which are benign or redundant – false positives arising from benign events being misinterpreted as potential attacks. This pervasive issue diminishes the efficiency of The manuscript has been accepted by WWW Companion ’25 Demo Track cyber defenders, leading to ‘alert fatigue’ and increasing the risk of critical threats going undetected. While existing Machine Learning (ML) approaches have shown promise in filtering and classifying alerts, they often lack the contextual awareness necessary to gen- erate actionable insights. Moreover, effectively integrating human expertise with automated systems remains a critical gap in current cybersecurity solutions. To address these challenges, we focused on the maritime sector in developing the cyber range for our training exercises, recognis- ing the rise in attacks targeting this critical infrastructure [9]. The range replicates the IT and operational technology (OT) systems of a shipping port, providing a realistic and secure environment for conducting Red vs. Blue Team wargames, where the Red Team simulates attackers and the Blue Team defends against threats. By simulating real-world attack scenarios, the cyber range supports Blue Teams in refining their skills while exploring innovative solu- tions to bridge the gap between human expertise and automated systems. Our demo addresses key research and engineering chal- lenges to aid Blue Team members in combating cyber threats with an effective human-AI collaboration. These challenges are outlined as follows: Challenge 1: Minimising Duplicated and Benign Alerts? Enterprise networks and OT systems in the cyber range generate a substantial volume of logs and alerts, much of which constitutes background noise. This noise often causes confusion, making it difficult to distinguish legitimate activity from actual attacks. Prior studies [10, 12] have shown that a high proportion of daily alerts in enterprise networks are duplicates, with only a small subset rep- resenting suspicious activity. ML-based methodologies have been explored to address this issue by reducing duplication or classifying alerts. For example, Kidmose et al. [3] proposed a supervised learn- ing method using recurrent neural networks (RNNs) and semantic analysis to map textual alerts to vector representations. This map- ping allowed the identification of incidents by clustering similar alerts in vector space. Other works have employed correlation [8] arXiv:2504.07457v1 [cs.CR] 10 Apr 2025 WWW Companion ’25, April 28-May 2, 2025, Sydney, NSW, Australia Minjune Kim et al. and alert clustering [2, 6] to reduce insignificant alerts. Classifica- tion methods have also been proposed to identify attacks based on textual similarity [4, 13]. Challenge 2: Generating Intelligent Suggestions with Con- textual Awareness? Incident alerts often lack the contextual in- formation necessary for security analysts to fully understand and address threats. Intelligent systems can enhance defenders’ decision- making by integrating alerts with system-based contextual data, such as the history of related incidents or predefined playbooks. This additional context helps ensure that suggestions are both rele- vant and actionable in real-time scenarios. Modern large language models (LLMs) offer advantages for solving complex problems us- ing general system knowledge. However, addressing specialised downstream tasks in the cybersecurity domain requires additional techniques, such as fine-tuning and prompt engineering. Retrieval- Augmented Generation (RAG) [5] provides a framework to enhance LLMs by retrieving relevant knowledge from external sources and incorporating it into the generation process. This approach com- bines domain-specific knowledge with real-time contextual infor- mation to improve the quality and relevance of outputs [14]. In our implementation, we utilise an LLM with a knowledge-graph RAG (KG-RAG) approach to combine general system knowledge with multiple knowledge sources and real-time data, enabling more precise and contextually aware suggestions. Challenge 3: Ensuring Comprehensive Validation of Pro- posed Methods? Evaluating the outputs generated by LLMs in the cybersecurity domain presents significant challenges due to the limited availability of relevant datasets. Existing resources, such as CyberMetric [11], which provides AI-driven questions and an- swers, and CyberBench [7], a multi-task benchmark for tasks like recognition and summarization, offer valuable starting points for evaluation. Similarly, Bhusal et al. [1] introduced a benchmark designed to assess LLM performance in realistic cybersecurity ad- visory contexts. However, these datasets do not fully capture the complexities and nuances of our specific use cases. To address this limitation, we conducted data collection during our Red vs. Blue Team events. This process included gathering system logs, expert responses, and alert messages, enabling us to construct a ground truth dataset tailored to our system-specific environments and sce- narios. This dataset serves as a robust foundation for evaluating our methods within the practical context of cybersecurity operations. Figure 1: CyberAlly Workflow: The system automatically analyses a high volume of incoming alert messages for the Wazuh SIEM1 via Slack2, generating intelligent suggestions for the Blue Team based on static and dynamic graph knowledge, and automates case ticket creation in Cydarm3. 2 Methodologies and System Design This paper introduces CyberAlly, an LLM-driven AI assistant that integrates knowledge graphs and LLMs to enhance incident re- sponse capabilities. During one of our 2-day training events, we collected a dataset of more than 60 thousand alert messages for training and verification. Of these, around 2.5 thousand distinct alert types were detected, excluding background noise, as summa- rized in Table 1. The table highlights the importance of removing duplicates and noise to enable effective response. The system ar- chitecture consists of two major components: alert filtering and dynamic prompting with knowledge graphs, as illustrated in Fig- ure 1. For alert filtering, we utilize a k-nearest neighbours (kNN) model for binary classification. For dynamic prompting, we imple- ment a KG-RAG using LlamaIndex, enabling contextually aware responses. Additionally, we leverage the Slack Bolt library 4 to ensure seamless user interactions with the system. Priority 3 4 5 6 7 8 9 10 12 15 # incl. dup 190 11 1461 20 109 5 47 612 1 55 # excl. dup 82 6 78 6 15 1 4 16 1 1 Table 1: #Alert messages: The first row shows the total number of alerts, including duplicates, while the second row indicates the count after duplicates are removed. 2.1 Alert Filtering and Classification Managing alert overhead is a critical challenge for cyber defenders, who often struggle to distinguish between benign and malicious ac- tivity amidst numerous alert messages. The simulated environment in the cyber range, designed to replicate real-world networks, in- herently generates false alerts from background activity. To address this issue, our system employs a two-step word-embedding-based approach: filtering duplicate alerts and categorising them using binary classification model. Duplicate Alert Filtering. To reduce alert volume, the system leverages sentence embeddings to map alert messages into a latent vector space. Input text for vectorization includes both full log de- tails and titles, with embeddings calculated as the average of word vectors. Cosine distance is then measured, and duplicates are ex- cluded if their similarity score exceeds a predefined threshold. This filtering process reduces redundancy and computational overhead. Benign only Benign + 1x Malicious Benign + 5x Malicious Benign + 10x Malicious Precision 0.9392 0.9904 0.9981 0.9992 Recall 0.9679 0.9974 0.9995 0.9997 F1 0.9533 0.9939 0.9988 0.9994 Table 2: Performance of the binary classification model with rebalanced datasets by upsampling malicious data instances at scales of 1x, 5x and 10x. Binary Classification with Feature Extraction. After filter- ing, a binary classification model categorizes the remaining alerts into two classes: benign or suspicious. As in the de-duplication pro- cess, semantic features are extracted from alert messages through the sentence embedding process, and the resulting embedding vec- tors are fed into the model, ensuring it retains critical contextual information for effective classification. The classification process employs a k-nearest neighbors (kNN) model with k=15, a value that 1https://wazuh.com/ 2https://slack.com/ 3https://www.cydarm.com/ 4https://api.slack.com/bolt CyberAlly: Leveraging LLMs and Knowledge Graphs to Empower Cyber Defenders WWW Companion ’25, April 28-May 2, 2025, Sydney, NSW, Australia demonstrated the best performance on our dataset. To address class imbalance, malicious samples were upsampled using a weighting technique, ensuring equitable representation during training. Addi- tionally, a time window of 30 minutes was configured to capture temporal patterns in the alert data. The model’s accuracy was eval- uated using 10-fold cross-validation to mitigate overfitting, with results summarized in Table 2. Alerts classified as benign are dis- carded, while those deemed suspicious progress to the next stage, where they are analyzed by the KG-RAG LLM system. This integra- tion enables defenders to focus on critical threats, minimizing false positives and enhancing response efficiency. 2.2 Dynamic Prompting using KG-RAG Despite advancements in LLMs, they often face challenges with domain-specific problems due to limited specialized knowledge and contextual understanding. To address these limitations, we pro- pose a Knowledge Graph-Enhanced Retrieval-Augmented Genera- tion (KG-RAG) framework, as shown in Figure 2, which integrates knowledge graphs to retrieve more accurate and context-specific data. The proposed knowledge graph architecture consists of two sub-graphs: a static graph representing knowledge from previous Red vs. Blue Team events, and a dynamic graph representing the current Red vs. Blue Team event and its alerts and Blue Team case management and change management tickets. Both the static and dynamic graphs contain the cyber range infrastructure and architec- ture details. With these sub-graphs, the KG-RAG can leverage both historical data and the current system state to inform the LLM’s generation process. This integration captures nuanced relationships between system components, enhancing the contextual accuracy of outputs. Figure 2: LLM with KG-RAG - Knowledge Graphs capture the relationships between past and present events and enhance contextual understanding. We implement the AI assistant using GPT-4o developed by Ope- nAI5 and KG-RAG to feed relevant information from internal and external sources (e.g., MITRE6 frameworks). This enables the sys- tem to stay up-to-date with current events and domain-specific contexts, improving the precision and relevance of its responses. KG-RAG enhances LLM-generated suggestions by dynamically en- riching the input prompt with relevant contextual information. To 5https://openai.com/ 6https://attack.mitre.org/ retrieve the most relevant information, KG-RAG computes similar- ity scores between the filtered incoming SIEM alert and the static and dynamic graphs, utilising LlamaIndex7. Our architecture extends standard knowledge graph-based meth- ods by incorporating dynamic updates to reflect real-time changes in the system. This approach allows the LLM to adapt to evolving conditions and provide more accurate and contextually relevant suggestions. Our preliminary experiments suggest that our KG- RAG module holds promise for addressing domain-specific tasks by leveraging both static and dynamic graphs. This approach enables the creation of a robust and adaptable system designed to enhance the accuracy and relevance of domain-specific outputs in real-time cybersecurity contexts. 2.3 Slack Integration The Cyber Security Incident Response Plan8 emphasizes the im- portance of effective logistics and communication tools, such as Slack, in coordinating incident response. During Red vs. Blue Team training events, the Blue Team relies primarily on Slack channels for communication. To enhance this workflow, CyberAlly has been integrated with Slack using a websocket, ensuring seamless and consistent interaction. As illustrated in Figure 3, we utilise Slack’s block builder to create customized message blocks that provide a comprehensive overview of incoming alerts. These blocks comprise three main components: i) Alert summary: Offers contextual insight into the alert, includ- ing any relevant connections to prior alerts or similar incidents., ii) Recommended Actions: Provides actionable insights and miti- gations, including command-line recommendations to address po- tential threats. iii) Explanation and Reasoning: Delivers transparent reasoning for the suggested actions, empowering users to make informed decisions. 3 Demonstration Figure 3 illustrates the key user interactions in the demonstration. During the real-time demo, participants will take on the role of Blue Team members and interact with CyberAlly to respond to simulated cybersecurity incidents. Alerts captured during previous events will be replayed to simluate a live environment, enabling participants to experience the functionality of CyberAlly in action. The primary workflows driving CyberAlly’s suggestions are as follows: (1) Wazuh Alert Monitoring: Participants will observe Wazuh posting alerts to Slack, where CyberAlly analyzes incoming data for suspicious behaviors. The system automatically fil- ters out alerts identified as duplicates or benign based on similarity thresholds. (2) Description & Suggested Actions: Participants will receive actionable recommendations from CyberAlly to address on- going attacks. By leveraging static and dynamic knowledge graphs, the system generates defence suggestions, includ- ing shell script-based commands, to guide participants in mitigating threats. 7https://www.llamaindex.ai/ 8https://www.cyber.gov.au/resources-business-and-government/governance-and- user-education/incident-response/cyber-security-incident-response-planning- practitioner-guidance WWW Companion ’25, April 28-May 2, 2025, Sydney, NSW, Australia Minjune Kim et al. Figure 3: CyberAlly in Slack. CyberAlly demo follows these steps: 1) monitor Wazuh alerts, 2) generate descriptions and suggest actions, 3) provide reasoning, 4) support decision-making, 5) create tickets in the Cydarm case management system, and 6) collect feedback. (3) Reasoning: CyberAlly will provide participants with expla- nations behind its recommendations, offering insights into the underlying reasons and relationships that inform its sug- gestions. This includes references to network architecture and historical events. (4) Decision Making: Participants will decide whether to cre- ate task tickets for handling incidents. CyberAlly facilitates this process by automatically populating tickets with recom- mended actions and relevant contextual information. (5) Cydarm Ticket Creation: Participants will see how Cy- berAlly generates and links task tickets in the Cydarm case management system, enabling efficient handling of suspi- cious alerts. (6) Feedback Collection: At the end of the demo, participants will provide feedback on CyberAlly’s performance, which will be collected to inform ongoing research and future im- provements. This hands-on experience allows participants to explore how Cy- berAlly enhances Blue Team workflows, demonstrating its ability to streamline decision-making and improve incident response ef- fectively. 4 Ethics This research adhered to ethical guidelines, with approval obtained from the ethics review boards of participating institutions. Par- ticipants in the cybersecurity wargame events provided informed consent prior to participation. During the demonstration at the conference, no data will be collected, but participants will receive a consent form detailing the nature of their involvement to ensure transparency and alignment with ethical best practices. 5 Conclusion This paper introduces a system designed to enhance human-AI collaboration within a cybersecurity wargame setting. CyberAlly is an intelligent suggestion system that assists cyber defenders by analyzing incoming alerts and providing context-aware recommen- dations for effective incident response. Integrating CyberAlly into a practical cyber range demonstrates its potential to reduce work- loads in SOCs while offering actionable insights linked to prior or related activities. This system represents a step forward in leverag- ing AI to support and augment human decision-making in complex cybersecurity environments. Acknowledgments The work has been supported by the Cyber Security Research Cen- tre Limited, whose activities are partially funded by the Australian Government’s Cooperative Research Centres Programme. References [1] Dipkamal Bhusal, Md Tanvirul Alam, Le Nguyen, Ashim Mahara, Zachary Light- cap, Rodney Frazier, Romy Fieblinger, Grace Long Torales, and Nidhi Rastogi. 2024. SECURE: Benchmarking Generative Large Language Models for Cyberse- curity Advisory. arXiv preprint arXiv:2405.20441 (2024). [2] Nengwen et al. 2020. Understanding and handling alert storm for online service systems. Proceedings - International Conference on Software Engineering (2020). [3] Egon Kidmose, Matija Stevanovic, Søren Brandbyge, and Jens M. Pedersen. 2020. Featureless Discovery of Correlated and False Intrusion Alerts. IEEE Access 8 (2020), 108748–108765. [4] Minjune Kim, Jin-Hee Cho, Hyuk Lim, Terrence J. Moore, Frederica Free-Nelson, Ryan K. L. Ko, and Dan Dongseong Kim. 2022. Evaluating Performance and Security of a Hybrid Moving Target Defense in SDN Environments. In 22nd IEEE International Conference on Software Quality, Reliability and Security, QRS 2022, Guangzhou, China, December 5-9, 2022. IEEE, 276–286. [5] Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim Rocktäschel, et al. 2020. Retrieval-augmented generation for knowledge-intensive nlp tasks. Advances in Neural Information Processing Systems 33 (2020), 9459–9474. [6] Derek Lin, Rashmi Raghu, Vivek Ramamurthy, Jin Yu, Regunathan Radhakr- ishnan, and Joseph Fernandez. 2014. Unveiling clusters of events for alert and incident management in large-scale enterprise it. Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (2014). [7] Zefang Liu, Jialei Shi, and John F Buford. 2024. Cyberbench: A multi-task bench- mark for evaluating large language models in cybersecurity. [8] Seyed Ali Mirheidari, Sajjad Arshad, and Rasool Jalili. 2013. Alert correlation algorithms: A survey and taxonomy. Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) 8300 LNCS (2013), 183–197. [9] Chalermpong Senarak. 2024. Port cyberattacks from 2011 to 2023: a literature review and discussion of selected cases. Maritime Economics & Logistics 26, 1 (2024), 105–130. [10] Riyanat Shittu, Alex Healing, Robert Ghanea-Hercock, Robin Bloomfield, and Rajarajan Muttukrishnan. 2014. OutMet: A new metric for prioritising intrusion alerts using correlation and outlier analysis. In Proceedings - Conference on Local Computer Networks, LCN. IEEE, 322–330. [11] Norbert Tihanyi, Mohamed Amine Ferrag, Ridhi Jain, and Merouane Debbah. 2024. Cybermetric: A benchmark dataset for evaluating large language models knowledge in cybersecurity. arXiv preprint arXiv:2402.07688 (2024). [12] Risto Vaarandi. 2021. A stream clustering algorithm for classifying network ids alerts. In 2021 IEEE International Conference on Cyber Security and Resilience (CSR). IEEE, 14–19. [13] Risto Vaarandi and K¯arlis Podiňš. 2010. Network IDS alert classification with frequent itemset mining and data clustering. In 2010 International Conference on Network and Service Management. 451–456. [14] Braden K Webb, Sumit Purohit, and Rounak Meyur. 2024. Cyber Knowledge Completion Using Large Language Models. arXiv preprint arXiv:2409.16176 (2024).