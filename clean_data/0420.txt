3rd IEEE International Conference on AI in Cybersecurity (ICAIC), DOI: 10.1109/ICAIC60265.2024.10433839, PREPRINT COPY CANAL - Cyber Activity News Alerting Language Model : Empirical Approach vs. Expensive LLMs Urjitkumar Patel Ratings Data Science S&P Global New York, USA urjitkumar.patel@spglobal.com Fang-Chun Yeh Ratings Data Science S&P Global New York, USA jessie.yeh@spglobal.com Chinmay Gondhalekar Ratings Data Science S&P Global New York, USA chinmay.gondhalekar@spglobal.com Abstract—In today’s digital landscape, where cyber attacks have become the norm, the detection of cyber attacks and threats is critically imperative across diverse domains. Our research presents a new empirical framework for cyber threat modeling, adept at parsing and categorizing cyber-related information from news articles, enhancing real-time vigilance for market stakehold- ers. At the core of this framework is a fine-tuned BERT model, which we call CANAL - Cyber Activity News Alerting Language Model, tailored for cyber categorization using a novel silver labeling approach powered by Random Forest. We benchmark CANAL against larger, costlier LLMs, including GPT-4, LLaMA, and Zephyr, highlighting their zero to few-shot learning in cyber news classification. CANAL demonstrates superior performance by outperforming all other LLM counterparts in both accuracy and cost-effectiveness. Furthermore, we introduce the Cyber Signal Discovery module, a strategic component designed to efficiently detect emerging cyber signals from news articles. Collectively, CANAL and Cyber Signal Discovery module equip our framework to provide a robust and cost-effective solution for businesses that require agile responses to cyber intelligence. Index Terms—Large Language Models (LLM), BERT, Natural Language Processing (NLP), Machine Learning, Generative AI (GenAI), Cyber Risk Modeling, Cyber Signal Discovery, Cyber News Alerts, Empirical Cost Analysis I. INTRODUCTION The recent escalation in cyber attacks is a significant concern that spans across multiple sectors. As reported by ISACA’s 2023 State of Cybersecurity [1], there’s an evident increase in cyberattacks across organizations. This trend is not limited to one domain; it affects diverse areas such as technology, oil and gas, healthcare, education, and finance. The technology sector frequently confronts data breaches and intellectual property theft, while the oil and gas industry faces threats to its critical infrastructure. In finance, cyber attacks can lead to significant financial losses and under- mine consumer confidence. Each of these sectors, including healthcare, where data encryption in ransomware attacks is alarmingly high [2], and education, with its highest rate of ransomware incidents [3], demonstrates the broad spectrum of cyber vulnerability. In this context, the timely detection and dissemination of information about cyber attacks and threats become crucial. News articles, in particular, play an essential role in pro- viding real-time information and early warnings. We define a framework which combines entity relevance with a novel categorization scheme that segments cyber-related news into five distinct groups, each providing unique insights. This system not only aids in constructing comprehensive cyber profiles for entities but also facilitates informed decision- making by providing nuanced insights into their cyber risk exposure. Recent advancements in Natural Language Processing (NLP), especially transformer-based models like BERT [4], T5 [5], Flan [6], GPT [7], Llama [8], Mistral [9], Claude [10], PaLM [11] have revolutionized various NLP tasks, including applications in the cyber domain. In past year, we have seen capable applications such as OpenAI’s ChatGPT [12], Google’s Bard [13] which are powered by multi billion param- eter models, GPT4 and Palm respectively, have become inte- gral part of indiviuals and organizations for their daily tasks. These powerful models have shown remarkable capabilities in processing and understanding complex language structures. However, the widespread adoption of these advanced models is often hampered by their need for substantial computational resources and the associated high costs of infrastructure or API usage. We demonstrate that for tasks such as Cyber Categorization, simpler and smaller BERT [4] model when finetuned with good data, outperforms these huge expensive models. Addressing the prevalent challenges, our research introduces a cost-efficient empirical framework, leveraging a finetuned BERT architecture with minimal training data requirements. This framework excels in accurately categorizing cyber-related content from news articles, ensuring timely awareness for stakeholders. A key feature is the Cyber Signal Discovery module, adept at spotting emerging threats and enhancing our cyber terminology database with human-verified updates. Below, we outline the pivotal contributions of our research to the field: • Introduction of CANAL (Cyber Activity News Alert- ing Language Model): A cutting-edge model specifically developed for the efficient categorization of cyber-related information within news articles. • Unique 5 Class Cyber Categorization: We introduce a novel classification scheme, grouping cyber-related news arXiv:2405.06772v1 [cs.CR] 10 May 2024 into five distinct categories, each serving a different function across business domains. • Efficient Fine-Tuning of CANAL: Empirical fine-tuning framework using a minimal dataset, achieving state-of- the-art results. • Benchmarking Against Larger Models: Comparative analysis with major LLMs, focusing on zero to few-shot learning in cyber classification. • Cyber Signal Discovery Module: Advanced module for detecting emerging cyber threats, integrated with human expertise. • Cost-Effective and Resource-Efficient Solution: Demonstrating a more economical and efficient alternative in cyber categorization. • Cyber Alerting Solution that Utilizes News Data: Utilizing raw news data for comprehensive and up-to- date cyber threat alerting. II. LITERATURE REVIEW The realm of cybersecurity is undergoing a significant transformation, driven by the increasing frequency and com- plexity of cyber threats in various sectors. The ISACA 2023 State of Cybersecurity report indicates a rise in cyberattacks impacting sectors such as technology, healthcare, education, and finance [1]. In response to these challenges, Artificial Intelligence (AI) is playing a crucial role in evolving the cybersecurity landscape. AI-driven approaches are enhancing threat detection capabilities and enabling automated responses. The advent of transformer-based models, such as those introduced by Vaswani et al. [14], has ushered in a new era in NLP. Jacob Devlin et al.’s BERT [4] stands out in this evolu- tion, leveraging deep bidirectional representations to transform tasks like question answering and language inference. Its application in domain-specific tasks, as exemplified by Dogu Araci’s FinBERT [15], showcases the adaptability of encoder- only transformer models, which are particularly effective for cyber-specific classification tasks where generative capabilities are less critical. While generative models like llama [8], BloombergGPT [16], GPT [7] [17] have expanded the scope of transformers, their scalability, seen in models like PaLM [11], introduces significant resource demands. The resource-intensive nature of these models [18] and the associated costs [19] make them less practical for smaller, specific applications. Hoffman et al.’s Chinchilla study [20] offers a balanced perspective on model size and training data, yet the deployment of such large models in constrained environments remains debatable. This context underscores the relevance of models like BERT, which provide a more feasible and efficient approach for specialized tasks in the realm of cybersecurity. The integration of NLP into cybersecurity, particularly using transformer-based models like BERT, has opened new avenues in threat detection and classification. Notable applications of BERT in cybersecurity extend beyond traditional models. Ebelechukwu et al.’s CAN-BERT for anomaly detection in automotive systems [21], Rahali et al.’s MalBERT for Malware identification using Android application source code [22], and Chen et al.’s BERT-Log for system log interpretation [23] are a few examples. Adding to this, Kimia Aneri et al. introduced CyBERT, which fine-tunes BERT for cybersecurity claim classification, focusing on optimal hyperparameters for en- hanced accuracy [24]. Furthermore, Salih Yasir et al. explored malware detection using fastText and BERT, emphasizing the purification and optimization of API call sequences for classification tasks [25]. Moreover, Aghaei et al. introduced SecureBERT, a cybersecurity language model capable of cap- turing text connotations in cybersecurity text tailored for Cyber Threat Intelligence (CTI) tasks, exemplifying the model’s adaptability to specialized cybersecurity needs [26]. These diverse applications underscore BERT’s adaptability and ef- fectiveness in addressing specialized cybersecurity challenges. The evolution of cybersecurity alert systems has been marked by significant advancements through the analysis of online data. In 2015, Yigit Erkal et al. utilized Twitter data for cyber security content identification, using a Naive Bayes Classifier and TF-IDF vectorization [27]. By 2018, Mohamad Syahir Abdullah et al. furthered this field by focusing on detecting cyber-attack news, employing a Conditional Random Field classifier and Latent Semantic Analysis [28]. In 2021, Thea Riebe et al. introduced CySecAlert, a Twitter-based system for alerting on cyber security topics [29]. On a cyber specific NER, Md TanvirAlum et al. proposed CyNER, a Python library for cybersecurity named entity recognition (NER), leveraging transformer-based models and heuristics to extract cybersecurity-related entities [30] However, despite these advancements, there appears to be a gap in the literature concerning the application of BERT- based models for generating cyber alerts from more real time news sources like Google News. To the best of our knowledge, no studies have yet explored the finetuning of BERT models specifically for the generation of cyber alerts based on Google News alert data. This gap signifies a potential area for future research, particularly given BERT’s proven efficacy in text classification and its potential applicability in the nuanced field of cyber risk modeling. Our study addresses a significant gap in cyber threat de- tection by introducing a framework that generates entity- focused cyber alerts from online news, utilizing cost-effective and efficient Large Language Models (LLMs). This approach overcomes key challenges such as limited training data and the dynamic nature of cyber threats. By processing vast amounts of online news to identify relevant cyber risks, our framework enhances the accuracy and timeliness of alerts, making it a valuable addition to existing cyber threat intelligence systems. Overall, our research contributes to advancing cyber threat detection strategies in today’s digital landscape. III. BACKGROUND AND THEORY A. Problem Statement In the rapidly evolving domain of cybersecurity, the daily influx of thousands of news articles presents a significant chal- lenge in information management and analysis. Our study’s goal is two-fold: firstly, to effectively categorize these articles into five distinct categories — Recent Cyber Attack, Litigation, Future Threats, Preventive Action, and “Other”; and secondly, to discover and highlight emerging cyber threats and signals. This dual approach is essential for systematically organizing and analyzing the vast array of incoming cyber-related news, enabling a more focused and efficient method for cyber threat intelligence. Our system aims to achieve these objectives using a practical, efficient, and cost-effective approach, distin- guishing it from the more expensive Large Language Models (LLMs). The categorization is as follows: • Recent Cyber Attack : This category encompasses articles that report on recent real cyber attacks targeting entities. These articles provide critical insights into actual cyber threats that have resulted in tangible damage to companies. These Articles constitute a significant portion of our dataset, as they offer invaluable information for understanding the evolving cyber threat landscape. • Cyber Litigation : Litigation Articles pertain to news ar- ticles that discuss legal actions, investigations, or charges related to cyber incidents. These articles are crucial for professionals tracking legal developments and conse- quences in the cybersecurity domain. • Future Cyber Threats: Future Threats category includes articles that address potential cyber risks and threats that organizations may face in the future. These articles are forward-looking and target an audience interested in proactive risk assessment. • Cyber Risk Preventive: Preventive Action articles high- light positive actions, remedies, vulnerability fixes, and patches aimed at reducing the likelihood of future cyber risks. This category is particularly important as it con- tributes to building a positive cyber profile for an entity. • Other: The “Other” category encompasses a diverse range of articles, including reports, studies, educational content, guidance materials, and miscellaneous topics related to cybersecurity. This category serves as a catch- all for articles that do not neatly fit into the first four classifications, providing additional context and insights into various aspects of cybersecurity. By efficiently sorting these articles into relevant categories, our system seeks to enhance the utility and accessibility of cyber news, making it more actionable for cybersecurity professionals and organizations. B. Data We utilize Google News data via news alerts RSS feeds for our entire experiment. Initially, leveraging SME (Subject Matter Expertise), we configured the Google News Alerts with specific cyber terms such as ’data breach,’ ’ransomware,’ and TABLE I: Data structure - Example of a single article entry from data theft feed id link published datetime updated datetime headline content feed name UQPuJ TWfJ9 8oipe wHLcF Ef https://www.bnnb loomberg.ca/tesla- data-breach- blamed- on-insider- wrongdoing- impcted-75-000- 1.1961383 2023- 08-20 17:40:21. 000 2023- 08-20 17:40:21. 000 Tesla Data Breach Blamed on ’Insider Wrongdoing’ Impacted 75,000 - BNN Bloomberg (Bloomberg) – Tesla Inc.’s May data breach impacted more than 75,000 people, included employee-related records and was a result of “insider ... data theft TABLE II: Five Cyber attack categories. Category News Headlines Recent Royal Mail hit by cyber attack causing ’severe disruption’ to services Cyber HHS compromised in massive MOVEit hack attack FTX says $415 million of crypto was hacked ... Future Metro Bank Warns Against Rising Malware Attacks Cyber Apple issues 30-day warning to iPhone users threat Alarm raised over Mozilla VPN security flaw ... Cisco Releases A Fix For The Major ClamAV Antivirus Software Flaw Cyber Microsoft issues 75 patches, including three for zero-day Prevention Android 14 Will Block Malware With Enhanced Security Updates ... CommonSpirit Health sued over ransomware attack Cyber Meta hit with 390 mn euro fine over EU data breaches Litigation JPMorgan Must Face Lawsuit by Ray-Ban Maker over $272 M ... This New McDonald’s Hack Turns Sprite Into Cotton Candy Soda Other Samsung Galaxy Z Fold 5 can fix design flaw present in the brand’s folding Our View: Google should have to answer for reckless site-blocking issues ... ’cyberattack.’ This setup generates a substantial number of news alerts daily, which we scrape and save to our database. We continually refine these feeds, adding new terms as they emerge in the cyber domain. Over a period of one year and ten months, starting from early 2022 through to the end of October 2023, we have amassed a collection of approximately 265,000 cyber ralated articles. Each article is accompanied by metadata such as ID, link, publication date, and a headline, as detailed in Table I. For our experiments, we focus exclusively on the headlines, which we have found to be sufficiently informative for our categorization challenge. Table II showcases various examples of news titles within each category. C. Theoretical Framework Given a news title comprising a sequence of N tokens w1, w2, . . . , wN, we aim to determine a probability distribution P over five cyber categories. This distribution is a function of the input tokens, represented as: P = f(w1, w2, . . . , wN) (1) Where f denotes the model that estimates the probability distribution that satisfy the following condition: 5 X i=1 Pi = 1, where Pi ∈{Pcyber attack, Pfuture threat, Pprevention, Plitigation, Pother} Fig. 1: An illustration of Emerging Cyber Signal Discovery Module The predicted final category is obtained through a decision function g, which could be a simple maximization of the probabilities or a threshold-based approach: Predicted Category = g(P), where g : P →Category This function evaluates the highest probability or applies a pre-defined threshold to determine the most likely category. IV. METHODOLOGY A. Emerging Cyber Signal Discovery Module In response to increasing cyber attack frequencies, we’ve developed an Emerging Cyber Signal Discovery Module to identify and catalog new cyber attack terms for related news article retrieval. The module comprises three integral components: predefined cyber base terminologies, a tailored word vector model, and human feedback. Initially, a curated set of 30 cyber base terminologies is selected with the aid of subject matter expertise. Subsequently, each terminology is fed into the model, which, in turn, outputs related new terms meeting predefined criteria. Lastly, through a process of human feedback, the returned terms are meticulously reviewed and incorporated into the existing repository of cyber base terminologies. This systematic approach ensures the continual augmentation and refinement of the terminology lexicon to effectively adapt to the evolving landscape of cyber threats. An illustration of the module can see in Fig. 1. The word vector model that we use in this module is trained by all news articles that we collect at the moment using the skip-gram method [31]. The training objective of the Skip-gram model is to find word representations that are useful for predicting the surrounding words in a sentence or a document. More formally, given a sequence of training words w1, w2, . . . , wT , the objective of the Skip-gram model is to maximize the average log probability 1 T T X t=1 X −c≤j≤c,j̸=0 log p(wt+j|wt) (2) Fig. 2: An illustration with Ransomware Feed Term where c is the size of the training context (which can be a function of the center word wt). Larger c results in more training examples and thus can lead to a higher accuracy, at the expense of the training time. The basic Skip-gram formulation defines p(wt+j|wt) using the softmax function: p(wO|wI) = exp(v′ wO T vwI) PW w=1 exp(v′w T vwI) (3) where vw and v′ w are the ”input” and ”output” vector representations of w, and W is the number of words in the vocabulary. Utilizing the word vector model, we map words from the corpus into vectors within a hundred-dimensional vector space, formalizing the transformation as a function f : word 7→R100. We then use cosine similarity to compute the similarity score between input cyber terms and other terms. The similarity score can be represented as: Similarity(wp, wq) = vwp · vwq ∥vwp∥∥vwq∥ (4) Here, wp and wq represent two different words, and vwp and vwq are their respective word vectors obtained from the skip- gram model. The dot product in the numerator measures the similarity in the orientation of the vectors, and the denominator normalizes the similarity by the magnitudes of the vectors. This cosine similarity metric provides a measure of the direc- tional similarity between words in the vector space, ranging from 0 (completely dissimilar) to 1 (completely similar). This approach allows us to quantify the semantic relationships between cyber terms and other terms in our corpus, aiding in the analysis of the contextual associations between words. In our Cyber Signal Discovery module, we adhere to two principal criteria for term selection: (1) Candidate terms must exhibit at least a 60% similarity score to the given cyber term. (2) Candidate terms must not duplicate or merely extend the existing entries in our cyber terminology database. Fig. 2 illustrates this procedure using ’ransomware’ as an input term. In the first iteration, terms such as ’LockBit’ and ’SickKids’ that score above the similarity threshold and are not already cataloged are identified. These are then subjected to human validation. For instance, ’LockBit’ is approved and subse- quently becomes a seed term for the next iteration, leading to the discovery of ’BlackCat’ and ’BianLian’ in subsequent rounds. This iterative process effectively enriches our database with relevant and emerging cyber terms. B. Random Forest Silver Labeling Silver labeling is an innovative technique situated between gold standard annotations and unsupervised predictions. It is particularly valuable in scenarios where acquiring labeled data is cost-prohibitive or logistically challenging. In our study, silver labels were generated to extend our training dataset, enabling us to train supervised models with a more substantial and diverse set of examples than would be feasible with manually annotated data alone. We use the Random Forest algorithm for its ensemble ap- proach that averages predictions from multiple decision trees, reducing overfitting risks. It is particularly suited for our small dataset size, outperforming gradient boosting methods like XGBoost [32] and LightGBM [33] that typically require larger datasets to avoid learning noise as patterns. We implemented a Random Forest with 100 decision trees, optimized through cross-validation to ensure a balance between computational efficiency and predictive accuracy. The decision trees utilize Entropy as a measure to maximize split quality, defined as E(S) = c X i=1 −pi log2 pi (5) where pi represents the probability of an element belonging to class i, and c is the number of classes. Information Gain (IG), crucial for determining the most informative feature at each split, is used in our model to guide the decision-making process of the trees: IG(D, A) = E(D) − m X j=1 |Dj| |D| E(Dj) (6) Here, IG(D, A) is the information gain from partitioning dataset D with feature A, E(D) is the dataset’s entropy, m is the number of distinct values feature A can take, and E(Dj) is the entropy of the subset where A equals j. The term |Dj| |D| weights the entropy of each subset, indicating the proportion of instances in subset Dj post-split. Information gain quantifies the expected reduction in entropy upon learning the value of attribute A. C. CANAL Central to our framework is CANAL (Cyber Activity News Alerting Language Model), a fine-tuned BERT [4] model meticulously crafted for cyber news categorization. BERT’s architecture includes multi-layer bidirectional transformer en- coders, self-attention mechanisms, and feed-forward neural networks, which are adept at processing complex text. The classifier layer is added atop the BERT model for classification tasks. The final hidden state from BERT, denoted by h, with weights W and bias b, produces the output y via: y = f(W · h + b) (7) Fig. 3: Illustration of CANAL with BERT Fine Tuning on cyber classification task. where f is the softmax activation function. Fine-tuning with a lower learning rate using AdamW optimizer and a custom learning rate scheduler is crucial to retain the pre-trained knowledge. The softmax function for the classifier output is: softmax(yi) = eyi P j eyj (8) where yi is the output logit for class i. The Fig. 3 presents a schematic of CANAL. The left section outlines the BERT Base Model structure, showcasing its dual training objectives: Next Sentence Prediction and Masked Language Model (LM) Prediction. These components process sequences of tokenized inputs, each sequence initiated with a [CLS] token and interspersed with [SEP] tokens. In the right section, the BERT Classifier is depicted, which has been fine-tuned using a curated dataset specific to cyber-related news for enhanced classification accuracy. The classifier also processes tokenized inputs through dense layers, ultimately yielding categorized outputs. This schematic encapsulates the model’s initial pre-training on diverse language data followed by its subsequent specialization through fine-tuning for cyber threat detection and classification. We explore several other fine-tuning techniques to opti- mize CANAL’s performance including Partial Finetuning with PEFT (Parameter-Efficient Fine-Tuning), and the integration of PEFT with LoRA (Low-Rank Adaptation). 1) Parameter-Efficient Fine-Tuning (PEFT): We explore Parameter-Efficient Fine-Tuning (PEFT) [34] for its efficiency in fine-tuning large LLMs. While full fine-tuning updates all parameters, partial fine-tuning in PEFT selectively freezes a portion of the model’s weights while fine-tuning the rest. The fine-tuning process for both full and partial parameter updates explores the performance impact on our multiclass classification task, providing insights into the trade-offs be- tween computational efficiency and classification effective- ness. Fig. 4: An illustration of LoRA from an original paper [35] 2) PEFT with LoRA: We also experiment with PEFT com- bined with Low-Rank Adaptation (LoRA) [35]. LoRA updates a pre-trained weight matrix W0 with a low-rank decomposition W0+∆W = W0+BA, where B ∈Rd×r and A ∈Rr×k, and the rank r ≪min(d, k). As shown in figure 4, during training, W0 is frozen, while A and B contain trainable parameters. The modified forward pass with LoRA is: h = W0x + ∆Wx = W0x + BAx (9) Our approach integrates BERT’s architecture with PEFT and LoRA fine-tuning for effective cyber multiclassification, as demonstrated in our methodology. D. Generative Models In our investigation of cyber-related text classification, we benchmark our model against three state-of-the-art language models that are at the forefront of NLP advancements. At the time of writing, GPT-4 by OpenAI has emerged as a frontrunner, leading the field with its remarkable capabilities in generating human-like text and is accessible through the OpenAI API. Alongside GPT-4, Llama 13B and Zephyr 7B Beta have made significant strides in the open-source space, excelling across various NLP benchmarks. Below, we provide brief introductions to the technical details of each model. 1) GPT-4: GPT-4 [7], an advanced multimodal model, stands out in the realm of natural language processing, par- ticularly in processing image and text inputs to generate text outputs. Its proficiency is highlighted in complex scenarios, such as human-designed exams, where it notably scored in the top 10% in a simulated bar exam. Surpassing earlier versions like GPT-3 and GPT-3.5, as well as other significant large language models (LLMs) including Cloude, Llama, and PaLM, GPT-4 demonstrates exceptional capabilities across multiple languages in standard NLP benchmarks. This versatility and robustness mark a new milestone in the evolution of language models. 2) Llama 2 Chat (Unquantized): The Llama 2 Chat [8] model, a fine-tuned version of Llama 2, is optimized for dialogue use cases and ranges from 7 × 109 to 7 × 1010 parameters. Its training incorporates the pretraining of Llama 2 with public online sources, followed by supervised fine- tuning, and further refinement through Reinforcement Learn- ing with Human Feedback (RLHF), using rejection sam- pling and Proximal Policy Optimization (PPO). The model adopts most architectural settings from Llama 1, including the standard transformer architecture with modifications like pre-normalization using RMSNorm, the SwiGLU activation function [36], and rotary positional embeddings (RoPE). Ad- ditionally, it features grouped-query attention and an increased context length, trained using the AdamW optimizer. 3) Zephyr 7B Beta (Unquantized): The Zephyr language model [37], as detailed in the paper, represents a significant shift from the Llama 2 Chat model in its approach to train- ing and alignment with user intent. Zephyr, specifically the 7-billion parameter model Zephyr-7B, is designed to be a smaller, more aligned model focusing on distilled supervised fine-tuning (dSFT) and distilled direct preference optimization (dDPO). Unlike Llama 2 Chat, Zephyr uses AI Feedback (AIF) from a set of teacher models for preference data, bypassing the need for human annotation and additional sampling. This approach enables rapid training in just a few hours, setting a new benchmark for 7B parameter chat models and surpassing the performance of Llama 2 Chat on certain benchmarks. These three language models, GPT-4, Llama 13B (unquan- tized), and Zephyr 7B Beta (unquantized), serve as bench- marks in our evaluation, allowing us to assess the performance of our cyber-related text classification model in comparison to the industry-leading and open-source state-of-the-art models in the field. E. Entity Relevance Module We introduce the Entity Relevance Module as part of our system to enhance the processing of news articles by deter- mining the contextual relevance of identified entities within the text. Unlike standard NER models that simply tag entities, this module assesses their contextual significance within the news titles. For instance, in the statement ”Cyber attacks rise, says Y Bank,” a traditional NER model would identify ”Y Bank” as an entity, but our module also evaluates its contextual relevance, recognizing that ”Y Bank” is offering an opinion rather than being the central focus. The model applies a sigmoid function to determine the probability of relevance: P(Class 1 - Relevant) = σ(W · Φ(input) + b) (10) where σ denotes the sigmoid activation function, W and b are the model weights and bias, and Φ(input) is the feature representation of the input. While details of the training process are beyond this paper’s scope, in summary, the Entity Relevance Module is trained on labeled data, producing probabilities that contribute to nuanced entity-centric analysis. V. TRAINING AND EVALUATION SCHEME A. Train-Test Data • Train Set Composition: The dataset utilized for training in this study was collated over a period extending from January 2022 to September 2023. This comprehensive dataset comprises a diverse array of samples a total volume of about 250000 samples. • Test Set Composition: In assessing the performance of CANAL, exclusive data from October 2023 was em- ployed for the evaluation. Specifically, a subset compris- ing 2000 articles from the articles of that month was sampled for testing. B. Data Labeling and Categorization • Gold Standard Dataset: A subset of 600 samples from train set was meticulously labeled by domain experts to establish a ’Gold Standard’ dataset. Special attention was paid to addressing class imbalance through stratified sampling and weighting classes inversely proportional to their frequencies in the input data. This dataset served as a benchmark for the initial Random Forest model training. • Silver Label Dataset using RF: The Random Forest model, initially trained on the 600- sample ’Gold Standard’ dataset, was then applied to the remaining data spanning from 2022 to September 2023. This step involved using the trained model to automate the labeling process, thereby generating ’Silver Labels’ for a large volume of data. This approach enabled us with additional 8,000 records, which exhibited a high degree of certainty in their labeling. • BERT Model Fine-Tuning Data: The selected sample set, enriched with both gold and silver labeled data, was employed for the fine-tuning of a BERT based model. This subset was specifically chosen to represent the population distribution accurately, ensuring that the model’s training would be reflective of the diverse char- acteristics present within the larger dataset. This step was crucial for adapting the model to the specific nuances and characteristics of our dataset. C. Cyber Signal Discovery Module Training Scheme The Emerging Cyber Signal Discovery Module is executed on a monthly basis to identify novel cyber terms. Prior to each run, the word vector model undergoes updates through the latest news data. We conclude the process either after 10 runs or when our stopping criteria are met. These criteria include: (1) words exhibiting a similarity score greater than 60% to the specified cyber term, and (2) words that neither duplicate nor merely extend the entries present in our cyber terminology database. We halt the process at the occurrence of the first of these conditions. This periodic assessment ensures the con- tinuous detection and incorporation of emerging cybersecurity terminology, contributing to the adaptability and efficacy of the system in capturing evolving cyber threats. TABLE III: Random Forest Hyperparameters Hyperparameter Value bootstrap True criterion entropy max depth 10 max features auto n estimators 100 random state 42 verbose 0 warm start False D. Random Forest Training Scheme Our Random Forest (RF) model was trained on a Gold Stan- dard dataset comprising 600 samples with expertly annotated labels to establish a robust initial model. The hyperparameters of the model are listed in Table III. To counter potential bias in silver label generation, we filtered our data retrieval with pre- cise SQL queries, ensuring a representative dataset for training. This phase was critical for establishing a strong foundational model capable of further refinement and application on a larger dataset. E. Training Scheme for BERT fine-tuning 1) Fine-Tuning Runs: We conducted a series of four distinct BERT fine-tuning runs, each with a specific configuration aimed at exploring the effects of different levels of layer- wise training on model performance. The configurations for the fine-tuning runs were as follows: • PeFT LoRA r=8: This run involved a Parameter efficient fine tuning (PeFT) approach with a Low-Rank Adaptation (LoRA) with a rank of 8, which creates adapter weight matrices which are used in conjunction with complete model weights to work on classification task. • Last Layer + Classification Layer: The second run was confined to training only the last layer of the BERT model in conjunction with the classification layer. • Last 2 Layers + Classification Layer: The third run extended the training to include the last two layers of the BERT model alongside the classification layer. • Full BERT Fine-Tuning: The final run encompassed a comprehensive fine-tuning of the entire BERT model. 2) Gradient Freezing: In our fine-tuning methodology, we employed gradient freezing for all layers except the ones undergoing fine-tuning. This technique not only requires less computational power but also reduces the time needed for model training compared to full model fine-tuning. Gradient freezing is a commonly adopted practice within the machine learning community for its efficiency in fine-tuning deep learning models. 3) BERT Hyper parameters: The table IV provides final hyper-parameters used for BERT model fine tuning. A com- prehensive analysis of the training, validation cross entropy loss and recall trends across multiple epochs during the fine- tuning process of the BERT-based model is plotted in Fig. 5. The x-axis represents the number of training epochs, ranging from 1 to 10. The y-axis denotes the cross entropy loss values TABLE IV: BERT Training Hyperparameters Parameter Value learning rate 2e-5 per device train batch size 8 per device eval batch size 8 data seed 727 seed 767 save strategy epoch evaluation strategy epoch load best model at end True num train epochs 10.0 and recall values, which are computed for both the training and validation datasets. F. Prompt Engineering for LLMs In our approach to classifying cyber news into five cate- gories, we iteratively refined prompt templates to enhance the understanding and performance of Language Large Models. • Template 1, Zero Shot: Basic Instruction Set Our initial template provided only the basic instruction and the five categories, relying on the LLMs’ inherent capabilities to interpret and classify the content correctly. Template 1 Zero Shot: You are a cyber analyst. You will be provided with a sentence of news regarding different entities. The entity could be an organization, location, place, person, or group. The sentence will be delimited with #### characters. Classify the sentence into one of five categories and output the category name only. Five categories are: 1) Recent Cyber Attack 2) Cyber Litigation 3) Cyber Attack Prevention 4) Future Cyber Threat 5) Other Fig. 5: Illustration of training and validation Cross-Entropy loss over 10 epochs • Template 2, Zero Shot: Defined Criteria for Each Category To improve clarity, the second template incorporated specific criteria for each category, particularly empha- sizing that the news should pertain to an identifiable entity in categories like Recent Cyber Attack, Litigation, Prevention, and Future Threat. Template 2 Zero Shot: You are a cyber analyst. You will ... Classify the sentence into one of the following five categories, now defined with specific criteria: 1) Recent Cyber Attack: Sentences reporting on recent cyber attacks targeting entities. 2) Cyber Litigation: Sentences discussing legal actions, investigations, or charges related to cyber incidents. 3) Cyber Attack Prevention: Sentences highlight- ing positive actions, remedies, vulnerability fixes, and patches aimed at reducing the like- lihood of future cyber risks. 4) Future Cyber Threat: Sentences addressing potential cyber risks and threats that organi- zations may face in the future. 5) Other: Sentences encompassing a diverse range of articles, including reports, studies, educational content, guidance materials, and miscellaneous topics related to cybersecurity. • Template 2, Few Shots: Inclusion of Examples To further assist the LLMs, we introduced examples in both one-shot and few-shot formats for each category. This approach was designed to further aid LLMs in grasping our categorization criteria, providing concrete instances as references. Template 2 with Few Shots: You are a cyber analyst. You will ... Classify the sentence into one of the five categories and output the category name only ... Five categories are: 1) Recent Cyber Attack: Sentences reporting on recent cyber attacks ... 2) ... 3) Other: Sentences encompassing a diverse range of articles ... Examples for each category are: {"sentence": "Royal Mail hit by cyber attack causing ’severe disruption’ to services.", "category": "Recent Cyber Attack"}, ... {"sentence": "Meta hit with 390 mn euro fine over EU data breaches", " category": "Cyber Litigation"} VI. EVALUATION RESULTS A. Evaluation Metrics In this section, we outline the performance metrics utilized to assess the models in our multi-class classification task. CANAL, finetuned BERT model, is designed to optimize cross-entropy loss across five cyber categories in a multi- class categorization context. For a comparative analysis with other LLMs, where probability distributions are inaccessible, we adopt standard metrics such as Precision, Recall, F1- Score, and Accuracy. These metrics are chosen for their clarity in conveying performance insights. Here below is a quick introduction to all these metrics, Cross-Entropy Loss (Log Loss): Quantifies the difference between predicted and actual class probabilities. Log Loss = −1 N N X i=1 M X j=1 yij log(pij) (11) Here, N is the number of instances, M is the number of classes, yij is 1 if instance i is in class j, and pij is the predicted probability. Precision: Evaluates the proportion of accurate positive predictions. Precision = True Positives True Positives + False Positives (12) Recall: Measures the model’s ability to identify all positive instances. Recall = True Positives True Positives + False Negatives (13) F1-Score: Balances precision and recall, providing a com- prehensive performance measure. F1-Score = 2 · Precision · Recall Precision + Recall (14) Accuracy: Quantifies the overall correctness of the model’s predictions. Accuracy = Number of Correct Predictions Total Number of Predictions (15) B. Evaluation Results 1) Evaluation of Cyber Signal Discovery Module: The Emerging Cyber Signal Discovery Module operates with a human-in-the-loop moderation approach. During each itera- tion, the algorithm generates a set of signals on average, proportional to the quantity of novel cyber-related content in the news. Typically, 15-20% of these signals are accepted through human validation. Compared to the exhaustive manual selection of cyber terminology, our module demonstrates re- markable efficiency in terms of time savings and in discerning emerging cyber attack-related terms. Fig. 6: Confusion matrix for a Random Forest classifier, with instances exceeding a 0.98 probability threshold. Categories are represented with 0: ’Other’, 1: ’Prevention’, 2: ’Recent Cyber Attack’, 3: ’Future Threat’, 4: ’Litigation’ 2) Evaluation of Random Forest Silver Labeling: We ap- plied various probability thresholds to the Random Forest classifier, ultimately settling on a 0.98 cutoff for sample inclusion. This threshold, rigorously chosen, ensures that only predictions with a confidence level of 0.98 or higher are considered. We ensured that this approach mirrors the distribution observed in the full dataset, allowing us to cul- tivate a sample that closely aligns with gold standard data quality. The resulting subset, approximately 8,000 records strong, showcases a high level of labeling confidence. Figure 6 presents a confusion matrix for the Random Forest classifier, demonstrating its accuracy when operating above this stringent confidence threshold. 3) Evaluation of BERT Fine-Tuning schemes: After ex- amining the loss in Fig. 5 and the recall in Fig. 7 at checkpoint 4 (epoch 4), the full fine-tuning of the BERT model demonstrated the best performance compared to other methods. While the focus was on absolute performance in Fig. 7: Recall scores for BERT Fine-Tuning Schemes Fig. 8: Accuracy Improvements with Prompt Engineering which full fine-tuning excelled, it is worth noting that other configurations, such as fine-tuning only the last layer plus the classifier and the last two layers plus the classifier, also showed promising results. These strategies may be preferred in scenarios where computational resources are limited or when working with very large models, where full fine-tuning would be too resource-intensive. 4) Evaluation of Expensive LLMs: Fig. 8 to Fig. 11 il- lustrate the performance of sophisticated language models (LLMs) in predicting various categories using different matri- ces. The abbreviations in these figures are as follows: ZS for Zero Shot, OS for One Shot, FS for Few Shot, T1 for Template 1, and T2 for Template 2. Upon examination, both GPT-4 and GPT-3.5 demonstrate a robust ability to identify cyber attacks, supported by high precision and recall. However, they encounter challenges in litigation, prevention, and future threat scenarios, where recall is exceptionally high but precision is relatively low. This suggests a tendency to over-identify instances in litigation, prevention, and future threat, potentially leading to more false positives. In Fig. 9 and Fig. 11, Llama 2 exhibits strong recall but lower precision in litigation and prevention scenarios under the template 1 Zero Shot, mirroring the behavior observed in GPT-4 and GPT-3.5. Notably, when presented with additional examples, there is a noticeable improvement in precision, signifying the model’s ability to learn from these examples and reduce false positive predictions in both litigation and prevention categories. In the context of Zephyr 7B, it is noteworthy that the Fig. 9: Precision Improvements with Prompt Engineering Fig. 10: F1 scores Improvements with Prompt Engineering application of prompt engineering yields more benefits com- pared to other LLMs. This insight is illustrated in Fig. 10, where when prompt engineering is applied, its F1 scores for litigation, prevention, future threat, and other categories show more significant improvement than those of other LLMs. Additionally, it is noticed that the results produced by Zephyr deviate from the desired structure, requiring extra time and effort for the extraction of predictions. In our comparative analysis, GPT-4 emerged as a front- runner among the LLMs, yet the overall performance of these models did not meet our expectations. As Table V shows, none achieved an F1 score above 82% in any category. This suggests that despite the use of prompt engineering to enhance task understanding, these models still face challenges in fully grasping the tasks. Notably, a closer examination of false positives revealed a tendency for incorrect predictions in samples with ambiguous content or lacking specific entity references, even with explicit instructions. This finding points to a critical area for improvement in terms of the LLMs ability to discern and interpret nuanced or incomplete information. 5) CANAL vs Other Expensive LLMs: In the comparative evaluation between our framework, CANAL, and other ex- pensive LLMs, CANAL emerges as the superior performer across all five assessed categories. For categories with very few samples, such as prevention and the future threat category, we expected these highly capable LLMs to perform well due to their training on large datasets. However, CANAL outperforms the expensive LLMs in these categories. In Table V, the accu- racy of CANAL for the prevention category is approximately Fig. 11: Recall Improvements with Prompt Engineering TABLE V: Model Performance Comparison Model Category Accuracy Precision Recall F1-Score GPT-3.5 Cyber Attack 58.67 90.26 62.63 73.95 FS Litigation 27.35 27.35 100.00 42.95 Prevention 35.00 39.87 74.12 51.85 Future Threat 25.00 37.70 42.59 40.00 Other 65.25 87.93 71.66 78.97 GPT-4 Cyber Attack 66.67 81.78 78.29 80.00 FS Litigation 42.86 44.12 93.76 60.00 Prevention 46.67 55.75 74.13 63.64 Future Threat 31.40 36.19 70.37 47.80 Other 68.39 94.14 71.43 81.23 Llama 13B Cyber Attack 62.43 87.93 71.66 78.97 FS Litigation 52.08 60.98 78.13 68.49 Prevention 38.14 57.69 52.94 55.21 Future Threat 18.64 25.58 40.74 31.43 Other 63.75 87.68 70.02 77.86 Zephyr 7B Cyber Attack 58.81 71.15 77.22 74.06 FS Litigation 38.89 77.78 43.75 56.00 Prevention 45.74 57.28 69.41 62.77 Future Threat 19.54 34.00 31.48 32.69 Other 70.42 86.45 79.16 82.64 CANAL Cyber Attack 81.44 83.69 96.80 89.77 Litigation 88.24 93.75 93.75 93.75 Prevention 60.82 83.10 69.41 75.64 Future Threat 47.37 90.00 50.00 64.29 Other 86.37 93.35 92.04 92.69 Note. The best results in each category are highlighted in bold, while the second-best results are underlined. FS stands for Few Shots. 13% higher than that of GPT-4 Few Shots, and the accuracy of CANAL for the future threat category is around 16% higher than that of GPT-4 FS. Conversely, in categories with a more substantial number of training samples, such as recent cyber attack and other category, CANAL exhibits even more exceptional perfor- mance than other LLMs. In the recent cyber attack category, where GPT-4 attains the highest accuracy among all high parameter LLMs with approximately 67%, CANAL surpasses this performance with an impressive accuracy of about 81%. Similarly, in the Other category, where Zephyr 7B leads with around 70% accuracy among LLMs, CANAL outshines with a superior accuracy of about 86%. These findings underscore CANAL’s robust and consistently superior performance across diverse categories, reinforcing its efficacy in handling nuanced language tasks. In Table VI, we provide an empirical comparison of in- ference time and cost for processing 10,000 articles between CANAL and other LLMs. Our results show that CANAL is highly efficient and cost-effective. Cost estimations are based on the current OpenAI API pricing [38] and the lowest available A100 & T4 usage rates, approximately $1/hour & $0.071/hour respectively [39] [40] at the time of writing. CANAL not only processes data faster but also maintains minimal operational costs, emphasizing its viability for large- scale applications. TABLE VI: Comparison of Models for Processing 10,000 Articles Model Inference Time (hr) Infrastructure Inference Cost ($) GPT-3.5 1.33 OpenAI API 4.4 GPT-4 2.50 OpenAI API 84.5 Llama 13B 7.83 A100 (48 GB) 10.2 Zyphyr 7B 2.83 A100 (48 GB) 3.0 CANAL 0.067 T4 (16 GB) 0.0047 TABLE VII: Example classification snippets. Cyber News CANAL + Cyber Signal Detec- tion + Entity Relevance McLaren Health Care Facing 3 Lawsuits in Ransomware... McLaren Health Care Facing 3 Lawsuits in Ransomware Hack - Class - Litigation Seiko confirms thousands of user accounts were ... Seiko confirms thousands of user accounts were breached in cyber- attack - Class - Cyber Attack Microsoft fixes over 100 vulnera- bilities, 2 act... Microsoft fixes over 100 vulnera- bilities, 2 actively exploited bugs - Class - Prevention Buffer overflow bug gives root on potentially millions... Buffer overflow bug gives root on potentially millions of Linux boxes - The Stack - Class - Future Threat Mastercard introduces new grocery delivery and ... Mastercard introduces new gro- cery delivery and streaming perks - CNBC - Class - Other 6) CANAL in action: In Table VII, we exhibit the cul- mination of our multifaceted analysis pipeline. Our dual ap- proach begins with key element extraction: identifying relevant entities (marked in red) via an entity relevance model and pinpointing cyber signals (highlighted in blue) through our continually updated cyber taxonomy. Subsequently, CANAL is deployed for cyber news classification. This integrated process enables us to construct in-depth cyber risk profiles, leveraging news data tailored to specific entities. VII. CONCLUSION We have successfully demonstrated that our framework, uniquely trained using a silver labeling approach with just 600 manually labeled data points, excels in 5-class cyber news categorization. CANAL not only outperforms current top Large Language Models in this specific task but also provides a more cost-efficient and empirical approach. Additionally, our detailed comparison reveals how existing industry LLMs perform in cyber categorization tasks and suggests that their efficacy can be further enhanced through prompt engineering techniques. Furthermore, we showcased the effectiveness of our Cyber Signal Discovery module in identifying emerg- ing cyber signals. Future research may focus on leveraging advancements in cost-effective and smaller-sized empirical LLMs, specifically tailored to the dynamic requirements of cyber categorization. REFERENCES [1] ISACA, “State of cybersecurity 2023,” https://www.isaca.org/resources/ reports/state-of-cybersecurity-2023, 2023, accessed: 2023-11-01. [2] “Ransomware attacks on healthcare organizations,” https://www.sophos .com/en-us/press/press-releases/2023/11/cybercriminals-successfully-e ncrypted-data-ransomware-attacks-nearly, 2023, accessed: 2023-11-01. [3] “The education sector reports the highest rate of ransomware attacks, sophos survey finds,” https://www.sophos.com/en-us/press/press-rel eases/2023/07/the-state-of-ransomware-in-education, 2023, accessed: 2023-11-01. [4] J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, “Bert: Pre-training of deep bidirectional transformers for language understanding,” 2019. [5] C. Raffel, N. Shazeer, A. Roberts, K. Lee, S. Narang, M. Matena, Y. Zhou, W. Li, and P. J. Liu, “Exploring the limits of transfer learning with a unified text-to-text transformer,” 2023. [6] J. Wei, M. Bosma, V. Y. Zhao, K. Guu, A. W. Yu, B. Lester, N. Du, A. M. Dai, and Q. V. Le, “Finetuned language models are zero-shot learners,” 2022. [7] OpenAI, “Gpt-4 technical report,” 2023. [8] H. Touvron, L. Martin, K. Stone, P. Albert, A. Almahairi, Y. Babaei, N. Bashlykov, S. Batra, P. Bhargava, S. Bhosale, D. Bikel, L. Blecher, C. C. Ferrer, M. Chen, G. Cucurull, D. Esiobu, J. Fernandes, J. Fu, W. Fu, B. Fuller, C. Gao, V. Goswami, N. Goyal, A. Hartshorn, S. Hosseini, R. Hou, H. Inan, M. Kardas, V. Kerkez, M. Khabsa, I. Kloumann, A. Korenev, P. S. Koura, M.-A. Lachaux, T. Lavril, J. Lee, D. Liskovich, Y. Lu, Y. Mao, X. Martinet, T. Mihaylov, P. Mishra, I. Molybog, Y. Nie, A. Poulton, J. Reizenstein, R. Rungta, K. Saladi, A. Schelten, R. Silva, E. M. Smith, R. Subramanian, X. E. Tan, B. Tang, R. Taylor, A. Williams, J. X. Kuan, P. Xu, Z. Yan, I. Zarov, Y. Zhang, A. Fan, M. Kambadur, S. Narang, A. Rodriguez, R. Stojnic, S. Edunov, and T. Scialom, “Llama 2: Open foundation and fine-tuned chat models,” 2023. [9] A. Q. Jiang, A. Sablayrolles, A. Mensch, C. Bamford, D. S. Chaplot, D. de las Casas, F. Bressand, G. Lengyel, G. Lample, L. Saulnier, L. R. Lavaud, M.-A. Lachaux, P. Stock, T. L. Scao, T. Lavril, T. Wang, T. Lacroix, and W. E. Sayed, “Mistral 7b,” 2023. [10] Anthropic, “Model Card: Claude,” https://www-files.anthropic.com/pro duction/images/Model-Card-Claude-2.pdf, 2023. [11] A. Chowdhery, S. Narang, J. Devlin, M. Bosma, G. Mishra, A. Roberts, P. Barham, H. W. Chung, C. Sutton, S. Gehrmann, P. Schuh, K. Shi, S. Tsvyashchenko, J. Maynez, A. Rao, P. Barnes, Y. Tay, N. Shazeer, V. Prabhakaran, E. Reif, N. Du, B. Hutchinson, R. Pope, J. Bradbury, J. Austin, M. Isard, G. Gur-Ari, P. Yin, T. Duke, A. Levskaya, S. Ghe- mawat, S. Dev, H. Michalewski, X. Garcia, V. Misra, K. Robinson, L. Fe- dus, D. Zhou, D. Ippolito, D. Luan, H. Lim, B. Zoph, A. Spiridonov, R. Sepassi, D. Dohan, S. Agrawal, M. Omernick, A. M. Dai, T. S. Pillai, M. Pellat, A. Lewkowycz, E. Moreira, R. Child, O. Polozov, K. Lee, Z. Zhou, X. Wang, B. Saeta, M. Diaz, O. Firat, M. Catasta, J. Wei, K. Meier-Hellstern, D. Eck, J. Dean, S. Petrov, and N. Fiedel, “Palm: Scaling language modeling with pathways,” 2022. [12] OpenAI, “ChatGPT: A large-scale generative model for language understanding,” 2022. [Online]. Available: https://chat.openai.com/ [13] Google, “Bard: conversational generative artificial intelligence chatbot developed by google,” 2023. [Online]. Available: https://bard.google.co m/ [14] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, L. Kaiser, and I. Polosukhin, “Attention is all you need,” 2023. [15] D. Araci, “Finbert: Financial sentiment analysis with pre-trained lan- guage models,” 2019. [16] S. Wu, O. Irsoy, S. Lu, V. Dabravolski, M. Dredze, S. Gehrmann, P. Kambadur, D. Rosenberg, and G. Mann, “Bloomberggpt: A large language model for finance,” 2023. [17] T. B. Brown, B. Mann, N. Ryder, M. Subbiah, J. Kaplan, P. Dhariwal, A. Neelakantan, P. Shyam, G. Sastry, A. Askell, S. Agarwal, A. Herbert- Voss, G. Krueger, T. Henighan, R. Child, A. Ramesh, D. M. Ziegler, J. Wu, C. Winter, C. Hesse, M. Chen, E. Sigler, M. Litwin, S. Gray, B. Chess, J. Clark, C. Berner, S. McCandlish, A. Radford, I. Sutskever, and D. Amodei, “Language models are few-shot learners,” 2020. [18] P. Ganesh, Y. Chen, X. Lou, M. A. Khan, Y. Yang, H. Sajjad, P. Nakov, D. Chen, and M. Winslett, “Compressing large-scale transformer-based models: A case study on bert,” Transactions of the Association for Computational Linguistics, vol. 9, p. 1061–1080, 2021. [Online]. Available: http://dx.doi.org/10.1162/tacl a 00413 [19] L. Floridi and M. C. Chiriatti, “Gpt-3: Its nature, scope, limits, and consequences,” Minds & Machines, vol. 30, pp. 681–694, 12 2020. [Online]. Available: https://doi.org/10.1007/s11023-020-09548-1 [20] J. Hoffmann, S. Borgeaud, A. Mensch, E. Buchatskaya, T. Cai, E. Rutherford, D. de Las Casas, L. A. Hendricks, J. Welbl, A. Clark, T. Hennigan, E. Noland, K. Millican, G. van den Driessche, B. Damoc, A. Guy, S. Osindero, K. Simonyan, E. Elsen, J. W. Rae, O. Vinyals, and L. Sifre, “Training compute-optimal large language models,” 2022. [21] E. Nwafor and H. Olufowobi, “Canbert: A language-based intrusion de- tection model for in-vehicle networks,” in 2022 21st IEEE International Conference on Machine Learning and Applications (ICMLA), 2022, pp. 294–299. [22] A. Rahali and M. A. Akhloufi, “Malbertv2: Code aware bert-based model for malware identification,” Big Data and Cognitive Computing, vol. 7, no. 2, 2023. [Online]. Available: https://www.mdpi.com/2504-2 289/7/2/60 [23] S. Chen and H. Liao, “Bert-log: Anomaly detection for system logs based on pre-trained language model,” Applied Artificial Intelligence, vol. 36, no. 1, p. 2145642, 2022. [Online]. Available: https://doi.org/10.1080/08839514.2022.2145642 [24] K. Ameri, M. Hempel, H. Sharif, J. Lopez Jr., and K. Perumalla, “Cybert: Cybersecurity claim classification by fine-tuning the bert language model,” Journal of Cybersecurity and Privacy, vol. 1, no. 4, pp. 615–637, 2021. [Online]. Available: https://www.mdpi.com/2624-8 00X/1/4/31 [25] S. Yesir and I. Sogukpinar, “Malware detection and classification using fasttext and bert,” in 2021 9th International Symposium on Digital Forensics and Security (ISDFS), 2021, pp. 1–6. [26] E. Aghaei, X. Niu, W. Shadid, and E. Al-Shaer, “Securebert: A domain- specific language model for cybersecurity,” 2022. [27] Y. Erkal, M. Sezgin, and S. Gunduz, “A new cyber security alert system for twitter,” in 2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA), 2015, pp. 766–770. [28] M. Abdullahi, Y. Baashar, H. Alhussian, A. Alwadain, N. Aziz, L. F. Capretz, and S. J. Abdulkadir, “Detecting cybersecurity attacks in internet of things using artificial intelligence methods: A systematic literature review,” Electronics, vol. 11, no. 2, 2022. [Online]. Available: https://www.mdpi.com/2079-9292/11/2/198 [29] T. Riebe, T. Wirth, M. Bayer, P. K¨uhn, M.-A. Kaufhold, V. Knauthe, S. Guthe, and C. Reuter, “Cysecalert: An alert generation system for cyber security events using open source intelligence data,” in Information and Communications Security, D. Gao, Q. Li, X. Guan, and X. Liao, Eds. Cham: Springer International Publishing, 2021, pp. 429–446. [30] M. T. Alam, D. Bhusal, Y. Park, and N. Rastogi, “Cyner: A python library for cybersecurity named entity recognition,” 2022. [31] T. Mikolov, I. Sutskever, K. Chen, G. S. Corrado, and J. Dean, “Distributed representations of words and phrases and their composi- tionality,” Advances in neural information processing systems, vol. 26, 2013. [32] T. Chen and C. Guestrin, “Xgboost,” Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining - KDD ’16, 2016. [Online]. Available: http: //dx.doi.org/10.1145/2939672.2939785 [33] G. Ke, Q. Meng, T. Finley, T. Wang, W. Chen, W. Ma, Q. Ye, and T.- Y. Liu, “Lightgbm: A highly efficient gradient boosting decision tree,” Advances in neural information processing systems, vol. 30, 2017. [34] H. Liu, D. Tam, M. Muqeeth, J. Mohta, T. Huang, M. Bansal, and C. Raffel, “Few-shot parameter-efficient fine-tuning is better and cheaper than in-context learning,” 2022. [35] E. J. Hu, Y. Shen, P. Wallis, Z. Allen-Zhu, Y. Li, S. Wang, L. Wang, and W. Chen, “Lora: Low-rank adaptation of large language models,” 2021. [36] N. Shazeer, “Glu variants improve transformer,” arXiv preprint arXiv:2002.05202, 2020. [37] L. Tunstall, E. Beeching, N. Lambert, N. Rajani, K. Rasul, Y. Belkada, S. Huang, L. von Werra, C. Fourrier, N. Habib, N. Sarrazin, O. San- seviero, A. M. Rush, and T. Wolf, “Zephyr: Direct distillation of lm alignment,” 2023. [38] “OpenAI Pricing,” https://openai.com/pricing, accessed: 2023-11-21. [39] “GPU Pricing,” https://www.databricks.com/blog/2021/12/15/are-gpus-r eally-expensive-benchmarking-gpus-for-inference-on-the-databricks-c lusters.html, accessed: 2023-11-21. [40] “GPU Pricing,” https://lambdalabs.com/service/gpu-cloud#pricing, accessed: 2023-11-21.