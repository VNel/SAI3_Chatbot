Deriving Cyber-security Requirements for Cyber Physical Systems Robert Laddaga1, Paul Robertson2, Howard Shrobe3, Dan Cerys2, Prakash Manghwani2, Patrik Meijer1 1Vanderbilt University and 2DOLL Labs, Inc. and 3MIT Nashville, TN and Lexington, MA and Cambridge,MA Abstract Today’s cyber physical systems (CPS) are not well protected against cyber attacks. Protected CPS often have holes in their defense, due to the manual nature of today’s cyber security design process. It is necessary to automate or semi-automate the design and implementation of CPS to meet stringent cyber security requirements (CSR), without sacriﬁcing functional performance, timing and cost constraints. Step one is deriv- ing, for each CPS, the CSR that ﬂow from the particular func- tional design for that CPS. That is the task assumed by our system, Deriving Cyber-security Requirements Yielding Pro- tected Physical Systems - DCRYPPS. DCRYPPS applies Ar- tiﬁcial Intelligence (AI) technologies, including planning and model based diagnosis to an important area of cyber security. Introduction Embedded and cyber physical systems (CPS) are tremen- dously important to our military, our nation and the world. Most of our weapons and military support systems are CPS, much of our critical infrastructure, such as the electric grid, pipelines, and transportation systems are implemented as CPS. The shift to digital control happened at the same time as our nascent digital computing efforts, and happened like the general computing developments, with little regard for cyber security concerns. Our critical infrastructure and weapons have always been vulnerable to physical attack, but for such massive systems, physical distribution and the en- ergy required to destroy or incapacitate them was itself a kind of protection. However, cyber attacks can be inexpen- sive, and networks can deliver those attacks throughout the world very quickly. Cyber attacks taking control of CPS con- trol systems have the ability to turn the CPS’s native power against itself. Current systems are vulnerable to attacks, which can lead to catastrophic consequences in a military as well as civil en- vironment. With the interconnectedness of CPS, such as au- tomobiles, weapon systems and critical infrastructure, this is already a huge problem. With the increasing penetration of the Internet of Things, this will soon become an even bigger challenge. A core deﬁciency in the current state of the art is the lack of the internal ability to accurately detect the attack and diagnose the corrupted state. Current computer systems rely on external host or network intrusion detection systems (IDS) to identify the incidence of intrusions. This approach has a number of intrinsic limitations. Existing IDS can only rely on target system’s generic monitoring capabilities, in- stead of using the application, and system speciﬁc informa- tion that might be available. Feature construction (e.g., sta- tistical measures for anomaly detection, attack signatures for misuse detection) has been a challenging issue. Without the knowledge of the systems intended behavior at design time, existing IDS systems rely on learning system run-time be- haviors from audit data and extracting their patterns. With- out application semantic context, this approach usually re- sults in low detection accuracy and the inability to separate meaningful program state from circumstantial operations. Furthermore, the lack of application-speciﬁc information forces the system administrators to rely on generic mitiga- tion techniques which might end up doing more harm than good. Consider the case where the functionality is critical and real-time in nature. In this case, any reconﬁguration that takes longer than the task’s periodicity might result in se- rious errors. Rather than complete reconﬁguration, in this case, a phased migration might be more appropriate wherein an active replica is started and the state is transferred be- fore the instance under attack is brought down. Today’s CPS are mostly not well protected against cyber-only attacks, let alone hybrid cyber-physical attacks. Those systems that are internally protected often have holes in their defense, due to the manual nature of today’s cyber security design process. We seek to provide a research driven answer to the prob- lem of how to automate or at least semi-automate the de- sign and implementation of CPS to meet stringent cyber security requirements, without sacriﬁcing functional perfor- mance, and timing and cost constraints. The ﬁrst step in that process is deriving, for each CPS, the cyber security require- ments that ﬂow from the particular functional design for that CPS. That is the task that our system, Deriving Cyber- security Requirements Yielding Protected Physical Systems - DCRYPPS, takes on. Figure 1 shows the architecture of the DCRYPPS system. The center of the system is the Vanderbilt Generic Modeling Environment (GME) (see (L´edeczi et al. 2001a), (Ledeczi et al. 2001b), (Maroti and et al 2014)), which serves as a de- sign environment, as well as a design tool integrator. Inputs to GME include functional design models and requirements, including constraints on information ﬂow, for example. One of the design and analysis tools that we have integrated with Figure 1: DCRYPPS Architecture Diagram GME is the DOLL Pamela modeling language, which sup- ports probabilistic models of CPS, plant models, resources and environments, as well as functional descriptions of CPS behavior. A GME user creates a design, using the input mod- els and requirements, and GME converts that model into a Pamela model, which feeds an analysis tool that uses at- tack/threat models and component reliability information to drive a diagnosis based analysis of how to thwart the threats. The outputs of the analysis are cyber security requirements and probabilistic certiﬁcates, which are then fed to a con- straint integrator. The constraint integrator provides options, via GME, to allow the designer to modify the tool behavior, for example, by adjusting the tradeoff between risk reduc- tion and the complexity of the output requirements. Finally, the cyber security requirements are delivered to system de- signers and implementors responsible for producing a CPS that meets cyber requirements, and well as functional per- formance, timing and other constraints. This basic concept of operations for DCRYPPS is shown in Figure 2. DCRYPPS Innovations DCRYPPS delivers signiﬁcant and beneﬁcial innovations, including: 1. Use of model based diagnosis to derive cyber security requirements from functional design models. Model based diagnosis is a proven technology for diagnosing a fault given an appropriate model of the system exhibiting the fault. However, we combine model based diagnostic technology with top down attack models in order to ex- haustively map fault achieving threats. The resulting di- agnoses are then used to generate cyber security require- ments that, if satisﬁed, rule out that speciﬁc diagnosis. 2. Focus on cyber physical properties and cyber physical attack models. Many attempts to formalize and prove cy- ber security properties of systems have focused on infor- Figure 2: DCRYPPS CONOPS Diagram mation ﬂow, which incorporates conﬁdentiality and mod- est portion of integrity. But unlike pure information sys- tems, CPS are physically tied to the world, have poten- tially dramatic physical effects, and vulnerable not only to cyber attacks, but also physical and hybrid attacks. We focus on attacks like sensor and actuator signal spooﬁng, timing attacks and network attacks, where the most seri- ous vulnerabilities of CPS are located. 3. Analysis of cyber requirements that is sensitive to risk and cost tradeoffs. Although we can generate an exhaus- tive list of faults, that doesn’t mean that we should gener- ate an exhaustive list of cyber requirements. Our system orders consideration of threats by likelihood and signiﬁ- cance of the effect of the threat. We can then tradeoff how deeply we descend the list of threats, against the remain- ing risk. We give system designers tools to explore this design tradeoff space, and the ability to adjust cost and likelihood metrics. 4. Use of probabilistic certiﬁcates in managing cyber se- curity requirements. Probabilistic Certiﬁcate of Correct- ness (PCC) is a metric used to capture risk in the engi- neered systems development processes. We use the PCC as a way of validating that the cyber requirements cover the needs to avoid cyber attacks. To achieve the maximum beneﬁt from this approach it is important that a require- ments veriﬁcation process with a PCC metric is imple- mented in a consistent way for all requirements. DCRYPPS Technical Details Building on Vanderbilt’s history in Cyber Physical Systems (CPS), we leverage our tool GME / Meta-GME for initially specifying the system. GME has had decades of use in both designing CPS, and in accepting a variety of modeling lan- guages and methodologies as inputs. One of our ﬁrst tasks was to integrate DOLL’s Pamela probabilistic modeling lan- guage with GME, so models built or imported into GME can be exported to Pamela, where they can be analyzed us- ing Pamela’s suite of solvers. We treat the derivation of cyber security requirements as a kind of inverse diagnosis problem. We use attack and threat models as guide for injecting faults into functional mod- els, and use diagnostic reasoning to derive cyber security requirements that can effectively block those speciﬁc diag- noses. This combination of functional system models and attack models was ﬁrst explored in Shrobe’s MIT AWDRAT Self Regenerative Systems project (Shrobe, Balzer, and et al. 2006), and builds on prior model based diagnosis work (Shrobe 2001), (Shrobe 2002), and (Davis et al. 1982). We carry this approach further by using it not just to elaborate attack models, but to actually derive cyber security require- ments. The inputs to the system are a functional model of CPS, in a language such as AADL (see (Feiler, Lewis, and Vestal 2006), (Feiler, Gluch, and Hudak 2006)), SYSML (see (Ob- ject Management Group 2012)), or other model based de- sign language, along with a set of desirable properties that designers believe must be maintained (invariants) even in the face of cyber attacks. An additional input is the level of conﬁdence the designer want to have that the invariants will hold. Essentially, in this approach, we hypothesize various in- variant violations that could occur, by negating each of the desirable property invariants. We assert that the violation has happened and we run diagnosis to generate possible causes. Then for each cause, we ask of the component implicated if various attack models are applicable to that component, and if so, we generate a cyber requirement such that that com- ponent be resilient against that attack model. Having added that requirement, the component is deemed safe and hence the problem must be elsewhere. We iterate through the pos- sible causes in order of most likely ﬁrst until we reach the point where there are no more possibilities that are cyber; hence in the end, the diagnosis will always be the failure of a part due to non-cyber causes. Given a risk target, we avoid descending too far down the list of decreasingly low probability chain of possible require- ments so as to manage the overall size of the cyber require- ments list. We can also weight the acceptable risk based on the importance of the function so that more cyber require- ments are generated to protect the most important assets. We keep track of the accumulated risk so that the generated cy- ber requirements should be veriﬁable by an implementer to produce a certiﬁcate within the acceptable risk speciﬁed. Finally, we emit the accumulated cyber requirements which essentially are constraints on the original system de- sign. Use Case For a worked use case, we consider a simple autopilot for a remotely piloted quadcopter. The quadcopter is guided from a ground station using cel- lular networking. The ground station can send new way- points to the quadcopter but the quadcopter always has a default plan to follow in case the communication with the ground station is lost. It does, however, require reliable navigation. For this rea- son, the autopilot, whose job it is to follow waypoints un- til landing at the ﬁnal waypoint, has two different sensors, a Figure 3: Auto pilot scenario. Figure 4: A simple autopilot. (Global Positioning System) GPS receiver which gives posi- tion and altitude, and a VHF Omnidirectional Range (VOR) sensor that gives directions towards a ground based transmit- ter. With the aid of navigation maps that show the locations of VOR transmitters, it is possible to navigate between VOR transmitters. Figure 3 depicts a quadcopter en route from Nantucket to Martha’s Vineyard. The job of the autopilot is to follow the path between waypoints. It uses sensors to determine position, it uses a Kalman ﬁlter to estimate position, calculates an error term and then calculates the appropriate control signals to feed to the actuators (which are themselves simple controllers). This is susceptible to all the types of attacks. The command interface has a web server for use at the ground station. Everything is controlled by the autopilot controller board. All of of the sensors, the GPS and the VOR, communicate with the controller board on a local network. The VOR requires an interface that sets frequencies and di- rections and the GPS has an interface that provides informa- tion on satellites being received and position. The autopilot has an up to date listing of all VORs in its operating region but the GPS is the preferred sensor for a variety of reasons that we won’t go in to here. The model of the autopilot is shown in Figure 4. For sim- plicity we have elided many details including the Kalman ﬁlter algorithm used by the autopilot program to track po- sition estimate independently for the two sensors VOR and GPS. The controller board, C1 supports the autopilot pro- gram, P1, which communicates with a local webserver W1 which in turn communicates with the ground station via the cellular network, CN1, in order to communicate with the ground station client. The two sensors VOR and GPS com- municate with P1 over a local network. The autopilot pro- gram continuously maintains an estimate of ’position’ using its two sensors. It maintains also ’distance-from-trajectory’ which is an estimate of how close to the target trajectory the quadcopter is at each moment. Other variables such as ’distance-to-next-waypoint’ are also maintained. The designer also deﬁnes a set of propositions that deﬁne what should not occur in the system, the invariant violations. Some of these propositions can be proposed automatically given the components being used, others are manually added to by the designer to indicate what is essential. Violation of invariants: distance(V OR, GPS) > MaximumSensorDisagreement distance −from −trajectory > MaximumOffTrajectory ... (1) Given this model, developed in GME or another system design tool for which a plug in is available for GME, the nature of all of the resources resides in resource models. In this example we have standard parts, the GPS and VOR sensors in the Hardware > Sensors > Navigation re- source hierarchy, and the control board in the Hardware > Computer > Controller resource hierarchy; the autopilot program P1 and the web server are in Software > ... and so on. Each resource model contains details of all aspects of the component in terms of requirements for its proper function, such as power and memory and also its cyber characteristics. The structure of the system design, which is essentially an attributed UML diagram, is translated by GME into Pamela to enable the cyber requirement diagnosis. a rough sketch of which is shown below. ;; Many details including inheritance ;; of resource attributes omitted ;; in this example for clarity. (defpclass VOR [localnet] ...) (defpclass GPS [localnet] ...) (defpclass FlightControls [localnet] ...) (defpclass ControllerBoard [localnet cellnet] :fields (pclass AutoPilotProgram self localnet cellnet) ...) (defpclass AutoPilotProgram [controller localnet cellnet] :fields (pclass webhost controller localhost cellnet) ...) (defpclass WebServer [board localnet cellnet] ...) (defpclass Network [...] ...) (defpclass CellularNetwork [...] ...) ;;; This class wires components (defpclass AutoPilotUnit [] :fields :n2 (lvar ‘‘localnetwork’’) :cn1 (lvar ‘‘internet’’) :controlboard (lvar ‘‘cb’’) :gps (pclass GPS :n2) :vor (pclass VOR :n2) :fc (pclass FlightControls :n2) :localnet (pclass Network :controlboard :n2 ...) :cellnet (pclass CellularNetwork :controlboard ...) :controller (pclass :controlboard :localnet :cellnet) ...) Given the Pamela model, the cyber requirements gener- ator invokes the diagnosis engine multiple times each time asserting one or more violation in order to produce a list of vulnerabilities. In this very simpliﬁed example, diagnosis will be invoked in order on: dist(V OR, GPS) > MaxSensorDisagreement (2) distFromTraj > MaxOffTraj (3) (dist(V OR, GPS) > MaxSensorDisagreement∧ distFromTraj > MaxOffTraj) (4) The diagnosis, which is described in the Section titled Generating Cyber Requirements Through Diagnostic Anal- ysis, uses the structural nature of the system model to iden- tify parts that may be vulnerabilities that cause the violations to occur. These things include normal failure as well as cy- ber attack possibilities. Normal failure probability is deter- mined by parameters of the resource model for the parts, and cyber attack possibilities are generated from matching cyber attack models to the violations and the components involved in the system design that are connected to the violations in question. In this case, distFromTraj > MaxOffTraj impli- cates in various degrees, the position sensors, the network over which they communicate, and the autopilot program. One of the vulnerabilities detected by the diagnosis en- gine is a match with ’spooﬁng attack’. Different variations of the spooﬁng attack are revealed: spooﬁng of the VOR sensor and spooﬁng of the GPS sensor; and man-in-the- middle attack on the ﬂight controls is also identiﬁed. Each of these cause cyber requirements to be generated for the components involved in the identiﬁed attack vulnerabilities, namely the auto pilot program itself, the local network, and the cellular network. Attack Modeling We use cyber attack and threat modeling in order to assist in driving the diagnostic analysis that examines components and connections to track and eliminate faults. In particular, an essential component of the proposed system is an attack matcher which will be invoked by the vulnerability ﬁnder as part of the cyber requirements generation. A database of at- tack types will support potential matches against part of the system design that is under review. It responds to the ques- tion: given that an invariant violation has been asserted, is there an attack type in the database that could result in that violation? A match will result in a possible cyber require- ment to present that attack from succeeding. We begin by considering several scenarios that arise in embedded control systems. In their simplest form, these con- trol systems have four main elements: 1. A set of sensors, with analog signals that are converted to digital form, collected in a data concentrator and then transmitted to the control element 2. A network, that in modern systems transmits both sen- sor data and control signals, using Ethernet cabling and lower level protocols, but preserves the older MODBUS or FIELDBUS application level protocols 3. The controller per se, that receives sensor data, estimates the state of the system, compares the estimated state to the desired state, and based on the difference between the two, computes control signals that are transmitted to ac- tuators 4. Actuators (or effectors) are digitally controlled devices that, in response to the control signal, have physical ef- fects on the system under control. For the system to work correctly: sensor data must be cap- tured and transmitted to the controller without modiﬁcation; the controller’s code must continue to accurately estimate the system state and correctly compute the transfer func- tion (state error to control signal); the control signal must reach the actuators unchanged; the actuators must respond correctly to the control signals; and each cycle from sensor to controller to actuator must take place within a time inter- val that depends on the physics of the system under control. Beneath this level of abstraction, each of these actions are carried out by computers: 1) Sensor data is captured by a data concentrator, a specialized but usually programmable computer. 2) The controller, often referred to as a Pro- grammable Logic Controller (or PLC) is typically a pro- grammable computer built around a micro-controller pro- cessor (or even a standard MIPS or ARM chip). 3) All el- ements interact with the network through a NIC (network interface card), which is usually built from a SoC (system on a chip). The ﬁrmware in these elements historically was in ROM (i.e. unwritable), but in more modern systems the ﬁrmware is kept in EEproms or other writable elements. Finally, note that the controller unit is today implemented as a standard computer, running a standard Real-time OS with the PLC ﬁrmware running as a real-time process. In ad- dition to the PLC ﬁrmware, most modern systems provide a web server (usually Nginx or Apache) that provide the man- agement interface to the system. Because, it is used as the management system, the web server runs at a privilege level that allows it to modify critical elements of the controller system (including setting of process control parameters and installing new control programs to be executed by the con- troller). Given this and attacker goals to, for example, disrupt the system, we can derive a number of attack scenarios, below. Sensor Data Spooﬁng If an attacker can modify all sen- sor data that reaches the controller, then a perfectly correct controller will issue actuator commands that can have dele- terious effects. For example, imagine a temperature sensor whose values are changed to read low. The controller will respond by commanding the actuators to provide more heat (say by increasing fuel or oxygen supply). Sensor spooﬁng is a very pernicious form of attack since the controller’s only perception of the real-world is via its sensors. Sensor spooﬁng can be effected in either of two gen- eral approaches: a) By penetrating the data concentrator and then using it to systematically change the real sensor data to spoofed data. b) By man-in-the-middle attacks on the net- work linking the data concentrators to the controller. Modiﬁcation of the Control System’s Transfer Function There are several ways an attacker can do this: a) In systems where the management interface is provided by a web server (or some other remote user interface) any of the vulnerabilities of the web server might be exploited to change control parameters or to download hacked versions of the controller code (as was done in Stuxnet, although not via a web interface). b) There might be sensitivities in the controller code to certain numeric values (or sequence of values) that can in- duce numeric errors that lead to unintended control ﬂows, code injection, or code reuse attacks. c) The controller maintains real-time network connections to its data concentrators and to its supervisory and human interface systems. If any of these network protocols can lead to buffer overﬂows, then these can be exploited to inject code or to conduct code-reuse attacks. d) The controller runs an off the shelf real-time OS. If this leaves certain ports open (e.g. FTP or Telnet) then the attacker may be able to log in via a stolen or guessed pass- word and then launch programs that can affect the controller process. Timing Attacks The sense-compute-actuate loop must execute within the time constant of the system under con- trol. Anything that the attacker can do to change the timing can have disastrous effects. 1) Depending on the scheduler of the system, excessive load placed on processes other than the controller can cause the controller process to miss its deadline. 2) If it’s possible to initiate a remote login, then this can be used to launch a large number of jobs. In the worst case, these would be jobs with real-time requirements more de- manding than that of the actual controller 3) The network can be saturated enough to make the sen- sor to actuator loop take too long. This could be done with a standard DDoS type of attack, although more subtle attacks might well be possible. Generating Cyber Requirements Through Diagnostic Analysis Given a model of the system that described all of the con- nections, dataﬂows, compute elements, and other attributes of the system design, we can use diagnosis (de Kleer and Williams 1987) to ﬁnd the cause of a fault. This technology is useful for diagnosing faults at runtime, but it can be used also to ﬁnd possible causes for hypothetical failures of the system at design time. First of all, our model needs to represent failure of the system, for whatever reason. A CPS can fail due to a hard- ware failure such as a failed sensor. It can also fail because of a cyber attack. These are often difﬁcult to distinguish, but our goal is to generate cyber requirements that render the cyber attacks impossible. The resulting diagnosis will there- fore generate system failures because the cyber possibilities will have been handled by the cyber requirements. A good abstract explanation of how diagnosis works, can be found in (de Kleer and Williams 1987). Violation implies that something has gone wrong. Some- times this is because of a failed part, sometimes it can be the result of a cyber attack. We can provide qualitative lev- els of violation so that the more serious violations can be given higher priority depending on what is demanded in the probabilistic certiﬁcate. Example of qualitative levels of failures may be: Catas- trophic, Reduced Capability, and Annoyance. The reverse diagnosis works by asserting that each one, in turn, of the violations has occurred and then diagnosing the fault. After all single fault cases have been diagnosed, dual fault cases are iterated through and so on. For each diagnosis step, the model is inspected to ﬁnd which parts could contribute to the failure. It generates a list of possible reasons for the failure and rank orders them in order of likelihood. Starting from the most likely causes, if the cause is a cyber attack, a cyber requirement is gener- ated and attached to the model component in question. That cause from that component will never be listed as having this vulnerability, so when we meet the same component from a different diagnosis, it will not be listed as a cyber require- ment candidate. By enumerating the faults in order of likeliness and by keeping the causes in order of likelihood, we can add the cy- ber requirements in order of greatest impact. Given a speci- ﬁed acceptable risk, we can stop adding cyber requirements when the acceptable risk level has been achieved by the cy- ber requirements. The values for likelihood and impact are computed using the attack models and the system model. The computation of the probabilities comes from rules in the attack models for cyber related failures or in the com- ponent models for failure rate based failures. In this case, for example, a hardware failure, such as a faulty memory chip in the control board could result in such a fault. For the non cyber attack faults, the numbers can be estimated by standard Mean Time Between Failures (MTBF) testing, and similar results can be obtained from software testing. These numbers could be augmented by machine learning from in situ data acquisition given the system model. In addition, the probabilities of cause can be adjusted based on distance in steps from the fault (Laddaga and Robertson 2013). Probabilistic Certiﬁcates Probabilistic Certiﬁcate of Correctness (PCC) (Van der Velden et al. 2012) is the manner in which we will formally encapsulate a model of cyber risk. The risk model estab- lishes overall risk on the basis of hierarchical decomposition of the design and thereby an accumulation of risk fragments throughout the design. The system deﬁnition is a connection of hierarchically nested parts. This hierarchical decomposition enables the calculation of a PCC for system requirements. PCC is a met- ric used to capture risk in the engineered systems develop- ment processes, in this case we use the PCC as a way of val- idating that the cyber requirements cover the needs to avoid cyber attacks. In a transitioned system, the PCC would in- clude non cyber requirements as well and the PCC is easily extendable to this, but for the purposes of this program we will limit ourselves to cyber requirements. To achieve the maximum beneﬁt from this approach it is important that a requirements veriﬁcation process with a PCC metric is im- plemented in a consistent way for all requirements. Our def- inition of the PCC will include the following key elements: 1. Probability of satisfying the cyber requirements (Ps), which gives the expected behavior as an estimated prob- ability for a given conﬁdence level (as a project risk pa- rameter). 2. Conﬁdence in the probability of satisfying cyber require- ments, which gives a statistical conﬁdence in the esti- mated probability. Conﬁdence relates to the likelihood of a given component of the system being compromised with an attack type given the provided safeguard against that remedy. Each potential vulnerability of the system will be analyzed and where appropriate constrained by a cyber requirement. Pamela The Pamela language is a system modeling language that supports reasoning over systems and machine learning of probabilistic variables. Pamela builds upon a long history in model-based programming. The modeling of processes has a long tradition rooted in pioneering work done at Xerox PARC (Kuhn and de Kleer 2010), NASA (Bernard et al. 1999a). The work has histor- ically been used to support automated reasoning about sys- tems and missions, to plan for mission implementations, and to dispatch the resulting plans, monitor their progress, diag- nose and track model state at run time. The success of these models, developed over a period of 15 years, has lead to a rich understanding of modeling languages. These languages have typically been connected to reactive planners (Bernard Figure 5: Pamela Architecture et al. 1999b), diagnosis engines, temporal planners (Efﬁn- ger 2006), and dispatchers. These models have been com- piled into specialized representations supporting specialized solvers, such as Temporal Plan Networks (Kim, Williams, and Abramson 2001) (TPN) for the temporal planner, Sim- ple Temporal Networks (Muscettola, Morris, and Tsamardi- nos 1998) for the dispatcher, and Probabilistic Hierarchical Constraint Automata (Williams, Chung, and Gupta 2001) for diagnosis. These specialized representations have in turn been the focus of specialized algorithms with good perfor- mance characteristics (Shah et al. 2007; Meuleau, Morris, and Yorke-Smith 2008). The most recent implementation of one of these languages, Reactive Model-Based Programming Lan- guage (Williams and Gupta 1999) (RMPL) comes at the tail of a long history of programming language design for cap- turing process algebras, most notably RAPS (Firby 1995), and Esterel (Berry and Gonthier 1992). Pamela is a language that supports the modeling pro- cess to produce a generalized process model that can be reﬁned into a collection/composition of specialized mod- els for which there exist specialized solvers. As a proba- bilistic programming language, Pamela is back end agnos- tic, and allows the programmer to specify his program in a language that generalizes over the known ML landscape so that the back end can reason about the best ML techniques and solvers for the model and the available hardware. Nature of the language The modeler frequently wants to deﬁne nested complex objects with complex interaction. Pamela is therefore an Object Oriented Domain Speciﬁc Language (OODSL). Pamela provides probabilistic variables, as well as state variables, mode variables, ﬁnite domain variables, and dis- tributions over each. Pamela is an actively developed open source modeling language that builds upon RMPL in many ways, but most signiﬁcantly by adding probabilistic variables, in situ data collection, and availability as an open source project. The general architecture of a model based program for a cyber physical system in Pamela is shown in blue in Fig- ure 5. The plant, a CPS, a robot, a software system, or a con- trollable device, is monitored by the model-based program that uses observations and commands along with the model of the system to predict modeled parts of its state. A con- trol program in the context of the plant state causes com- mands to be emitted that achieve desired states in the plant. In DCRYPPS we use the model ofﬂine in order to reason over cyber requirements of the system design, but it should be noted that the same model used in the delivered system can also monitor and track the cyber state of the system and could be used for validation purposes. The Pamela Learning Architecture adds learning, shown in blue in Figure 5, and brings in support for data collection and learning algorithms that can learn the bindings of the probabilistic variables. Given that we are generating PCCs as part of this effort, it is important to ask where the prob- abilities come from. For the non cyber part of the system, measuring the probabilities in real systems is an interest- ing possibility and with the Pamela architecture, the in situ learning of probabilistic variables could be used for accu- rate probabilistic estimates. The situation for cyber attacks is more complicated given that at any moment a new form of attack could be invented. Since we are unable to reason over attack types that have yet to be seen, we can only reason over known attack models and measure the effectiveness of the solutions in hosted systems. Evaluation DCRYPPS was evaluated on an autopilot architecture simi- lar to the use case presented here. The autopilot model, im- plemented in Pamela, was accompanied by a set of 17 de- sirable properties. DCRYPPS generated ﬁve cyber physical requirements. An independent evaluation team determined that our ﬁve cyber requirements were necessary and sufﬁ- cient to protect the autopilot CPS given the agreed terms of engagement. The agreed upon terms of engagement were that the at- tacker does not have physical access to the system at any point in its life cycle; the attacker does not have ability to modify the hardware or software during its development or deployment; the attacker is assumed to have complete knowledge of the system design, software, and its memory layout; the attacker has remote access to the system through the internet and radio. Categories of desirable properties included: safety, sys- tem protection, performance, regulations, resources and in- formation security. A selection of desirable properties that contributed to the generation of output cyber requirements were three proper- ties specifying that the absolute value of position discrepan- cies between pairs of position sensors (VOR, GPS and iner- tial navigation) be below speciﬁc threshholds. An example output cyber requirement was: WAN (Cellular) communication between Ground Station and Autopilot should be authenticated using public key en- cryption. Conclusion and Further Work Given a small scale formal model of a CPS, and a set of desirable invariant properties, DCRYPPS was able to gener- ate an adequate set of cyber requirements. Future work in- cludes completing the development of PCCs to accompany the generated requirements, and scaling up to larger CPS. Also needed is the ability to read in and convert to Pamela models represented in other modeling languages. Acknowledgment This material is based upon work supported by the Defense Advanced Research Projects Agency (DARPA) and Space and Naval Warfare Systems Center Paciﬁc (SSC Paciﬁc) un- der Contract No. N66001-18-C-4005. References [Bernard et al. 1999a] Bernard, D. andDorais, G.; Gamble, E.; Kanefsky, B.; Kurien, J.; Man, G.; Millar, W.; Muscet- tola, N.; Nayak, P.; Rajan, K.; Rouquette, N.; Smith, B.; Taylor, W.; and Tung, Y. 1999a. Spacecraft autonomy ﬂight experience: The ds1 remote agent experiment. In In Pro- ceedings of the AIAA Space Technology Conference & Ex- position. [Bernard et al. 1999b] Bernard, D. andDorais, G.; Gamble, E.; Kanefsky, B.; Kurien, J.; Man, G.; Millar, W.; Muscet- tola, N.; Nayak, P.; Rajan, K.; Rouquette, N.; Smith, B.; Taylor, W.; and Tung, Y. 1999b. Spacecraft autonomy ﬂight experience: The ds1 remote agent experiment. In In Pro- ceedings of the AIAA Space Technology Conference & Ex- position. [Berry and Gonthier 1992] Berry, G., and Gonthier, G. 1992. The esterel synchronous programming language: Design, semantics, implementation. Science of Computer Program- ming 19(2):87–152. [Davis et al. 1982] Davis, R.; Shrobe, H.; Hamscher, W.; Wieckert., K.; Shirley., M.; and Polit, S. 1982. Diagnosis based on descriptions of structure and function. In National Conference on Artiﬁcial Intelligence AAAI 82, 137 – 142. [de Kleer and Williams 1987] de Kleer, J., and Williams, B. C. 1987. Diagnosing multiple faults. Artiﬁcial Intelli- gence 32(1):97–130. [Efﬁnger 2006] Efﬁnger, R. 2006. Optimal Temporal Plan- ning at Reactive Time Scales via Dynamic Backtracking B&B. Ph.D. Dissertation, Massachusetts Institute of Tech- nology, Department of Aeronautics and Astronautics. [Feiler, Gluch, and Hudak 2006] Feiler, P. H.; Gluch, D. P.; and Hudak, J. J. 2006. The Architecture Analysis & De- sign Language (AADL): An Introduction. Technical Report ADA455842, DTIC Document. [Feiler, Lewis, and Vestal 2006] Feiler, P.; Lewis, B. A.; and Vestal, S. 2006. The SAE Architecture Analysis & De- sign Language (AADL) A Standard for Engineering Perfor- mance Critical Systems. In Computer Aided Control System Design, 1206–1211. [Firby 1995] Firby, R. 1995. The rap language manual. Uni- versity of Chicago: Working Note AAP-6. [Kim, Williams, and Abramson 2001] Kim, P.; Williams, B.; and Abramson, M. 2001. Executing reactive, model-based programs through graph-based temporal planning. In In Pro- ceedings of IJCAI-2001. [Kuhn and de Kleer 2010] Kuhn, L., and de Kleer, J. 2010. Diagnosis with incomplete models: diagnosing hidden inter- action faults. In In 24th International Workshop on Qualita- tive Reasoning (QR 2010). [Laddaga and Robertson 2013] Laddaga, R., and Robertson, P. 2013. Adaptive security and trust. In Proceedings of the 2nd International Conference on Cyber Security, Cyber Peacefare and Digital Forensic - Cybersec 2013, 231–239. [L´edeczi et al. 2001a] L´edeczi, A.; Bakay, A.; Mar´oti, M.; V¨olgyesi, P.; Nordstrom, G.; Sprinkle, J.; and Karsai, G. 2001a. Composing domain-speciﬁc design environments. Computer 34(11):44–51. [Ledeczi et al. 2001b] Ledeczi, A.; Maroti, M.; Bakay, A.; Karsai, G.; Garrett, J.; Thomason, C.; Nordstrom, G.; Sprin- kle, J.; and Volgyesi, P. 2001b. The generic modeling envi- ronment. In Workshop on Intelligent Signal Processing. [Maroti and et al 2014] Maroti, M., and et al. 2014. Next generation (meta)modeling: Web- and cloud-based collabo- rative tool infrastructure. Multi-Paradigm Modeling 1237:41 – 60. [Meuleau, Morris, and Yorke-Smith 2008] Meuleau, N.; Morris, R.; and Yorke-Smith, N. 2008. A variable elimination approach for optimal scheduling with linear preferences. In In Proceedings ICAPS 2008. [Muscettola, Morris, and Tsamardinos 1998] Muscettola, N.; Morris, P.; and Tsamardinos, I. 1998. Reformulating temporal plans for efﬁcient execution. In In Principles of Knowledge Representation and Reasoning. [Object Management Group 2012] Object Management Group. 2012. Systems Modeling Language (SysML), Version 1.3. Object Management Group, OMG Document formal/2012-06-01 edition. [Shah et al. 2007] Shah, J.; Robertson, P.; Stedl, J.; and Willaims, B. 2007. A fast incremental algorithm for main- taining dispatchability of partially controllable plans. In In Proceedings ICAPS 2007. [Shrobe, Balzer, and et al. 2006] Shrobe, H.; Balzer, R.; and et al. 2006. Awdrat: Architectural differencing, wrappers, diagnosis, recovery, adaptivity and trust management. In Proceeding of the AAAI Conference on Innovative Applica- tions of Artiﬁcial Intelligence. AAAI Press. [Shrobe 2001] Shrobe, H. 2001. Model-based diagnosis for information survivability. In Laddaga, R.; Robertson, P.; and Shrobe, H., eds., Self-Adaptive Software. Springer-Verlag. [Shrobe 2002] Shrobe, H. 2002. Computational vulnerabil- ity analysis for information survivability. In Innovative Ap- plications of Artiﬁcial Intelligence. AAAI. [Van der Velden et al. 2012] Van der Velden, A.; Koch, P.; Devanathan, S.; Haan, J.; Naehring, D.; and Fox, D. 2012. Probabilistic certiﬁcate of correctness for cyber physical systems. In In ASME. International Design Engineering Technical Conferences and Computers and Information in Engineering Conference, volume 2. [Williams and Gupta 1999] Williams, B., and Gupta, V. 1999. Unifying model-based and reactive programming in a model-based executive. In In Proceedings of the 10th Inter- national Workshop on Principles of Diagnosis. [Williams, Chung, and Gupta 2001] Williams, B.; Chung, S.; and Gupta, V. 2001. Mode estimation of model-based programs: monitoring systems with complex behavior. In In Proc. 17th International Joint Conference on Artiﬁcial Intel- ligence.