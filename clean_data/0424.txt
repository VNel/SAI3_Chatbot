arXiv:2405.12852v1 [cs.CR] 21 May 2024 Application Layer Cyber Deception without Developer Interaction Mario Kahlhofer Dynatrace Research mario.kahlhofer@dynatrace.com Stefan Rass Johannes Kepler University Linz stefan.rass@jku.at Abstract—Cyber deception techniques that are tightly inter- twined with applications pose signiﬁcant technical challenges in production systems. Security measures are usually the responsibility of a system operator, but they are typically limited to accessing built software artifacts, not their source code. This limitation makes it particularly challenging to de- ploy cyber deception techniques at application runtime and without full control over the software development lifecycle. This work reviews 19 technical methods to accomplish this and evaluates them based on technical, topological, opera- tional, and efﬁcacy properties. We ﬁnd some novel techniques beyond honeypots and reverse proxies that seem to have received little research interest despite their promise for cyber deception. We believe that overcoming these technical challenges can drive the adoption of more dynamic and personalized cyber deception techniques, tailored to speciﬁc classes of applications. Index Terms—cyber deception, honeytokens, honeypots, ap- plication layer deception, runtime deception, Kubernetes 1. Introduction There is no shortage of research on the beneﬁts of cyber deception: [34], [35] Techniques such as honey- pots or honeytokens are effective at slowing-down and deterring adversaries, providing threat intelligence, and improving incident detection and response. What remains a barrier to widespread adoption of cyber deception tech- nology is its deployment in real-world software systems. Lance Spitzner, one of the ﬁrst to study honeypots [112], [113] and honeytokens [114], commented in 2019, three decades after their inception, that cyber deception was held back not by the concept, but by technology: “Every honeypot back then had to be crafted, customized and managed by hand.” [19]. Recent advances in virtualization technology have improved the applicability of “classic” honeypots [133], but the practical application of deception techniques that are closely intertwined with applications (e.g., fully automated honeytokens in ﬁle systems) has not yet been fully realized. Intertwining deception techniques tightly with software systems shall increase their effective- ness compared to self-contained honeypots [49], which are easier to discern from genuine assets [80], [115]. Modern research on cyber deception and moving target defense mimics characteristics of real data [12] and strives towards dynamic and personalized deception [26], [43], [83]. Such new concepts often require the insertion of decoys into already built software applications, as well as regular customization. These requirements are most critical when deception technology is provided “as a service“ [4], [39]. Han et al. classify the layer of deception into net- work, system, application and data [50]. Our work fo- cuses on the application layer, that is, techniques that are “linked to speciﬁc classes of applications, such as web applications”. This perspective also harmonizes well with modern service-oriented architectures [44] and cloud- native paradigms [20]. Container orchestration platforms such as Kubernetes are prevalent not only in modern software systems, but also in recent research on cloud- based honeypots [46], [47], [62], [68], [73], [74], [86], [89], [97], [111], [132]. Therefore, our work includes methods that are speciﬁcally suited for Kubernetes. Four methods are exclusive to Kubernetes; most are applicable to any computer system.1 Our contributions are: 1) A technical overview of 19 methods to achieve application layer cyber deception, given already built software artifacts without source code. 2) A qualitative evaluation of these on technical, topological, operational, and efﬁcacy properties. 2. Problem Scope We demonstrate three typical use cases for application layer cyber deception [60], given only built artifacts of an application (no source code access), in the context of cloud-native environments (represented by Kubernetes). Application layer cyber deception. (A) Decoy re- quest. We want to add the code in Listing 1 to the HTML payload of an HTTP response. If adversaries probe the associated application for vulnerabilities, we expect them to waste time in exploiting this endpoint, because it seems to carry a path traversal weakness. We then need to detect access attempts to this endpoint. (B) Fake API. To make the previous use case more interactive, we want to patch an “/admin/api” endpoint into our application – if it does not already exist – and respond to it with some deceptive payload. (C) Honeytoken. Suppose an adversary has man- aged to gain access to a (container) ﬁle system. We want to place ﬁles that appear sensitive (e.g., a “service-token”) and detect access attempts to them. const req = new XMLHttpRequest(); req.open("GET", "/admin/api?p=../config.json"); req.send(); Listing 1. JavaScript code to issue a suspicious HTTP request. 1. These methods (§5) are exclusive to Kubernetes: S2 K8s operator, S3 secondary containers, P2 policy engine, and P3 CNI plugin. No developer interaction. Software applications are rarely deployed by the team that wrote the code, and often the responsibility for security measures lies entirely elsewhere. While this situation is improving [10], [27], it is valuable to explore how we can intertwine defensive cyber deception with applications without having control over the entire software development lifecycle. The desire to add cyber deception on top of an existing system becomes increasingly strong in large organizations, where security operators want to add cyber deception – among other security measures – consistently across hundreds of applications, following a uniﬁed process. We assume that we only have access to built artifacts, which are typically distributed as container images. This adds a few technical challenges that are rarely addressed in the literature, e.g., dealing with a wide variety of software technologies [101], limited access to source code, and compatibility issues [8]. Cloud-native platforms. Cloud-native paradigms, that is, building loosely coupled systems combined with robust automation [20], harmonize well with the requirements of modern, dynamic, adaptive cyber deception techniques. Thus, we include methods that are applicable to Kuber- netes, which is the dominant platform for modern software development. Figure 1 shows its typical components: A pod represents the actual workload (the software applica- tion). A pod consists of one or more containers that share storage and network resources. Their container images contain the built software artifacts. A node is the physical or virtual machine that runs these pods. A cluster is formed from one or more nodes. Unique to Kubernetes is the so-called control plane, which administers the cluster. Parts of it can also be customized, e.g., the admission con- trol can be set to modify the manifest of new workloads (e.g., mounted volumes, environment variables) before workloads are added to the cluster (see S2 K8s operator). Workloads are often addressed indirectly through services, which provide a network-accessible endpoint for some business logic. An ingress is a special kind of pod at the perimeter that provides connectivity to the outside world. The underlying workload of ingresses are often reverse proxies, such as NGINX [116] or Envoy [120]. 3. Related Work, Surveys, and Taxonomies The concept of honeypots [113], [114] and honeyto- kens [114] was originally described by Spitzner as “an information system resource whose value lies in unautho- rized or illicit use of that resource” [113]. Many surveys, taxonomies, and classiﬁcations on cy- ber deception have been introduced [2], [18], [28], [31], [38], [50], [58], [72], [78], [79], [91], [99], [108], [127], [131], [133], but few authors focused on technical aspects of HP honeypots and their deployment [40], [82] and yet none focused exclusively on the application layer and methods that require no developer interaction. Han et al. also noted that “[most works] focused on the introduc- tion of new deceptive techniques and elements, but [...] rarely discussed where (and how) such elements should be placed in the system” [50]. The inventors of hon- eypatches [5]–[7], which are silently-patched application layer vulnerabilities that still seem exploitable on the surface, also noted that “the concept of honey-patching is straightforward, realizing it in practice is not” [6]. Node Pods Container Application Runtime Shared Libraries Control Plane Network Host Kernel kube-proxy Ingress Service Users Figure 1. Components of a typical Kubernetes cluster. Cyber deception is often studied using game the- ory [87], [134]. Methods that dynamically adapt deception techniques to an adversary’s behavior have been well- studied from a theoretical standpoint [95]. However, these models mostly assume a set of known deception strategies that are randomly interchangeable, but do not necessarily specify how to technically realize a game move. C2 Runtime instrumentation, the C3 LD_PRELOAD trick, and tracing with C4 ptrace are technical methods to hook and patch functions, which is well studied [55], [71]. Hooking-based approaches are commonly found in the domain of malware analysis, where malware is de- ceived with intercepted API methods [3], [56], [103], [104]. Custom K4 ﬁle system implementation are also used to detect ransomware speciﬁcally [21], [64], [109]. Most work on application layer cyber deception places RP reverse proxies in-front of applications [6], [9], [39], [49], [88], [101]. Reti et al. [96] used K2 Netﬁlter in com- bination with Scapy [13], which is a user-space process for packet manipulation. Kern [63] used C3 LD_PRELOAD to modify HTTP packet headers for deception. Araujo and Taylor [8] patched applications by injecting (and just-in-time compiling) code into running processes with C4 ptrace. Deploying honeypots as containers and in cloud platforms has been well studied [46], [47], [62], [68], [73], [74], [86], [89], [97], [111], [132]. Notably, Gupta et al. [46], [47] introduced “HoneyKube” to or- chestrate deployment and monitoring of self-contained HP honeypots in Kubernetes. Research on application layer cyber deception also fo- cuses on quantifying the enticingness of novel techniques and automating the generation of enticing payloads [12], [17], [100]–[102]. The effectiveness of cyber deception and its psychological aspects are also extensively stud- ied [11], [22]–[24], [32]–[36], [41], [43], [48], [53]. 4. Properties of Technical Methods We categorize methods by their type, properties (tech- nical, topological, operational), efﬁcacy, and suitability to achieve our three representative use cases (Figure 2). We map properties to methods in Table 1. Reasons for excluding some properties are found in Appendix A. D-C-S Type Supported Use Cases Properties of Efﬁcacy Inconspicuousness Non-interference [16] Topological Properties Deployment Mode [50] Layer of Deception [50] Application Dimension Kubernetes Plane Technical Properties Payload Modiﬁcation Payload Access Mode Zero Downtime Software Dependencies Resource Efﬁciency Operational Properties Detectability [16] Simplicity Maintainability Scalability Figure 2. Properties of technical methods for application layer cyber deception. D-C-S Type. Fan et al. [31] proposed to differentiate decoys and captors (D-C). Decoys are the entities that are attacked (e.g., honeypots), while captors perform security- related functions (e.g., logging attacks). We adopt this distinction and further differentiate supporting methods, which assist in deploying or conﬁguring a decoy or captor, but are not themselves decoys or captors. Topological Properties. Han et al. [50] classify de- ception techniques into four dimensions: their goal (e.g., detection of attacks), their unit (e.g., service, vulnerability) – as originally introduced by Almeshekah and Spafford [2] –, their deployment mode, and the layer of deception. We adopt the deployment mode and layer dimensions, but not the goal dimension, which we see as independent of technical methods, nor the unit dimension, which we see as implementation-speciﬁc. They introduced the following deployment modes: [50] ∙ Ð Built-in means to add something at the design phase of an application, e.g., in source code, which typically requires developer interaction. ∙ In-front of means to interpose something be- tween an adversary and a genuine application, e.g., with proxies, ﬁlters, or (function) hooks. ∙  Added-to means to include, integrate, or modify something at runtime, e.g., adding ﬁles to ﬁle systems, but also pods or conﬁguration to a cluster. ∙ à Stand-alone methods are separated and isolated from target (production) systems. They introduced the following layers: [50] ∙ Network layer methods (e.g., typical honeypots) are “accessible over the network and [...] are not bound to any speciﬁc host conﬁguration” [50] ∙ System layer methods are bound to hosts. We consider Kubernetes nodes and the entire platform to be part of this layer, so this layer also includes kernel-based techniques and cluster-wide policies. ∙ Application layer methods are bound to speciﬁc applications. We consider containers, pods and their ﬁle system to be part of this layer. ∙ The data layer leverages data, documents, or ﬁles. We further subdivide the application layer into six ﬁner levels, inspired by the ones introduced by Islam et al. [55]: ∙ Source code level. Methods that directly modify the source code, probably at the design phase. ∙ Plugin system level. Applications that provide means for third parties to easily add custom code. ∙ Runtime level. Reﬂection and introspection capa- bilities provided by managed languages such as the JVM Tool Interface (JVM TI) [85]. ∙ Library level. Shared libraries, which are typically linked on application startup. ∙ Container level. Methods that operate from within a typical container namespace, seeing resources such as processes and their (network) interfaces (e.g., listening HTTP sockets) and the ﬁle system (and application artifacts or auxiliary ﬁles). ∙ Kernel level. Operating system features, e.g. kernel modules, eBPF programs [98], or device drivers. We also differentiate where a method is used in a cloud- native platform. This is important for system operators because they are often only authorized to maintain some parts of a cluster. Note also that the location where a method is employed (e.g., a central conﬁguration) may be different from the location it affects (e.g., a workload on a node). We differentiate: ∙ Data plane components, i.e., methods employed at cluster nodes, affecting pods or containers. ∙ Control plane components, e.g., methods that touch the central conﬁguration, admission control, the scheduler, the API server, or operators. Technical Properties. We ﬁnd the following technical properties relevant to our problem statement. The ﬁrst two can be seen as sub-dimensions of adaptability [31]: ∙ Payload modiﬁcation, i.e., the ability to modify or redirect application data. Deception methods beyond self-contained honeypots need to modify response payloads, install new endpoints, or mod- ify ﬁle contents. This can be done by directly modifying code or data, or indirectly, e.g., with a proxy. We typically prefer indirect modiﬁcation, as we want to be “invisible” to adversaries [96]. ∙ Zero downtime, i.e., if a method requires a restart of an application when ﬁrst installed (potentially resulting in a short service downtime), and also, if a restart is required to reconﬁgure or adapt an already deployed deception method. The latter is a critical requirement to realize dynamic and adaptive deception [57], [93], but also a strategy in game-theoretic defense models against intru- sions [67], [94]. ∙ Few software dependencies and compatibility with many programming languages and runtimes. ∙ Resource efﬁciency, i.e., low CPU and memory overhead and fast response times compared to an unmodiﬁed application. Since increased response times are also noticeable to adversaries [80], it is critical not to reveal a method by that. Operational Properties. We assume that people re- sponsible for maintaining or relying on a cyber deception method (e.g., for incident detection and response), care about at least the following properties: ∙ How well the method is able to detect attacks and generate alerts. Bowen et al. [16] introduced this as a necessary property for all decoys. ∙ The technical simplicity of the method. ∙ How much maintenance the method requires. ∙ How well the method scales to large systems. Properties of Efﬁcacy. The efﬁcacy of a complete deception strategy may depend on the following: ∙ Inconspicuousness, i.e., how obvious or clearly visible a deception method is to an adversary. We treat ﬁngerprintability [46], [47], i.e., attacker’s ability to discern deceptive from genuine assets, as a sub-dimension of that. Inconspicuousness is not to be confused with the conspicuousness of decoys [16], which instead describes how obvious a concrete deception element is, not the method. ∙ Non-interference with genuine assets of an ap- plication [16], [96], and its differentiability to legitimate users. Since differentiability typically correlates with non-interference [11], we combine them. In our evaluation, we also combine this with a measure of how well methods avoid in- creasing the attack surface of an application, i.e., “it must not make the system less secure” [96]. Gupta et al. [46], [47] denoted this aspect as security measures for decoys. 5. Technical Methods We primarily categorize methods according to their (virtual) location in a (cloud) platform (Figure 3), as this corresponds well with the perspective of system operators: ∙ S Supporting methods (§5.1) ∙ HP Self-contained honeypots (§5.2) ∙ RP Reverse proxies (§5.3) ∙ C Containers and pods (§5.4) ∙ K Kernel and network (§5.5) ∙ P Container platform (§5.6) ∙ D Methods with developer interaction (§5.7) This categorization shows good consistency, although, we acknowledge that some supporting methods are also container platform-speciﬁc, and that some kernel-speciﬁc methods may also ﬁt container- and pod-speciﬁc methods. 5.1. Supporting Methods 5.1.1. S1 Deployment Agent. The most ordinary (sup- porting) method is to create and deploy a process (or, often called an agent) that then places decoys and captors in a system. The term agent is also commonly used in other methods as well (e.g., C2 runtime instrumentation agents), although they are not supporting the deployment or conﬁguration of said methods. A deployment agent can freely perform C1 container ﬁle modiﬁcations to create honeytokens, or use container- and pod-speciﬁc meth- ods (§5.4) to modify applications and data. With sufﬁcient privileges, kernel- and network-speciﬁc methods (§5.5) are also available to this agent. Running a process next to an application carries lit- tle risk of interference and provides great ﬂexibility in implementing deception scenarios. A deployment agent can be installed directly inside the application container (requiring a S2 K8s operator, S3 secondary containers, or S4 lifecycle hooks to bring the agent inside the con- tainer) or on the container host (i.e., the node). A direct deployment within a container keeps the agent close to and isolated from the application, and is also more robust because Kubernetes then manages the lifecycle of that deployment artifact. Instead, deploying the agent on the container host would require a broader set of permissions so that it can still interact with the Linux namespaces of individual containers. The latter would keep the agent hidden from an adversary that compromised the container, since otherwise an adversary could easily detect its pres- ence by listing all running processes. 5.1.2. S2 Kubernetes Operator and API. Controller and Operator patterns [54] are well-deﬁned ways to add custom, decoupled resources to a Kubernetes cluster that can also hook into controlling processes. This is similar to having a S1 deployment agent, but it is deployed in its own pod and has pre-set access to the Kubernetes API. To place a honeytoken in a container’s ﬁle system, an operator ﬁrst conﬁgures a mutating admission webhook through the Kubernetes API. Before new resources are deployed to the cluster, the operator’s webhook is invoked and can mutate the resource deﬁnition. Honeytokens can be added to containers by conﬁguring P1 volume mounts for them that contain honeytokens. For already running containers, the operator can also execute commands in containers via the Kubernetes API [30], which allows this method to directly add ﬁles at runtime, install a S1 deployment agent in a container without restarting it, or – assuming sufﬁcient privileges – execute container- and pod-speciﬁc methods (§5.4) or even kernel- and network-speciﬁc methods (§5.5) directly. 5.1.3. S3 Secondary Containers. Kubernetes can add special kinds of containers next to application containers. Init containers, which are meant to run setup scripts, will always run before the application containers, and the application containers will not start before their com- pletion. They use their own container image and cannot access ﬁles from the application image, but can share the same P1 volume mounts with the application container. An init container can place honeytokens in a volume that will later be mounted by the application container. Init containers can be deﬁned via a S2 K8s operator or P2 policy engine, but do not take effect until the next time the pod is restarted. Ephemeral containers, which are meant for debugging running applications, provide a way to dynamically launch a container in pods that are already running. They can then interact with application processes and their ﬁle system and implement deception methods at runtime. A sidecar container is a similar concept in this cate- gory, which can be used to log events or monitor the main application. We typically use them to place RP reverse proxies in-front of application containers. Cluster Domain Developer Domain CI/CD Build Process Intervent. D2 Source Code Deception Software Framework D1 Node Pods Pod Ctr. Honeypot HP App Container Second. Ctr. S3 Sidecar Proxy RP Application Runtime Shared Libs. Agent S1 Volume Mounts P1 Container File Modiﬁcations C1 Runtime Instrumentation C2 LD_PRELOAD C3 ptrace C4 Lifecycle Hooks S4 Control Plane API Server Policy Mngmt. P2 Kubernetes Operator and API S2 Network CNI Plugin P3 Host Kernel eBPF Netﬁlter Filesystem Impl. K1 K3 K2 K4 kube-proxy Ingress Services Users Developers Proxy RP Figure 3. A topological overview of the 19 technical methods that we present. 5.1.4. S4 Container Lifecycle Hooks. Most container orchestration platforms provide the ability to run scripts on container startup (pre-start and post-start hooks) and shutdown (post-stop hook). This is not only available in Kubernetes, but is also standardized in the OCI Runtime Speciﬁcation [84]. These platforms also typically allow to override the entrypoint of a container, i.e., the command or process that is run at start. Such hooks can perform deception methods similar to what a S1 deployment agent can do. As with S3 sec- ondary containers, such hooks must ﬁrst be set in the manifest with a S2 K8s operator or by a P2 policy engine. 5.2. HP Self-contained Honeypots This work distinguishes between deception techniques that are intertwined with an application and self-contained, sometimes isolated honeypot software that typically emu- lates services or protocols [82]. If honeypots are provided as container images [46], [47], [62], [68], [73], [74], [86], [89], [97], [111], [132], they can easily be added alongside application containers in the same pod, or, for better isola- tion and to avoid restarting the application, as a new pod. A S2 K8s operator or P2 policy engine can automate and orchestrate the deployment of such honeypots. 5.3. RP Reverse Proxies Placing reverse proxies in-front of applications is the most commonly found method in research on application layer cyber deception [6], [9], [39], [49], [88], [101]. A reverse proxy accepts network requests on behalf of an application. We can conﬁgure them to modify some HTTP response payloads (e.g., to add decoy requests like the one in Listing 1) or have them respond to fake API endpoints that would not otherwise exist. Proxies can also redirect, drop, or delay [59] trafﬁc in order to deceive. In Kubernetes, one can either conﬁgure the ingress proxy at the perimeter, or place a proxy in a sidecar container inside the application pod, which is then di- rectly in-front of the application container. The latter achieves better defense-in-depth, as adversaries already acting from inside the cluster will still connect to these proxies ﬁrst when addressing services. A S2 K8s operator or P2 policy engine could be used to add these proxies to the deployment manifests of applications. S3 Secondary containers and S4 lifecycle hooks could possibly also change the conﬁguration on disk before the proxy starts. Sidecar containers are also commonly used by service meshes [69], which is a pattern that places a proxy in each pod, so that all cluster trafﬁc can be centrally monitored and controlled. This pattern comes with a signiﬁcant per- formance overhead [29], [42], [106], [107], [135], which is why industry appears to be moving toward hybrid solutions that aim to do much of the work in the kernel instead [45], [52]. 5.4. Container- and Pod-speciﬁc Methods 5.4.1. C1 Container File Modiﬁcations. This method requires a method that can modify ﬁles in a container, such as a S1 deployment agent. We can then freely modify ﬁles in application containers or add honeytokens, e.g., at well-known locations such as ~/.ssh/id_rsa. Theoretically, we could also modify some application artifacts directly. If an application is written in an inter- preted language such as Python or JavaScript, we could patch the source code directly in the container. Somewhat more complex and risky, but still possible, would be to patch shared libraries or even binaries [6]. With this method, one often wants to patch ﬁles before the application starts. This can be done using a wrapper script approach: Let a S2 K8s operator override the container entrypoint (see S4 lifecycle hooks) to that of a S1 deployment agent (the wrapper), which will then patch the application before it starts. The wrapper agent is added via P1 volume mounts or with an init container (see S3 secondary containers). 5.4.2. C2 Runtime Instrumentation. Managed lan- guage runtimes, such as the Java Virtual Machine (JVM) or the .NET Common Language Runtime (CLR) provide the means to attach agents or proﬁlers that can inspect and control the execution of applications at runtime. The JVM provides the JVM Tool Interface (JVM TI) [85] and .NET provides the .NET CLR Proﬁling API [77]. By hooking socket connection handlers or injecting code that places honeytokens in the ﬁle system, one can enrich an application with advanced cyber deception scenarios. Runtime agents are typically attached by passing their path as an argument to the runtime process [85], which re- quires overriding the entrypoint with S4 lifecycle hooks. 5.4.3. C3 LD_PRELOAD Trick. By specifying the path of a shared library in the LD_PRELOAD environment vari- able or placing the library in /etc/ld.so.preload, one instructs the dynamic linker, in Linux, to ﬁrst load that library before any others. Similar methods exist for other operating systems [81]. This method can be used to override or wrap the implementation of typical shared li- braries, such as libc, which powers many modern language runtimes. By hooking low-level functions such as send or read, one can modify network packets or ﬁle operations of an application, also for cyber deception purposes [63]. In Kubernetes, one can set the LD_PRELOAD environ- ment variable in the container manifest with a S2 K8s operator or P2 policy engine. Also, P1 volume mounts are required to provide the shared library. 5.4.4. C4 Tracing with ptrace. The ptrace system call can, in Linux, be issued to “trace” another process. This means that the tracer can inspect and control the execution and memory of the tracee. While this method is typically used by debuggers [51], it is also rarely used to implement deception strategies [8], although, this then needs to be coded at the machine code level, since that is the interface provided by ptrace. 5.5. Kernel- and Network-speciﬁc Methods 5.5.1. K1 Monitoring with eBPF. The extended Berke- ley Packet Filter (eBPF) is a Linux kernel technology that makes the kernel programmable [98]. It allows one to write small programs that hook into system calls, network events, kernel and user probes, and more. This technology is widely used to gain observability into system and network events [70], [110], which makes it a natural ﬁt for building captors. In Kubernetes, one can use tools like Falco [121] or Tetragon [124] to conveniently setup eBPF-based moni- toring rules, e.g., to alert when a honeytoken (placed by a S1 deployment agent) is later opened by any process. 5.5.2. K2 Routing with Netﬁlter. Netﬁlter is a Linux kernel framework that is responsible for controlling the ﬂow of network packets. Netﬁlter (and its “frontend” iptables) often assist in realizing honeypot systems [1], [14], [37], [82], [90], [96]. To implement application layer cyber deception techniques, one could follow an approach similar to the one proposed by Reti et al. [96], where Netﬁlter is used to redirect packets to a user space process that modiﬁes payloads, before they are sent to the their original destination. 5.5.3. K3 Routing with eBPF. eBPF can also be used to redirect packets [25], [75], [126]. Similar to the K2 Net- ﬁlter method, we could also use this method to redirect packets to a user space process, modify their payloads in user space, and then send them back to their original destination. However, there are signiﬁcant challenges to using eBPF [75], [125], [128], which probably explains why we have not found any works that use it to implement application (rather than network) layer cyber deception. Nevertheless, solutions that facilitate the eBPF developer experience [76] seem promising for future research. 5.5.4. K4 File System Implementations. The Linux kernel allows to overlay, merge, and implement custom ﬁle systems (even in user space, with FUSE [117]). We can use this to place honeytokens in ﬁle systems, monitor ﬁle access, and perform C1 container ﬁle modiﬁcations. This method is commonly used for malware detection and cyber decepetion use cases [6], [65], [118], [129], [130] 5.6. Container Platform-speciﬁc Methods 5.6.1. P1 Volume Mounts. If one cannot make C1 con- tainer ﬁle modiﬁcations directly, an alternative option is to mount ﬁles and directories into application containers. This requires modifying the deployment manifest with a S2 K8s operator or P2 policy engine, as well as a restart of the affected pod for the initial setup. This method offers a convenient way to add honey- tokens to container ﬁle systems. If the volume is not mounted read-only, these ﬁles can also be modiﬁed at runtime. Despite its simplicity, we are not aware of any research that has reported using this method. 5.6.2. P2 Policy Management. Kubernetes provides pol- icy management solutions [105] such as Kyverno [122], that give cluster administrators a convenient way to spec- ify and enforce cluster-wide policies. Among many other things, a policy can enforce that new pods have P1 vol- ume mounts with honeytokens, that sidecar containers with RP reverse proxies exist, that the C3 LD_PRELOAD environment variable is set, or that an K1 eBPF-based tracing policy exists. To enforce network policies, a com- patible P3 CNI plugin is also needed. 5.6.3. P3 CNI Plugin. A Container Network Interface (CNI) plugin such as Cilium [119] implements the Ku- bernetes network model. This layer could potentially im- plement network layer cyber deception, though it may be challenging to lift that up to the application layer. This may be why we have not yet found any works on that. 5.7. Methods with Developer Interaction 5.7.1. D1 Deception Software Framework. Instead of costly function hooking and patching, one could instead embed (standardized) interfaces within applications at build time (in the “Develop” phase [66]) that allow dy- namic attachment and conﬁguration of deception scenar- ios. Such a tool is best provided as an easy-to-integrate software framework that provides standard use cases (e.g., honeytokens, fake API endpoints) out-of-the-box and also TABLE 1. OVERVIEW OF TECHNICAL METHODS TO ACHIEVE APPLICATION LAYER CYBER DECEPTION Property Deployment Agent K8s Operator Secondary Ctrs. Ctr. Lifecycle Hooks Self-cont. Honeypots Reverse Proxies Ctr. File Mods. Runtime Instrument. LD_PRELOAD Trick Tracing w/ ptrace Monitoring w/ eBPF Routing w/ Netﬁlter Routing w/ eBPF File System Impl. Volume Mounts Policy Management CNI Plugin Decept. Framework Build Proc. Intervent. Supporting Methods Containers & Pods Kernel & Network Container Platform Dev. Inter. S1 S2 S3 S4 HP RP C1 C2 C3 C4 K1 K2 K3 K4 P1 P2 P3 D1 D2 D-C-S Type Decoy ○ ○ ◑ ○ ● ● ● ● ● ● ○ ◑ ◑ ● ● ○ ◑ ● ◑ Captor ◑ ◑ ◑ ○ ◑ ◑ ○ ● ● ● ● ◑ ◑ ◑ ○ ● ◑ ● ◑ Support ● ● ● ● ○ ◑ ◑ ○ ○ ○ ○ ● ● ◑ ◑ ● ● ◑ ● Use Cases Decoy Request ○ ○ ◑ ○ ○ ● ◑ ● ● ● ◑ ◑ ◑ ○ ○ ○ ● ● ◑ Fake API ◑ ○ ◑ ○ ◑ ● ◑ ● ● ● ◑ ◑ ◑ ○ ○ ○ ● ● ◑ Honeytoken ● ● ● ● ○ ○ ● ◑ ◑ ◑ ◑ ○ ○ ● ● ● ○ ● ● Topological Properties Deployment Mode [50]     1     Ð Ð Layer of Decept. [50] APP2 SYS APP APP NET APP DAT3 APP APP APP SYS SYS SYS DAT2 DAT3 SYS NET APP DAT3 Application Dim. CTR — CTR CTR — CTR CTR RUN LIB CTR KER KER KER KER CTR — — SRC CTR K8s Control Plane ✘ ✔ ✘ ✘ ✘ ✘ ✘ ✘ ✘ ✘ ✘ ✘ ✘ ✘ ✘ ✔ ✔ — — Technical Properties Payload Modiﬁcation ✔ ✔ ✔ ✔ ✘ ✔ ✔ ✔ ✔ ✔ ✘ ✘ ✘ ✔ ✔ ✔ ✔ ✔ ✔ Indirect Data Access ✘ ✘ ✘ ✘ — ✔ ✘ ✔ ✔ ✔ — — — ✔ ✘ ✘4 ✔ ✘ ✘ Zero Downtime ... for intial setup ✔ ✔ ✔5 ✘ ✔ ✘ ✔6 ✔7 ✘ ✔ ✔ ✔ ✔ ✘ ✘ ✔ ✘ ✘ ✘ ... for live changes ✔ ✔ ✔5 ✘ ✔ ✔ ✔6 ✔ ✔ ✔ ✔ ✔ ✔ ✔ ✔ ✔ ✔ ✔ ✘ Software Dependencies — K8S K8S OCI — SM — MR LIBC — EBPF NF EBPF — OCI PM CNI — — Operational Props. Detectability [16] ◕ ◑ ◕ ◔ ● ● ◔ ◕ ◑ ◑ ● ◔ ● ◕ ◔ ◕ ◕ ● ◕ Simplicity ◑ ◑ ◕ ● ◕ ◕ ◕ ◔ ◔ ◔ ◑ ◑ ◑ ◑ ◕ ◕ ◔ ◔ ◑ Maintainability ◔ ◔ ◑ ◑ ● ◕ ◕ ◕ ◕ ◕ ◕ ◕ ◕ ◕ ◕ ◕ ◕ ◑ ◑ Scalability ◑ ● ◕ ◕ ◕ ● ◑ ◕ ◕ ◕ ● ◕ ◕ ◕ ● ● ● ◕ ◕ Properties of Efﬁcacy Inconspicuousness [16] ◕ ◕ ◕ ◕ ◔ ◑ ● ● ● ● ● ◕ ◕ ◕ ◕ ◑ ● ● ● Non-interference [16] ◑ ◑ ◑ ◑ ● ◔ ◔ ○ ○ ○ ◕ ◑ ◑ ◑ ◑ ◔ ◔ ○ ◔ Description: The table shows properties (§4) of each method (§5). Appendix B lists questions that we asked for each individual cell. D-C-S Type ﬁts either ●excellently, ◑partially, or ○not at all. Use Cases are supported ●excellently, ◑partially, or ○not at all. Deployment Mode is either Ð built-in (at the design phase), in-front of (e.g., proxies, hooks), or  added-to (e.g., ﬁles, containers). Layer of Deception is either network (NET), system (SYS), application (APP), or data (DAT). Application Dimension is either source code (SRC), runtime (RUN), shared libraries (LIB), container (CTR), or kernel (KER). Software Dependencies are either Kubernetes (K8S), an OCI-compliant container platform (OCI), a service mesh (SM), a policy management solution (PM), a CNI plugin (CNI), an application relying on the C standard library (LIBC), an application running in a managed language runtime (MR), an eBPF-enabled kernel (EBPF), a system with Netﬁlter (NF), or no dependencies. Operational properties and efﬁcacy follow an absolute category rating (Appendix B): ●excellent, ◕good, ◑fair, ◔poor, and ○bad. 1 We consider honeypots as being added-to the same cluster, and not as stand-alone to a production system. 2 This method could also be considered part of the system layer when it is installed on the host, or when it needs to interact with the kernel. 3 This method could also be considered part of the application layer when used to interact with application artifacts. 4 Typical policies want to directly modify workload artifacts and be transparent to the system operator, but exceptions may be technically feasible. 5 Only ephemeral containers can be added and patched without restarting the application. Init and sidecar only run after the pod is recreated. 6 Except for modifying (binary) application artifacts that are not hot-reloaded, which would require an application restart then. 7 Assuming that the runtime supports live agent injection. Some technologies such as JVM TI [85] do support that for certain environments. allows for further customization. Despite the prevalence of the term “deception framework” in the literature [3], [56], [103], [104], its use appears to refer mostly to theoretical concepts, but software frameworks or respective efforts do not seem to appear in the scientiﬁc literature yet. 5.7.2. D2 Build Process Intervention. Access to an application’s source code may not always be possible, but when one can at least control the build pipeline (in the “Distribute” phase [66]), container- and pod-speciﬁc methods (§5.4) as well as HP honeypots or RP reverse proxies can already be incorporated at build time. 6. Discussion We compare technical methods, show opportunities for future research, and note challenges that we encountered. Technical methods at the container- and pod-level can be difﬁcult to detect for adversaries, but also risk interfering with the genuine ﬂow of an application. Bringing cyber deception techniques closer to the appli- cation layer is supposed to increase their effectiveness in engaging adversaries without them noticing [49]. Invasive container- and pod-speciﬁc methods (§5.4) cover a wide range of technical capabilities [8], [63], while remaining stealthy and thus difﬁcult for an adversary to detect. Compared to RP reverse proxies and HP honeypots, which can often be ﬁngerprinted [80], [115], we expect application-level hooks and patches to be harder to de- tect. Stealthy technical methods paired with enticing pay- loads [100], [101] leave little room for countermeasures by adversaries. Methods with a low performance overhead may even evade timing-based ﬁngerprinting [80], espe- cially in cloud environments, which exhibit high network latencies [61]. Extensive studies on the ﬁngerprintability of these methods have not yet appeared in the literature. These invasive methods share many of the properties and capabilities of methods that would require devel- oper interaction, but they may introduce more application inconsistencies, incompatibilities, and vulnerabilities [8], [56], [92]. Thus, it is reasonable that reverse proxies receive most of the attention instead [6], [9], [39], [49], [88], [101]. However, since this pattern often comes with a signiﬁcant performance overhead [29], [42], [106], [107], [135], we believe that future research is needed to reduce this overhead, e.g., with hybrid solutions that ofﬂoad work to the kernel, inspired by industry trends [45], [52]. We encourage future research on invasive technical methods that are also non-interfering, maintainable, and scalable; on leveraging cloud-native platforms; and on software frameworks for deception. Our re- view showed that some methods that leverage Kubernetes design patterns [54] ( S2 K8s operator, S3 secondary containers, S4 lifecycle hooks, and P1 volume mounts) score relatively high in non-interference and scalability; P1 volume mounts are also low-maintenance. These methods have been used for logging and monitoring, also in the context of cyber deception [46], [47], but they do not yet appear to be used for placing decoys. Future research on the usability of deception meth- ods for system operators also seems interesting: What can be done to make deception policies transparent and easy to integrate, scale, and maintain? Custom Resource Deﬁnitions (CRDs) [54], in Kubernetes, could be used to transparently deﬁne and manage deception policies. Although few studies limit themselves to methods without developer interaction (as we do), we are surprised that there is no work yet on software frameworks (or plugin systems) that make it easy to embed cyber de- ception at the design phase. Certainly, the wide variety of software frameworks that one would like to support will be a challenge [101], but this problem has been solved in other domains: OpenTelemetry [123], in the observability domain, succeeded in establishing a standard for collecting (custom) telemetry data from applications. The best technical methods for cyber deception must also to be paired with enticing payloads, which in turn can be mined by technical methods. This work did not research which payloads (e.g., ﬁlenames and their contents) are most enticing to adversaries [12], [17], [100]–[102]. Some of the methods we explored in this work can also provide data for precisely such experiments, e.g. by using K1 eBPF to monitor which ﬁles in a ﬁle system show conspicuous access patterns, or by detecting API endpoints of running applications with RP reverse proxies. The latter could then be used to automatically derive new deceptive API endpoints from that, as demon- strated by Sahin et al. [100]. Technical methods should not be considered in isolation, but in combination. We have chosen not to map the interdependencies between the methods, as there are many creative combinations. Our work should not be read with the intention of picking the “best” method, but with the motivation to ﬁnd a suitable combination of methods. As an example, suppose one wants to automate the placement of honeytokens in all container ﬁle systems. In addition, we want to automatically receive alerts on access attempts to these ﬁles. We could use a P2 policy engine such as Kyverno [122] and specify two policies. The ﬁrst policy deﬁnes P1 volume mounts that place a honeytoken (the decoy) in every container ﬁle system at /var/run/secrets/, which is the path where Kuber- netes secrets are typically mounted. The second policy will add an K1 eBPF-based tracing policy (the captor) with Tetragon [124] which monitors for ﬁle access attempts to this path and sends alerts to operators. A S2 K8s operator could deploy and manage such policies. Cloud-native environments and various technical circumstances made it difﬁcult to clearly categorize methods. The distinction of the layer of deception [50] into network, system, application, and data needed further deﬁnition to better ﬁt the world of clusters, platforms, pods, and containers (§4). Some technical properties were difﬁcult to assign; e.g., whether installing a C2 runtime instrumentation agent at runtime is possible or not depends not only on the speciﬁc runtime environment and its version, but also on machine architectures and the scope of the agent to be installed. Since many (modern) methods are also changing rapidly, it may be necessary to re-evaluate some of them. 7. Conclusion This work reviewed 19 technical methods to achieve application layer cyber deception. We identiﬁed properties for evaluating these methods and categorized them into container- and pod-speciﬁc, kernel- and network-speciﬁc, and container platform-speciﬁc methods. We separately group supporting methods, and commonly used methods such as self-contained honeypots and reverse proxies. This overview shall help practitioners and researchers to bring models from game theory and creative deception ideas into contact with production-grade systems, which require robust, scalable, and maintainable technical solu- tions. It is particularly challenging when methods need to be added after the design phase, but still need to be close to the application layer, as this not only increases complexity, but also the risk of interfering with genuine application assets. However, being less conspicuous to adversaries and more independent of the software develop- ment lifecycle keeps this approach interesting. Our work also ﬁnds less explored methods that seem to manage this balancing act: Leveraging design patterns of cloud- native platforms and building software frameworks for cyber deception. Acknowledgments We thank Anis and Markus for reviewing the methods, their categorization, and terminology, and the anonymous reviewers for their clear and useful feedback on our work. References [1] J. C. Acosta, A. Basak, C. Kiekintveld, N. Leslie, and C. Kamhoua, “Cybersecurity Deception Experimentation Sys- tem,” in 2020 IEEE Secure Development, ser. SecDev ’20, At- lanta, GA, USA, Sept. 2020, pp. 34–40. [2] M. H. Almeshekah and E. H. Spafford, “Planning and Integrating Deception into Computer Security Defenses,” in Proceedings of the 2014 New Security Paradigms Workshop, ser. NSPW ’14. Victoria, British Columbia, Canada: Association for Computing Machinery, Sept. 2014, pp. 127–138. [3] M. N. Alsaleh, J. Wei, E. Al-Shaer, and M. Ahmed, “gExtractor: Towards Automated Extraction of Malware Deception Parame- ters,” in Proceedings of the 8th Software Security, Protection, and Reverse Engineering Workshop, ser. SSPREW-8. San Juan, PR, USA: Association for Computing Machinery, Dec. 2018, pp. 1– 12. [4] F. Araujo, “Engineering Cyber-Deceptive Software,” Ph.D. dissertation, The University of Texas at Dallas, Dallas, Texas, USA, Aug. 2016. [Online]. Available: https://personal.utdallas. edu/∼hamlen/araujo16thesis.pdf [5] F. Araujo and K. W. Hamlen, “Embedded Honeypotting,” in Cyber Deception: Building the Scientiﬁc Foundation. Cham: Springer International Publishing, 2016, pp. 201–231. [6] F. Araujo, K. W. Hamlen, S. Biedermann, and S. Katzenbeisser, “From Patches to Honey-Patches: Lightweight Attacker Misdirec- tion, Deception, and Disinformation,” in Proceedings of the 2014 ACM SIGSAC Conference on Computer and Communications Security, ser. CCS ’14. Scottsdale, Arizona, USA: Association for Computing Machinery, Nov. 2014, pp. 942–953. [7] F. Araujo, M. Shapouri, S. Pandey, and K. Hamlen, “Experiences with Honey-Patching in Active Cyber Security Education,” in Proceedings of the 8th USENIX Conference on Cyber Security Experimentation and Test, ser. CSET ’15, Washington, DC, USA, Aug. 2015. [Online]. Available: https://www.usenix.org/ conference/cset15/workshop-program/presentation/araujo [8] F. Araujo and T. Taylor, “Improving Cybersecurity Hygiene through JIT Patching,” in Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Sym- posium on the Foundations of Software Engineering, ser. ES- EC/FSE 2020. Virtual Event, USA: Association for Computing Machinery, Nov. 2020, pp. 1421–1432. [9] T. Barron, J. So, and N. Nikiforakis, “Click This, Not That: Extending Web Authentication with Deception,” in Proceedings of the 2021 ACM Asia Conference on Computer and Communi- cations Security, ser. ASIA CCS ’21. Virtual Event, Hong Kong: Association for Computing Machinery, May 2021, pp. 462–474. [10] F. Beetz and S. Harrer, “GitOps: The Evolution of DevOps?” IEEE Software, vol. 39, no. 4, pp. 70–75, July 2022. [11] M. Ben Salem and S. J. Stolfo, “Decoy Document Deployment for Effective Masquerade Attack Detection,” in Proceedings of the 8th International Conference on Detection of Intrusions and Malware, and Vulnerability Assessment, ser. DIMVA ’11. Amsterdam, The Netherlands: Springer, July 2011, pp. 35–54. [12] M. Bercovitch, M. Renford, L. Hasson, A. Shabtai, L. Rokach, and Y. Elovici, “HoneyGen: An Automated Honeytokens Gener- ator,” in Proceedings of 2011 IEEE International Conference on Intelligence and Security Informatics, ser. ISI ’11, July 2011, pp. 131–136. [13] P. Biondi, “Scapy,” SecDev. [Online]. Available: https://scapy. net/ [14] K. Borders, L. Falk, and A. Prakash, “OpenFire: Using Deception to Reduce Network Attacks,” in 2007 Third International Confer- ence on Security and Privacy in Communications Networks and the Workshops, ser. SecureComm ’07, Nice, France, Sept. 2007, pp. 224–233. [15] N. Boumkheld, S. Panda, S. Rass, and E. Panaousis, “Honeypot Type Selection Games for Smart Grid Networks,” in Proceedings of the 10th International Conference on Decision and Game Theory for Security, ser. GameSec ’19. Stockholm, Sweden: Springer International Publishing, 2019, pp. 85–96. [16] B. M. Bowen, S. Hershkop, A. D. Keromytis, and S. J. Stolfo, “Baiting Inside Attackers Using Decoy Documents,” in Security and Privacy in Communication Networks, ser. Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering. Berlin, Heidelberg: Springer, 2009, pp. 51–70. [17] B. M. Bowen, V. P. Kemerlis, P. Prabhu, A. D. Keromytis, and S. J. Stolfo, “Automating the Injection of Believable Decoys to Detect Snooping,” in Proceedings of the Third ACM Conference on Wireless Network Security, ser. WiSec ’10. Hoboken, New Jersey, USA: Association for Computing Machinery, March 2010, pp. 81–86. [18] M. L. Bringer, C. A. Chelmecki, and H. Fujinoki, “A Survey: Recent Advances and Future Trends in Honeypot Research,” International Journal of Computer Network and Information Se- curity, vol. 4, no. 10, pp. 63–75, Sept. 2012. [19] A. Chuvakin, “Will Deception Fizzle ... Again?” March 2019. [Online]. Available: https://web.archive.org/web/ 20230606234401/https://blogs.gartner.com/anton-chuvakin/2019/ 03/01/will-deception-ﬁzzle-again/ [20] Cloud Native Computing Foundation, “Cloud Native Deﬁnition,” Feb. 2024. [Online]. Available: https://github.com/cncf/toc/blob/ main/DEFINITION.md [21] A. Continella, A. Guagnelli, G. Zingaro, G. De Pasquale, A. Barenghi, S. Zanero, and F. Maggi, “ShieldFS: A Self-healing, Ransomware-aware Filesystem,” in Proceedings of the 32nd An- nual Conference on Computer Security Applications, ser. ACSAC ’16. Los Angeles, California, USA: Association for Computing Machinery, Dec. 2016, pp. 336–347. [22] E. A. Cranford, C. Gonzalez, P. Aggarwal, S. Cooney, M. Tambe, and C. Lebiere, “Adaptive Cyber Deception: Cognitively Informed Signaling for Cyber Defense,” in Proceedings of the 53rd Hawaii International Conference on System Sciences, ser. HICSS ’20, Maui, Hawaii, Jan. 2020. [23] E. A. Cranford, C. Gonzalez, P. Aggarwal, M. Tambe, S. Cooney, and C. Lebiere, “Towards a Cognitive Theory of Cyber Decep- tion,” Cognitive Science, vol. 45, no. 7, p. e13013, 2021. [24] E. A. Cranford, C. Lebiere, C. Gonzalez, S. Cooney, P. Vayanos, and M. Tambe, “Learning About Cyber Deception Through Simulations: Predictions of Human Decision Making With Deceptive Signals in Stackelberg Security Games,” in Proceedings of the 40th Annual Meeting of the Cognitive Science Society, ser. CogSci ’18. Madison, WI, USA: Curran Associates, Inc., 2018-07-25/2018-07-28, pp. 256–261. [Online]. Available: https://mindmodeling.org/cogsci2018/papers/0067/index.html [25] L. DeLosSantos, “eBPF Networking Techniques - Packet Redirection,” Dec. 2023. [Online]. Available: https://who. ldelossa.is/posts/ebpf-networking-technique-packet-redirection/ [26] S. Dowling, “A New Framework for Adaptive and Agile Honeypots,” Ph.D. dissertation, NUI Galway, Jan. 2020. [Online]. Available: https://aran.library.nuigalway.ie/handle/10379/15832 [27] C. Ebert, G. Gallardo, J. Hernantes, and N. Serrano, “DevOps,” IEEE Software, vol. 33, no. 3, pp. 94–100, May 2016. [28] A. I. M. Efendi, Z. Ibrahim, M. N. A. Zawawi, F. A. Rahim, N. A. M. Pahri, and A. Ismail, “A Survey on Deception Tech- niques for Securing Web Application,” in 2019 IEEE 5th In- ternational Conference on Big Data Security on Cloud, High Performance and Smart Computing and Intelligent Data and Security, ser. BigDataSecurity & HPSC & IDS ’19, Washington, DC, USA, May 2019, pp. 328–331. [29] Y. Elkhatib and J. P. Poyato, “An Evaluation of Service Mesh Frameworks for Edge Systems,” in Proceedings of the 6th Inter- national Workshop on Edge Systems, Analytics and Networking, ser. EdgeSys ’23. Rome, Italy: Association for Computing Machinery, May 2023, pp. 19–24. [30] E. Erol, “How Does ’kubectl exec’ Work?” Aug. 2019. [Online]. Available: https://erkanerol.github.io/post/how-kubectl- exec-works/ [31] W. Fan, Z. Du, D. Fern´andez, and V. A. Villagr´a, “Enabling an Anatomic View to Investigate Honeypot Systems: A Survey,” IEEE Systems Journal, vol. 12, no. 4, pp. 3906–3919, Dec. 2018. [32] K. J. Ferguson-Walter, “An Empirical Assessment of the Effec- tiveness of Deception for Cyber Defense,” Ph.D. dissertation, University of Massachusetts Amherst, Amherst, Massachusetts, March 2020. [33] K. J. Ferguson-Walter, M. Major, D. Van Bruggen, S. Fugate, and R. Gutzwiller, “The World (of CTF) is Not Enough Data: Lessons Learned from a Cyber Deception Experiment,” in 2019 IEEE 5th International Conference on Collaboration and Internet Computing, ser. CIC ’19, Los Angeles, CA, USA, Dec. 2019, pp. 346–353. [34] K. J. Ferguson-Walter, M. M. Major, C. K. Johnson, C. J. Johnson, D. D. Scott, R. S. Gutzwiller, and T. Shade, “Cyber Expert Feedback: Experiences, Expectations, and Opinions about Cyber Deception,” Computers & Security, vol. 130, p. 103268, July 2023. [35] K. J. Ferguson-Walter, M. M. Major, C. K. Johnson, and D. H. Muhleman, “Examining the Efﬁcacy of Decoy- based and Psychological Cyber Deception,” in Proceedings of the 30th USENIX Security Symposium, ser. USENIX Security ’21. USENIX Association, 2021, pp. 1127– 1144. [Online]. Available: https://www.usenix.org/conference/ usenixsecurity21/presentation/ferguson-walter [36] K. J. Ferguson-Walter, T. Shade, A. Rogers, E. Niedbala, M. Trumbo, K. Nauer, K. Divis, A. Jones, A. Combs, and R. Abbott, “The Tularosa Study: An Experimental Design and Im- plementation to Quantify the Effectiveness of Cyber Deception,” in Proceedings of the 52nd Hawaii International Conference on System Sciences, ser. HICSS ’19, Maui, Hawaii, Jan. 2019. [37] J. Franco, A. Aris, B. Canberk, and A. S. Uluagac, “A Survey of Honeypots and Honeynets for Internet of Things, Industrial Internet of Things, and Cyber-Physical Systems,” IEEE Commu- nications Surveys & Tutorials, vol. 23, no. 4, pp. 2351–2383, 2021. [38] D. Fraunholz, S. D. Anton, C. Lipps, D. Reti, D. Krohmer, F. Pohl, M. Tammen, and H. D. Schotten, “Demystifying Deception Tech- nology: A Survey,” April 2018. [39] D. Fraunholz, D. Reti, S. Duque Anton, and H. D. Schotten, “Cloxy: A Context-aware Deception-as-a-Service Reverse Proxy for Web Services,” in Proceedings of the 5th ACM Workshop on Moving Target Defense, ser. MTD ’18. Toronto, Canada: Association for Computing Machinery, Jan. 2018, pp. 40–47. [40] D. Fraunholz, M. Zimmermann, and H. D. Schotten, “Towards Deployment Strategies for Deception Systems,” Advances in Sci- ence, Technology and Engineering Systems Journal, vol. 2, no. 3, pp. 1272–1279, Aug. 2017. [41] R. Gabrys, A. Venkatesh, D. Silva, M. Bilinski, M. Major, J. Mauger, D. Muhleman, and K. J. Ferguson-Walter, “Emotional State Classiﬁcation and Related Behaviors Among Cyber Attackers,” in Proceedings of the 56th Hawaii International Conference on System Sciences, ser. HICSS ’23, Maui, Hawaii, Jan. 2023. [Online]. Available: https://hdl.handle.net/10125/ 102735 [42] M. Ganguli, S. Ranganath, S. Ravisundar, A. Layek, D. Ilangovan, and E. Verplanke, “Challenges and Opportunities in Performance Benchmarking of Service Mesh for the Edge,” in 2021 IEEE International Conference on Edge Computing, ser. EDGE ’21, Chicago, IL, USA, Sept. 2021, pp. 78–85. [43] C. Gonzalez, P. Aggarwal, C. Lebiere, and E. A. Cranford, “Design of Dynamic and Personalized Deception: A Research Framework and New Insights,” in Proceedings of the 53rd Hawaii International Conference on System Sciences, ser. HICSS ’20, Maui, Hawaii, Jan. 2020. [44] B. G¨otz, D. Schel, D. Bauer, C. Henkel, P. Einberger, and T. Bauernhansl, “Challenges of Production Microservices,” Pro- cedia CIRP, vol. 67, pp. 167–172, Jan. 2018. [45] T. Graf, “How eBPF Will Solve Service Mesh - Goodbye Sidecars,” Dec. 2021. [Online]. Available: https://isovalent.com/ blog/post/2021-12-08-ebpf-servicemesh/ [46] C. Gupta, “HoneyKube: Designing a Honeypot Using Microservices-Based Architecture,” Master’s thesis, University of Twente, NB Enschede, The Netherlands, Aug. 2021. [Online]. Available: http://essay.utwente.nl/88323/ [47] C. Gupta, T. Van Ede, and A. Continella, “HoneyKube: Designing and Deploying a Microservices-based Web Honeypot,” in 2023 IEEE Security and Privacy Workshops, ser. SecWeb ’23, San Francisco, CA, USA, May 2023, pp. 1–11. [48] R. Gutzwiller, K. J. Ferguson-Walter, S. Fugate, and A. Rogers, ““Oh, Look, A Butterﬂy!” A Framework For Distracting At- tackers To Improve Cyber Defense,” Proceedings of the Human Factors and Ergonomics Society Annual Meeting, vol. 62, no. 1, pp. 272–276, Sept. 2018. [49] X. Han, N. Kheir, and D. Balzarotti, “Evaluation of Deception- Based Web Attacks Detection,” in Proceedings of the 2017 Work- shop on Moving Target Defense, ser. MTD ’17. Dallas, Texas, USA: Association for Computing Machinery, Oct. 2017, pp. 65– 73. [50] ——, “Deception Techniques in Computer Security: A Research Perspective,” ACM Computing Surveys, vol. 51, no. 4, pp. 80:1– 80:36, July 2018. [51] T. Holl, P. Klocke, F. Franzen, and J. Kirsch, “Kernel-Assisted Debugging of Linux Applications,” in Proceedings of the 2nd Reversing and Offensive-oriented Trends Symposium, ser. ROOTS ’18. Vienna, Austria: Association for Computing Machinery, Nov. 2018, pp. 1–9. [52] J. Howard, E. J. Jackson, Y. Kohavi, I. Levine, and J. Pettit, “Introducing Ambient Mesh,” Sept. 2022. [Online]. Available: https://istio.io/v1.15/blog/2022/introducing-ambient-mesh/ [53] L. Huang, S. Jia, E. Balcetis, and Q. Zhu, “ADVERT: An Adaptive and Data-Driven Attention Enhancement Mechanism for Phishing Prevention,” IEEE Transactions on Information Forensics and Security, vol. 17, pp. 2585–2597, 2022. [54] B. Ibryam and R. Huß, Kubernetes Patterns. O’Reilly Media, Inc., April 2019. [Online]. Available: https://www.oreilly.com/ library/view/kubernetes-patterns/9781492050278/ [55] C. Islam, V. Prokhorenko, and M. A. Babar, “Runtime Software Patching: Taxonomy, Survey and Future Directions,” Journal of Systems and Software, vol. 200, p. 111652, June 2023. [56] M. M. Islam, A. Dutta, M. S. I. Sajid, E. Al-Shaer, J. Wei, and S. Farhang, “CHIMERA: Autonomous Planning and Orches- tration for Malware Deception,” in 2021 IEEE Conference on Communications and Network Security, ser. CNS ’21, Tempe, AZ, USA, Oct. 2021, pp. 173–181. [57] S. Jajodia, A. K. Ghosh, V. Swarup, C. Wang, and X. S. Wang, Moving Target Defense: Creating Asymmetric Uncertainty for Cyber Threats, ser. Advances in Information Security. New York, NY: Springer, 2011, vol. 54. [58] A. Javadpour, F. Ja’fari, T. Taleb, M. Shojafar, and C. Benza¨ıd, “A Comprehensive Survey on Cyber Deception Techniques to Im- prove Honeypot Performance,” Computers & Security, p. 103792, March 2024. [59] D. P. Julian, “Delaying-Type Responses for Use by Software Decoys,” Ph.D. dissertation, Naval Postgraduate School, Monterey, California, Sept. 2002. [Online]. Available: https:// apps.dtic.mil/sti/citations/tr/ADA407043 [60] M. Kahlhofer, M. H¨olzl, and A. Berger, “Towards Reconstruct- ing Multi-Step Cyber Attacks in Modern Cloud Environments with Tripwires,” in Proceedings of the European Interdisciplinary Cybersecurity Conference, ser. EICC ’20. Rennes, France: Association for Computing Machinery, Nov. 2020, pp. 1–2. [61] M. Kahlhofer, P. Kern, S. Henning, and S. Rass, “Benchmarking Function Hook Latency in Cloud-Native Environments,” in 14th Symposium on Software Performance, ser. SSP ’23, vol. 43. Karlsruhe, Germany: Gesellschaft f¨ur Informatik e.V., Nov. 2023, pp. 11–13. [Online]. Available: https://dl.gi.de/handle/20. 500.12116/43246 [62] A. Kedrowitsch, D. D. Yao, G. Wang, and K. Cameron, “A First Look: Using Linux Containers for Deceptive Honeypots,” in Proceedings of the 2017 Workshop on Automated Decision Making for Active Cyber Defense, ser. SafeConﬁg ’17. Dallas, Texas, USA: Association for Computing Machinery, Nov. 2017, pp. 15–22. [63] P. Kern, “Injecting Shared Libraries with LD PRELOAD for Cy- ber Deception,” Master’s thesis, Vienna University of Technology, Vienna, Austria, Jan. 2024. [64] A. Kharaz, S. Arshad, C. Mulliner, W. Robertson, and E. Kirda, “UNVEIL: A Large-Scale, Automated Approach to Detecting Ransomware,” in 25th USENIX Security Symposium, ser. USENIX Security ’16. Austin, Texas: USENIX Association, 2016, pp. 757–772. [Online]. Available: https://www.usenix.org/conference/usenixsecurity16/ technical-sessions/presentation/kharaz [65] A. Kohlbrenner, F. Araujo, T. Taylor, and M. P. Stoecklin, “POSTER: Hidden in Plain Sight: A Filesystem for Data Integrity and Conﬁdentiality,” in Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security, ser. CCS ’17. Dallas, Texas, USA: Association for Computing Machinery, Oct. 2017, pp. 2523–2525. [66] B. Krieger, C. Kennedy, F. De˘girmenci, P. Joglekar, R. Faisal, and S. Raghunathan, “Cloud Native Security Whitepaper,” May 2022. [Online]. Available: https://github.com/cncf/tag-security/ tree/main [67] C. Lei, D.-H. Ma, and H.-Q. Zhang, “Optimal Strategy Selection for Moving Target Defense Based on Markov Game,” IEEE Access, vol. 5, pp. 156–169, 2017. [68] H. Li, Y. Guo, P. Sun, Y. Wang, and S. Huo, “An Optimal Defensive Deception Framework for the Container-based Cloud with Deep Reinforcement Learning,” IET Information Security, vol. 16, no. 3, pp. 178–192, 2022. [69] W. Li, Y. Lemieux, J. Gao, Z. Zhao, and Y. Han, “Service Mesh: Challenges, State of the Art, and Future Research Opportunities,” in 2019 IEEE International Conference on Service-Oriented Sys- tem Engineering, ser. SOSE ’19, San Francisco, CA, USA, April 2019, pp. 122–1225. [70] C. Liu, Z. Cai, B. Wang, Z. Tang, and J. Liu, “A Protocol- independent Container Network Observability Analysis System based on eBPF,” in 2020 IEEE 26th International Conference on Parallel and Distributed Systems, ser. ICPADS ’20, Hong Kong, Dec. 2020, pp. 697–702. [71] J. Lopez, L. Babun, H. Aksu, and A. S. Uluagac, “A Survey on Function and System Call Hooking Approaches,” Journal of Hardware and Systems Security, vol. 1, no. 2, pp. 114–136, June 2017. [72] Z. Lu, C. Wang, and S. Zhao, “Cyber Deception for Computer and Network Security: Survey and Challenges,” July 2020. [73] S. Machmeier, “Honeypot Implementation in a Cloud Environ- ment,” Jan. 2023. [74] N. Memari, S. J. B. Hashim, and K. B. Samsudin, “Towards Virtual Honeynet Based on LXC Virtualization,” in 2014 IEEE REGION 10 SYMPOSIUM, ser. TENSYMP ’14, Kuala Lumpur, Malaysia, April 2014, pp. 496–501. [75] S. Miano, M. Bertrone, F. Risso, M. Tumolo, and M. V. Bernal, “Creating Complex Network Services with eBPF: Experience and Lessons Learned,” in 2018 IEEE 19th International Conference on High Performance Switching and Routing, ser. HPSR ’18, Bucharest, Romania, June 2018, pp. 1–8. [76] S. Miano, F. Risso, M. V. Bernal, M. Bertrone, and Y. Lu, “A Framework for eBPF-Based Network Functions in an Era of Microservices,” IEEE Transactions on Network and Service Management, vol. 18, no. 1, pp. 133–151, March 2021. [77] Microsoft, “.NET CLR Proﬁling: Unmanaged API Reference,” Sept. 2021. [Online]. Available: https://learn.microsoft.com/en- us/dotnet/framework/unmanaged-api/proﬁling/ [78] P. V. Mohan, S. Dixit, A. Gyaneshwar, U. Chadha, K. Srinivasan, and J. T. Seo, “Leveraging Computational Intelligence Techniques for Defensive Deception: A Review, Recent Advances, Open Problems and Future Directions,” Sensors, vol. 22, no. 6, p. 2194, Jan. 2022. [79] I. Mokube and M. Adams, “Honeypots: Concepts, Approaches, and Challenges,” in Proceedings of the 45th Annual Southeast Regional Conference, ser. ACM SE ’07. Winston-Salem, North Carolina: Association for Computing Machinery, March 2007, pp. 321–326. [80] S. Mukkamala, K. Yendrapalli, R. Basnet, M. K. Shankarapani, and A. H. Sung, “Detection of Virtual Environments and Low In- teraction Honeypots,” in 2007 IEEE SMC Information Assurance and Security Workshop, ser. IAW ’07, West Point, NY, USA, June 2007, pp. 92–98. [81] D. S. Myers and A. L. Bazinet, “Intercepting Arbitrary Functions on Windows, UNIX, and Macintosh OS X Platforms,” Institute for Advanced Computer Studies, University of Maryland, Maryland, MD, USA, Tech. Rep. CS-TR-4585, UMIACS-TR- 2004-28, Jan. 2004. [Online]. Available: http://wwwold.cs.umd. edu/Library/TRs/CS-TR-4585/CS-TR-4585.pdf [82] M. Nawrocki, M. W¨ahlisch, T. C. Schmidt, C. Keil, and J. Sch¨onfelder, “A Survey on Honeypot Software and Data Anal- ysis,” Aug. 2016. [83] A. Niakanlahiji, J. H. Jafarian, B.-T. Chu, and E. Al-Shaer, “Hon- eyBug: Personalized Cyber Deception for Web Applications,” in Proceedings of the 53rd Hawaii International Conference on System Sciences, ser. HICSS ’20, Maui, Hawaii, Jan. 2020. [84] Open Containers Initiative, “Open Container Initiative Runtime Speciﬁcation,” Nov. 2023. [Online]. Available: https://specs. opencontainers.org/runtime-spec/?v=v1.0.2 [85] Oracle, “JVM(TM) Tool Interface 1.2.3,” June 2013. [Online]. Available: https://docs.oracle.com/javase/8/docs/platform/jvmti/ jvmti.html [86] A. Osman, P. Bruckner, H. Salah, F. H. P. Fitzek, T. Strufe, and M. Fischer, “Sandnet: Towards High Quality of Deception in Container-Based Microservice Architectures,” in ICC 2019 - 2019 IEEE International Conference on Communications, ser. ICC ’19, Shanghai, China, May 2019, pp. 1–7. [87] J. Pawlick, E. Colbert, and Q. Zhu, “A Game-theoretic Taxon- omy and Survey of Defensive Deception for Cybersecurity and Privacy,” ACM Computing Surveys, vol. 52, no. 4, pp. 82:1–82:28, Aug. 2019. [88] C. Pohl, A. Zugenmaier, M. Meier, and H.-J. Hof, “B.Hive: A Zero Conﬁguration Forms Honeypot for Productive Web Appli- cations,” in ICT Systems Security and Privacy Protection, ser. IFIP SEC ’15. Hamburg, Germany: Springer International Publishing, 2015, pp. 267–280. [89] V. S. D. Priya and S. S. Chakkaravarthy, “Containerized Cloud- based Honeypot Deception for Tracking Attackers,” Scientiﬁc Reports, vol. 13, no. 1, p. 1437, Jan. 2023. [90] N. Provos and T. Holz, Virtual Honeypots: From Botnet Tracking to Intrusion Detection, 1st ed. Upper Saddle River, NJ: Addison- Wesley Professional, July 2007. [91] X. Qin, F. Jiang, M. Cen, and R. Doss, “Hybrid Cyber Defense Strategies Using Honey-X: A Survey,” Computer Networks, vol. 230, p. 109776, July 2023. [92] A. Ramaswamy, S. Bratus, S. W. Smith, and M. E. Locasto, “Katana: A Hot Patching Framework for ELF Executables,” in 2010 International Conference on Availability, Reliability and Security, ser. ARES ’10, Krakow, Poland, Feb. 2010, pp. 507– 512. [93] S. Rass, S. K¨onig, and S. Schauer, “On the Cost of Game Playing: How to Control the Expenses in Mixed Strategies,” in Proceedings of the 8th International Conference on Decision and Game Theory for Security, ser. GameSec ’17. Vienna, Austria: Springer International Publishing, 2017, pp. 494–505. [94] S. Rass, S. K¨onig, J. Wachter, V. Mayoral-Vilches, and E. Panaousis, “Game-theoretic APT Defense: An Experimental Study on Robotics,” Computers & Security, vol. 132, p. 103328, Sept. 2023. [95] S. Rass, S. Schauer, S. Koenig, and Q. Zhu, Cyber-Security in Critical Infrastructures: A Game-Theoretic Approach, ser. Advanced Sciences and Technologies for Security Applications. Springer International Publishing, 2020. [96] D. Reti, T. Angeli, and H. D. Schotten, “Honey Inﬁltrator: In- jecting Honeytoken Using Netﬁlter,” in 2023 IEEE European Symposium on Security and Privacy Workshops, ser. EuroS&PW ’23, Delft, Netherlands, July 2023, pp. 465–469. [97] D. Reti and N. Becker, “Escape the Fake: Introducing Simulated Container-Escapes for Honeypots,” April 2021. [98] L. Rice, What Is eBPF? O’Reilly Media, Inc., April 2022. [Online]. Available: https://isovalent.com/books/ebpf/ [99] N. C. Rowe and H. S. Rothstein, “Two Taxonomies of Deception for Attacks on Information Systems,” Journal of Information Warfare, vol. 3, no. 2, pp. 27–39, 2004. [Online]. Available: https://www.jstor.org/stable/26502783 [100] M. Sahin, C. H´ebert, and R. Cabrera Lozoya, “An Approach to Generate Realistic HTTP Parameters for Application Layer Deception,” in Applied Cryptography and Network Security, ser. ACNS ’22. Rome, Italy: Springer International Publishing, 2022, pp. 337–355. [101] M. Sahin, C. H´ebert, and A. S. De Oliveira, “Lessons Learned from SunDEW: A Self Defense Environment for Web Applica- tions,” in Proceedings 2020 Workshop on Measurements, Attacks, and Defenses for the Web, ser. MADWeb ’20. San Diego, CA, USA: Internet Society, Feb. 2020. [102] M. Sahin, T. ¨Unl¨u, C. H´ebert, L. A. Shepherd, N. Coull, and C. M. Lean, “Measuring Developers’ Web Security Awareness from Attack and Defense Perspectives,” in 2022 IEEE Security and Privacy Workshops, ser. SPW ’22, San Francisco, CA, USA, May 2022, pp. 31–43. [103] M. S. I. Sajid, J. Wei, B. Abdeen, E. Al-Shaer, M. M. Islam, W. Diong, and L. Khan, “SODA: A System for Cyber Deception Orchestration and Automation,” in Annual Computer Security Applications Conference, ser. ACSAC ’21. Virtual Event, USA: Association for Computing Machinery, Dec. 2021, pp. 675–689. [104] M. S. I. Sajid, J. Wei, M. R. Alam, E. Aghaei, and E. Al-Shaer, “DodgeTron: Towards Autonomous Cyber Deception Using Dy- namic Hybrid Analysis of Malware,” in 2020 IEEE Conference on Communications and Network Security, ser. CNS ’20, Avignon, France, June 2020, pp. 1–9. [105] A. Salier, A. Chetal, J. Ramanathan, J. Bugwadia, and R. Ficcaglia, “Kubernetes Policy Management Whitepaper,” Jan. 2022. [Online]. Available: https://github.com/kubernetes/sig- security [106] M. Schneider, “Performance Benchmarking of Open-Source Service Meshes Using Load Testing,” Master’s thesis, University of Applied Sciences Campus Vienna, Vienna, Austria, May 2023. [Online]. Available: http://pub.fh-campuswien.ac.at/obvfcwhsacc/ 8874844 [107] M. Schober, “Istio Service Mesh - How it Impacts Application Performance and Developer Experience,” Master’s thesis, University of Applied Sciences Upper Austria, Hagenberg, Austria, Nov. 2023. [Online]. Available: https://permalink.obvsg. at/fho/AC17133217 [108] B. Scottberg, W. Yurcik, and D. Doss, “Internet Honeypots: Pro- tection or Entrapment?” in IEEE 2002 International Symposium on Technology and Society (ISTAS’02). Social Implications of Information and Communication Technology, ser. ISTAS ’02, Raleigh, NC, USA, June 2002, pp. 387–391. [109] S. Sheen, K. A. Asmitha, and S. Venkatesan, “R-Sentry: Decep- tion based Ransomware Detection Using File Access Patterns,” Computers and Electrical Engineering, vol. 103, p. 108346, Oct. 2022. [110] D. Soldani, P. Nahi, H. Bour, S. Jafarizadeh, M. F. Soliman, L. Di Giovanna, F. Monaco, G. Ognibene, and F. Risso, “eBPF: A New Approach to Cloud-Native Observability, Networking and Security for Current (5G) and Future Mobile Networks (6G and Beyond),” IEEE Access, vol. 11, pp. 57 174–57 202, 2023. [111] N. Spahn, N. Hanke, T. Holz, C. Kruegel, and G. Vigna, “Con- tainer Orchestration Honeypot: Observing Attacks in the Wild,” in Proceedings of the 26th International Symposium on Research in Attacks, Intrusions and Defenses, ser. RAID ’23. Hong Kong, China: Association for Computing Machinery, Oct. 2023, pp. 381–396. [112] L. Spitzner, Honeypots: Tracking Hackers. Boston, MA, United States: Addison-Wesley Professional, Sept. 2002. [113] ——, “Honeypots: Catching the Insider Threat,” in Proceedings of the 19th Annual Computer Security Applications Conference, ser. ACSAC ’03. Las Vegas, NV, USA: IEEE, Dec. 2003, pp. 170–179. [114] ——, “Honeytokens: The Other Honeypot,” July 2003. [Online]. Available: https://www.symantec.com/connect/articles/ honeytokens-other-honeypot [115] S. Srinivasa, J. M. Pedersen, and E. Vasilomanolakis, “Gotta Catch ’em All: A Multistage Framework for Honeypot Finger- printing,” Digital Threats: Research and Practice, vol. 4, no. 3, pp. 42:1–42:28, Oct. 2023. [116] I. Sysoev, “NGINX.” [Online]. Available: https://www.nginx. com/ [117] M. Szeredi, “Libfuse.” [Online]. Available: https://github.com/ libfuse/libfuse [118] T. Taylor, F. Araujo, A. Kohlbrenner, and M. P. Stoecklin, “Hidden in Plain Sight: Filesystem View Separation for Data Integrity and Deception,” in Detection of Intrusions and Malware, and Vulnerability Assessment, ser. DIMVA ’18. Saclay, France: Springer International Publishing, June 2018, pp. 256–278. [119] The Cilium Authors, “Cilium,” The Linux Foundation. [Online]. Available: https://cilium.io [120] The Envoy Project Authors, “Envoy,” The Linux Foundation. [Online]. Available: https://www.envoyproxy.io/ [121] The Falco Authors, “Falco,” The Linux Foundation. [Online]. Available: https://falco.org/ [122] The Kyverno Authors, “Kyverno,” The Linux Foundation. [Online]. Available: https://kyverno.io/ [123] The OpenTelemetry Authors, “OpenTelemetry,” The Linux Foundation. [Online]. Available: https://opentelemetry.io/ [124] The Tetragon Authors, “Tetragon,” The Linux Foundation. [Online]. Available: https://tetragon.io/ [125] V.-H. Tran and O. Bonaventure, “Beyond Socket Options: To- wards Fully Extensible Linux Transport Stacks,” Computer Com- munications, vol. 162, pp. 118–138, Oct. 2020. [126] C.-C. Tu, J. Stringer, and J. Pettit, “Building an Extensible Open vSwitch Datapath,” ACM SIGOPS Operating Systems Review, vol. 51, no. 1, pp. 72–77, Sept. 2017. [127] V. E. Urias, W. M. Stout, J. Luc-Watson, C. Grim, L. Liebrock, and M. Merza, “Technologies to Enable Cyber Deception,” in 2017 International Carnahan Conference on Security Technology, ser. ICCST ’17, Madrid, Spain, Oct. 2017, pp. 1–6. [128] M. A. M. Vieira, M. S. Castanho, R. D. G. Pac´ıﬁco, E. R. S. Santos, E. P. M. C. J´unior, and L. F. M. Vieira, “Fast Packet Processing with eBPF and XDP: Concepts, Code, Challenges, and Applications,” ACM Computing Surveys, vol. 53, no. 1, pp. 16:1–16:36, Feb. 2020. [129] J. von der Assen, A. H. Celdr´an, R. Sefa, G. Bovet, and B. Stiller, “MTFS: A Moving Target Defense-Enabled File System for Mal- ware Mitigation,” Nov. 2023. [130] J. von der Assen, C. Feng, A. H. Celdr´an, R. Oleˇs, G. Bovet, and B. Stiller, “GuardFS: A File System for Integrated Detection and Mitigation of Linux-based Ransomware,” Jan. 2024. [131] B. Whaley, “Toward a General Theory of Deception,” Journal of Strategic Studies, vol. 5, no. 1, pp. 178–192, March 1982. [132] M. Zambianco, C. Facchinetti, R. Doriguzzi-Corin, and D. Sir- acusa, “Resource-aware Cyber Deception in Cloud-Native Envi- ronments,” Nov. 2023. [133] L. Zhang and Vrizlynn. L. L. Thing, “Three Decades of Deception Techniques in Active Cyber Defense - Retrospect and Outlook,” Computers & Security, vol. 106, p. 102288, July 2021. [134] M. Zhu, A. H. Anwar, Z. Wan, J.-H. Cho, C. A. Kamhoua, and M. P. Singh, “A Survey of Defensive Deception: Approaches Us- ing Game Theory and Machine Learning,” IEEE Communications Surveys & Tutorials, vol. 23, no. 4, pp. 2460–2493, 2021. [135] X. Zhu, G. She, B. Xue, Y. Zhang, Y. Zhang, X. K. Zou, X. Duan, P. He, A. Krishnamurthy, M. Lentz, D. Zhuo, and R. Mahajan, “Dissecting Overheads of Service Mesh Sidecars,” in Proceedings of the 2023 ACM Symposium on Cloud Computing, ser. SoCC ’23. Santa Cruz, CA, USA: Association for Computing Machinery, Oct. 2023, pp. 142–157. Appendix A. Excluded Properties Many more properties have been introduced to catego- rize cyber deception techniques [31], [50], [82], some of which are still considered “difﬁcult to formalize and mea- sure” [50]. We brieﬂy explain which ones we excluded: ∙ The ﬁdelity or interaction level [15], [79] (low, medium, high) describes how “immersive” a hon- eypot is for an adversary. Technical methods do not limit the creative freedom here, especially not when a combination of methods is used. ∙ We exclude properties of decoys such as believ- ability, enticingness, conspicuousness and vari- ability, as introduced by Bowen et al. [16], because they are typically inﬂuenced by concrete names and payloads, but not by technical properties. ∙ We exclude typical measures for honeypots that lie outside the application layer [31], [82] such as their role (server, client), physicality or virtuality, and also their deployment strategy [108]. ∙ We exclude measures for captors, as introduced by Fan et al. [31], e.g., describing attack monitoring, prevention, detection, response, and proﬁling. We see concrete implementations on these independent of general technical methods. Appendix B. Guide for Qualitative Evaluation of Methods D-C-S Type. From a system operator’s perspective, we categorize if a type ﬁts a method’s primary use case perfectly (●), partially (◑), or not at all (○). A partial ﬁt indicates that a method is technically able to represent that type, although, it would be uncommon or unreasonable to use a method like that. ∙ Decoy. Does this method typically represent – not necessarily create (like a supporting method) – the entity with which an adversary will interact with? (e.g., honeypot, honeytoken, reverse proxy) ∙ Captor. Is this method typically used to detect attacks or events on decoys? (e.g., by observing logs, monitoring events) ∙ Support. Does this method typically assist in deploying, implementing, or conﬁguring another method? (e.g., the process that places decoys) Supported Use Cases. Categorized based on whether that method is capable (●) or not capable (○) to realize the use cases that we introduced in §2, regardless of complexity. Reliance on other (supporting) methods (e.g., user space processes) that might restrict the applicability of the method when considered in isolation, shall be indicated with partial capability (◑) then. ∙ Decoy request. Can this method append deceptive payloads to the HTML response of an application? ∙ Fake API. Can this method respond to a request for “/admin/api” on behalf of the application? ∙ Honeytoken. Can this method create or represent a “service-token” ﬁle in a ﬁle system? Deployment Mode. We adopt the categorization from Han et al. [50] from a system operator’s perspective. ∙ Ð Built-in. Does this method add something at design phase? (e.g., source code, build process). ∙ In-front of. Does this method interpose some- thing between an adversary and a genuine appli- cation? (e.g., proxies, ﬁlters, hooks) ∙  Added-to. Does this method include, integrate, or modify something at runtime? (e.g., add ﬁle to ﬁle system, add pod to cluster, change setting) ∙ à Stand-alone. Is this method isolated from the target system? (e.g., honey accounts on the inter- net, honeypots outside your Kubernetes cluster) Layer of Deception. We adopt the categorization from Han et al. [50] and interpret it for cloud-native architectures such as Kubernetes. If the layer of deception is application, or if it affects applications (e.g., kernel- based techniques that affect applications), we also assign it to one of the ﬁner levels, exactly as described in §4 under topological properties. ∙ Network. Does this method realize deception tech- niques that are ”accessible over the network and that are not bound to any speciﬁc host conﬁgu- ration” [50]? (e.g., typical honeypots, or methods that produce false network topologies) ∙ System. Does this method realize deception tech- niques that are bound to hosts? In Kubernetes, we consider nodes, and also the whole platform part of this layer. (e.g., kernel-based techniques, or platform-wide policy management) ∙ Application. Does this method realize deception techniques bound to speciﬁc applications? We con- sider containers, pods and their ﬁle system part of this layer. (e.g., honeytokens in ﬁle systems, runtime instrumentation techniques) ∙ Data. Does this method realize deception tech- niques by leveraging data, documents, or ﬁles? (e.g., honeytokens in a ﬁle system) Kubernetes Plane. ∙ Data plane. Does this method primarily act on the data plane (on the node, pod, or container level)? ∙ Control plane. Does this method primarily act, work with, conﬁgure, or need the control plane? Payload Modiﬁcation. Is this method capable of mod- ifying, extending, or removing data payloads on disk, or in transit, directly or indirectly, but deﬁnitely on its own? More speciﬁcally, we refer to data payloads, not just (packet) header ﬁelds or metadata. If so, we further ask if payloads can – but not must – be modiﬁed indirectly, i.e., by changing it on read, in transit, through a proxy or wrapper, but never by directly editing the original data item in the ﬁle system, database, or source code. Zero Downtime. Can this method be ﬁrst installed without requiring an application restart? Once installed, can the deception be easily enabled and disabled, modi- ﬁed, and also reconﬁgured? Detectability. How capable is this method to send alerts, log events, or monitor honeypots? We only consider the capability that ﬁts the primary use case of that method, e.g., a method that places honeytokens in the ﬁle system will be evaluated on its ability to detect access attempts to them, and we will not consider its detection capabilities for other use cases. We assess detectability by focusing on how much control we have over the piece of code or component that detects or monitors: ∙ ●Do we have direct control over this code? ∙ ◕Would we need to integrate this code or com- ponent into an existing system? ∙ ◑Would we need to integrate this code or com- ponent into an existing system and rely on more than one other software component? ∙ ◔Would we need another supporting method or have little control over a persistent solution? ∙ ○Is this not possible at all? Simplicity. On a technical level, how simple – not easy – is this method to implement or conﬁgure? ∙ ●Does this method require only a small amount of code or conﬁguration to be added or changed? ∙ ◕Is this method similar in technical complexity to typical work tasks of an engineer or operator? ∙ ◑Will this method take a typical engineer a few weeks to implement? ∙ ◔Could this method easily require a full engi- neering team (min. 3-7 developers) to implement? Maintainability. From a system operator’s and decep- tion designer’s perspective, how much maintenance does this method require? ∙ ●Does this require almost no maintenance? ∙ ◕Must this only be checked a few times per year? ∙ ◑Must this be checked every few days or weeks? ∙ ◔Could this method easily require a full engi- neering team (min. 3-7 developers) to maintain? Scalability. From a system operator’s perspective, how easy is it to scale this method to hundreds an thousands of computer systems? ∙ ●Is this method cluster-wide almost by default? ∙ ◕Does this method require only a small amount of code or conﬁguration to be scaled cluster-wide? ∙ ◑Will this method take a typical engineer a few weeks of work before it can be scaled cluster-wide? ∙ ◔Could this method easily require a full engi- neering team (min. 3-7 developers) to scale it? ∙ ○Is it almost impossible to scale this method? Inconspicuousness. From an adversary’s perspective, how obvious or clearly visible is that deception method? ∙ ●Is this method very difﬁcult or impossible to detect by observing the behavior of an applica- tion, even if the adversary has compromised the container hosting the application? ∙ ◕Is this method very difﬁcult or impossible to detect by observing the behavior of an application unless the adversary has compromised the con- tainer hosting the application? ∙ ◑If the adversary spends a few weeks working on this, will this method eventually be detected? ∙ ◔Is this method fairly easy to detect, even for an average adversary? ∙ ○Is this method so obvious that it doesn’t even take a good hacker to discover it? Non-interference. From a system operator’s perspec- tive, how low is the risk of this method interfering with genuine application and system assets? ∙ ●Is this method almost isolated, or stand-alone from the real production system? ∙ ◕Does this method only passively monitor? ∙ ◑Does this method add processes, ﬁles, or con- ﬁguration with little risk of interference? ∙ ◔Does this method instrument genuine applica- tions at runtime or modify data? ∙ ○Could this method easily crash an application?